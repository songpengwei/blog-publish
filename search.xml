<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop-0.1.0代码调试运行</title>
    <url>/2017/06/29/hadoop-0.1.0-code-debug/</url>
    <content><![CDATA[<p>之前雄心勃勃的从GitHub上下了Hadoop源码，想要通读涨涨姿势，甚至想自己写一个简易版本。<br>不料代码啃起来味同嚼蜡，在读了基本的RPC之后，就此搁置。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<p>后来，抱着没有干不好的事，只有打开方式不对的心态，换个姿势，再学一次。<br>这次计划如下：</p>
<ol>
<li>首先，将代码在本地调试。</li>
<li>然后，按模块进行debug。</li>
</ol>
<p>今天主要说第一块的探索，花了两个晚上:&gt;。</p>
<ul>
<li><code>git fork</code>下源码，<code>git clone</code>到本地，通过<code>git tag --list</code> 查看所有标签，找到<strong>0.1.0</strong>版本。<br>并且checkout出来。</li>
<li>配置JAVA_HOME，HADOOP_HOME, PATH环境变量。</li>
<li>下载安装ant，并且配置环境变量(ANT_HOME,PATH)</li>
<li>Eclipse新建<strong>Java Project</strong>，然后选择<strong>Java Project From Existing Ant Buildfile</strong>,<br>从现有文件夹中打开，选择hadoop所在文件夹，它会自动识别出build.xml，然后新建Ant工程。</li>
<li>右击build.xml，<strong>run as-&gt; ant built</strong>，选第二个，进行配置（选对运行文件夹以及build文件，如果<br>不行就在含build.xml目录中执行命令ant，然后就会生成build文件夹，并且根据conf文件夹模板生成<br>必要的conf文件。</li>
<li>修改hadoop脚本（在**${HADOOP_HOME}&#x2F;bin**里），为了不破坏原来文件，<code>cp hadoop hadoop-debug</code>。<br>然后在此脚本中，将最后一行运行命令，加上一些用于调试的参数。修改如下<ul>
<li>修改前  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">run it</span></span><br><span class="line">exec &quot;$JAVA&quot; $JAVA_HEAP_MAX $HADOOP_OPTS -classpath &quot;$CLASSPATH&quot; $CLASS &quot;$@&quot;</span><br></pre></td></tr></table></figure></li>
<li>修改后  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">run it</span></span><br><span class="line">exec &quot;$JAVA&quot; -Xdebug -Xrunjdwp:transport=dt_socket,address=9090,server=y,suspend=y </span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">JAVA_HEAP_MAX <span class="variable">$HADOOP_OPTS</span> -classpath <span class="string">&quot;<span class="variable">$CLASSPATH</span>&quot;</span> <span class="variable">$CLASS</span> <span class="string">&quot;<span class="variable">$@</span>&quot;</span></span></span><br></pre></td></tr></table></figure></li>
<li>-Xdebug指明是调试，-Xrunjdwp引出后面参数。transport:通信方式，address：端口。</li>
</ul>
</li>
<li>然后选择一个模块运行，比如NameNode：<code>bin/hadoop-debug namenode -format</code>。</li>
<li>在Eclipse中选择<strong>Debug-&gt;Debug configurations-&gt;Remote Java Application</strong>，选择对工程，localhost<br>以及<strong>对应</strong>端口就行。记得在代码中加断点，然后就可以愉快地运行了。</li>
</ul>
<p>夜深啦，今天先到这里。</p>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>Hadoop</tag>
        <tag>源码</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop 源码阅读之DFS（一）：一些基本的类</title>
    <url>/2017/07/02/hadoop-source-DFS/</url>
    <content><![CDATA[<p>计划花一个月左右的时间，通读一遍Hadoop 0.1.0的源码，尽量少写一些废话，多记录一些思考。</p>
<p>Random一下，就从分布式文件系统（DFS）开始吧。<br>DFS即分布式文件系统，集合多台机器存储在预定义位置上的一组文件作为存储构件，在此基础上实现一些分布式操作，从而对外抽象出一套基本文件读写API。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="Block"><a href="#Block" class="headerlink" title="Block"></a><span id="block">Block</span></h2><hr>
<h3 id="blkid和len"><a href="#blkid和len" class="headerlink" title="blkid和len"></a>blkid和len</h3><p><strong>Block</strong>是HDFS的文件存储的基本单位，有两个关键属性<code>blkid</code> 和<code>len</code>，前者用来标识一个操作系统上的文件，并且通过<code>&quot;blk_&quot; + String.valueOf(blkid)</code>拼接出文件名；后者是该文件以字节为单位的长度。<br>它抽象出了<strong>存储</strong>的两个基本维度，起始和大小。变量，数组，文件等等莫不如此。</p>
<h3 id="注册工厂方法"><a href="#注册工厂方法" class="headerlink" title="注册工厂方法"></a>注册工厂方法</h3><p>另一个有意思的地方是所有实现Writable接口的类，都注册了一个工厂方法，具体有什么用，以后来补。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> &#123;                                      <span class="comment">// register a ctor</span></span><br><span class="line"> WritableFactories.setFactory</span><br><span class="line">   (Block.class,</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">WritableFactory</span>() &#123;</span><br><span class="line">      <span class="keyword">public</span> Writable <span class="title function_">newInstance</span><span class="params">()</span> &#123; <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Block</span>(); &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h3><p>实现<code>Writable</code>利用Java的序列化接口（<code>DataOutput</code>），实现Block基本字段的序列化和反序列化。<br>每个待序列化类单独实现自己一对序列化和反序列化函数，是一个常用的基本设计，我在实习写桌面程序的时候，想将一些控件信息存储为xml，用的想法和这个是相同的，但是做的不好的事没有定义出这个Writable接口作为对这个行为的抽象。</p>
<p><strong>实现了<code>Comparable</code>（大概是为了被索引时可比较）和<code>Writable</code>接口</strong></p>
<h2 id="BlockCommand"><a href="#BlockCommand" class="headerlink" title="BlockCommand"></a><span id="block-command">BlockCommand<span></h2><hr>
<p>一个命令（instruction）参数的封装，该命令作用于某个<code>DataNode</code>下的一系列Blocks；有两种操作，移动这组Blocks到另外一个<code>DataNode</code>，或者标记改组Blocks为失效状态。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">transferBlocks</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"><span class="type">boolean</span> <span class="variable">invalidateBlocks</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">Block blocks[];</span><br><span class="line">DatanodeInfo targets[][];</span><br></pre></td></tr></table></figure>
<p>用两个标志变量来指明是哪种操作；<br>用两个数组来存储操作对象。</p>
<p>然后通过构造函数重载，给出了三个构造函数，无参，移动命令或者失效命令。并且提供了各个字段的读权限。</p>
<p><strong>实现了<code>Writable</code>接口</strong>。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>对一个简单的命令基本信息的封装，用构造函数接受参数，确定操作类型和操作对象；用标志变量+数组对象来进行实现。<br>将一组数据按照某种语义捆绑在一起，在函数间传递时也方便，复用性也更好。</p>
<h2 id="LocatedBlock"><a href="#LocatedBlock" class="headerlink" title="LocatedBlock"></a><span id="located-block">LocatedBlock</span></h2><hr>
<p>一个数据对，包含一个<code>Block</code>和其几个replicate所在的<code>DataNode</code>的信息。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Block b;</span><br><span class="line">DatanodeInfo locs[];</span><br></pre></td></tr></table></figure>
<p>相当于维持某个逻辑Block到其存储位置的指针，用于定位Block物理位置。</p>
<p><strong>实现了<code>Writable</code>接口</strong>。</p>
<h2 id="DataNodeInfo"><a href="#DataNodeInfo" class="headerlink" title="DataNodeInfo"></a><span id="datanode-info">DataNodeInfo</span></h2><hr>
<p>包含了一个<code>DataNode</code>的状态信息（总大小，剩余大小，上次更新时间），用名字（自定义的<code>UTF8</code>存储的<code>host:port</code>）作为ID，并且维持了其上所有<code>Block</code>的引用，以查找树（<code>TreeSet</code>应该是红黑树，以<code>Block</code>的blkid进行排序）的形式组织。 </p>
<h3 id="关键函数"><a href="#关键函数" class="headerlink" title="关键函数"></a>关键函数</h3><p>更新状态信息（<strong>一次心跳</strong>。名字起得好啊——好像DataNode在说，“我还活着，我的基本体征如下，balabala”，传神好记。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">updateHeartbeat</span><span class="params">(<span class="type">long</span> capacity, <span class="type">long</span> remaining)</span> &#123;</span><br><span class="line">   <span class="built_in">this</span>.capacityBytes = capacity;</span><br><span class="line">   <span class="built_in">this</span>.remainingBytes = remaining;</span><br><span class="line">   <span class="built_in">this</span>.lastUpdate = System.currentTimeMillis();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>实现了<code>Comparable</code>和<code>Writable</code>（比较有意思的是，blocks没有被序列化）接口</strong></p>
<h2 id="DataNodeReport"><a href="#DataNodeReport" class="headerlink" title="DataNodeReport"></a><span id="datanode-report">DataNodeReport</span></h2><hr>
<p>一个<span class="exturl" data-url="aHR0cHM6Ly9tYXJ0aW5mb3dsZXIuY29tL2JsaWtpL1BPSk8uaHRtbA==">POJO<i class="fa fa-external-link-alt"></i></span>，哈哈，想起这个名字的由来就想笑，马大叔真是有才的别具猥琐。看它的字段就知道，这是心跳来源+心跳信息的一个简单封装，每个字段都具有包级访问权限，还提供了几个public的读方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String name;</span><br><span class="line">String host;</span><br><span class="line"><span class="type">long</span> capacity;</span><br><span class="line"><span class="type">long</span> remaining;</span><br><span class="line"><span class="type">long</span> lastUpdate;</span><br></pre></td></tr></table></figure>
<p><code>DataNodeInfo</code>的ID加心跳信息。<br>最后有一个toString函数，毕竟是搞报告工作的。</p>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>Hadoop</tag>
        <tag>源码</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop 源码阅读之DFS（二）：DataNode</title>
    <url>/2017/07/11/hadoop-source-DataNode/</url>
    <content><![CDATA[<p>上一篇把一些零碎的小类集在一起，凑成一篇。这篇打算对比较长的一个类<code>DataNode</code>读读。<br>每个DataNode代表一个数据节点，对应某台机器的一个文件夹，本质上是一定数量的Block的集合，能够和NameNode，client以及其他DataNode进行通信，以对该Block集合进行操作，主要包括client的读和写，其他DataNode block的复制，以及响应NameNode操作，进行删除等操作。<br>具体实现来说，数据结构上，维持了一个block到byte array的表；执行时，DataNode内部是一个无限循环，不断询问NameNode，报告状态（心跳），执行命令<strong>（RPC）</strong>。</p>
<ol>
<li>状态信息。[<code>DataNodeInfo</code>](&#x2F;hadoop-source-DFS#datanode-info)：总大小，剩余大小，上次更新时间。</li>
<li>执行命令。<ul>
<li>客户端读写Blocks</li>
<li>让其他DataNode复制Blocks</li>
<li>删除某些Blocks</li>
</ul>
</li>
</ol>
<p>此外，DataNode还维持着一个Server Socket以处理来自Client或者其他DataNode请求。DataNode会将其对外暴露的<em>host:port</em>提交给NameNode，后者会将该信息进一步下发给相关的其他DataNode或者client。<br>(摘自类注释)</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="StartUp"><a href="#StartUp" class="headerlink" title="StartUp"></a>StartUp</h2><p>DataNode启动的时候主要干了以下事情：<br>为每个<code>dfs.data.dir</code>实例化一个<code>DataNode</code>，DataNode有以下几个重要字段：</p>
<ol>
<li><code>namenode</code>，<code>DatanodeProtocol</code>类型，和NameNode进行RPC通信。</li>
<li><code>data</code>， <code>FSDataset</code>类型，对应一个文件夹，负责具体的本地磁盘操作。</li>
<li><code>localName</code>， machine name + port，对外暴露的网络机器名和端口。</li>
<li><code>dataXceiveServer</code>，一个socket Server，监听上述端口，处理读写请求。</li>
<li>其他一些配置字段，包括<code>blockReportInterval</code>， <code>datanodeStartupPeriod</code>等。</li>
</ol>
<h2 id="Main-Loop-When-Run"><a href="#Main-Loop-When-Run" class="headerlink" title="Main Loop When Run"></a>Main Loop When Run</h2><p><code>offerService</code>，该函数根据当前时间与上次动作时间差值，决定是否再一次执行该动作（<code>DataNode</code>对<code>NameNode</code>的RPC）；这几个动作基本对应<code>DataNodeProtocol</code>的各个函数，即RPC的几个动作约定。这些事件有<strong>向NameNode</strong>：</p>
<ul>
<li>发送心跳信息</li>
<li>上传<code>block</code>信息</li>
<li>获取<code>NameNode</code>指令</li>
</ul>
<p>下面分别就每一项进行详细说明：</p>
<h4 id="1-发送心跳信息"><a href="#1-发送心跳信息" class="headerlink" title="1. 发送心跳信息"></a>1. 发送心跳信息</h4><p>心跳信息包括以下几项内容：</p>
<ul>
<li>DataNode名字</li>
<li>DataNode数据传输端口</li>
<li>DataNode总容量</li>
<li>DataNode剩余字节数</li>
</ul>
<h4 id="2-上传当前Block信息"><a href="#2-上传当前Block信息" class="headerlink" title="2. 上传当前Block信息"></a>2. 上传当前Block信息</h4><p>报告本DataNode的所有Block信息，以更新表machine-&gt;block list 和表block-&gt;machine list。利用TreeMap实现，能得到按BlockId排序的数组，通过逐一比较新旧上报Block数组的每个元素（<code>oldReport</code>和<code>newReport</code>），利用<code>removeStoredBlock</code>和<code>addStoredBlock</code>将旧数组更新为新数组。</p>
<p>然后NameNode将需要删除的Block数组返回，利用<code>data</code>（<code>FSDataSet</code>）句柄进行删除。</p>
<h4 id="3-报告新收到的Block信息，即ReceivedBlock"><a href="#3-报告新收到的Block信息，即ReceivedBlock" class="headerlink" title="3. 报告新收到的Block信息，即ReceivedBlock"></a>3. 报告新收到的Block信息，即ReceivedBlock</h4><p>当Client写数据，或者其他DataNode复制数据给当前<code>DataNode</code>的时候，该DataNode通过RPC，执行此函数。然后NameNode将其更新到保存元数据的table里。</p>
<h4 id="4-获取-NameNode指令"><a href="#4-获取-NameNode指令" class="headerlink" title="4. 获取 NameNode指令"></a>4. 获取 NameNode指令</h4><p>根据<code>BlockCommand</code>类的字段：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">transferBlocks</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"><span class="type">boolean</span> <span class="variable">invalidateBlocks</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">Block blocks[];</span><br><span class="line">DatanodeInfo targets[][];</span><br></pre></td></tr></table></figure>
<p>可以看出，指令动作包括交换（transfer）和删除（delete or invalidate）；动作对象包括一系列blocks和DataNode，表示将<code>blocks[i]</code>传送到<code>targets[i][0] </code>… <code>targets[i][j]</code>的DataNode上去。<br>具体传送实现，为每一个!invalid的block，启动一个线程，负责具体数据传送，代码为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="title class_">Daemon</span>(<span class="keyword">new</span> <span class="title class_">DataTransfer</span>(xferTargets[i], blocks[i])).start();</span><br></pre></td></tr></table></figure>
<p>后面将对<code>DataTransfer</code>类进行详细注解。</p>
<h2 id="DataTransfer"><a href="#DataTransfer" class="headerlink" title="DataTransfer"></a>DataTransfer</h2><p>该类实现了<code>Runnable</code>接口，在每次有数据需要传输时被启动；其动作主要为：</p>
<ol>
<li>连接第一个Target DataNode的socket，作为输出。</li>
<li>从<code>FSDataSet</code>中获取Block元信息以及本机器上该block对应的数据文件，作为输入。</li>
<li>从输入端读取数据，写到输出端。</li>
</ol>
<p>因此，该类只负责将block信息写到第一个target DataNode，比如说Node1，剩下的将由Node1机器上的线程进行数据传送。</p>
<p>该block在本机实际的文件夹路径和文件名都可以根据blockId进行确定。对于一个64bit的blockId，从高位到地位，每四位作为一个文件夹的名字（0~15），进行路由，因此文件实际位置的深度可能高达64&#x2F;4&#x3D;16层；存储数据的文件命名方式为blk_{blockId}.</p>
<h2 id="DataXceiveServer"><a href="#DataXceiveServer" class="headerlink" title="DataXceiveServer"></a>DataXceiveServer</h2><p>该类也实现了<code>Runnable</code>接口，在<code>DataNode</code>初始化的时候被启动，用于监听Client或者其他DataNodes的请求，以进行block数据的传输。<br>具体实现为，使用<code>SocketServer</code>，根据信号<code>shouldListen</code>来循环监听所有请求。当请求到来时，使用<code>DataXceiver</code>类进行具体连接的处理；</p>
<h2 id="DataXceiver"><a href="#DataXceiver" class="headerlink" title="DataXceiver"></a>DataXceiver</h2><p>该类负责具体实现数据传输的逻辑，包括Block的写和读，每次传输一个Block块，将该Block首先写入本地文件系统，然后传送给下一个目标DataNode；具体来说，<br>首先，打开socket输入流，读取首字节，判断操作类型；<br>然后，进行写或者读操作。</p>
<h4 id="写操作（OP-WRITE-BLOCK）"><a href="#写操作（OP-WRITE-BLOCK）" class="headerlink" title="写操作（OP_WRITE_BLOCK）"></a>写操作（OP_WRITE_BLOCK）</h4><ol>
<li><p>读入header，包括以下几个字段</p>
 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">a. shouldReportBlock --&gt; bool</span><br><span class="line">b. block <span class="title function_">info</span><span class="params">(blkid+len)</span> --&gt; Block</span><br><span class="line">c. numTargets --&gt; <span class="type">int</span></span><br><span class="line">d. targets --&gt; DatanodeInfo[]</span><br><span class="line">e. encodingType --&gt; <span class="type">byte</span></span><br><span class="line">f. data length --&gt; <span class="type">long</span></span><br></pre></td></tr></table></figure></li>
<li><p>然后将这些header信息，去掉该DataNode（<code>targets[0]</code>）的信息后，写入下一个DataNode （<code>target[1]</code>）。</p>
</li>
<li><p>从socket中读取具体存储的数据，先后写入本地存储（当前DataNode）和下一个DataNode的socket。这里有一点设计，就是如果写Socket异常后，可以终止Socket，但仍然继续写本地存储。</p>
</li>
<li><p><code>encodingType</code>的类型不同，读取数据方式不同：对于<code>RUNLENGTH_ENCODING</code>类型，其结构是length(say l)+data(of the length l)，因此读一次就结束；而<code>CHUNKED_ENCODING</code>类型，结构为l1 + data1 + l2 + data2 + … + ln + datan + **l(n+1) (&#x3D;0)**；因此需要循环继续读如长度，然后读入该长度数据，直到len&#x3D;0结束。</p>
</li>
<li><p>如果和下一个DataNode间的socket仍然正常，则从该socket读回一些关于写数据的反馈，包括long型的结束符和<code>LocatedBlock</code>–&gt;写成功后的block网络位置，是一个<code>Block</code>和<code>DatanodeInfo[]</code>对，表示该Block以及已经写成功的DataNode list。整个写操作和备份的过程类似于一个递归调用的过程，由client写datanode1， 然后datanode1写datanode2，然后datanode2写datanode3；然后datanode3将写成功信号，以及datanode3位置告诉datanode2，然后datanode2将写成功信号以及datanode2，datanode3位置告诉datanode1等等。</p>
</li>
</ol>
<h4 id="读操作（OP-READ-BLOCK-OP-READSKIP-BLOCK）"><a href="#读操作（OP-READ-BLOCK-OP-READSKIP-BLOCK）" class="headerlink" title="读操作（OP_READ_BLOCK || OP_READSKIP_BLOCK）"></a>读操作（<code>OP_READ_BLOCK</code> || <code>OP_READSKIP_BLOCK</code>）</h4><p>首先读入待读取的Block信息，然后，如果是<code>OP_READSKIP_BLOCK</code>类型，则读取需要跳过的字节数（<code>toSkip</code>–&gt;long）；<br>然后通过<code>data</code> –&gt; FSDataSet 定位block本地存储文件位置，根据类型决定是否跳过特定字节（toSkip），然后逐字节读取该文件。</p>
<h2 id="Aside-info"><a href="#Aside-info" class="headerlink" title="Aside info"></a>Aside info</h2><p>如果类需要作为Key，比如<code>TreeMap</code>，则需要实现<code>Comparable</code>接口，只有可以比较才能进行排序和Hash；如果需要进行序列化和反序列化，则需要实现<code>Writable</code>接口。</p>
<p>​	</p>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>Hadoop</tag>
        <tag>源码</tag>
        <tag>分布式系统</tag>
        <tag>source reading</tag>
      </tags>
  </entry>
  <entry>
    <title>一些有意思的细节</title>
    <url>/2017/07/15/java-details/</url>
    <content><![CDATA[<p>编程中有很多有意思的细节，看到了，就记在这里。</p>
<h3 id="简化判断"><a href="#简化判断" class="headerlink" title="| 简化判断"></a><code>|</code> 简化判断</h3><p>一堆数按位或，只要有多于一个数为负，则结果为负。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(<span class="type">byte</span> b[], <span class="type">int</span> off, <span class="type">int</span> len)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">   <span class="keyword">if</span> ((off | len | (b.length - (len + off)) | (off + len)) &lt; <span class="number">0</span>)</span><br><span class="line">       <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IndexOutOfBoundsException</span>();</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span> ; i &lt; len ; i++) &#123;</span><br><span class="line">       write(b[off + i]);</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>from</em>: <code>FilterOutputStream</code></p>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop 源码阅读之DFS（三）：FileSystem</title>
    <url>/2017/07/23/hadoop-0.1.0-file-system/</url>
    <content><![CDATA[<h3 id="FileSystem"><a href="#FileSystem" class="headerlink" title="FileSystem"></a>FileSystem</h3><p>FileSystem是一个抽象基类，为<code>LocalFileSystem</code>和<code>DistributedFileSystem</code>提供一些公共方法。通过<code>HashMap</code>:name-&gt; filesystem，维护所有使用的的文件系统，其key或者为“Local”，或者为“Host:Port”（标识一个NameNode）。<br>继承了<code>Configured</code>类，可以通过配置加载一些基本参数，保存在<code>Configuration</code>中。<br>为了提高可靠性，给每个文件生成一个校验和，保存在<code>.*.crc</code>的<strong>隐藏</strong>文件中。</p>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>Hadoop</tag>
        <tag>源码</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Android 学习笔记（一）：搜索框的实现</title>
    <url>/2017/12/02/android-search-box/</url>
    <content><![CDATA[<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>输入关键字，实时显示搜索结果。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h3 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h3><p>从<span class="exturl" data-url="aHR0cHM6Ly9kZXZlbG9wZXIuYW5kcm9pZC5jb20vZ3VpZGUvdG9waWNzL3NlYXJjaC9zZWFyY2gtZGlhbG9nLmh0bWw=">官方文档<i class="fa fa-external-link-alt"></i></span>入手，由于初入门，相关术语懂得少，而该文档又非代码级实现，导致没能完整搭起搜索的架子。该文档主要讲了以下几点：</p>
<ol>
<li>两种实现方式，search dialog和search widget；对于Android 3.0 以后的机器，推荐使用后者，较为灵活。</li>
<li>三个主要组件：<ul>
<li>搜索配置（a searchable configuration）</li>
<li>搜索容器（a searchable Activity）（困惑点1）</li>
<li>搜索结构（a search interface)</li>
</ul>
</li>
<li>搜索过程：<ul>
<li>接受查询（Receive the query）<br>使用Itent（困惑点2）</li>
<li>查询数据（Search your data）</li>
<li>呈现结果（Present the results）（困惑点3）</li>
</ul>
</li>
</ol>
<p>我想使用Search Widget方式，主要遇到以下几个困惑点：</p>
<ol>
<li>如何在<code>Activity</code>中触发搜索，就是AppBar右上角的搜索图标如何做出来。</li>
<li>如果使用<code>Intent</code>的查询数据，如示例一般，应该不能做到实时匹配输入字符。我猜想应该有listener之类的，但是例子没给。</li>
<li>如何呈现结果，文档建议让<code>SearchAbleActivity</code>继承<code>ListView</code>来实现，但是具体细节，如怎么接受结果，传递给<code>ListView</code>，都没有提。<br>等于搜索过程的三个环节都没有搞清楚，一脸懵逼。</li>
</ol>
<p>于是搜索关键词 SearchView action bar，找到一篇帖子：<span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvMjE1ODUzMjYvaW1wbGVtZW50aW5nLXNlYXJjaHZpZXctaW4tYWN0aW9uLWJhcg==">Implementing SearchView in action bar<i class="fa fa-external-link-alt"></i></span>，反复琢磨，才弄清楚了以上几个问题。</p>
<p>首先，对于触发搜索，该回答使用的是具有App Bar的Activity作为SearchableActivity，并且在复写onCreateOptionsMenu函数，实例化其参数menu，并且将SearchView作为其一个item。如此一来，SearchableActivity的右上角就会有搜索按钮。相关代码如下：<br><strong>res\menu\search.xml:</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;utf-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">menu</span> <span class="attr">xmlns:android</span>=<span class="string">&quot;http://schemas.android.com/apk/res/android&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">xmlns:app</span>=<span class="string">&quot;http://schemas.android.com/apk/res-auto&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">item</span> <span class="attr">android:id</span>=<span class="string">&quot;@+id/search_menu&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">android:title</span>=<span class="string">&quot;@string/search_hint&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">app:showAsAction</span>=<span class="string">&quot;ifRoom|collapseActionView&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">app:actionViewClass</span>=<span class="string">&quot;android.widget.SearchView&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">menu</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong>SearchableActivity.java</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">onCreateOptionsMenu</span><span class="params">(Menu menu)</span> &#123;</span><br><span class="line">    getMenuInflater().inflate(R.menu.search, menu);</span><br><span class="line">    <span class="built_in">this</span>.menu = menu;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get the SearchView and set the searchable configuration</span></span><br><span class="line">    <span class="type">SearchManager</span> <span class="variable">searchManager</span> <span class="operator">=</span> (SearchManager) getSystemService(Context.SEARCH_SERVICE);</span><br><span class="line">    <span class="type">SearchView</span> <span class="variable">searchView</span> <span class="operator">=</span> (SearchView) menu.findItem(R.id.search_menu).getActionView();</span><br><span class="line">    <span class="comment">// Assumes current activity is the searchable activity</span></span><br><span class="line">    <span class="type">ComponentName</span> <span class="variable">name</span> <span class="operator">=</span> getComponentName();</span><br><span class="line">    searchView.setSearchableInfo(searchManager.getSearchableInfo(name));</span><br><span class="line">    searchView.setIconifiedByDefault(<span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">    searchView.setOnQueryTextListener(<span class="keyword">new</span> <span class="title class_">SearchView</span>.OnQueryTextListener() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">onQueryTextSubmit</span><span class="params">(String s)</span> &#123;</span><br><span class="line">            doMySearch(s);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">onQueryTextChange</span><span class="params">(String s)</span> &#123;</span><br><span class="line">            doMySearch(s);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>AndroidManifest.xml</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;activity android:name=&quot;.SearchableActivity&quot;&gt;</span><br><span class="line">    &lt;intent-filter&gt;</span><br><span class="line">        &lt;action android:name=&quot;android.intent.action.SEARCH&quot; /&gt;</span><br><span class="line">    &lt;/intent-filter&gt;</span><br><span class="line">    &lt;meta-data android:name=&quot;android.app.searchable&quot;</span><br><span class="line">        android:resource=&quot;@xml/searchable&quot;/&gt;</span><br><span class="line">&lt;/activity&gt;</span><br></pre></td></tr></table></figure>

<p><strong>res&#x2F;xml&#x2F;searchable.xml</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;</span><br><span class="line">&lt;searchable xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;</span><br><span class="line">    android:label=&quot;@string/app_label&quot;</span><br><span class="line">    android:hint=&quot;@string/app_label&quot; &gt;</span><br><span class="line">&lt;/searchable&gt;</span><br></pre></td></tr></table></figure>
<p>其次是实时匹配查询结果；也是在<code>onCreateOptionsMenu</code>函数中，给<code>SearchView</code>设置listeners，具体可以见上面代码，但是return true&#x2F;false暂时有什么区别还没搞清楚。</p>
<p>最后是展示数据；如官方文档所说，利用ListView，具体做法是通过Adapter将数据（比如List<String>）传给利用xml渲染（inflate）的ListView，该答案是用CursorAdaptor（对接数据库数据更合适）。具体代码如下：<br><strong>res&#x2F;layout&#x2F;item.xml</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;</span><br><span class="line">&lt;RelativeLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;</span><br><span class="line">    android:layout_width=&quot;match_parent&quot;</span><br><span class="line">    android:layout_height=&quot;match_parent&quot;&gt;</span><br><span class="line">    &lt;TextView</span><br><span class="line">    android:id=&quot;@+id/item&quot;</span><br><span class="line">    android:layout_width=&quot;wrap_content&quot;</span><br><span class="line">    android:layout_height=&quot;wrap_content&quot; /&gt;</span><br><span class="line">&lt;/RelativeLayout&gt;</span><br></pre></td></tr></table></figure>

<p>ResultAdapter.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ResultAdapter</span> <span class="keyword">extends</span> <span class="title class_">CursorAdapter</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; items;</span><br><span class="line">    <span class="keyword">private</span> TextView text;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ResultAdapter</span><span class="params">(Context context, Cursor cursor, List&lt;String&gt; items)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(context, cursor, <span class="literal">false</span>);</span><br><span class="line">        <span class="built_in">this</span>.items = items;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">bindView</span><span class="params">(View view, Context context, Cursor cursor)</span> &#123;</span><br><span class="line">        text.setText(items.get(cursor.getPosition()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> View <span class="title function_">newView</span><span class="params">(Context context, Cursor cursor, ViewGroup parent)</span> &#123;</span><br><span class="line">        <span class="type">LayoutInflater</span> <span class="variable">inflater</span> <span class="operator">=</span> (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE);</span><br><span class="line">        <span class="type">View</span> <span class="variable">view</span> <span class="operator">=</span> inflater.inflate(R.layout.item, parent, <span class="literal">false</span>);</span><br><span class="line">        text = view.findViewById(R.id.item);</span><br><span class="line">        <span class="keyword">return</span> view;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>SearchableActivity.java</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">doMySearch</span><span class="params">(String query)</span>&#123;</span><br><span class="line">    String[] columns = <span class="keyword">new</span> <span class="title class_">String</span>[] &#123; <span class="string">&quot;_id&quot;</span>, <span class="string">&quot;text&quot;</span> &#125;;</span><br><span class="line">    Object[] temp = <span class="keyword">new</span> <span class="title class_">Object</span>[] &#123; <span class="number">0</span>, <span class="string">&quot;default&quot;</span> &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="type">MatrixCursor</span> <span class="variable">cursor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MatrixCursor</span>(columns);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; items.size(); i++) &#123;</span><br><span class="line"></span><br><span class="line">        temp[<span class="number">0</span>] = i;</span><br><span class="line">        temp[<span class="number">1</span>] = items.get(i);</span><br><span class="line">        cursor.addRow(temp);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// SearchView</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">SearchView</span> <span class="variable">search</span> <span class="operator">=</span> (SearchView) menu.findItem(R.id.search_menu).getActionView();</span><br><span class="line">    search.setSuggestionsAdapter(<span class="keyword">new</span> <span class="title class_">ResultAdapter</span>(<span class="built_in">this</span>, cursor, items));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><ol>
<li>Android官方文档，<span class="exturl" data-url="aHR0cHM6Ly9kZXZlbG9wZXIuYW5kcm9pZC5jb20vZ3VpZGUvdG9waWNzL3NlYXJjaC9zZWFyY2gtZGlhbG9nLmh0bWw=">https://developer.android.com/guide/topics/search/search-dialog.html<i class="fa fa-external-link-alt"></i></span></li>
<li>Stack Overflow回答，<span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvMjE1ODUzMjYvaW1wbGVtZW50aW5nLXNlYXJjaHZpZXctaW4tYWN0aW9uLWJhcg==">https://stackoverflow.com/questions/21585326/implementing-searchview-in-action-bar<i class="fa fa-external-link-alt"></i></span></li>
<li>官方视频，<span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj05T1dtbllQWDF1Yw==">https://www.youtube.com/watch?v=9OWmnYPX1uc<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>APP开发</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>安卓</tag>
        <tag>搜索框</tag>
      </tags>
  </entry>
  <entry>
    <title>一些设计模式</title>
    <url>/2017/08/03/design-patterns/</url>
    <content><![CDATA[<p>写程序的时候，规模小，尚不能感觉设计模式的重要性。等规模一上来，需求一迭代，一个应用了恰当设计模式的工程，总能以最小的代价进行最快的迭代。<br>但是一个奇怪的点是，我总记不住具体的实现所对应的设计模式的名字，但是对他们背后的设计思想，却是念念不忘——依赖于抽象而非具体；对扩展开放，对修改关闭；</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h3 id="Builder"><a href="#Builder" class="headerlink" title="Builder"></a>Builder</h3><p>首先，将一个复杂逻辑抽象成一组构建过程（具有前后先后次序，即时序约束）或者一组元操作（便于进行组合实现复杂逻辑），用一个接口封装。<br>然后，不同的逻辑实体类，继承该接口，进行不同的具体实现。<br>最后，依赖于接口，组合构建过程或元操作，进行具体业务代码实现。以后想换一个实现，只需要某处换一个具体实现类就行了。</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9zb3VyY2VtYWtpbmcuY29tL2Rlc2lnbl9wYXR0ZXJucy9idWlsZGVyL2phdmEvMg==">小例子一枚<i class="fa fa-external-link-alt"></i></span>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* &quot;Product&quot; */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pizza</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">dough</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">sauce</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">topping</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDough</span><span class="params">(String dough)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.dough = dough;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSauce</span><span class="params">(String sauce)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.sauce = sauce;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setTopping</span><span class="params">(String topping)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.topping = topping;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* &quot;Abstract Builder&quot; */</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">PizzaBuilder</span> &#123;</span><br><span class="line">    <span class="keyword">protected</span> Pizza pizza;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Pizza <span class="title function_">getPizza</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> pizza;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">createNewPizzaProduct</span><span class="params">()</span> &#123;</span><br><span class="line">        pizza = <span class="keyword">new</span> <span class="title class_">Pizza</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">buildDough</span><span class="params">()</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">buildSauce</span><span class="params">()</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">buildTopping</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* &quot;ConcreteBuilder&quot; */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HawaiianPizzaBuilder</span> <span class="keyword">extends</span> <span class="title class_">PizzaBuilder</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">buildDough</span><span class="params">()</span> &#123;</span><br><span class="line">        pizza.setDough(<span class="string">&quot;cross&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">buildSauce</span><span class="params">()</span> &#123;</span><br><span class="line">        pizza.setSauce(<span class="string">&quot;mild&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">buildTopping</span><span class="params">()</span> &#123;</span><br><span class="line">        pizza.setTopping(<span class="string">&quot;ham+pineapple&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* &quot;ConcreteBuilder&quot; */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpicyPizzaBuilder</span> <span class="keyword">extends</span> <span class="title class_">PizzaBuilder</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">buildDough</span><span class="params">()</span> &#123;</span><br><span class="line">        pizza.setDough(<span class="string">&quot;pan baked&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">buildSauce</span><span class="params">()</span> &#123;</span><br><span class="line">        pizza.setSauce(<span class="string">&quot;hot&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">buildTopping</span><span class="params">()</span> &#123;</span><br><span class="line">        pizza.setTopping(<span class="string">&quot;pepperoni+salami&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* &quot;Director&quot; */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Waiter</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> PizzaBuilder pizzaBuilder;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPizzaBuilder</span><span class="params">(PizzaBuilder pb)</span> &#123;</span><br><span class="line">        pizzaBuilder = pb;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Pizza <span class="title function_">getPizza</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> pizzaBuilder.getPizza();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">constructPizza</span><span class="params">()</span> &#123;</span><br><span class="line">        pizzaBuilder.createNewPizzaProduct();</span><br><span class="line">        pizzaBuilder.buildDough();</span><br><span class="line">        pizzaBuilder.buildSauce();</span><br><span class="line">        pizzaBuilder.buildTopping();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* A customer ordering a pizza. */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PizzaBuilderDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Waiter</span> <span class="variable">waiter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Waiter</span>();</span><br><span class="line">        <span class="type">PizzaBuilder</span> <span class="variable">hawaiianPizzabuilder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HawaiianPizzaBuilder</span>();</span><br><span class="line">        <span class="type">PizzaBuilder</span> <span class="variable">spicyPizzaBuilder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SpicyPizzaBuilder</span>();</span><br><span class="line"></span><br><span class="line">        waiter.setPizzaBuilder( hawaiianPizzabuilder );</span><br><span class="line">        waiter.constructPizza();</span><br><span class="line"></span><br><span class="line">        <span class="type">Pizza</span> <span class="variable">pizza</span> <span class="operator">=</span> waiter.getPizza();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这就是一个典型的依赖于抽象而非具体。</p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>desgin pattern</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>Android 学习笔记（二）：代码组织</title>
    <url>/2017/12/12/android-dail-pad/</url>
    <content><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>在进行模块化的时候，试图将诸如<code>SearchListener</code>, <code>CallManager</code> 的模块从<code>MainActivity</code>中拆出来，然而在响应事件的时候，不可避免的需要改变其他资源状态，那么就需要获取其句柄。由此还需要把<code>MainActivity</code>作为句柄传入代码。</p>
<span id="more"></span>

<p>更令人纠结的是，由于存在一些异步事件（如申请权限），其触发在模块（<code>CallManager</code>）中，其接受在主体视图（<code>MainActivity</code>）中，又需要将保有的参数重新传回<code>MainActivity</code>，如此绕来绕去，让我不禁反思我模块化时候存在的问题。</p>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h3 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CallManager.java</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">playCall</span><span class="params">(String phoneNumber)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (ContextCompat.checkSelfPermission(activity,</span><br><span class="line">            Manifest.permission.CALL_PHONE)</span><br><span class="line">            != PackageManager.PERMISSION_GRANTED) &#123;</span><br><span class="line">        ActivityCompat.requestPermissions(activity,</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;Manifest.permission.CALL_PHONE&#125;,</span><br><span class="line">                CALL_PHONE_REQUEST);</span><br><span class="line"></span><br><span class="line">        <span class="type">MainActivity</span> <span class="variable">ma</span> <span class="operator">=</span> (MainActivity) activity;</span><br><span class="line">        **ma.setPhoneNumber(phoneNumber);**</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MainActivity.java</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">String</span> <span class="variable">phoneNumber</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPhoneNumber</span><span class="params">(String number)</span> &#123;<span class="built_in">this</span>.phoneNumber = number;&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onRequestPermissionsResult</span><span class="params">(<span class="type">int</span> requestCode,</span></span><br><span class="line"><span class="params">                                       String permissions[], <span class="type">int</span>[] grantResults)</span> &#123;</span><br><span class="line">    <span class="keyword">switch</span> (requestCode) &#123;</span><br><span class="line">        <span class="keyword">case</span> CallManager.CALL_PHONE_REQUEST:</span><br><span class="line">            <span class="keyword">if</span> (grantResults.length &gt; <span class="number">0</span></span><br><span class="line">                    &amp;&amp; grantResults[<span class="number">0</span>] == PackageManager.PERMISSION_GRANTED) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (phoneNumber != <span class="literal">null</span> ) &#123;</span><br><span class="line">                    <span class="type">CallManager</span> <span class="variable">callManager</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CallManager</span>(<span class="built_in">this</span>);</span><br><span class="line">                    callManager.playCall(phoneNumber);</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在<code>Activity</code>中接收到call event调用<code>CallManager</code>，然后在其中请求权限，利用Set方法，将<code>PhoneNumber</code>传回<code>Activity</code>。初步想法是可以将请求权限、被授予权限后执行回调函数这种和<code>Activity</code>紧耦合的代码方法写在<code>MainActivity</code>中，然后<code>CallManager</code>只处理call逻辑。但仍需要一个类变量来保存电话号码，以进行从请求权限到执行回调之前的参数传递工作。</p>
]]></content>
      <categories>
        <category>APP开发</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop源码阅读之MapReduce（一）：基本概念和接口</title>
    <url>/2018/02/24/hadoop-map-reduce/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>梳理一下MapReduce框架涉及到的一些基本接口和类。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="文件读写相关"><a href="#文件读写相关" class="headerlink" title="文件读写相关"></a>文件读写相关</h2><p><code>RecordReader</code>：从输入文件中读入键值对，这里是指的map的输入，还是reduce的输入？接口有三个函数<code>next(Writable key, Writable value)</code>，<code>getPos()</code>和<code>close()</code>，由此看来，该接口类似于一个抽象的迭代器。<code>InputFormat</code>实现了该接口。</p>
<p><code>RecordWriter</code>：将键值对写到输出文件，<code>OutputFormat</code>实现了该接口。包含函数：<code>write(WritableComparable key, Writable value)</code>和<code>close(Reporter reporter)</code>。</p>
<p><code>OutputCollector</code>：作为参数传送给<code>Mapper</code>和<code>Reducer</code>来输出结果数据。该接口只有一个函数<code>collect(key, val)</code>。</p>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>Hadoop</tag>
        <tag>分布式系统</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法（一）：二叉树的非递归遍历</title>
    <url>/2018/02/24/tree-traversal-nonrecursive/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>最近在琢磨关于树的非递归遍历的一些思路和对应的实现，写在这里，聊以备忘。 </p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="直接迭代写法"><a href="#直接迭代写法" class="headerlink" title="直接迭代写法"></a>直接迭代写法</h2><p>基本思路是，一路往左走，撞了南墙（碰到NULL）就回头；回头摆到右（子树的根），接着往左走（循环）。</p>
<p>基本代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * struct TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode *left;</span></span><br><span class="line"><span class="comment"> *     TreeNode *right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">traversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">    stack&lt;TreeNode*&gt; s;</span><br><span class="line">    TreeNode* current = root;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!s.<span class="built_in">empty</span>() || current) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current) &#123;</span><br><span class="line">            s.<span class="built_in">push</span>(current); <span class="comment">//(1)</span></span><br><span class="line">            current = current-&gt;left;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            current = s.<span class="built_in">top</span>()-&gt;right; <span class="comment">// (3)</span></span><br><span class="line">            s.<span class="built_in">pop</span>(); <span class="comment">// if we pop the node, then we do not have (5)</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对应的完整遍历路径如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">      (1) root (5?)</span><br><span class="line">         / (3)  \</span><br><span class="line">        /        \</span><br><span class="line">(2)l-subtree   (4)r-subtree</span><br></pre></td></tr></table></figure>
<p>对于某个节点root来说，有三次访问机会：</p>
<ol>
<li>从父亲节点过来(1)</li>
<li>访问完左子树后回来(3)</li>
<li>访问完右子树后回来(5)</li>
</ol>
<p>对应的，按照二叉树遍历的定义，</p>
<ol>
<li>如果在(1)访问节点，就是前序遍历：先根(1)，然后左子树(2)，最后右子树(4)。</li>
<li>如果在(3)访问节点，就是中序遍历：先左子树(2)，然后根(3)，最后右子树(4)。</li>
<li>如果在(5)访问节点，就是后序遍历：先左子树(2)，然后右子树(4)，最后根(5)。</li>
</ol>
<p>由于访问完左子树需要继续访问右子树，故需要保存root的指针，即stack在这里的作用。随着访问的深入，stack不断入栈节点，最大长度即为树的深度。这里需要着重说明的是，随着访问左子树归来，将会不断的退栈，因为在获得右子树指针后，已经不需要再保存root的指针了。因此如果不做特殊处理，步骤(5)是没有的。</p>
<p>所以对于二叉树前序遍历和中序遍历的非递归代码，可以直接给出：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// preorder traversal:</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">preorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">    stack&lt;TreeNode*&gt; s;</span><br><span class="line">    TreeNode* current = root;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!s.<span class="built_in">empty</span>() || current) &#123;</span><br><span class="line">        <span class="keyword">while</span> (current) &#123;</span><br><span class="line">            s.<span class="built_in">push</span>(current); </span><br><span class="line">            cout &lt;&lt; current-&gt;val &lt;&lt; endl;<span class="comment">//(1)</span></span><br><span class="line">            current = current-&gt;left;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        current = s.<span class="built_in">top</span>()-&gt;right; </span><br><span class="line">        s.<span class="built_in">pop</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// inorder traversal:</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">inorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">    stack&lt;TreeNode*&gt; s;</span><br><span class="line">    TreeNode* current = root;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (!s.<span class="built_in">empty</span>() || current) &#123;</span><br><span class="line">        <span class="keyword">while</span> (current) &#123;</span><br><span class="line">            s.<span class="built_in">push</span>(current);</span><br><span class="line">            current = current-&gt;left;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        current = s.<span class="built_in">top</span>()-&gt;right; </span><br><span class="line">        cout &lt;&lt; s.<span class="built_in">top</span>()-&gt;val &lt;&lt; endl;<span class="comment">//(3)</span></span><br><span class="line">        s.<span class="built_in">pop</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于后序遍历的代码，会稍微复杂一点，所需要做的改动主要为：不能在第二次访问（即图中(3)）后退栈，而需要在阶段(5)退栈。这就牵扯出如何判断阶段(5)的问题。这里我的做法是引入一个prev指针，标记访问序列中前一个二叉树节点，如果root-&gt;right即为prev，或者root-&gt;right为NULL，就可以判断已经从右子树访问返回，即为阶段(5)。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">postorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">    stack&lt;TreeNode*&gt; s;</span><br><span class="line">    TreeNode* current = root, *prev = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (current || !s.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="keyword">while</span> (current) &#123;</span><br><span class="line">            s.<span class="built_in">push</span>(current);</span><br><span class="line">            current = current-&gt;left;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        TreeNode* now = s.<span class="built_in">top</span>();</span><br><span class="line">        <span class="keyword">if</span> (now-&gt;right == <span class="literal">NULL</span> || now-&gt;right == prev) &#123;</span><br><span class="line">            <span class="comment">// stage (5)</span></span><br><span class="line">            cout &lt;&lt; now-&gt;val;</span><br><span class="line">            prev = now; <span class="comment">// update the prev</span></span><br><span class="line">            s.<span class="built_in">pop</span>();</span><br><span class="line">            current = <span class="literal">NULL</span>; <span class="comment">// let the stack keep popping</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// stage (4)</span></span><br><span class="line">            current = now-&gt;right;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="递归翻译写法"><a href="#递归翻译写法" class="headerlink" title="递归翻译写法"></a>递归翻译写法</h2><p>我们知道，可以用栈来模拟函数调用，或者说函数调用本来就是函数栈帧的入栈和退栈。由于二叉树遍历足够简单，也让我们的模拟变的相对容易实现。</p>
<p>比如，对于先序遍历，由于栈会使访问反序，因此先压入右子树。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">preorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">    stack&lt;TreeNode*&gt; s;</span><br><span class="line">    <span class="keyword">if</span> (root) s.<span class="built_in">push</span>(root);</span><br><span class="line">    <span class="keyword">while</span> (!s.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        TreeNode* now = s.<span class="built_in">top</span>();</span><br><span class="line">        cout &lt;&lt; now-&gt;val;</span><br><span class="line">        s.<span class="built_in">pop</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (now-&gt;right) s.<span class="built_in">push</span>(now-&gt;right);</span><br><span class="line">        <span class="keyword">if</span> (now-&gt;left) s.<span class="built_in">push</span>(now-&gt;left);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果先压入左子树呢，就成了逆后序遍历，这样只需要再加一个栈，就能得到后序遍历。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">inversePostorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">    stack&lt;TreeNode*&gt; s;</span><br><span class="line">    <span class="keyword">if</span> (root) s.<span class="built_in">push</span>(root);</span><br><span class="line">    <span class="keyword">while</span> (!s.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        TreeNode* now = s.<span class="built_in">top</span>();</span><br><span class="line">        cout &lt;&lt; now-&gt;val;</span><br><span class="line">        s.<span class="built_in">pop</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (now-&gt;left) s.<span class="built_in">push</span>(now-&gt;left);</span><br><span class="line">        <span class="keyword">if</span> (now-&gt;right) s.<span class="built_in">push</span>(now-&gt;right);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Morris中序遍历"><a href="#Morris中序遍历" class="headerlink" title="Morris中序遍历"></a>Morris中序遍历</h2><p>以上遍历方法，不论递归还是非递归，其额外的空间复杂度都为O(h)即O(lgn)，因为栈开销最大为树的深度。那么有没有一种不借助额外空间的方法来实现树的遍历呢？聪明的你可能会想到线索二叉树，Bingo！这就是Morris中序遍历。</p>
<p>闲话少说，先上代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">inorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">    TreeNode* current = root;</span><br><span class="line">    <span class="keyword">while</span> (current != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (current-&gt;left == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            cout &lt;&lt; current-&gt;val;</span><br><span class="line">            current = current-&gt;right;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            TreeNode* prev = current-&gt;left;</span><br><span class="line">            <span class="keyword">while</span> (prev-&gt;right != <span class="literal">NULL</span> &amp;&amp; prev-&gt;right != current) &#123;</span><br><span class="line">                prev = prev-&gt;right;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (prev-&gt;right == <span class="literal">NULL</span>) &#123;</span><br><span class="line">                prev-&gt;right = current;</span><br><span class="line">                current = current-&gt;left;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (prev-&gt;right == current) &#123;</span><br><span class="line">                cout &lt;&lt; current-&gt;val;</span><br><span class="line">                current = current-&gt;right;</span><br><span class="line">                prev-&gt;right = <span class="literal">NULL</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>基本思路是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. Initialize current as root </span><br><span class="line">2. While current is not NULL</span><br><span class="line">   If current does not have left child</span><br><span class="line">      a) Print current’s data</span><br><span class="line">      b) Go to the right, i.e., current = current-&gt;right</span><br><span class="line">   Else</span><br><span class="line">      a) Make current as right child of the rightmost node in current&#x27;s left subtree</span><br><span class="line">      b) Go to this left child, i.e., current = current-&gt;left</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>好吧，其实这就是伪代码，出处见<span class="exturl" data-url="aHR0cHM6Ly93d3cuZ2Vla3Nmb3JnZWVrcy5vcmcvaW5vcmRlci10cmVlLXRyYXZlcnNhbC13aXRob3V0LXJlY3Vyc2lvbi1hbmQtd2l0aG91dC1zdGFjay8=">这里<i class="fa fa-external-link-alt"></i></span>。核心要点就是，当我们一头扎向南墙时，为了能无痛返回，需要在南墙打个洞，通回原路，并且过了洞之后将洞补上。但是打洞是需要时间的，这就是典型的用时间换空间–每次都得在找左孩子最右边那个元素的时候多浪费点时间。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>使用栈进行二叉树遍历的本质是：利用栈保存访问时路径（即从根节点到当前节点的路径），这样就可以在左子树无法前进时，进行回溯，去访问右子树。</p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>data structures</tag>
        <tag>algorithms</tag>
        <tag>数据结构</tag>
        <tag>tree</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法（二）：二分搜索</title>
    <url>/2018/03/11/binary-search/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>以前对二分查找的认识只停留在有序数组查找给定整数上，后来发现一类问题都可以用二分的思想来做，概括来说就是：如果要求的结果所在的集合（值域）和要搜索的数的集合（定义域）存在单调（映射）关系，就可以通过二分思想来解决，说起来有点抽象，后面将用几个例子来说明。</p>
<p>二分思想以其每次迭代将规模砍一半的效率，有着极其广阔的应用。</p>
<p>本文分两大部分，第一部分对二分查找的各个细节探讨；第二部分拓展二分查找为一般的二分思想。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="二分查找–边边角角"><a href="#二分查找–边边角角" class="headerlink" title="二分查找–边边角角"></a>二分查找–边边角角</h2><h3 id="基本代码（C-）"><a href="#基本代码（C-）" class="headerlink" title="基本代码（C++）"></a>基本代码（C++）</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;arr, <span class="type">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> left = <span class="number">0</span>, right = arr.<span class="built_in">size</span>()<span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (left &lt;= right) &#123;</span><br><span class="line">        <span class="type">int</span> mid = (left + right) / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (arr[mid] == target) &#123;</span><br><span class="line">            <span class="keyword">return</span> mid;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (arr[mid] &lt; target)&#123;</span><br><span class="line">            left = mid + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            right = mid - <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>像上面这一段平平无奇的代码，在实际运用的时候却又诸多变化。二分查找的基本思路不再多说，现在只分析边边角角（Corner Case）。这就涉及到我们一个基本原则，既要让所有元素有可以搜索到的机会，又不至于陷入死循环。具体来说有以下几个问题：</p>
<ol>
<li>循环条件。什么时候用<code>left &lt;= right</code>，什么时候用<code>left &lt; right</code>呢？</li>
<li>取中方式。<code>mid</code>常用的有几种计算方式：<code>mid = (left+right)/2</code>， <code>mid = left+(right-left)/2</code> 和 <code>mid = (left+right+1)/2</code>。</li>
<li>边界移动。<code>left </code>和 <code>right</code> 都有两种移动方式，拿<code>left</code>来说：<code>left=mid+1 </code>和 <code>left=mid</code>。</li>
<li>最终状态。如果没有查找到指定值，比如说[1,2,3,5]中查找数字4，那么最后跳出循环后，left 和 right 分别指向5和3的位置。也就是说，在4应该插入的位置两侧，并且left &gt; right。</li>
</ol>
<p>上面的几个问题其实是相互勾连的，视遇到的问题来适当组合。比如说，查找一个有序数组{1, 2, 3, 3, 3, 5}某个数字 {3} 的左右边界下标：[2, 4]</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">find_range</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;arr, <span class="type">int</span> target, <span class="type">bool</span> left_range)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> left = <span class="number">0</span>, right = arr.<span class="built_in">size</span>() - <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (left &lt; right) &#123;</span><br><span class="line">        <span class="type">int</span> mid = left_range ? (left + right) / <span class="number">2</span> : (left + right + <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (arr[mid] == target) &#123;</span><br><span class="line">        <span class="comment">// Find left boundary: if we round right when calculate mid, then</span></span><br><span class="line">        <span class="comment">// we will trap into infinite loop here(imagine</span></span><br><span class="line">        <span class="comment">// we only have two elements in the array).</span></span><br><span class="line">        <span class="comment">// Find right boundary: the similar reason.</span></span><br><span class="line">            left_range ? right = mid : left = mid;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (arr[mid] &lt; target) &#123;</span><br><span class="line">            left = mid + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            right = mid - <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> left;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码，在要查找的数字存在的时候是对的，如果不存在需要加额外判断。需要加什么判断呢？这也就是需要说明的另一个地方：当我们进行二分查找的时候，是在中途找到结果就退出(return)呢，还是一直到循环条件被打破退出呢？前者用来最简单的查找指定值，而后者一般是查找某个边界，或者符合条件的最值。该问题因为是由于破坏了循环条件<code>left &lt; right</code>退出的，所以得判断下<code>arr[left]</code>是否和<code>target</code>相等。</p>
<p>因此：</p>
<ol>
<li><p>循环条件，和移动方式和跳出边界时判断相关。</p>
</li>
<li><p>取中方式，和是否会溢出相关。比如 left 和 right 都很大，则 (left + right)&#x2F;2 一般。</p>
</li>
<li><p>边界移动，这个要看是否需要循环最后跳出的左右边界结果，还是仅仅缩小范围。</p>
</li>
<li><p>最终状态，看是要查找到某个特定值结束，还是需要不断二分直到边界缩小为负值跳出。</p>
</li>
</ol>
<h2 id="推广二分"><a href="#推广二分" class="headerlink" title="推广二分"></a>推广二分</h2><p>仔细思考有序数组的二分查找的过程可以得到几个特点：</p>
<ol>
<li>数组数值（查找范围）和其下标（查找目标）呈现一种单调的映射关系。</li>
<li>每次二分，都会砍掉当前数据规模的一半，因此也叫“折半查找”。</li>
</ol>
<h3 id="单调映射"><a href="#单调映射" class="headerlink" title="单调映射"></a>单调映射</h3><p>将二分思想推广，只要查找范围中的数值和目标值所构成的函数是单调的，我们就可以通过比较查找对象，来缩小目标值的范围。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>有些点还没想清楚，以后再补充。</p>
<p>​     </p>
]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>data structures</tag>
        <tag>algorithms</tag>
        <tag>数据结构</tag>
        <tag>binary search</tag>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Hexo引擎配置静态博客</title>
    <url>/2019/02/17/hexo-blog/</url>
    <content><![CDATA[<h2 id="hexo-博客搭建"><a href="#hexo-博客搭建" class="headerlink" title="hexo 博客搭建"></a>hexo 博客搭建</h2><p>今年新年愿望之一，督促自己每周写博客。作为一个新的开始，打扫屋子清爽一番是我的一贯风格。加上感觉jeklly 引擎不怎么好使，就想换个新的引擎 hexo。去年注意到越来越多的博客开始用这个引擎，于是关注了下，感觉的确不错（主题，模式等等），说干就干。想着作为科班出身，看别人教程多low，于是直接看官方文档开搞，当然了，坑是不可避免的，下面来聊一下。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="时间线"><a href="#时间线" class="headerlink" title="时间线"></a>时间线</h2><ol>
<li>前一天，花了一个小时左右过了下hexo官方文档：<span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL3poLWNuLw==">https://hexo.io/zh-cn/<i class="fa fa-external-link-alt"></i></span></li>
<li>另起炉灶，新申请了个github账号，对hexo实验一番</li>
<li>在原来github账号上将以前的寥寥几篇笔记迁过去</li>
</ol>
<h2 id="看文档"><a href="#看文档" class="headerlink" title="看文档"></a>看文档</h2><p>hexo文档写的挺清楚的，又有中文，大致溜了一下。先讲讲主要可能用到的是一些基本命令和常规配置，然后大概谈谈我理解的hexo的原理。</p>
<h3 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h3><p>按用到的顺序大致捋一遍，我用的 hexo 版本：hexo: 3.8.0，hexo-cli: 1.1.0</p>
<ol>
<li>安装 nodejs，参见文档概述一节。主要是 npm 命令，就是个 js 包管理工具，静态网页，自然离不了大量的js依赖。</li>
<li>安装 hexo 命令行:  <code>npm install -g hexo-cli</code></li>
<li>初始化 hexo： <code>hexo init</code></li>
<li>新建文章： <code>hexo new [layout] &lt;filename&gt;</code></li>
<li>发布静态网页： <code>hexo d (hexo deploy简写)</code></li>
</ol>
<h3 id="常规配置"><a href="#常规配置" class="headerlink" title="常规配置"></a>常规配置</h3><p>主要针对 github pages：</p>
<p>总配置文件即 hexo&#x2F;_config.yml ：基本设定如 title, subtitle 等按下不表，需要注意的是 deploy 和 theme</p>
<p>针对git，如果有自己的博客域名，注意在 hexo&#x2F;source 里面加上CNAME（里面写上自己的域名）文件，这时候，就算你输入 qtmuniao.github.io ，也会自动跳转到 <span class="exturl" data-url="aHR0cDovL3d3dy5xdG11bmlhby5jb20uLw==">www.qtmuniao.com。<i class="fa fa-external-link-alt"></i></span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: &lt;repository url&gt; #https://bitbucket.org/JohnSmith/johnsmith.bitbucket.io</span><br><span class="line">  branch: [branch] #published</span><br></pre></td></tr></table></figure>

<p><code>hexo deploy -g</code> 是常用的文章发布命令，其中 deploy 的意思是将博客网站呈现所需的文件（去掉了hexo引擎本身的一些杂七杂八文件）push 到指定 repo 的某个 branch 中去，然后将github pages 指向该 repo 的该分支就行了。 -g 是指在 push 到上述分支钱，将生成的静态文件放到 public 文件夹中。</p>
<p>对于主题，知乎有篇<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzI0NDIyMzM1">文章<i class="fa fa-external-link-alt"></i></span>对流行的 hexo 主题进行了下统计，我这里选的人气最高的 next，并根据其<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RoZW1lLW5leHQvaGV4by10aGVtZS1uZXh0L2Jsb2IvbWFzdGVyL2RvY3MvemgtQ04vSU5TVEFMTEFUSU9OLm1k">文档<i class="fa fa-external-link-alt"></i></span> 安装了一番，我用的版本是 <em>Version 6.0.6</em>。</p>
<p>针对 next 主题配置  <em>thems&#x2F;next&#x2F;_config.yml</em>，主要是选了个 <em>Scheme：Gemini</em>，加了点谷歌统计的信息，以便对网站的访问情况进行跟踪。</p>
<h3 id="大概原理"><a href="#大概原理" class="headerlink" title="大概原理"></a>大概原理</h3><p>简要说说我对 hexo 的理解：</p>
<p>hexo 大致可以理解为一个写静态博客的引擎。</p>
<p>说先说静态，意思就是没有服务器后台交互，可以粗理解为没有数据库去存烂七八糟的用户信息，博客信息以及其他元信息。由于近年来前端的进一步发展，js 可以做的事情越来越多，仅仅依靠 html + js + css 就可以满足日常码字以及炫酷主题的需求，并且不需要部署服务，租空间，再加上github pages的免费，安全，快速，因此静态博客日趋流行。</p>
<p>那么什是引擎呢，我理解就是将所有与写作无关的事情给你通过 <strong>简单命令+默认配置</strong> 的方式给你管好，你只需要安心码字就行。当然由于个性化的需要，主题和插件被解耦出来，并且可以定制，可以发布，可以交流，由此极大丰富了可玩性。</p>
<p>hexo 通过模板，主题，插件等模块化解耦，使得写博客这件事变得易上手，可钻研。</p>
<h2 id="新账号"><a href="#新账号" class="headerlink" title="新账号"></a>新账号</h2><p>第一念头就是直接在原仓库里改，思考片刻，强行按下这不靠谱的想法。于是新申请一个github账号，问题随之而来：</p>
<p><strong>1. 不同的github账号不能添加同一个ssh key</strong></p>
<p>Google 一番，找到一个方案。</p>
<p>a.  重新生成一个 ssh pair（生成的时候注意位置选择，我觉得最好还放在 ~&#x2F;.ssh目录下吧，当然着看个人口味，然后起一个规整名字）</p>
<p>b. 编辑 ssh 配置文件， ~&#x2F;.ssh&#x2F;config，指定两个 host 条目，设置使其用不同的 ssh key。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Host host1</span><br><span class="line">    HostName github.com</span><br><span class="line">    PreferredAuthentications publickey</span><br><span class="line">    IdentityFile ~/.ssh/id_rsa</span><br><span class="line"></span><br><span class="line">Host qtmuniao</span><br><span class="line">    HostName github.com</span><br><span class="line">    PreferredAuthentications publickey</span><br><span class="line">    IdentityFile ~/.ssh/qtmuniao_id_rsa</span><br></pre></td></tr></table></figure>

<p>然后可以用  <code>ssh -T git@qtmuniao</code>  测试下配置结果</p>
<p>c. 修改 git clone repo.git 中路径：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">改前： git@github.com:qtmuniao/qtmuniao.github.io.git</span><br><span class="line">改后： git@qtmuniao:qtmuniao/qtmuniao.github.io.git</span><br></pre></td></tr></table></figure>

<p>就是把 <code>@</code> 后 <code>:</code> 的 hostname 改为配置的 hostname。</p>
<h2 id="hexo实验"><a href="#hexo实验" class="headerlink" title="hexo实验"></a>hexo实验</h2><p>然后就开始按照以前想法，直接建了一个 <code>qtmuniao.github.io</code> 的仓库，然后在 <code>hexo deploy</code>  的时候遇到第二个问题：</p>
<p><strong>2. qtmuniao.github.io 仓库的 Settings 中 GitHub Pages 项的 source 只能设置为 master</strong></p>
<p>a. 先详细交代下问题由来</p>
<p>hexo 的设定是，写博客以及所需要的 hexo 依赖，维护在一个 branch 中（比如说 <em>master</em> branch），然后针对 git 方式 deploy 的时候将所有有用的文件给 <code>push (-- force) </code> 到一个新分支（比如说 <em>publish</em> branch）上去，然后在 github 中将该分支设为 github pages 的指向分支。</p>
<p>b. 但是 hexo 给的指向方案不好使啊，即：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">https://hexo.io/zh-cn/docs/deployment:</span><br><span class="line">登入 Github/BitBucket/Gitlab，请在库设置（Repository Settings）中将默认分支设置为_config.yml配置中的分支名称。稍等片刻，您的站点就会显示在您的Github Pages中。</span><br></pre></td></tr></table></figure>

<p>我将 <code>qtmuniao.github.io</code> 的默认分支改为 publish 后，打开 <span class="exturl" data-url="aHR0cHM6Ly9xdG11bmlhby5naXRodWIuaW8v">https://qtmuniao.github.io/<i class="fa fa-external-link-alt"></i></span> ，发现仍然指向 master 分支。</p>
<p>c. 于是就有了该问题：qtmuniao.github.io 仓库的 Settings 中 GitHub Pages 项的 source 只能设置为 master，因为它是灰的。</p>
<p>Stack Overflow 一番，大概弄明白了，您的 github 所有仓库都可以将其根目录，或者根目录下 docs 文件夹设为待发布的 github pages。但是当 username.github.io 仓库存在的时候呢，就默认将 username.github.io master分支设置为待发布的 github pages， 还不能更改。</p>
<p>d. 既然这样，那我就新建了个 blog 的仓库，然后每次利用 hexo 将博客代码发布到 gh-pages 分支，并在 blog 仓库的 Settings 中，将Github Pages 项的 Source 设置为 gh-pages 就可以了。美中不足的是，访问路径就带了 blog ，主页就变成了： <span class="exturl" data-url="aHR0cHM6Ly9xdG11bmlhby5naXRodWIuaW8vYmxvZy8=">https://qtmuniao.github.io/blog/<i class="fa fa-external-link-alt"></i></span> ，这个稍后估计能修改配置解决。</p>
<p>e. 后来弄了下路径问题，发现在 hexo&#x2F;_config.yml 里面有以下提示： <em>If your site is put in a subdirectory, set url as ‘<span class="exturl" data-url="aHR0cDovL3lvdXJzaXRlLmNvbS9jaGlsZA==">http://yoursite.com/child<i class="fa fa-external-link-alt"></i></span>‘ and root as ‘&#x2F;child&#x2F;‘</em> ；如实加上后，果然没有了blog的子路径；但是如果我用自己的域名进行指向后，就发现各种资源文件（js+css）获取不到了，而将上面配置改回 <em>url: <span class="exturl" data-url="aHR0cDovL3lvdXJzaXRlLmNvbS8=">http://yoursite.com<i class="fa fa-external-link-alt"></i></span> and roots as ‘&#x2F;‘</em> 就好了。</p>
<h2 id="笔记迁移"><a href="#笔记迁移" class="headerlink" title="笔记迁移"></a>笔记迁移</h2><p>参考 hexo 文档 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL3poLWNuL2RvY3MvbWlncmF0aW9uI0pla3lsbA==">https://hexo.io/zh-cn/docs/migration#Jekyll<i class="fa fa-external-link-alt"></i></span>  没遇到什么问题。</p>
<h2 id="评论区"><a href="#评论区" class="headerlink" title="评论区"></a>评论区</h2><p>为了增加互动性，结识更多同好，我想增加个评论区。感觉由于用的 Next 版本比较高级，其默认支持常见评论插件：gitment，gitalk</p>
<p>我这里选用的是 gitalk，由于其是基于 Github Issue 和 Preact 开发的评论插件。因此需要先注册一个 github application，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NldHRpbmdzL2FwcGxpY2F0aW9ucy9uZXc=">https://github.com/settings/applications/new<i class="fa fa-external-link-alt"></i></span> 。需要注意的是 Homepage URL 和 Authorization callback URL 填一致的就行，如果有配置域名指向的填域名就行。</p>
<p>注册成功后获取 client Id 和 secret，在 hexo&#x2F;themes&#x2F;next&#x2F;_config.yml 中打开下面配置就行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gitalk:</span><br><span class="line">  enable: true</span><br><span class="line">  github_id:   # Github repo owner</span><br><span class="line">  repo:   # Repository name to store issues.</span><br><span class="line">  client_id:  # Github Application Client ID</span><br><span class="line">  client_secret:  # Github Application Client Se</span><br><span class="line">  admin_user:   # GitHub repo owner and collaborators, only these guys can in</span><br><span class="line">  distraction_free_mode: true # Facebook-like distraction free mode</span><br></pre></td></tr></table></figure>

<p>需要注意的 repo 一项仅需要填 git repo 的名字，而非地址。</p>
<p>然后 <code>hexo clean &amp;&amp; hexo deploy</code> 重新部署就行。</p>
<p>可能会出现 <strong>登录出现 404 错误</strong> ，点下登陆 github 就行。</p>
<p>最后祝大家玩得愉快。</p>
]]></content>
      <categories>
        <category>搭建博客</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title>6.824 - Raft 实现（一）：Leader选举</title>
    <url>/2018/07/11/raft-leader-election/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>记录下在实现6.824 lab2 raft 的一些想法和经验，聊以备忘。</p>
<h2 id="实验概述"><a href="#实验概述" class="headerlink" title="实验概述"></a>实验概述</h2><p>6.824是MIT的一门分布式课程，我跟的是<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9sYWItcmFmdC5odG1s">2018 spring<i class="fa fa-external-link-alt"></i></span> 。在第二个实验中要求简单实现一个分布式一致性协议–<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvcGFwZXJzL3JhZnQtZXh0ZW5kZWQucGRm">raft<i class="fa fa-external-link-alt"></i></span>。</p>
<p>这是一个专为方便教学和工程实现所设计的协议，它将协议拆解为几个相对独立的模块–leader选举，log复制，安全保证。论文里图二基本给出了Raft的所有实现细节，可谓字字珠玑。但也因为太微言大义了，导致有些状态转换分散在不同描述中，假如你真只照着这幅图实现，很容易遗漏些细节。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="leader选举"><a href="#leader选举" class="headerlink" title="leader选举"></a>leader选举</h2><p>这是lab2A的内容，说来惭愧，从开始构思到测试用例pass，前前后后拖了两个多月。虽然只是晚上和周末写写，但是也的确进展缓慢，不过收获颇多。暗想要是本科实验也这么来，可能就真如知乎所说，一学期顶多学两门课，回想大三时候四门四学分的课，从课程设计上来说就是注定要我们划水的。</p>
<p>吐槽完毕，说说踩过的坑。</p>
<h3 id="定时器"><a href="#定时器" class="headerlink" title="定时器"></a>定时器</h3><p>raft主要有两个event loop，一个是（Follower，Candidate）超时发起选举，一个是（Leader）定期心跳（有时捎带日志同步）。最容易想到的就是本科写大作业无脑用的loop+sleep，即外层一个while true，内层用一个稍小（但比electionTimeout和heartbeatInterval至少小一个数量级才够用）的时间间隔（比如说t）sleep，来周期性检测时间节点（needElection，heartbeat）的到来。</p>
<p>但是我老强迫症的觉得，这么着不准确，误差至少是那个检测时间间隔t。这要是好多线程搞来搞去，面对这么复杂的状态变化，会不会由误差而导致错误，但是用go的timer好像很复杂的样子，每每想到这就想不清了，这么着也耽搁了一阵子。</p>
<p>直到后来，在另一个也在做raft的孩子提醒下才注意到，其实课程很贴心的给出了<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9yYWZ0LXN0cnVjdHVyZS50eHQ=">建议<i class="fa fa-external-link-alt"></i></span>–还就是利用loop+sleep来周期性检测超时。这时候我茅塞顿开，悟出了上面括弧中我的注释–只要保证检测间隔小于超时间隔一两个数量级，基本上就没啥问题。这种实现的优点是简单，粗暴，直接，可控。</p>
<p>我在实现的时候又突然觉得好玩，弄成了两种稍有不同的实现，下附代码，为了看着清楚，都做了些简略化处理。<br>一种是只有一个loop：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    now := time.Now()</span><br><span class="line">    <span class="keyword">if</span> now.Sub(last) &lt; electionTimeout &#123;</span><br><span class="line">      time.Sleep(checkGapInMs)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 起初我还纠结此两句顺序，后来想通了</span></span><br><span class="line">      <span class="comment">// 只要startElection没有啥IO等阻塞型操作，顺序就无所谓</span></span><br><span class="line">      startElection()</span><br><span class="line">      last = time.Now()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure>

<p>另一种是两个嵌套loop，内层loop专门用来等待（或许是联想到了CPU的忙等待）。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">  <span class="comment">// ping all the peers</span></span><br><span class="line">  <span class="keyword">for</span> s := <span class="number">0</span>; s &lt; <span class="built_in">len</span>(rf.peers); s++ &#123;</span><br><span class="line">     <span class="comment">// append entry rpc</span></span><br><span class="line">  &#125;(s, args)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// wait until time comes</span></span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    now := time.Now()</span><br><span class="line">    <span class="keyword">if</span> now.Sub(lastPingTime) &lt; pingGapInMs &#123;</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      lastPingTime = time.Now()</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>虽然前者更简洁，但是后者逻辑更明白；有时候简洁的代码是复用了不同的逻辑，导致语义上可能稍微有点不清楚。考虑到代码的第一要义是给人看的（啥？你说是给机器看的？咳咳，我觉得这是代码之所以为代码的前提，不然编译器不给你过啊），我觉得还是第后者好一些。</p>
<h3 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h3><p>课程也很贴心的给出了<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9yYWZ0LWxvY2tpbmcudHh0">提示<i class="fa fa-external-link-alt"></i></span>，但作为一个从大一电梯大作业开始就开始‘玩锁’的人，我直接将其略过，不管三七二十一，昂首挺胸，赤膊上阵，狂撸代码。然而，记忆是会骗人的，教训是很惨痛的，竟然一直死锁而我却不知道是哪的问题。后来只得乖乖将提示看了好几遍，发现写的真是好啊。。。</p>
<p>其要点总结起来，就是将有全局变量读写的地方先全部给加上锁，然后再将有阻塞（rpc call等等）的地方去掉锁。</p>
<p>它这原则先按下不表，来说说我跳坑的两个地方：</p>
<h4 id="函数调用外持有了锁，在函数调用里面又重新申请："><a href="#函数调用外持有了锁，在函数调用里面又重新申请：" class="headerlink" title="函数调用外持有了锁，在函数调用里面又重新申请："></a>函数调用外持有了锁，在函数调用里面又重新申请：</h4><p>犯这个错误的原因是咱看着那么长的代码，凭着经验，总得给他包一下吧，包的时候发现我擦全是全局变量，赶紧申请锁啊。但是后来在调用该函数的时候，忘了放在临界区了；也就是说吃着碗里的，又想盛锅里的。死锁成就1 get，废话不多讲，上代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">a.</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> startElection() &#123;</span><br><span class="line">  rf.mu.Lock()</span><br><span class="line">  <span class="comment">// balalala</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">b.</span><br><span class="line">rf.mu.Lock()</span><br><span class="line"><span class="comment">// balala</span></span><br><span class="line">rf.startElection()</span><br></pre></td></tr></table></figure>

<h4 id="分支break-x2F-return忘记释放锁"><a href="#分支break-x2F-return忘记释放锁" class="headerlink" title="分支break&#x2F;return忘记释放锁"></a>分支break&#x2F;return忘记释放锁</h4><p><code>break，continue，return</code>这种偷偷摸摸的提前结束分支的行为，虽然我们平时干的很开心，但是它不符合人的既定对称认知啊，就导致有时候忘了处理它，什么叫不对称呢？上代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> !check(arg) &#123;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> condition &#123;</span><br><span class="line">  <span class="keyword">if</span> need &#123;</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// because here are so many balalala</span></span><br><span class="line">  <span class="comment">// then break can be used to reduce indent</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>v.s.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> !check(arg) &#123;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> condition &#123;</span><br><span class="line">    <span class="keyword">if</span> !need &#123;</span><br><span class="line">      <span class="comment">// because here are so many balalala</span></span><br><span class="line">      <span class="comment">// then break can be used to reduce indent</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果是后者，对着<code>if else</code>扫一眼对齐，函数有几个出口，一目了然。然而对于前者来说，如果分支语句淹没在巨量代码中，就很容易忘记某个猥琐角落还藏着一个出口，自然就不会上锁。</p>
<p>具体到我的情况，就是在candidate要票的时候，如果得到多数票，就直接变为leader；如果后面仍有人给票，我会判断当前身份是否已经是leader，如果是就直接返回，不在意这些票了，的确好邪恶。。于是，你懂得，返回前忘还回锁了。代码如下，有删节。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(server <span class="type">int</span>, args RequestVoteArgs)</span></span> &#123;</span><br><span class="line">  <span class="comment">// use args to request vote</span></span><br><span class="line">  reply := RequestVoteReply&#123;&#125;</span><br><span class="line">  ok := rf.sendRequestVote(server, &amp;args, &amp;reply)</span><br><span class="line"></span><br><span class="line">  isBecomeLeader := <span class="literal">false</span></span><br><span class="line">  rf.mu.Lock()</span><br><span class="line">  <span class="keyword">if</span> rf.state != Candidate || rf.currentTerm != args.Term&#123;</span><br><span class="line">    rf.mu.Unlock() <span class="comment">//&lt;---就是这个邪恶的地方</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// check the votes</span></span><br><span class="line">  <span class="keyword">if</span> reply.VotedGranted &#123;</span><br><span class="line">    votes++</span><br><span class="line">    DPrintf(<span class="string">&quot;%d get vote from %d, now votes are %d, total members are:%d&quot;</span>,</span><br><span class="line">      rf.me, server, votes, peersCount)</span><br><span class="line">    <span class="keyword">if</span> votes &gt; peersCount/<span class="number">2</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> rf.state == Candidate &#123;</span><br><span class="line">        isBecomeLeader = <span class="literal">true</span></span><br><span class="line">        DPrintf(<span class="string">&quot;%d become leader&quot;</span>, rf.me)</span><br><span class="line">      &#125;</span><br><span class="line">      rf.state = Leader</span><br><span class="line">    &#125;</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> reply.Term &gt; rf.currentTerm &#123;</span><br><span class="line">    rf.currentTerm = reply.Term</span><br><span class="line">    rf.state = Follower</span><br><span class="line">    rf.votedFor = <span class="number">-1</span></span><br><span class="line">   &#125;</span><br><span class="line">  rf.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> isBecomeLeader &#123;</span><br><span class="line">    rf.startHeartbeat()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;(s, args)</span><br></pre></td></tr></table></figure>

<h4 id="Gap之后，注意自检"><a href="#Gap之后，注意自检" class="headerlink" title="Gap之后，注意自检"></a>Gap之后，注意自检</h4><p>由于状态是在多个loop（好吧，也就两个，但是为啥觉得很多呢）中来回改变的，因此在异步&#x2F;阻塞调用前后，可能身份角色（自身）和选举周期（外界）早已天翻地覆，因此需要进行自检。<br>说来惭愧，这个也是在多方查看资料后才意识到的。</p>
<ol>
<li>异步调用，即goroutine内外。</li>
<li>阻塞调用，即rpc前后。</li>
</ol>
<p>Leader进行心跳检测时候，由于是异步调用，所以需要先检测自己还是不是leader，以及是否还在自己任期（由args保存了当时的任期）；当rpc返回后，再一次进行该检查，无误，才能按照自己是leader来进行下一步动作。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(server <span class="type">int</span>, args *AppendEntriesArgs)</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> rf.currentTerm != args.Term || rf.state != Leader &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  reply := &amp;AppendEntriesReply&#123;&#125;</span><br><span class="line">  rf.sendAppendEntries(server, args, reply)</span><br><span class="line"></span><br><span class="line">  rf.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> rf.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> rf.currentTerm != args.Term || rf.state != Leader &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// need handle the reply</span></span><br><span class="line">  <span class="keyword">if</span> reply.Term &gt; rf.currentTerm &#123;</span><br><span class="line">    rf.currentTerm = reply.Term</span><br><span class="line">    rf.state = Follower</span><br><span class="line">    rf.votedFor = <span class="number">-1</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>分布式系统</category>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>raft</tag>
        <tag>6.824</tag>
        <tag>courses</tag>
        <tag>公开课</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 闭包</title>
    <url>/2019/02/23/python-closure/</url>
    <content><![CDATA[<p> <img src="https://i.loli.net/2020/02/09/zMtSnoRFshGc6dl.png" alt="python-learn.png"></p>
<h2 id="小引"><a href="#小引" class="headerlink" title="小引"></a>小引</h2><p>以前学 js 的时候第一次见到闭包，当时不甚了了，还为了应付面试强行记住了一个模棱两可的“定义”：在函数中嵌套定义函数，并且在外层将内层函数返回，一同返回了外层函数的环境。当时从字面意思以及当时一个经典例子试图去理解闭包，加之”闭包”这个翻译也很不容易让人味出其中的道理，导致对其总感觉懵懵懂懂。最近工作需要，用起 python，又遇到闭包，这次看到了一些新奇有趣的资料，这才算大致把一些字面上的概念（first-class functions，bind，scope等等）贯通在一起，反过来对闭包有了更深的理解。</p>
<p>引用资料列在最后，十分推荐大家去读读。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>计算机中有些英文专业词汇，字面直译，难免因缺少上下文而显得苍白拗口，须得多方铺垫，方能味得古怪下面的原理。<strong>闭包</strong>（closure）便是一个这样牵扯了许多上下文的概念，包括编程语言最基本的<strong>绑定</strong>（binding），<strong>环境</strong>（environments），变量<strong>作用域</strong>（scope）以及<strong>函数是第一等公民</strong>（function as the first-class）等等。</p>
<h2 id="Binding（绑定）"><a href="#Binding（绑定）" class="headerlink" title="Binding（绑定）"></a>Binding（绑定）</h2><p>在Python中，binding 是编程语言最基本的抽象手法，它将一个值绑定到一个变量上，并且稍后可以引用或者修改该变量。下面是几种不同层次的绑定，每组语句在运行时将一个名字与对应值绑定到其定义所在的环境中。</p>
<p>包括将名字绑定到一块内存，通过赋值语句实现，当然函数调用时，形参和实参结合也是绑定：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: square = <span class="number">4</span></span><br></pre></td></tr></table></figure>

<p>将名字绑定到一组复合运算，即<strong>函数定义</strong>，利用 <strong>def</strong> 关键字实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">def</span> <span class="title function_">square</span>(<span class="params">x</span>):</span><br><span class="line">        <span class="keyword">return</span> x*x</span><br></pre></td></tr></table></figure>

<p>将名字绑定到一个数据集合，即<strong>类定义</strong>，使用 <strong>class</strong> 实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">class</span> <span class="title class_">square</span>:</span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x</span>):</span><br><span class="line">                self.x = x</span><br><span class="line"></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">value</span>(<span class="params">self</span>):</span><br><span class="line">                <span class="keyword">return</span> self.x * self.x</span><br></pre></td></tr></table></figure>

<p><strong>依照执行顺序，多次同名绑定，后面会覆盖前面</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: square = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: square</span><br><span class="line">Out[<span class="number">2</span>]: <span class="number">3</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: <span class="keyword">def</span> <span class="title function_">square</span>(<span class="params">x</span>):</span><br><span class="line">   ...:     <span class="keyword">return</span> x * x</span><br><span class="line">   ...:</span><br><span class="line">   ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: square</span><br><span class="line">Out[<span class="number">4</span>]: &lt;function __main__.square(x)&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: <span class="keyword">class</span> <span class="title class_">square</span>:</span><br><span class="line">   ...:     <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x</span>):</span><br><span class="line">   ...:         self.x = x</span><br><span class="line">   ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: square</span><br><span class="line">Out[<span class="number">6</span>]: __main__.square</span><br></pre></td></tr></table></figure>

<p>说这些都是抽象，是因为它们提供了对数据，复合操作或数据集合的封装手段，即将一个名称与复杂的数据或逻辑进行捆绑，使调用者不用关心其实现细节，并且以此来作为构建更复杂的工程的基本元素。可以说绑定是编程的基石。</p>
<p>回到本文的主题上来，闭包首先是函数，只不过是一种特殊的函数，至于这个特殊性在哪，等稍后引入更多概念后再进行阐述。</p>
<h2 id="Scope-（作用域）"><a href="#Scope-（作用域）" class="headerlink" title="Scope （作用域）"></a>Scope （作用域）</h2><p>scope（作用域），顾名思义，也就是某个binding 能罩多大的范围，或者说你可以在多大范围内访问一个变量。每个函数定义会构造一个局部定义域。</p>
<p>python，和大多数编程语言一样，使用的是<strong>静态作用域</strong>（static scoping，有时也称 lexical scoping）规则。在函数嵌套定义的时候，内层函数内可以访问外层函数的变量值。因此你可以把作用域想象成一个容器，即它是可以嵌套的，并且内层作用域会扩展外层作用域，而最外层作用域即全局作用域。</p>
<p>上一小节提到了，<strong>多次同名绑定，后面会覆盖前面</strong>，其实有隐含前提：<strong>在同一作用域内</strong>。如果是嵌套作用域，其实是隐藏的关系，内层函数的变量定义会遮蔽外层函数同一名字定义，但是在外层作用域中，该变量仍是原值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: a = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">17</span>]: <span class="keyword">def</span> <span class="title function_">outer</span>(): </span><br><span class="line">    ...:     a = <span class="number">5</span></span><br><span class="line">    ...:     <span class="built_in">print</span>(a)</span><br><span class="line">    ...:     <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">    ...:         a = <span class="number">6</span></span><br><span class="line">    ...:         <span class="built_in">print</span>(a)</span><br><span class="line">    ...:     inner()</span><br><span class="line">    ...:     <span class="built_in">print</span>(a)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: outer()</span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: <span class="built_in">print</span>(a)</span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure>

<p>可以看出，<strong>作用域</strong>其实也可以从另一个角度理解，即我们在某个环境（environment）中，在确定一个name binding 值的时候，会从最内层作用域顺着往外找，找到的第一个该名字 binding 的对应的值即为该 name 引用到的值。</p>
<p>需要强调的时候，函数的嵌套定义会引起定义域的嵌套，或者说环境扩展（内层扩展外层）关系。类的定义又稍有不同，class 定义会引入新的 namespace，namespace 和 scope 是常拿来对比的概念，但这里按下不表，感兴趣的可以自己去查查资料。</p>
<p>说到这里，要提一下，一个常被说起的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">50</span>]: a = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: <span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    ...:     <span class="built_in">print</span>(a) <span class="comment"># 这里应该输出什么？</span></span><br><span class="line">    ...:     a = <span class="number">5</span></span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">52</span>]: test()</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">UnboundLocalError                         </span><br><span class="line">Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">52</span>-fbd55f77ab7c&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> test()</span><br><span class="line"></span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">51</span>-200f78e91a1b&gt; <span class="keyword">in</span> test()</span><br><span class="line">      <span class="number">1</span> <span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">----&gt; <span class="number">2</span>     <span class="built_in">print</span>(a)</span><br><span class="line">      <span class="number">3</span>     a = <span class="number">5</span></span><br><span class="line">      <span class="number">4</span></span><br><span class="line"></span><br><span class="line">UnboundLocalError: local variable <span class="string">&#x27;a&#x27;</span> referenced before assignment</span><br></pre></td></tr></table></figure>

<p>想象中，上面 <code>print</code> 处应该输出 4 或者 5 才对，为什么会报错呢？这是因为 <code>test</code> 函数在定义时候，分词器会扫一遍 test 函数定义中的所有 token，看到赋值语句 <code>a=5</code> 的存在，就会明确 <code>a</code> 是一个局部变量，因此不会输出4。 而在执行到 <code>print(a)</code> 的时候，在局部环境中，<code>a</code> 还未被binding，因此会报 <code>UnboundLocalError</code>。</p>
<p>稍微探究一下，虽然 python 是解释执行的，即输入一句，解释一句，执行一句。但是对于<strong>代码块</strong>（即头部语句，冒号与其关联的缩进块所构成的<strong>复合语句</strong>（compound sentences），常见的有函数定义，类定义，循环语句等等）来说，还是会整体先扫一遍的。</p>
<h2 id="First-Class-Function（函数是第一等公民）"><a href="#First-Class-Function（函数是第一等公民）" class="headerlink" title="First-Class Function（函数是第一等公民）"></a>First-Class Function（函数是第一等公民）</h2><p>一般来说，组成编程语言的元素，如变量，函数和类，会被设定不同的限制，而具有最少限制的元素，被我们成为该编程语言中的<strong>一等公民</strong>。而一等公民最常见的特权有：</p>
<ol>
<li>可以被binding到名字上</li>
<li>可以作为参数在函数中传递</li>
<li>可以作为返回值被函数作为结果返回</li>
<li>可以被包含在其他数据结构中</li>
</ol>
<p>套用到python中的函数来说来说，即一个函数可以被赋值给某个变量，可以被函数接收和返回，可以定义在其他函数中（即嵌套定义）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">32</span>]: <span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    ...:     <span class="built_in">print</span>(<span class="string">&#x27;hello world&#x27;</span>)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: t = test <span class="comment"># 赋值给变量</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: t()</span><br><span class="line">hello world</span><br><span class="line"></span><br><span class="line">In [<span class="number">35</span>]: <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">func</span>):</span><br><span class="line">    ...:     <span class="built_in">print</span>(<span class="string">&#x27;wrapper&#x27;</span>)</span><br><span class="line">    ...:     func()</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">36</span>]: wrapper(t) <span class="comment"># 作为参数传递</span></span><br><span class="line">wrapper</span><br><span class="line">hello world</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: <span class="keyword">def</span> <span class="title function_">add_num</span>(<span class="params">a</span>): </span><br><span class="line">    ...:     <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">b</span>): <span class="comment"># 嵌套定义</span></span><br><span class="line">    ...:         <span class="keyword">return</span> a + b</span><br><span class="line">    ...:     <span class="keyword">return</span> add <span class="comment"># 作为函数的返回值</span></span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: add5 = add_num(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: add5(<span class="number">4</span>)</span><br><span class="line">Out[<span class="number">39</span>]: <span class="number">9</span></span><br></pre></td></tr></table></figure>

<p>并不是在所有语言中，函数都是一等公民，比如 Java，上面四项权利 Java 中的函数全都没有。</p>
<p>在这里，能够操作其他函数的函数（即以其他函数作为参数或者返回值的函数），叫做<strong>高阶函数</strong>。高阶函数使得语言的表达能力大大增强，但同时，也不容易用好。</p>
<h2 id="Stack-Call（栈式调用）"><a href="#Stack-Call（栈式调用）" class="headerlink" title="Stack Call（栈式调用）"></a>Stack Call（栈式调用）</h2><p>每个函数调用，会在环境中产生一个<strong>栈帧</strong>（frame），并且在栈帧中会进行一些绑定，然后压入函数调用栈中。在函数调用结束时，栈帧会被弹出，其中所进行的绑定也被解除，即垃圾回收，局部作用域也随之消亡。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">47</span>]: <span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    ...:     x = <span class="number">4</span></span><br><span class="line">    ...:     <span class="built_in">print</span>(x)</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: test()</span><br><span class="line"><span class="number">4</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">49</span>]: x</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">NameError                                 </span><br><span class="line">Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">49</span>-6fcf9dfbd479&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; <span class="number">1</span> x</span><br><span class="line"></span><br><span class="line">NameError: name <span class="string">&#x27;x&#x27;</span> <span class="keyword">is</span> <span class="keyword">not</span> defined</span><br></pre></td></tr></table></figure>

<p>即在调用结束后，局部定义的变量  <code>x</code> 在外边是访问不到的。但是如之前例子 中，返回的 <code>add  </code>函数却引用了已经调用结束的 <code>add_num</code> 中的变量 <code>a</code>，怎么解释这种现象呢？可以记住一条，也是之前提到过的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">函数嵌套定义时，内部定义的函数所在的环境会自动扩展其定义所在环境</span><br></pre></td></tr></table></figure>

<p>因此在外部函数返回后，返回的内部函数依然维持了其定义时的扩展环境，也可以理解为由于内部函数引用的存在，外部函数的环境中所有的 bindings 并没有被回收。</p>
<h2 id="Closure（闭包）"><a href="#Closure（闭包）" class="headerlink" title="Closure（闭包）"></a>Closure（闭包）</h2><p>千呼万唤始出来，以为高潮其实已结束。</p>
<p>闭包就是建立在前面的这些概念上的，上面提到的某个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">37</span>]: <span class="keyword">def</span> <span class="title function_">add_num</span>(<span class="params">a</span>): </span><br><span class="line">    ...:     <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">b</span>): <span class="comment"># 嵌套定义</span></span><br><span class="line">    ...:         <span class="keyword">return</span> a + b</span><br><span class="line">    ...:     <span class="keyword">return</span> add <span class="comment"># 作为函数的返回值</span></span><br><span class="line">    ...:</span><br><span class="line">    ...:</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: add5 = add_num(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">39</span>]: add5(<span class="number">4</span>)</span><br><span class="line">Out[<span class="number">39</span>]: <span class="number">9</span></span><br></pre></td></tr></table></figure>

<p>其实就是<strong>闭包</strong>。捡起之前伏笔，给出我对闭包的一个理解：它是一种<strong>高阶函数</strong>，并且外层函数（例子中的*<code>add_num</code><em>）将其内部定义的函数（</em><code>add</code><em>）作为返回值返回，同时由于返回的内层函数扩展了外层函数的<strong>环境</strong>（environment），也就是对其产生了一个引用，那么在调用返回的内部函数（</em><code>add5</code>*）的时候，能够引用到其（<code>add</code>）定义时的外部环境（在例子中，即 <code>a</code> 的值）。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>说了这么多，其实只是在逻辑层面或者说抽象层面去解释<strong>闭包</strong>是什么，跟哪些概念纠缠在一起。但这些其实都不本质，或者说依然是空中楼阁，如果想要真正理解<strong>闭包</strong>，可以去详细了解下 python 的解释执行机制，当然，那就是编译原理范畴的东西了。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9jczYxYS5vcmcv">cs61a<i class="fa fa-external-link-alt"></i></span> 课程资料： <span class="exturl" data-url="aHR0cDovL2NvbXBvc2luZ3Byb2dyYW1zLmNvbS8=">composing programs<i class="fa fa-external-link-alt"></i></span>，也是 <span class="exturl" data-url="aHR0cHM6Ly93ZWIubWl0LmVkdS9hbGV4bXYvNi4wMzcvc2ljcC5wZGY=">SICP<i class="fa fa-external-link-alt"></i></span> 一书的配套课程，书是神书，课程是好课程，资料更是有趣，不妨一读。</li>
<li>谷歌到的不错的文章： <span class="exturl" data-url="aHR0cHM6Ly9tZWRpdW0uY29tL0BkYW5ueW1jd2F2ZXMvYS1weXRob24tdHV0b3JpYWwtdG8tdW5kZXJzdGFuZGluZy1zY29wZXMtYW5kLWNsb3N1cmVzLWM2YTNkM2JhMDkzNw==">A Python Tutorial To Understanding Scopes and Closures<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>closure</tag>
        <tag>闭包</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 混入类 Mix-Ins</title>
    <url>/2019/03/06/python-mixins/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/zMtSnoRFshGc6dl.png" alt="python-learn.png"></p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>某次在用到 Python 的 socketserver 时，看到了 <code>ForkingMixIn</code> 和 <code>ThreadingMixIn</code>。当时就对这种插件式语法糖感觉很神奇。最近自己写代码，也想写一些这种即插即用的插件代码，于是对 python 的 mix-in 机制探究了一番。</p>
<p>简单来说它是利用多继承的特性，通过插拔额外代码片段，对原类进行花样式增强的一种技术。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><p>开宗明义，先说结论，使用MixIn，总结起来只需注意几个要点：</p>
<ol>
<li>Mix-in class 本质上是<strong>代码片段</strong>，不能独立存活。</li>
<li>增强“兄弟” [1] 类中的同名函数功能，来达到<strong>可插拔</strong>的效果。</li>
<li>定义子类时，基类继承顺序不能乱，MixIn 类须在被混入类前面。</li>
</ol>
<h2 id="代码片段"><a href="#代码片段" class="headerlink" title="代码片段"></a>代码片段</h2><p>与静态语言不同，Python 是动态binding。因此在定义时，是可以作为代码片段独立“存在”（但并不能“存活”，即不能用其来定义类的实例，进行binding），并且可以引用该片段中并不存在的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SetOnceMappingMixin</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Only allow a key to be set once.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    __slots__ = ()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setitem__</span>(<span class="params">self, key, value</span>):</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self:</span><br><span class="line">            <span class="keyword">raise</span> KeyError(<span class="built_in">str</span>(key) + <span class="string">&#x27; already set&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().__setitem__(key, value)</span><br></pre></td></tr></table></figure>

<p>该代码片段显然不能单独进行实例化，但是单独定义并无妨，而且它假设被混入类具有<code>__setitem__</code> 。</p>
<h2 id="多继承替换"><a href="#多继承替换" class="headerlink" title="多继承替换"></a>多继承替换</h2><p>既然是可插拔，那么便是有没有该Mixin，被混入类[2] API 保持不变。而实现这一机制的原理，便是使用同名函数来替换原函数。而Mixin强调插件作用，即在原有函数实现上，增加额外功能。为了达到这一目的，须复用原函数。而Python中具有该功效的函数，便是<code>super()</code>。</p>
<p>在只允许单继承的编程语言中，如Java，super() 毫无争议的是获取父类的引用。但是对于支持多继承的 Python 来说，super() 最终指向谁，就需要安排安排了，看以下例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Base.__init__&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">Base</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__() <span class="comment"># 1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;A.__init__&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">B</span>(<span class="title class_ inherited__">Base</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__() <span class="comment"># 2</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;B.__init__&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">C</span>(A,B):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__() </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;C.__init__&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    c = C()</span><br></pre></td></tr></table></figure>

<p>可以猜猜输出是什么，然后注释掉 #1 和 #2 看下输出什么。</p>
<p>原因在于，对于每个类，Python会计算出一个方法解析顺序（MRO）列表。通过<code>super().func()</code> 函数会沿着该列表从前往后遍历，找到第一个具有 <code>func</code> 函数的类，然后调用该函数。MRO列表的构建规则很简单，不严谨的说就是<strong>从左往右，从下到上</strong>。</p>
<p>因此类 <code>C</code>的 MRO 列表为[3]：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>C.__mro__</span><br><span class="line">(&lt;<span class="keyword">class</span> <span class="string">&#x27;__main__.C&#x27;</span>&gt;, &lt;<span class="keyword">class</span> <span class="string">&#x27;__main__.A&#x27;</span>&gt;, &lt;<span class="keyword">class</span> <span class="string">&#x27;__main__.B&#x27;</span>&gt;,</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;__main__.Base&#x27;</span>&gt;, &lt;<span class="keyword">class</span> <span class="string">&#x27;object&#x27;</span>&gt;)</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>

<p>但如果类继承搞的极度混乱，比如说如果出现环形依赖，在获取 <code>C.__mro__</code> 时就会报错： <code>TypeError: Cannot create a consistent method resolution</code> ，这里不详细展开，感兴趣的朋友可以自行去 Google。</p>
<p>回到混入类上来，这样依赖，在定义子类时候，混入类为什么要定义在被混入类的前面，也就清楚了：为了使得混入类可以通过 <code>super()</code> 方法调用被混入类的同名函数。</p>
<p>一个完整的例子[4]如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SetOnceMappingMixin</span>:</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Only allow a key to be set once.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    __slots__ = ()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setitem__</span>(<span class="params">self, key, value</span>):</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self:</span><br><span class="line">            <span class="keyword">raise</span> KeyError(<span class="built_in">str</span>(key) + <span class="string">&#x27; already set&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().__setitem__(key, value)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SetOnceDefaultDict</span>(SetOnceMappingMixin, defaultdict):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">d = SetOnceDefaultDict(<span class="built_in">list</span>)</span><br><span class="line">d[<span class="string">&#x27;x&#x27;</span>].append(<span class="number">2</span>)</span><br><span class="line">d[<span class="string">&#x27;x&#x27;</span>].append(<span class="number">3</span>)</span><br><span class="line"><span class="comment"># d[&#x27;x&#x27;] = 23  # KeyError: &#x27;x already set&#x27;</span></span><br></pre></td></tr></table></figure>



<h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><p>[1] 这里的 “兄弟”关系指的是多继承中的两个类的关系。比如 <code>class Child(A, B)：pass</code> 中类 <code>A</code> 和 <code>B</code> 就是兄弟关系。</p>
<p>[2] 被混入类，即Mixin的“兄弟”。如 <code>class Strong(Week, PowerMixIn)</code> ，<code>Week</code> 即是 <code>PowerMixin</code> 的被混入类。</p>
<p>[3] 调用父类方法：<span class="exturl" data-url="aHR0cHM6Ly9weXRob24zLWNvb2tib29rLnJlYWR0aGVkb2NzLmlvL3poX0NOL2xhdGVzdC9jMDgvcDA3X2NhbGxpbmdfbWV0aG9kX29uX3BhcmVudF9jbGFzcy5odG1s">https://python3-cookbook.readthedocs.io/zh_CN/latest/c08/p07_calling_method_on_parent_class.html<i class="fa fa-external-link-alt"></i></span></p>
<p>[4] 利用Mixins扩展类功能： <span class="exturl" data-url="aHR0cHM6Ly9weXRob24zLWNvb2tib29rLnJlYWR0aGVkb2NzLmlvL3poX0NOL2xhdGVzdC9jMDgvcDE4X2V4dGVuZGluZ19jbGFzc2VzX3dpdGhfbWl4aW5zLmh0bWw=">https://python3-cookbook.readthedocs.io/zh_CN/latest/c08/p18_extending_classes_with_mixins.html<i class="fa fa-external-link-alt"></i></span> </p>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>mixins</tag>
        <tag>混入类</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Logging 库分析</title>
    <url>/2019/03/16/python-logger/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/zMtSnoRFshGc6dl.png" alt="python-learn.png"></p>
<h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><p>使用 Logging 前可以先捋一下我们常见的日志输出需求，俗话说，不管需求的设计就是耍流氓。</p>
<ol>
<li>能够定位<a href="#logevent">事件</a>（Event）的产生位置（代码文件&amp;行数）和生成时间，用于调试和跟踪。</li>
<li>一份日志可以同时送到多个<a href="#dstout">目标输出</a>。</li>
<li>可以通过不同级别或者更精细条件筛选日志输出。</li>
<li>可以方便的控制第三方模块的日志输出。</li>
<li>实现上面的一切的前提下，配置&#x2F;设置 尽量简单。</li>
</ol>
<p>Python 的 Logging 模块通过神奇的模块化设计，<a href="#tree">树</a>形的方式组织完美的实现了以上五点。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="模块设计"><a href="#模块设计" class="headerlink" title="模块设计"></a>模块设计</h2><p>Python 的 logger 抽象出了几个具有从属关系的元概念，Logger，Handler ，Filter和  Formattor 作为 logger 实现的基石。</p>
<ol>
<li>Loggers 提供了应用代码可以直接使用的接口</li>
<li>Handlers 将（loggers生成的）日志记录分发到合适的输出</li>
<li>Filters 提供了对哪些日志进行输出的精细控制</li>
<li>Formatters 则决定了日志在最终的输出上样式</li>
</ol>
<h3 id="Loggers"><a href="#Loggers" class="headerlink" title="Loggers"></a>Loggers</h3><p><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9saWJyYXJ5L2xvZ2dpbmcuaHRtbCNsb2dnaW5nLkxvZ2dlcg==">Logger<i class="fa fa-external-link-alt"></i></span> 类作为日志库的基本模块，能做三件小事：</p>
<ul>
<li>它是在用户代码中进行日志输出调用的类，暴露了<code>debug(), info()</code> 等接口；</li>
<li>根据日志级别和 filter 类决定用户调用该类（<code>logger.info(msg)</code>）时，是否创造一个日志记录（LogRecord）并传递该日志输出的事件；</li>
<li>作为日志模块树的一个节点，将该事件往根部传递，所有处于传递路径（该logger-&gt;parent logger -&gt; … -&gt; root logger）上的所有 logger 节点添加的所有 Handler 都会相应该事件。当然，通过设置 logger 的 propagate &#x3D; False 或者没有parent logger 可以阻止事件传播。</li>
</ul>
<h3 id="Handlers"><a href="#Handlers" class="headerlink" title="Handlers"></a>Handlers</h3><p><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9saWJyYXJ5L2xvZ2dpbmcuaHRtbCNsb2dnaW5nLkhhbmRsZXI=">Handler<i class="fa fa-external-link-alt"></i></span> 负责将符合级别要求的日志消息分发到各种 handler 指定的目标输出。Logger 实例可以通过 <code>addHandler</code> 方法添加零到多个 Handler。<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9ob3d0by9sb2dnaW5nLmh0bWwjdXNlZnVsLWhhbmRsZXJz">常见的可以添加的 Handler<i class="fa fa-external-link-alt"></i></span> 子类有 <code>StreamHandler</code>，<code>FileHandler</code>，<code>BaseRotatingHandler</code> 等等。</p>
<p>设想一个场景，某个应用想将所有级别日志信息输出到文件中，将 error 级别以上的日志在标准输出显示，而将所有severity 以上的日志通过邮件报警。那么就可以设置三个 handler，每个handler分别负责捕获不同级别的消息，并且发送到不同的目标输出。</p>
<p>Handler 的最常用的几个方法：</p>
<ul>
<li><code>setLevel()</code> 和 logger 的同名方法一样，设置最低有效级别。只不过 logger 的行为是将该级别以上的日志消息发送给其所有handler，而 handler的行为是将该级别以上的日志消息输出到相应目标输出。</li>
<li><code>setFormatter()</code> 选择该 handler 输出的布局和格式。</li>
<li><code>addFilter()</code> 和 <code>removeFilter</code> 增删过滤规则，用以决定某条日志消息是要过滤掉。</li>
</ul>
<p>应用程序不要直接使用 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9saWJyYXJ5L2xvZ2dpbmcuaHRtbCNsb2dnaW5nLkhhbmRsZXI=">Handler<i class="fa fa-external-link-alt"></i></span> 类，这只是一个基类，规定了一些接口和默认行为。</p>
<h3 id="Formatters"><a href="#Formatters" class="headerlink" title="Formatters"></a>Formatters</h3><p>与 Handler 不同的是，用户程序可以直接实例化并使用 <code>logging.Formatter</code> 类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">logging.Formatter.__init__(fmt=<span class="literal">None</span>, datefmt=<span class="literal">None</span>, style=<span class="string">&#x27;%&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>其中 <code>fmt</code> 规定消息布局和格式，<code>datefmt</code>  指定日期显示格式，<code>style</code> 指定 <code>fmt</code> 串中变量解析方式。</p>
<p>想说下的几个点是</p>
<ul>
<li><code>fmt</code> 不仅可以指定格式，在 terminal 进行输出时，可以使用 <code>ColoredFormatter</code> 设定配色方案，使命令行输出变的炫酷起来。</li>
<li><code>style</code> 是 <code>%, ‘&#123;‘ or ‘$’</code> 三选一，默认是 <code>%</code>。但 python3 推荐用 <code>str.format</code> 方式进行字符串格式化，可以改成 <code>style = &#39;&#123;&#39;</code></li>
</ul>
<h3 id="Filters"><a href="#Filters" class="headerlink" title="Filters"></a>Filters</h3><p>精细的控制日志过滤，就先不讲啦，高阶玩家可以自己去看官方文档。</p>
<h2 id="树形组织"><a href="#树形组织" class="headerlink" title="树形组织"></a>树形组织</h2><p>Logging 库利用 Python 中天然存在的 Module 间的树形层次结构构建了以 Logger 为树节点的日志系统。这表现在</p>
<ol>
<li>logger 和 module_name 具有一一对应关系</li>
<li>logger 的“有效级别”（<em>effective level</em>）是通过树中向上遍历确定的</li>
<li>logger 会将事件（写某条日志）沿着树结构像上传递，所有含有 handlers 的 logger 节点都会进行响应</li>
</ol>
<p>此外，日志模块有个内置的根节点，负责给所有模块日志输出行为一个默认实现。可以通过 <code>root_logger = Logging.getLogger()</code> 即 <code>module_name = None</code> 来获取。该 root_logger 默认的有效日志级别为 <code>WARNING</code>，并 添加了一个默认的 handler，该 handler 绑定了一个简单的 formatter。</p>
<p>也就是说，用户无需任何配置，只要通过 <code>root_logger = Logging.getLogger()</code>  获取 <code>root_logger</code> 即可进行日志输出。而有额外需求的用户，则可以通过前述机制对不同模块的输出位置和布局格式进行精细化的配置。这种<strong>开箱即用 + 增量细调</strong> 的设计时程序框架常见的手法，可以同时兼顾入门菜鸟和高阶玩家的不同需求。</p>
<h3 id="一一对应"><a href="#一一对应" class="headerlink" title="一一对应"></a>一一对应</h3><p>每个logger 是和 python 的 module_name 一一对应的单例。也就是说，在同一进程中，不同位置通过：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">smap_logger = logging.getLogger()</span><br></pre></td></tr></table></figure>

<p>获取的smap_logger 是同一实例。</p>
<h3 id="有效级别"><a href="#有效级别" class="headerlink" title="有效级别"></a>有效级别</h3><p>logger 有一个<strong>有效级别</strong>的概念，当一个 logger 没有被显式的设置日志级别（setLevel）的时候，它就会使用其父节点 logger 的日志级别。如果其父节点的日志级别也没有被显式设置，就会继续看其祖父节点。如此往复，直到找到一个被显式设置了有效级别的 logger 节点。当然，无论如何这个搜寻过程都会在根节点结束，而根节点默认的级别为 <code>WARNING</code>。</p>
<p>当 logger 接收到一个日志输出的事件时，会根据其有效级别来确定该事件是否会分发给该 logger 所添加的所有 handlers。</p>
<h3 id="事件响应"><a href="#事件响应" class="headerlink" title="事件响应"></a>事件响应</h3><p>子 loggers 会将日志事件沿着树中的路径向其祖先传递。因此并不需要为所有 logger 绑定 handler，只需要在几个合适的关键顶层节点添加 handler 就可以使得其所有子分支上的日志节点，按该 handler 的行为进行日志输出。</p>
<p>当然，你还可以通过设置某 logger 的 <em>propagrate</em> 属性为 <code>False</code> 来阻止该节点向上传递日志事件。</p>
<p>输出日志流程，可以用下面一张图来说明：</p>
<p><img src="https://docs.python.org/3/_images/logging_flow.png" alt="Logging Flow"></p>
<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h3 id="一个-example"><a href="#一个-example" class="headerlink" title="一个 example"></a>一个 example</h3><p>官方文档提供的一个最基本示例，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="comment"># create logger</span></span><br><span class="line">logger = logging.getLogger(<span class="string">&#x27;simple_example&#x27;</span>)</span><br><span class="line">logger.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create console handler and set level to debug</span></span><br><span class="line">ch = logging.StreamHandler()</span><br><span class="line">ch.setLevel(logging.DEBUG)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create formatter</span></span><br><span class="line">formatter = logging.Formatter(<span class="string">&#x27;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add formatter to ch</span></span><br><span class="line">ch.setFormatter(formatter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add ch to logger</span></span><br><span class="line">logger.addHandler(ch)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#x27;application&#x27; code</span></span><br><span class="line">logger.debug(<span class="string">&#x27;debug message&#x27;</span>)</span><br><span class="line">logger.info(<span class="string">&#x27;info message&#x27;</span>)</span><br><span class="line">logger.warning(<span class="string">&#x27;warn message&#x27;</span>)</span><br><span class="line">logger.error(<span class="string">&#x27;error message&#x27;</span>)</span><br><span class="line">logger.critical(<span class="string">&#x27;critical message&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>此外，像 log4j 等 Java 的日志框架一样，这些配置能通过配置文件来完成。包括基本格式和YAML格式。<strong>官方文档</strong>都有讲。</p>
<h3 id="自己的例子"><a href="#自己的例子" class="headerlink" title="自己的例子"></a>自己的例子</h3><p>我在写 smap（slice-map，对数据集分片，分发到多机执行map的一个计算框架）的 Python 库时，想实现功能：可以让用户侧在使用该库时，动态设置该库的日志级别。当时还费劲心机的将日志级别作为一个参数，传递到框架中，然后每次用之前先将该模块的 logger 设置为该有效级别。</p>
<p>如果能早就知道 logging 库模块级别的单例以及树形组织设计，那么基本上实现这个功能就啥也不用做，只需要告诉用户我使用的是 logging 日志库就可以了。用户就可以通过 </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">smap_logger = logging.getLogger()</span><br><span class="line">smap_logger.setLevel(logging.INFO)</span><br></pre></td></tr></table></figure>

<p>就行了。</p>
<h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><p><span id="tree">「<strong>树</strong>」</span>：是计算机中一种常用的数据结构，用来模拟具有树种结构性质的<strong>数据集合</strong>，看起来像一棵根朝上，叶朝下的倒挂树。详细参见<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU2JUEwJTkxXyglRTYlOTUlQjAlRTYlOEQlQUUlRTclQkIlOTMlRTYlOUUlODQp">维基百科<i class="fa fa-external-link-alt"></i></span>。</p>
<p>「<strong>父节点，祖先节点</strong>」：都是树这种数据结构范畴内的概念。</p>
<p><span id="logevent">「<strong>日志事件</strong>」</span>： 由 <code>logger.info()</code> 等 API 调用产生，发送给日志系统，让系统决定如何响应该事件在合适位置进行以合适布局和格式进行输出。其他所谓<strong>消息</strong>（<code>Message</code>），<strong>日志记录</strong>（<code>LogRecord</code>）其实都是类似的意思。</p>
<p><span id="dstout">「<strong>目标输出</strong>」</span>：各种输出目的地，比如说标准输出（stdout），文件（File），数据库（db），邮件（email），中心化日志服务（log service）等等。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9ob3d0by9sb2dnaW5nLmh0bWw=">Logging facility for Python<i class="fa fa-external-link-alt"></i></span>， 该篇大部分来源于此，只是做了个翻译和重新组织。</li>
</ol>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>logger</tag>
        <tag>logging</tag>
        <tag>日志模块</tag>
      </tags>
  </entry>
  <entry>
    <title>Finding a Needle in Haystack：Facebook&#39;s Photo Storage</title>
    <url>/2019/03/24/haystack/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/NIHbnLgEcsa7rSB.png" alt="serving a photo"></p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>Haystack 的基本思想就是将索引信息放在内存中，避免额外的IO。为了做到这一点，主要进行了两方面的设计：</p>
<ol>
<li>将小文件集合成大文件，减少文件数，从而减少了元信息的数目。</li>
<li>精简文件元信息，去掉一切在 Facebook 场景中不需要的 POSIX 语义中元信息。</li>
</ol>
<p>这样就可以将数据元信息减小到一个内存可以放的下的量级，基本上每次每次数据访问同一个一次 IO 就可以完成，而非以前的好几次。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="Facebook业务量级"><a href="#Facebook业务量级" class="headerlink" title="Facebook业务量级"></a>Facebook业务量级</h2><p>2600w， 20P</p>
<p>峰值每秒钟100w图片。</p>
<h2 id="key-observation"><a href="#key-observation" class="headerlink" title="key observation"></a>key observation</h2><p>传统文件系统设计导致了过多的元信息查找，我们进行的减少了每个图片的元信息使得Haystack 能够在内存中进行所有的元信息查找操作。</p>
<h2 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h2><p>是一个对象存储，用来存分享的图片，针对的是一次写，经常读，从来不改，很少删的数据集。不得不造轮子，因为传统的分拣系统在如此高并发下，表现太差。</p>
<h2 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h2><p>POSIX：目录组织，并且每个文件存了过多的我们用不到的元信息，如用户权限。而在读文件的时候，元信息必须预先读入内存，在有数十亿量级的文件时，这几乎是不可忍受的。尤其对于NAS（network attached storage）</p>
<p>一个图片读写需要三次访问磁盘：</p>
<ol>
<li>将文件名翻译为inode</li>
<li>从磁盘读入inode</li>
<li>根据inode信息读文件本身</li>
</ol>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p><strong>高并发低延迟</strong>： CDN太贵，只能减少单个文件的metadata，然后将所有metadata保存在内存中，尽量做到一次访盘。</p>
<p><strong>容错</strong>：异地备份</p>
<p><strong>花销</strong>： 比 CND 便宜。</p>
<p><strong>简单</strong>： 没有那么长时间的完善和测试，为了可用，只能做到尽量简单。 </p>
<h2 id="旧流程"><a href="#旧流程" class="headerlink" title="旧流程"></a>旧流程</h2><p>首先访问 webserver，获取图片的的全局URL，里面包含图片的位置信息。然后用CDN做缓存，命中返回，否则去 photo storage加载到CDN再访问。</p>
<p>一个文件夹存数千张图片的时候，目录到block映射增大，一次不能载入内存，更加重了访问次数。</p>
<p>总之，我们明白了无论是内部缓存还是外部缓存（memcached），都无助于长尾形式的访问流量。</p>
<p>RAM-to-disk 比率，提高这个比率，但是一个图片最少占一个inode，从而带来至少数百比特的额外元信息占用。</p>
<h2 id="新设计"><a href="#新设计" class="headerlink" title="新设计"></a>新设计</h2><p>传统来说，如果网页静态内容服务如果出现瓶颈，就用CDN来解决。但是长尾文件的访问还需另谋他路，当然我们承认非热门图片的请求是可以访盘的，但是我们可以减少这个次数。</p>
<p>一个图片存一个文件元信息太多，那么直观的想法就是一堆图片存成一个文件。</p>
<p>接下来我们区分两种元信息：</p>
<ol>
<li>应用元信息，用来构建浏览器可以用来检索图片的URL。</li>
<li>文件系统元信息，用以让某个主机在其磁盘上定位该图片。</li>
</ol>
<h3 id="概览-1"><a href="#概览-1" class="headerlink" title="概览"></a>概览</h3><p>三个主要组件：Haystack Store, Haystack Directory, Haystack Cache，简略起见，我们将 Haystack 省略代称为存储，目录和缓存。</p>
<ol>
<li>Store 对图片的持久化层做了封装，是唯一管理图片文件元信息的组件。实现上来说，我们将主机的存储进行划分，称为一个个物理上的 Volume。然后不同主机上的某几个物理 volume 作为一组称为一个逻辑上的 volume。那么这几个物理上的volume就是该逻辑 volume 的 replica，以进行备份，容错和分流。</li>
<li>Directory 维护了逻辑到物理的映射，以及另外一些应用信息，包括图片到逻辑volume的映射，有空闲空间的逻辑volume</li>
<li>Cache 起内部CDN的作用。当对热门图片的请求过来时，上层CDN不可用或者没命中时，屏蔽了直接对store的访问。</li>
</ol>
<p>一个典型的要访问CDN的图片请求URL长这样：http:&#x2F;&#x2F;⟨CDN⟩&#x2F;⟨Cache⟩&#x2F;⟨Machine id⟩&#x2F;⟨Logical volume, Photo⟩ </p>
<p>在CDN，Cache，Machine，层如果命中就返回，否则剥离该层次地址，然后将请求转发到下一层。</p>
<p><img src="https://i.loli.net/2020/02/09/NIHbnLgEcsa7rSB.png" alt="serving a photo"></p>
<p>上传一个图片的时候，首先请求被打到 web server 中；然后 server 从 Directory 中选择一个可写的逻辑卷（logic volume）。最后，webserver 给该图片一个 id，并且将图片上传到选定的逻辑卷对应的几个物理卷中。</p>
<p><img src="https://i.loli.net/2020/02/09/f5ZAatgdiFNDWUI.png" alt="up loading a photo"></p>
<p>这里我有两个问题：1. 如何选择逻辑卷？和图片请求的大区相关吗？ 2. 明显有可能造成不一致。即从 Directory 选择逻辑卷后，写的时候发现全满了或者网络问题写失败怎么办？试看paper接下来怎么说。</p>
<h3 id="Haystack-Directory"><a href="#Haystack-Directory" class="headerlink" title="Haystack Directory"></a>Haystack Directory</h3><p>Directory 负责四方面的功能：</p>
<ol>
<li>维护逻辑卷到物理卷的映射</li>
</ol>
<p>webserver 使用该映射关系进行上传图片和构建图片请求URL</p>
<ol start="2">
<li><p>负责逻辑卷间写的负载均衡和跨物理卷间的读</p>
</li>
<li><p>决定一个请求是由CDN处理还是Cache处理</p>
</li>
<li><p>检查是否由于逻辑卷达到容量或者操作原因导致逻辑卷变为只读</p>
</li>
</ol>
<h3 id="Haystack-Cache"><a href="#Haystack-Cache" class="headerlink" title="Haystack Cache"></a>Haystack Cache</h3><p>Cache 会从CDN或者直接从用户浏览器收到图片的HTTP请求。Cache被组织成了分布式的Hash Table，并且用图片的 id 去定位 cache。命不中，则从根据 URL 从指定 Store 拉去图片。</p>
<p>只有当满足</p>
<ol>
<li>请求直接从浏览器而非 CDN 过来。</li>
<li>图片被从可写服务器拉去</li>
</ol>
<p>才会在 Cache 中缓存该请求的图片。</p>
<p>理由二是因为a. 图片被写后往往会很快被读取  b. 读写分开速度会更快</p>
<h3 id="Hyastack-Store"><a href="#Hyastack-Store" class="headerlink" title="Hyastack Store"></a>Hyastack Store</h3><p>Haystack 的主要设计就在于 Store 的组织上。</p>
<p>每个物理卷在物理上是一个大文件，每个 Store 机器和通过一个逻辑卷id + offset 来迅速定位一个图片。Heystack 一个关键设计就在于此：不用硬盘访问就可以获取某个图片的文件名，偏移量和大小。因为Store 的每个物理节点一直在内存中维护着每个物理卷对应文件的描述符和图片 id 到其元信息的映射。</p>
<p>具体组织上来说，每个物理卷就是一个包含一个超级块（superblock）和一系列 needles。每个needle保存图片元信息和图片本身。其中 flag 是为了标记该图片是否被删除，cookie 是在上传图片时随机生成，为了防止猜 url ，而 alternate key 是为了保存同一个图片的不同分辨率的文件而增加的。Data Checksum 进行数据校验，而 padding 可能是为了硬盘块对齐。</p>
<p><img src="https://i.loli.net/2020/02/09/JBYr8FL4O53Cz6Q.png" alt="layout of haystack store file"></p>
<p>为了加快图片的访问，物理机在内存中维护所有图片的基本元信息，如下图，只剩下了最简单的几项信息。为了加快机器重启后内存中元信息的构建，物理机会将内存中的这些元信息定期做 snapshot 即 index file；其顺序和 store file 保持一致。</p>
<p><img src="https://i.loli.net/2020/02/09/9AKPDpN7OwBgTVM.png" alt="layout of haystack index file"></p>
<p>根据上述物理结构，我们来过一遍 Haystack 每个 API 对应的实际流程：</p>
<h4 id="Photo-Read"><a href="#Photo-Read" class="headerlink" title="Photo Read"></a>Photo Read</h4><p>一个来自 Cache 的读请求会携带 volume id, key, alternate key 和 cookie，Store 物理机会在内存中查找图片相关的元信息，找到（文件描述符，offset 和 size）， 从而读出该图片文件及其元信息；然后进行 cookie 比对和 checksum 校验，通过后返回图片数据。</p>
<h4 id="Photo-Write"><a href="#Photo-Write" class="headerlink" title="Photo Write"></a>Photo Write</h4><p>来自 web server 的写请求会携带逻辑 volume id，key，alternate key，cookie 和 图片数据，每个物理机会同步的将这些信息追加到对应的 Store file 中。对于图片的 update 请求（比如图片旋转），我们也是进行简单的追加。但这样会造成重复的 key + alternate key；如果其和原图片落在不同逻辑卷中，Directory 只需要更新图片到逻辑卷的映射就行；如果落在同一个逻辑卷，那么通过 offset 就能获取版本的新旧（看起来除了index file 这种顺序组织，还有是利用 id 作为索引的 dict，新旧的元信息会落到一个桶内，每次取offset大的那个）</p>
<h4 id="Photo-Delete"><a href="#Photo-Delete" class="headerlink" title="Photo Delete"></a>Photo Delete</h4><p>删除文件很直观，就是同步的依次设置下内存和 store  file 中对应图片元信息的 flag。如果请求到某个被删的 Photo，在内存中发现其 flag 被设置了，就报一个异常。暂时的，被置为已删除的图片所占的空间会暂时不可用；在定期的紧缩（compact）时，会回收这部分空间。</p>
<h4 id="The-Index-File"><a href="#The-Index-File" class="headerlink" title="The Index File"></a>The Index File</h4><p>然后说回 index file。既然是定期做 snapshot 得到的 index file ，那么就会有宕机一致性问题。包括，新增文件写入 volume 和内存后没有及时写到 index file 就宕机；设置某图片 Store file 和内存删除 flag 时候没有及时同步到 index file 就宕机。应对这两个问题也简单，对于前者在重启时，读index file 时候，可以对比对应 offset 的 volume id，看是否是最新的，否则将最新的补到 index 和内存中就行；对于后者，每次读取图片时，除了内存中做检查，额外检查下 Store file 中图片的删除 flag 是否被设置，并将其同步到内存和 index file 中。</p>
<h4 id="Filesystem"><a href="#Filesystem" class="headerlink" title="Filesystem"></a>Filesystem</h4><p>此外，为了减少不必要的读盘，没有采用传统的 POSIX 文件系统，而是用了对大文件友好的 XFS。</p>
<h3 id="错误恢复"><a href="#错误恢复" class="headerlink" title="错误恢复"></a>错误恢复</h3><p>跑在大规模廉价硬件上的系统总避免不了出现一些错误，比如说硬件驱动错误，RAID 控制器问题，主板故障等等。我们的应对方法也简单，做了两件小事，一个是定期检测，一个是适时恢复。</p>
<p>我们用一个叫 Pitchfork（草叉） 的后台任务，定期检测每台存储节点（Store machine）的健康状况。比如查看与每个节点的连通情况，每个 volume 的可用性，并尝试从物理节点读一些数据以进行测试。一旦健康检查失败，Pitchfork 程序就回标记该物理机上的所有 volume id 为只读。</p>
<p>稍后一旦确诊，就会立即修复这些问题。偶尔修复不了的，就只能先重置该节点数据，然后从备份节点利用一个比较重的 bulk sync 的操作去同步数据过来。</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>一些常用的优化有：</p>
<p><strong>定期紧缩</strong>（Compaction）：这是个在线操作，旨在收回被删除文件和重复（key 和 alternate key都一样）文件所占的空间；具体做法是新生成一个文件，逐个拷贝有效的文件，跳过被删除和重复的文件。一旦完成，就暂时阻止所有落到该 volume 的修改请求，然后交换 Store file 和内存映射。</p>
<p><strong>精简内存</strong>，由于现在用 flag 只做是否删除的标志，太浪费了。可以改成将内存中所有删除了的文件对应的元信息的 offset 设置为0。并且不再内存中保存图片的 cookie，改为从硬盘读取，如此一来，省了百分之二十左右的内存。</p>
<p><strong>批量上传</strong>，硬盘在进行大批量写的时相对随机写平均性能会好一些，因此我们尽可能的追求批量上传。幸运的是，用户更倾向于同时上传一批图片而非一张图片。</p>
<p>下面还有一些进行性能评估的段落，就先不翻了。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>haystack</tag>
        <tag>distributed storage</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title>6.824 - Raft 实现（二）：日志同步（Log Replication）</title>
    <url>/2018/08/29/raft-log-replication/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一次在做完 lab2a 即 raft 的 leader 选举之后，一直卡在日志同步这一块（log replication）；直到昨晚进行了一下 appendEntries 的优化（prevLog 不匹配时，一下跳过本 term 所有 logEntries），一直困扰的 TestBackup2B 竟然神奇 Passed 的了。跑了两遍还不大信，特地将其改回去，看到果然 Fail 才放心下来，看来是效率太低超时了。</p>
<p>趁着还新鲜，索性今晚就将这一段时间的血泪史记下来吧。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="实验概述"><a href="#实验概述" class="headerlink" title="实验概述"></a>实验概述</h2><p>6.824是MIT的一门分布式课程，我跟的是<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9sYWItcmFmdC5odG1s">2018 spring<i class="fa fa-external-link-alt"></i></span> 。在第二个实验中要求简单实现一个分布式一致性协议–<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvcGFwZXJzL3JhZnQtZXh0ZW5kZWQucGRm">raft<i class="fa fa-external-link-alt"></i></span>。</p>
<p>这是一个专为方便教学和工程实现所设计的协议，它将协议拆解为几个相对独立的模块–leader选举，日志同步，安全保证。论文里图二基本给出了Raft的所有实现细节，可谓字字珠玑。但也因为太微言大义了，导致有些状态转换分散在不同描述中，假如你真只照着这幅图实现，很容易遗漏些细节。</p>
<h2 id="日志同步（Log-Replication）"><a href="#日志同步（Log-Replication）" class="headerlink" title="日志同步（Log Replication）"></a>日志同步（Log Replication）</h2><p>这是lab2B的内容，又是反反复复，猜坑，排雷，放弃，捡起一月余才将日志同步这一块完成，最终代码不到七百行（694），其间有些实现细节还受过网上的启发。其间状态类似于网上看到的一幅调侃程序猿的漫画——啊，出bug了，为什么啊，改改改；还是不对，改改改；啊终于对了，可是，又是为什么啊？</p>
<p>最终 Passed 版本我觉得还待改进，有些地方隐隐然感觉略多余。但暂时先高兴会，把心得赶到纸上来，毕竟老年人脑袋的内存实在有限，而且易挥发。</p>
<p>上一篇 leader 选举中主要是对实现技巧做了些记录，这一篇主要是对实现各个逻辑细节进行探讨。</p>
<h3 id="大致流程"><a href="#大致流程" class="headerlink" title="大致流程"></a>大致流程</h3><p>当初论文大概看明白了，觉得各个细节都搞懂了，但是整个流程在脑中还是转不起来。现在想来，Leader上线后，日志同步过程大概是这样：</p>
<ol>
<li>Leader 选出后，进行初始化，主要是对 nextIndex 数组和 matchIndex 数组的初始化，可能有多种思路，但是我是这么做的：所有 <code>nextIndex = len(rf.log)</code> ，所有 <code>matchIndex = 0</code></li>
<li>然后立即开始心跳，即 AppendEntries，论文上说开始发一个不带内容的心跳就行，但是我的实现中还是发了带一个 logEntry 的心跳。这取决于我上面的初始化方法以及下面的参数构造策略。</li>
<li>同步过程，我将其分为对 match 位置的 <strong>试探阶段</strong> 和 match 后的<strong>传送阶段</strong>；即首先通过每次前移 <code>prevLogIndex+prevLogTerm</code> 匹配上 Follower 中的某个 <code>logEntry</code>，然后 Leader 将匹配到的 <code>logEntry</code> 之后的 entries 一次性送给 Follower。</li>
<li>每次参数构造，其他几个都比较确定，主要考虑三个字段 <code>prevLogIndex</code>，<code>prevLogTerm</code> 和 <code>entires</code>。其中 <code>prevLogTerm</code> 又由 <code>prevLogIndex</code> 决定，因此主要考虑 <code>prevLogIndex</code> 和 <code>entries</code>。对于 <code>prevLogIndex</code>，在 <strong>试探阶段</strong> 我将其定为 <code>nextIndex-1</code>，这么做是为了在试探时降低不必要的 <code>entries</code>传输；在<strong>传送阶段</strong>，可以将 <code>prevLogIndex</code> 定为 <code>matchIndex</code>，也即已经匹配上的最后一条数据。对于 <code>entries</code>，即取 Leader log 中  <code>[prevIndex+1, min(nextIndex, len(rf.log)-1)]</code> 的一个闭区间。</li>
<li>这样，每次试探的时候是不传送数据的（即为 [] ，因为此时<code>prevLogIndex</code> &#x3D; <code>nextIndex</code>-1），在传送阶段可以一次性的将所有匹配之后的 Leader 上的 logEntries 全部传送过去。如果没有新日志了，几个变量将维持在：<code>nextIndex = len(rf.log)；prevLogIndex = matchIndex = len(rf.log)-1</code>，<code>entries</code> 为 []；</li>
</ol>
<p>其他点就是附着于此流程之上的一些细节：</p>
<ol>
<li>定时检测大多数 logEntry match Index，以决定是否要进行 commit，即前移 Leader 的 <code>commitIndex</code> ，并且在以后的 <code>AppendEntries</code> 的 RPC 中将其同步给各个 Follower。</li>
<li>同时另一个线程要检测 <code>lastApplied</code> 是否跟上了 <code>commitIndex</code> ，保证将已提交 log 及时应用到状态机中。这两个变量分开我觉得主要是为了逻辑上的解耦——在 Leader 上是 Leader 主动检测来更新 <code>commitIndex</code> 的，在 Follower 上，是被动接受 Leader 消息来更新的。</li>
<li>Leader 接受了新的 cmd 后，需要将 <code>matchIndex</code> 数组中本身对应的位置更新，因为它本身也是最后计算大多数时的一票。</li>
<li>Follower 连不上之后，Leader要及时终止执行回调后边内容。</li>
</ol>
<h3 id="AppendEntries-心跳-amp-同步"><a href="#AppendEntries-心跳-amp-同步" class="headerlink" title="AppendEntries 心跳&amp;同步"></a>AppendEntries 心跳&amp;同步</h3><p>主要对应上面说的两个阶段，试探阶段和传送阶段；其他要注意的就是上一篇提到的加锁和状态自检。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// need handle the reply</span></span><br><span class="line"><span class="keyword">if</span> reply.Term &gt; rf.currentTerm &#123;</span><br><span class="line">    rf.becomeFollower(reply.Term)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> !reply.Success &#123;</span><br><span class="line">        <span class="comment">// roll back per term every time</span></span><br><span class="line">        nextIndex := rf.nextIndex[server] - <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> nextIndex &gt; <span class="number">1</span> &amp;&amp; rf.log[nextIndex].Term == args.PrevLogTerm  &#123;</span><br><span class="line">            nextIndex--</span><br><span class="line">        &#125;</span><br><span class="line">        rf.nextIndex[server] = nextIndex</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// if match, sync all after</span></span><br><span class="line">        rf.matchIndex[server] = args.PrevLogIndex + <span class="built_in">len</span>(args.Entries)</span><br><span class="line">        rf.nextIndex[server] = <span class="built_in">len</span>(rf.log)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后就是参数构造，对于 <code>prevIndex </code> 来说，也是两个阶段不同构造。然后取合适窗口的 <code>entries</code>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> constructAppendEntriesArg(idx <span class="type">int</span>) *AppendEntriesArgs &#123;</span><br><span class="line">  prevLogIndex := <span class="number">0</span></span><br><span class="line">  <span class="keyword">if</span> rf.matchIndex[idx] == <span class="number">0</span> &#123;</span><br><span class="line">    prevLogIndex = rf.nextIndex[idx] - <span class="number">1</span>	<span class="comment">// try to find a match</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    prevLogIndex = rf.matchIndex[idx]		<span class="comment">// after match to sync</span></span><br><span class="line">  &#125;</span><br><span class="line">  prevLogTerm := rf.log[prevLogIndex].Term</span><br><span class="line"></span><br><span class="line">  <span class="comment">// the need to replica window [prevLogIndex+1, nextIndex)</span></span><br><span class="line">  <span class="keyword">var</span> entries []*LogEntry</span><br><span class="line">  start := prevLogIndex + <span class="number">1</span></span><br><span class="line">  end := min(rf.nextIndex[idx], <span class="built_in">len</span>(rf.log)<span class="number">-1</span>)</span><br><span class="line">  <span class="keyword">for</span> i := start; i &lt;= end; i++ &#123;</span><br><span class="line">    entries = <span class="built_in">append</span>(entries, rf.log[i])</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> &amp;AppendEntriesArgs&#123;rf.currentTerm, rf.me, prevLogIndex,</span><br><span class="line">    prevLogTerm, entries, rf.commitIndex&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最后 AppendLogEntries 回调，看到先前 term 的请求，直接拒绝，这没什么好说的，注意将自己的 term 带回去就行。此外，无论 args.Term &gt; or &#x3D; rf.currentTerm ，收到 AppendEntries 的 peer 都要变成 Follower，并且重置 timer。此外在匹配 logEntry 的时候，要注意进行截断。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) &#123;</span><br><span class="line">  rf.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> rf.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  reply.Term = rf.currentTerm</span><br><span class="line">  <span class="comment">// reject the append entries</span></span><br><span class="line">  <span class="keyword">if</span> args.Term &lt; rf.currentTerm &#123;</span><br><span class="line">    reply.Success = <span class="literal">false</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  rf.leaderId = args.LeaderId</span><br><span class="line">  rf.becomeFollower(args.Term)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> args.PrevLogIndex &gt;= <span class="built_in">len</span>(rf.log) &#123;</span><br><span class="line">    reply.Success = <span class="literal">false</span></span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> rf.log[args.PrevLogIndex].Term != args.PrevLogTerm &#123;</span><br><span class="line">    reply.Success = <span class="literal">false</span></span><br><span class="line">    rf.log = rf.log[:args.PrevLogIndex]</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    reply.Success = <span class="literal">true</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment">// delete not match and append new ones</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args.Entries) &gt; <span class="number">0</span> &#123;</span><br><span class="line">      rf.log = <span class="built_in">append</span>(rf.log[:args.PrevLogIndex+<span class="number">1</span>], args.Entries...)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// commit index</span></span><br><span class="line">    <span class="keyword">if</span> args.LeaderCommit &gt; rf.commitIndex &#123;</span><br><span class="line">      rf.commitIndex = min(args.LeaderCommit, <span class="built_in">len</span>(rf.log)<span class="number">-1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="CommitIndex-更新"><a href="#CommitIndex-更新" class="headerlink" title="CommitIndex 更新"></a>CommitIndex 更新</h3><p>主要依赖 leader 的 matchIndex[] ，具体做法是将其升序排序，然后取中位数位置的 Index（当时拍脑袋想出来的，感觉很神奇）。另一个要注意的点是论文中着重强调的，就是只能提交本 Term 中的 logEntry，这是为了 Leader 你方唱罢我方登场引起的反复覆盖。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> checkCommitIndex() &#123;</span><br><span class="line">  peersCount := <span class="built_in">len</span>(rf.peers)</span><br><span class="line">  matchIndexList := <span class="built_in">make</span>([]<span class="type">int</span>, peersCount)</span><br><span class="line">  <span class="built_in">copy</span>(matchIndexList, rf.matchIndex)</span><br><span class="line">  sort.Ints(matchIndexList)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// match index before the &quot;majority&quot; are all matched by majority peers</span></span><br><span class="line">  <span class="comment">// before we inc commitIndex, we must check if its term match currentTerm</span></span><br><span class="line">  majority := peersCount / <span class="number">2</span></span><br><span class="line">    peerMatchIndex := matchIndexList[majority]</span><br><span class="line">    <span class="keyword">if</span> peerMatchIndex &gt; rf.commitIndex &amp;&amp; rf.log[peerMatchIndex].Term == rf.currentTerm &#123;</span><br><span class="line">        rf.commitIndex = peerMatchIndex</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="响应投票"><a href="#响应投票" class="headerlink" title="响应投票"></a>响应投票</h3><p>每个 peer 在每个 term 最多投一票，但是每次更新 term 后，可将 votedFor 赋值为 -1，即又可以投票了。这个 case 发生在响应 candidate 要求投票时，如果他已经投了票，这是好像不能投票，但是发现 term 没有 candidate 的大，那么需要立即变为 Follower ，并且给该 candidate 投票。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) &#123;</span><br><span class="line">  rf.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> rf.mu.Unlock()</span><br><span class="line">    </span><br><span class="line">  reply.Term = rf.currentTerm</span><br><span class="line"></span><br><span class="line">  <span class="comment">// once find a peer with higher term, follow</span></span><br><span class="line">  <span class="keyword">if</span> args.Term &gt; rf.currentTerm &#123;</span><br><span class="line">    rf.becomeFollower(args.Term)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// compare term and test if it voted</span></span><br><span class="line">  <span class="keyword">if</span> args.Term &lt; rf.currentTerm || rf.votedFor != <span class="number">-1</span> &#123;</span><br><span class="line">    reply.VotedGranted = <span class="literal">false</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// compare the last log entry</span></span><br><span class="line">  lastIndex := <span class="built_in">len</span>(rf.log) - <span class="number">1</span></span><br><span class="line">  lastLogTerm := rf.log[lastIndex].Term</span><br><span class="line">  <span class="keyword">if</span> args.LastLogTerm &gt; lastLogTerm ||</span><br><span class="line">    args.LastLogTerm == lastLogTerm &amp;&amp; args.LastLogIndex &gt;= lastIndex &#123;</span><br><span class="line">    reply.VotedGranted = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// convert to follower</span></span><br><span class="line">    rf.becomeFollower(args.Term)</span><br><span class="line">    rf.votedFor = args.CandidateId <span class="comment">// do not forget</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    reply.VotedGranted = <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里涉及到 becomeFollower 的实现，即更改状态，然后重设 timer，并且根据 term 是否更新来决定是否可以投票。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> becomeFollower(term <span class="type">int</span>) &#123;</span><br><span class="line">  DPrintf(<span class="string">&quot;%d[%d] become follower&quot;</span>, rf.me, term)</span><br><span class="line">  rf.resetElectionTimer()</span><br><span class="line">  rf.state = Follower</span><br><span class="line">  <span class="keyword">if</span> term &gt; rf.currentTerm &#123;</span><br><span class="line">    rf.votedFor = <span class="number">-1</span></span><br><span class="line">  &#125;</span><br><span class="line">  rf.currentTerm = term</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>分布式系统</category>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title>Python函数的默认参数的那些&quot;坑&quot;</title>
    <url>/2019/04/05/python-default-parameter-values/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/pA3sWeiMj6xl2T1.png" alt="python-default-parameter.png"></p>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>栽在 Python 的默认参数的“坑”中几次之后打算专门弄一篇博客来说一下这个事情。但是最近看到一篇很好地<span class="exturl" data-url="aHR0cDovL2VmZmJvdC5vcmcvem9uZS9kZWZhdWx0LXZhbHVlcy5odG0=">英文文章<i class="fa fa-external-link-alt"></i></span>（<em>Default Parameter Values in Python，Fredrik Lundh | July 17, 2008 | based on a comp.lang.python post</em>），鞭辟入里。珠玉在前，就不舞文弄墨了。当然，也算是偷个懒，在这里简单翻译一下，希望更多的人能看到。</p>
<p>以下是翻译，意译，加了一些私货，不严格跟原文保持一致，语法特性以 <em><strong>Python3</strong></em> 为准。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>Python 处理默认参数值的方式是少数的几个能绊倒大部分初学者的问题之一（虽然一般只会绊倒一次）。</p>
<p>Python 做出这种让人费解的行为，往往是因为你把一个“可变”对象当做了函数的默认参数。即，一个可以原地进行改变的对象，比如说列表或者字典。</p>
<p>一个栗子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">function</span>(<span class="params">data=[]</span>):</span><br><span class="line"><span class="meta">... </span>    data.append(<span class="number">1</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> data</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>function()</span><br><span class="line">[<span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>function()</span><br><span class="line">[<span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>function()</span><br><span class="line">[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>如代码所示，返回值列表变得的越来越长，而不是想象中的每次都是 <code>[1]</code> 。试着查看一下每次返回的列表的 ID，发现竟然没有变过。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">id</span>(function())</span><br><span class="line"><span class="number">12516768</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">id</span>(function())</span><br><span class="line"><span class="number">12516768</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">id</span>(function())</span><br><span class="line"><span class="number">12516768</span></span><br></pre></td></tr></table></figure>

<p>原因也很简单，<code>function()</code> 函数在不同函数调用中一直在使用同一个列表对象。我们的修改（<code>data.append(1)</code>）变成了粘滞操作。</p>
<h2 id="为什么会这样"><a href="#为什么会这样" class="headerlink" title="为什么会这样"></a>为什么会这样</h2><p>答案就是：默认参数语句，总是在 <code>def </code> 关键字定义函数的时候被求值，且仅执行这一次。可以查阅 <em>Python 语言参考（The Python Language Reference）</em> 的相关章节： </p>
<p><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvemgtY24vMy43L3JlZmVyZW5jZS9jb21wb3VuZF9zdG10cy5odG1sI2Z1bmN0aW9uLWRlZmluaXRpb25z">https://docs.python.org/zh-cn/3.7/reference/compound_stmts.html#function-definitions<i class="fa fa-external-link-alt"></i></span></p>
<blockquote>
<p><strong>默认形参值会在执行函数定义时按从左至右的顺序被求值</strong>。这意味着当函数被定义时将对表达式求值一次，相同的“预计算”值将在每次调用时被使用。</p>
</blockquote>
<p>需要注意的是，以关键字 <code>def</code> 开头的函数签名在 Python 中是个可执行语句，默认参数就是在<code>def</code> 表达式中被求值的。如果你执行 <code>def</code> 表达式多次，Python 就会每次为你创建一个新的函数对象（默认参数自然也会重新计算）。在接下来的例子中我们将会认识到这一点。</p>
<h2 id="那么要如何做"><a href="#那么要如何做" class="headerlink" title="那么要如何做"></a>那么要如何做</h2><p>一个临时的变通办法是，当然其他人也提到了：用一个无意义值当做默认参数仅用来占位，而不是每次都直接修改该默认参数。<code>None</code> 就是这样一个常用占位符：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">myfunc</span>(<span class="params">value=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> value <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        value = []</span><br><span class="line">    <span class="comment"># modify value here</span></span><br></pre></td></tr></table></figure>

<p>如果你需要处理任意类型的数据（包括 <code>None</code> 在内），可以用一个哨兵实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentinel = <span class="built_in">object</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">myfunc</span>(<span class="params">value=sentinel</span>):</span><br><span class="line">    <span class="keyword">if</span> value <span class="keyword">is</span> sentinel:</span><br><span class="line">        value = expression</span><br><span class="line">    <span class="comment"># use/modify value here</span></span><br></pre></td></tr></table></figure>

<p>当然在一些旧的代码里，<code>object</code> 还没有被引入 Python 的时候，下面语句也常被使用创建一个值为非假（not false）唯一实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentinel = [<span class="string">&#x27;placeholder&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>因为 <code>[] </code> 每次执行时，都会创建一个新的实例。</p>
<h2 id="正确利用姿势"><a href="#正确利用姿势" class="headerlink" title="正确利用姿势"></a>正确利用姿势</h2><p>值得一提的是，一些高级 Python 代码常常反而会利用此特性。例如，你想通过一个循环来创建一堆按钮，你可能会这么做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">callback</span>():</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;clicked button&quot;</span>, i</span><br><span class="line">    UI.Button(<span class="string">&quot;button %s&quot;</span> % i, callback)</span><br></pre></td></tr></table></figure>

<p>却不幸的发现所有回调函数都打印出了同一个值（在上面例子中，大概率都是9）。其原因是，在 Python 的内层嵌套作用域中，绑定的是外层变量本身，而非其值。因此所有的回调函数都会看到变量 <code>i</code> 的最后的值。可以通过在内层函数调用时，对参数进行显式传递来解决这一问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">callback</span>(<span class="params">i=i</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;clicked button&quot;</span>, i</span><br><span class="line">    UI.Button(<span class="string">&quot;button %s&quot;</span> % i, callback)</span><br></pre></td></tr></table></figure>

<p><code>i=i</code> 语句，利用 <code>def</code> 语句在每次执行时都会重新进行绑定的特性，将当前外层 <code>i</code> 的值，绑定到局部变量（也就是形参） <code>i</code> 上。</p>
<p>还有两个其他可能的用途，一是结果缓存&#x2F;记忆：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">calculate</span>(<span class="params">a, b, c, memo=&#123;&#125;</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        value = memo[a, b, c] <span class="comment"># return already calculated value</span></span><br><span class="line">    <span class="keyword">except</span> KeyError:</span><br><span class="line">        value = heavy_calculation(a, b, c)</span><br><span class="line">        memo[a, b, c] = value <span class="comment"># update the memo dictionary</span></span><br><span class="line">    <span class="keyword">return</span> value</span><br></pre></td></tr></table></figure>

<p>这种使用姿势在某些递归函数中非常有用（比如记忆化搜索）。</p>
<p>二是，对于需要高度优化的代码，可以将全局变量绑定到局部来优化性能：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">this_one_must_be_fast</span>(<span class="params">x, sin=math.sin, cos=math.cos</span>):</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>

<h2 id="详细说下原理"><a href="#详细说下原理" class="headerlink" title="详细说下原理"></a>详细说下原理</h2><p>当 Python 执行一个 <code>def</code> 表达式（也就是函数定义）的时候，会利用一些已有的环境片段（比如说编译好的函数体代码，对应<code>__code__</code>；当前命名空间的环境，对应<code>__globals__</code>）来构建一个新的函数对象。Python 在这么做的时候，也会对默认参数进行求值，并当做一个属性放到函数对象里。</p>
<p>当然，这些环境通过函数对象的属性都能访问到：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>function.__name__</span><br><span class="line"><span class="string">&#x27;function&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>function.__code__</span><br><span class="line">&lt;code <span class="built_in">object</span> function at 00BEC770, file <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>function.__defaults__</span><br><span class="line">([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>function.__globals__</span><br><span class="line">&#123;<span class="string">&#x27;function&#x27;</span>: &lt;function function at <span class="number">0x00BF1C30</span>&gt;,</span><br><span class="line"><span class="string">&#x27;__builtins__&#x27;</span>: &lt;module <span class="string">&#x27;__builtin__&#x27;</span> (built-<span class="keyword">in</span>)&gt;,</span><br><span class="line"><span class="string">&#x27;__name__&#x27;</span>: <span class="string">&#x27;__main__&#x27;</span>, <span class="string">&#x27;__doc__&#x27;</span>: <span class="literal">None</span>&#125;</span><br></pre></td></tr></table></figure>

<p>既然你可以访问当默认值，那么你当然可以修改它：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>function.__defaults__[<span class="number">0</span>][:] = []</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>function()</span><br><span class="line">[<span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>function.__defaults__</span><br><span class="line">([<span class="number">1</span>],)</span><br></pre></td></tr></table></figure>

<p>不过，你最好别这么干（修改一些你不了解的的东西，比如私有变量或者系统变量，会导致一些神奇的后果）。</p>
<p>另一个对默认参数进行重置的方法就是重新执行同样的 <code>def</code> 函数定义语句，也即，把 <code>function</code> 定义再执行一次。当你这么做时，Python 就会为编译函数体重新创建一个代码对象，重新对默认参数进行求值，然后将该函数对象再一次绑定到 <code>function</code> 这个名字上。不过，再强调一次，只要在你明确知道某种写法会产生什么后果时，再去做。</p>
<p>当然也可以通过 <code>new</code> 模块中的 <code>function</code> 类去定义你自己的函数对象（不过，在 Python3 中 <code>new</code> 模块已经被舍弃了）</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>一切根源在于 Python 是动态语言，它定义函数时，也像定义普通变量一样，进行了一个名字到函数对象的绑定。并且只在绑定的时候执行函数头里的赋值语句，并将参数保存为函数对象的一部分（即其属性）。之后通过改名字进行函数调用的时候，只是执行函数体（通过 <code>__code__</code>  指向的代码片段）的语句。</p>
<p>而在函数不是第一等公民静态语言中，函数定义是在编译阶段做的，不能在运行时多次重复绑定。在每次函数调用时，形参实参都会进行一次结合，默认参数会被重新进行赋值。</p>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>默认参数</tag>
      </tags>
  </entry>
  <entry>
    <title>f4：Facebook’s Warm BLOB Storage System</title>
    <url>/2019/03/30/f4/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/67YwWZRbthK3qFX.png" alt="over BLOB Storage Architecture"></p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>首先说下 BLOB 的意思， 英文全称是 <em>Binary Large OBjects</em>，可以理解为任意二进制格式的大对象；在 Facebook 的语境下，也就是用户在账户里上传的的图片，视频以及文档等数据，这些数据具有<em>一次创建，多次读取，不会修改，偶尔删除</em> 的特点。</p>
<p>之前简单翻译了 Facebook 的前驱之作 —— Haystack，随着业务量发展，数据量进一步增大，过去玩法又不转了，如果所有 BLOG 都用 Haystack 存，由于其三备份的实现，在这个量级下，性价比很低。但是完全用网络挂载+传统磁盘+Unix-like（POSIX）文件系统等冷存储，读取跟不上。于是计算机科学中最常用的<strong>分而治之</strong>的思想登场了。</p>
<p>他们首先统计了 BLOBs 的访问频次与创建时间的关系，然后提出了随着时间推移 BLOB 访问出现的冷热分布概念（和长尾效应差不多）。并据此提出了热、温分开的访问策略：用 HayStack 当做热存储去应对那些频繁访问的流量，然后用 F4 去响应剩下的不那么频繁访问的 BLOB流量，在此假设（F4只存储那些基本不怎么变动，访问量相对不大的数据）前提下，可以大大简化 F4 的设计。当然有个专门的<strong>路由层</strong>于两者之上进行了屏蔽，并进行决策和路由。</p>
<p>对于 Haystack 来说，从其论文出来时，已经过去了七年（07~14）。相对于当时，做了少许更新，比如说去掉了 Flag 位，在 <em>data file</em>，<em>Index file</em> 之外，增加了 <em>journal file</em>，专门用来记录被删除的 BLOB 条目。</p>
<p>对于 F4 来说，主要设计目的在于保证容错的前提下尽可能的减小<em><strong>有效冗余倍数</strong></em>（<em>effective-replication-factor</em>），以应对日益增长的<em><strong>温数据</strong></em> 存取需求。此外更加模块化，可扩展性更好，即能以加机器方式平滑扩展应对数据的不断增长。</p>
<p>我总结一下，本论文主要高光点就是<strong>温热分开，冗余编码，异地取或</strong>。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="数据量级"><a href="#数据量级" class="headerlink" title="数据量级"></a>数据量级</h2><p>到2014年，Facebook 大概有超 4000 亿张图片。</p>
<h2 id="访问频度的热力图"><a href="#访问频度的热力图" class="headerlink" title="访问频度的热力图"></a>访问频度的热力图</h2><p>论文的结论是，<em>访问频度的热力图是存在的，创建时间是影响其变化关键因子，而且<strong>温部数据</strong>是持续增长的</em>。</p>
<p>论文的度量方法也很简单，就是追踪其网站上不同类型的 BLOB 数据的访问频次随着创建时间变化曲线，创建时间小于一天的数据的访问频次大概是创建时间一年的数据的100多倍。具体数据就不列了，可以去 paper 里看。</p>
<p>然后论文探讨了区分<strong>热数据</strong>和<strong>温数据</strong>的一个界限，通过对访问频次和删除频次随着创建时间的变化的分析，对于大部分 BLOG，得到了一个的大概值：一个月。但是有两个例外，一个是用户头像，一直是热数据；另外一个普通图片，使用三个月作为阈值。</p>
<p>热数据总是那些头部数据，相对来说增长较慢。但是历史数据，也就是<strong>温数据</strong>是随着时间推移而尾巴越来越长，这势必要求存储架构进行相应的调整。</p>
<h2 id="存储系统总体架构"><a href="#存储系统总体架构" class="headerlink" title="存储系统总体架构"></a>存储系统总体架构</h2><p>设计原则是让每个组件尽可能简单、内聚并且高度契合其要承担的工作。这是从 UNIX 以来就一直在强调的一个原则。下图是总体架构图，包括创建（C1-C2，由 Haystack 负责），删除（D1-D2，大部分是 Haystack 负责，少部分是 f4 负责）和读取（R1-R4 由 Haystack 和 f4 共同负责）。</p>
<p><img src="https://i.loli.net/2020/02/09/67YwWZRbthK3qFX.png" alt="over BLOB Storage Architecture"></p>
<p>如前述论文 Haystack 所述，我们将一批 BLOG 集结为<strong>逻辑卷</strong>，尽可能减少 meta 信息，从而减少IO次数。每个逻辑卷我们设计了 100G 左右的容量，在满之前是为 <em>未锁定</em> （<em>unlocked</em>） 的状态，一旦达到容量，就变为<em>锁定</em> （<em>locked</em>）状态，只允许读取和删除。</p>
<p>每个卷包含三个文件，一个数据文件，一个索引文件和一个备忘文件（journal file）。和 Haystack 论文提到的一样，数据文件就是记录 BLOG 本身和其原信息，索引文件就是内存中的查找结构的快照。备忘文件是新增的，它通过记录所有被删除的 BLOG 的记录来进行删除操作。而原 Haystack 论文中，删除文件是通过直接修改索引文件和数据文件来实现的。在<strong>未锁定</strong>阶段，三个文件均可读写，在<strong>锁定</strong>阶段，只有备忘文件可以读写，其他两个文件都会变成只读的。</p>
<h3 id="控制模块（Controller）"><a href="#控制模块（Controller）" class="headerlink" title="控制模块（Controller）"></a>控制模块（Controller）</h3><p>统筹整个系统，比如提供新的存储机器；维持一个未锁定卷（unlocked volumes ）的池子；确保所有逻辑卷有足够的物理卷来备份；根据需求适时创建物理卷；进行周期性的维护任务，比如说数据紧缩（compaction）和垃圾回收。</p>
<h3 id="路由层（Route-Tier）"><a href="#路由层（Route-Tier）" class="headerlink" title="路由层（Route Tier）"></a>路由层（Route Tier）</h3><p>路由层负责BLOB 存储系统向对外提供接口，它屏蔽了系统底层的实现，使得可以方便添加如 f4 一样的子系统。所有的路由层的机器角色都是一样的，因为该层将所有状态（如逻辑卷到物理卷的映射）都存在了另外的数据库里（<em><strong>将所有相关状态收集起来额外存储，使得剩下的部分无状态可以平滑扩展，这也是系统设计常用的原则</strong></em>）。这使得路由层的可以不依赖其他模块来平滑扩展。</p>
<p>对于读取请求，路由模块会从 BLOB id 中解析出 逻辑卷 id，然后根据数据库中读出的映射关系来找到对应的所有物理卷信息。一般来说会从最近一个主机取数据，如果失败的话，会产生一个超时事件，去下一个物理卷所在的主机进行尝试。</p>
<p>对于创建请求，路由模块会选取一个有空闲空间的逻辑卷，然后将 BLOB 发送到该逻辑卷对应的所有物理卷进行写入（是并行发，还是链式发还是串行发？）如果遇到任何问题，就会中断写，并且将已经写入的数据废弃，且重新挑选一个可用逻辑卷，重复上述过程。（看起来像并行写，容错策略也超级粗暴）</p>
<p>对于删除请求，路由模块会将其发送到所有对应的物理卷（然后就快速返回），然后对应物理主机程序会<strong>异步</strong>的进行删除，遇到错误就一直重试，直到成功删除所有对应物理卷上的对应 BLOB。（倒也简单，但不知道实现的时候是会写入 journal file 后返回，还是只是在内存中标记下就返回。对应的数据文件上的 BLOB 肯定是在 compact 的时候才会删掉）。</p>
<p>路由层通过将实现细节隐藏，使得（对用户）无感知地构建温存储成为可能，当一个卷被从热存储移到温存储的时候，会在两者上同时存在一段时间，直到有效（逻辑卷到物理卷）的映射被更新后，客户端的请求将被无感知的地导向温存储。</p>
<h3 id="转换层（Transformer-Tier）"><a href="#转换层（Transformer-Tier）" class="headerlink" title="转换层（Transformer Tier）"></a>转换层（Transformer Tier）</h3><p>转换层负责处理对检索到的 BLOB 数据的变换操作，比如图片的缩放和裁剪。在 Facebook 的老版本的系统中，这些计算密集型的操作会在存储节点上完成。</p>
<p>增加转换层可以解放存储节点，使其专注于提供存储服务。将计算任务分离出来也有利于将存储层和转换层进行独立的扩展。然后，它也可以让我们精确地控制存储节点的容量以恰好满足需求。更进一步，也可以使我们针对不同任务类型进行更优的硬件选型。比如说我们可以将存储节点设计为具有大量硬盘，但只有一个CPU和少量内存。</p>
<h3 id="缓存栈（Caching-Stack）"><a href="#缓存栈（Caching-Stack）" class="headerlink" title="缓存栈（Caching Stack）"></a>缓存栈（Caching Stack）</h3><p>一开始是为了处理热点 BLOB 数据的请求，缓解后端存储系统的压力。对于温存储来说，它也可以减小其请求压力。这里说的应该是 CDN 以及类似 akamai 内容分发商提供的缓存。</p>
<h3 id="Haystack-热存储（Hot-Storage-with-Haystack）"><a href="#Haystack-热存储（Hot-Storage-with-Haystack）" class="headerlink" title="Haystack 热存储（Hot Storage with Haystack）"></a>Haystack 热存储（Hot Storage with Haystack）</h3><p>Haystack 开始是被设计来尽可能的提高 IOPS 的，通过揽下所有创建请求，大部分的删除请求和高频读请求，使得温存储的设计可以大大简化。</p>
<p>如相关 paper 提到的，Haystack 通过合并 BLOB 和简化元信息使得 IOPS 大大提高。具体来说，包括将逻辑卷设计为集合了一批 BLOB 的单个文件，利用三个物理卷对同一个逻辑卷进行冗余备份等等。</p>
<p>读请求过来后，会在内存中拿到请求的 BLOB 的元信息，并且看其是否被删除，然后通过物理文件位置+ offset + size ，仅进行一次 IO 拿到对应 BLOB 数据。</p>
<p>当主机收到创建请求后，会同步的将 BLOB 数据追加到数据文件上，然后更新内存中的元信息并将更改写入索引文件和备忘文件中（备忘文件不是只记录删除操作吗？）。</p>
<p>当主机收到删除请求时，会更新索引文件和备忘文件。但是对应数据仍然存在于数据文件中，定期地我们会进行紧缩操作，才会真正的删除数据，并回收相应空间。</p>
<h3 id="容错（Fault-tolerance）"><a href="#容错（Fault-tolerance）" class="headerlink" title="容错（Fault tolerance）"></a>容错（Fault tolerance）</h3><p>Haystack 通过在一个数据中心的不同机架上各放一个副本，然后再不同数据中心再放一个副本的三副本策略获得了对硬盘，主机，机架甚至数据中心的容错能力。然后通过 RAID-6（1.2倍冗余数据编码，能够小范围的纠正错误，可以读读纠错码之类的文章）进行额外的硬盘容错，更上一层保险。但是付出的代价是 3*1.2 &#x3D; 3.6 倍的有效冗余因子，这也是 Haystack 的局限之处，虽然最大化了 IOPS，但是在存储使用上却并不高效，造成了很多 BLOB 的数据冗余。</p>
<h3 id="暂存内容驱动（Expiry-Driven-Content）"><a href="#暂存内容驱动（Expiry-Driven-Content）" class="headerlink" title="暂存内容驱动（Expiry-Driven Content）"></a>暂存内容驱动（Expiry-Driven Content）</h3><p>有些类型的 BLOB 具有一定的过期时间，比如说用户上传的视频，会从原始格式转化为我们的存储格式。在此之后原始视频需要删掉。我们会避免将此类具有过期时间的数据移动到 F4 上，从而让 Haystack 负责这些频繁的删除请求，并通过频繁紧缩来回收空间。</p>
<h2 id="f4-设计"><a href="#f4-设计" class="headerlink" title="f4 设计"></a>f4 设计</h2><p>设计目标是在容错的基础上尽可能高效。也就是在能够容忍硬盘错误，主机故障，机架问题，数据中心灾难的前提下，把有效冗余倍数降一降。</p>
<h3 id="f4-概览（f4-Overview）"><a href="#f4-概览（f4-Overview）" class="headerlink" title="f4 概览（f4 Overview）"></a>f4 概览（f4 Overview）</h3><p>f4 是温数据存储架构的子系统。包含一系列  数据单元（cell），每个 cell 都在同一个数据中心（机房，datacenter）里。当前（2014）的 cell 包含 14 个机架，每个机架有15个主机，每个主机有三十块 4T 容量的硬盘。cell 负责存储逻辑卷，每个逻辑卷实际存储时，会将数据利用<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU5JTg3JThDJUU1JUJFJUI3LSVFNiU4OSU4MCVFNyVCRCU5NyVFOSU5NyVBOCVFNyVBMCU4MQ==">里所码<i class="fa fa-external-link-alt"></i></span>（Reed-Solomon coding，简称RS，这是前面提到的RAID-6 标准的重要成员）进行冗余编码，比如 RS(n, k) 就是每存 n 个比特，就要编入额外的 k 个比特，以此来容忍最多 k 个比特的出错。通过这种编码方式可以解决硬盘，主机和机架出错问题。</p>
<p>此外利用异或编码（XOR coding）来解决跨数据中心或者地理位置的出错问题。我们选取两个不同机房的对等数量 volume&#x2F;stripe&#x2F;block 结成对子，然后将每一对的异或值存在第三个机房。</p>
<h3 id="单个-f4-cell（Individual-f4-Cell）"><a href="#单个-f4-cell（Individual-f4-Cell）" class="headerlink" title="单个 f4 cell（Individual f4 Cell）"></a>单个 f4 cell（Individual f4 Cell）</h3><p>每个 f4 数据单元（cell） 只处理锁定的卷（Volume），也就是只用支持读取和删除操作。数据文件和索引文件都是只读的，Haystack 中的备忘文件在 f4 中是不存在的。我们用了另一种方式来达到“删除”的效用，将每个 BLOB 进行加密后存储，将用于加密的秘钥（key）存在一个外部数据库中。响应删除请求时，<strong>只需要将 BLOB 对应的秘钥删掉就行</strong>（有点绝，对用户提供了隐私保证，而且将删除操作的延时降到很低）。</p>
<p>索引文件由于比较小，直接用了三副本存储来保证可靠性，可以省去编解码带来的额外复杂度。数据文件用 n&#x3D;10, k &#x3D; 4 的里所码进行编码。具体来说，将每个数据文件切分为 n 个连续的数据块（block），每个具有固定尺寸 b（最后一个块不满，而又写不进去一个新 BLOB 的情况下，在结尾补零，<em><strong>类似这种打 padding 也是数据对齐常用的手法</strong></em>）；对于每 n 个这样的块，生成 k 个同样尺寸的<em>奇偶校验块</em>（parity block），这样 n+k 个数据块构成一个逻辑上的 <em>条带</em>（stripe）。同一条带上的任意两个块互称为<strong>兄弟块</strong>（companion block）。正常读取时，可以直接从数据块中读（我猜是那n个块，不用额外进行计算还原，有待考证，还得看里所码原理以及具体实现）。如果某些块不可用了，就会在同一条带上任取 n 块，解码后还原；此外还有个性质，就是读取 n 个 block 上对应的 n 截数据（比如某个 BLOB），也可以进行解码（这两个性质都是编码决定的，类似于 n 元线性方程组，有 k 个冗余方程）。</p>
<p><img src="https://i.loli.net/2020/02/09/laNjLhZgwp5e8Yz.png" alt="BLOBs in Block in Stripes in Volumes"></p>
<p>通常 b 为 1G，即每个数据块（Block）选取 1G 大小（这有个疑问，看起来每个Block仍在Volume中，而不是单独拿出来，那么定位一个物理block是不是就得通过 volume 文件打开句柄 + offset + length），选这么大有两方面的考虑，一个是尽量减小 BLOB 的跨块概率，以减少读取一个 BLOB 还得多次 IO 的频率；另一个是降低 block 所需要维护的总元信息数量。不选更大的是因为重建起来会付出更大代价（但为什么就是 1G 呢？）。</p>
<p>下图是架构图，接下来逐一介绍下各个模块。</p>
<p><img src="https://i.loli.net/2020/02/09/67YwWZRbthK3qFX.png" alt="overall architecture"></p>
<h3 id="名字节点（Name-Node）"><a href="#名字节点（Name-Node）" class="headerlink" title="名字节点（Name Node）"></a>名字节点（Name Node）</h3><p>name node 维护了<em>数据块</em>、<em>奇偶校验块</em> 到实际存储这些块的存储节点（也就是下一节的存储节点）之间的映射；这些映射（利用标准技术？还说参考了GFS，这没大看懂，留个坑回头读 GFS 填上）分配到存储节点中。名字节点使用主从备份策略进行容错。</p>
<h3 id="存储节点（Storage-Nodes）"><a href="#存储节点（Storage-Nodes）" class="headerlink" title="存储节点（Storage Nodes）"></a>存储节点（Storage Nodes）</h3><p>存储节点是 Cell 的主要组件，处理所有常规的读取和删除请求。对外暴露两个 API：Index API 负责提供 Volume 的有无检查和位置信息；File API 提供实际的数据访问。（<em>File API 与 Data API 的区别估计在于，前者是提供上层抽象 BLOB 的操作接口，而后者会暴露底层数据块 Block 的访问的接口</em>）</p>
<p>存储节点将 index file （包括BLOB到 volume 的映射，偏移量和长度）存在硬盘上，并且加载到自定义存储结构的内存中。此外还维持了volume 偏移量到物理数据块的映射（由于一个 volume 被整齐的切成了好多 block， 因此定位一个数据块的逻辑位置，需要记下他的所在volume+offset）。上述两个信息都被存在内存里，以避免硬盘 IO（似乎后面也有变化，index 也不小随着ssd更便宜，存ssd也可以）。；</p>
<p>由于每个 BLOB 都是加密过的，其秘钥放在额外的存储，通常是数据库中。通过删除其秘钥就可以达到事实上的 BLOB 的删除，这样就避免了数据紧缩（为什么可以不回收那些删除空间呢，毕竟对于文存储，删除量只有很小一部分，之前的温存储的假设就用在这里）；同时也省去了用备忘文件（journal file）来追踪删除信息。</p>
<p>下面说下读取流程。首先通过 Index API 来检查文件是否存在（R1过程），然后将请求转到该 BLOB 所在的数据块所在的存储节点上。Data API 提供了对数据块和奇偶校验块（parity block）的访问。正常情况下的读请求会被导向合适的存储节点（R2流程），然后直接从该 BLOB 所在块读取它（R3）。在失败的情况下，会通过 Data API 读取损坏模块中的所有 n+k 个兄弟模块中完好的 n 个块，送到回退节点（back-off node）进行重建。</p>
<p>在进行实际数据读取（无论是 R1-R3 的正常流程还是 R1，R4，R5的出错回退流程）的同时，路由层（route tier）会并行的从外部数据库读取该 BLOB 对应的秘钥，然后在路由层进行解密操作，这是一个计算密集型任务，放在这里可以让数据层专注于存储，并且两层可以独立的扩展。</p>
<h3 id="回退节点（Backoff-Nodes）"><a href="#回退节点（Backoff-Nodes）" class="headerlink" title="回退节点（Backoff Nodes）"></a>回退节点（Backoff Nodes）</h3><p>就是负责给出正常读取流程出错时的一种回退方案。</p>
<p>当 cell 中出现故障时，会有些块变得不可用，就需要从其兄弟块和奇偶校验块中进行在线恢复。回退模块都是IO稀疏而计算密集型节点，来处理这些计算密集型的在线恢复操作。</p>
<p>回退模块对外暴露 File API，以处理正常读取失败情况下的回退重试（R4）。在此时，读取请求已经被一个主卷服务器（primary volume-server，<em>不过这是个什么节点？</em>）解析成了数据文件，偏移量和长度的元组，回退节点会向除损坏数据块之外的 n-1 个兄弟块和 k 个奇偶校验块中对应偏移量，读取对应长度的信息。只要收到n个回应（<em>估计是并行发？然后为了节省时间，收到任意n个回应就开始干活，进行差错纠正</em>？）</p>
<p>当然了，回了照顾读取延迟，每次进行在线回退读纠错的时候，都只恢复对应BLOB的数据而不是其所在的整个数据块 Block 的信息。整个数据块的恢复会交给重建节点（Rebuilder Nodes）离线的去做。</p>
<h3 id="重建节点（Rebuilder-Nodes）"><a href="#重建节点（Rebuilder-Nodes）" class="headerlink" title="重建节点（Rebuilder Nodes）"></a>重建节点（Rebuilder Nodes）</h3><p>在民用物理机数目达到一定量级的情况下，硬盘和节点的故障是不可避免的。存储在损坏模块上的数据块就需要进行重建。重建节点是存储稀疏而计算密集型的，负责在后台默默地进行重建工作。每个重建节点通过探针（定期扫描其负责的范围内的数据？还是在每个数据节点上安装探针？）检测数据块错误，并且将其汇报到协调节点（Coordinator Nodes），然后通过取出同一条带（Stripe）上兄弟块和奇偶校验块中的没有损坏过的n块，对损坏节点进行重建（如果n+k中有其他模块坏了估计也一并重建吧）。这是一个很重的处理过程，并且会给存储节点带来极大的网络和 IO 负载。因此重建节点会对其吞吐量进行限流，以防对正常的用户请求造成不利影响。而统筹调度重建工作，以尽量减小数据丢失的风险，则是协调节点的工作。</p>
<h3 id="协调节点（Coordinator-Nodes）"><a href="#协调节点（Coordinator-Nodes）" class="headerlink" title="协调节点（Coordinator Nodes）"></a>协调节点（Coordinator Nodes）</h3><p>一个数据单元（cell）需要很多日常的运维任务，比如安排（大概就是确定一个重建顺序，并且在不同的重建节点间进行分配吧）损坏的数据块重建，调整当前的数据分布以尽可能减小数据的不可用概率。协调节点也是存储稀疏计算密集型的，用来执行数据单元范围的任务。</p>
<p>如之前提到的，一个数据条带上的不同数据块需要被分散放置于不同的数据容错区域内以最大化可靠性。然而，在经过故障，重建和替换后，肯定会有一些不符合上述原则的情况，比如两个同条带上的数据块被放在了同一个数据容错区域中。协调节点会运行一个平衡摆放位置的进程去检查一个数据单元中的数据块分布。和重建操作一样，也会给存储节点带来相当大的额外硬盘和网络负载，因此协调节点也会进行自我限流以减小对正常请求的影响。</p>
<h2 id="地理备份"><a href="#地理备份" class="headerlink" title="地理备份"></a>地理备份</h2><p>单个 f4 的数据单元都存在一个数据中心中，因此难以抵御数据中心的故障。于是在开始的时候，我们将两份同样的数据单元放在不同的数据中心中，这样一个损坏仍然可以利用另一个对请求进行响应。这样将有效冗余因子从 Haystack 的 3.6 降低到了 2.8 。</p>
<p><img src="https://i.loli.net/2020/02/09/yUSnKop1hGH6QEj.png" alt="geo replicated xor coding"></p>
<p>考虑到数据中心级别的故障还是很稀少的，我们找到了一种可以进一步减小有效冗余因子的方案——当然，也减小了吞吐率。不过，现在XOR方案可以将有效冗余因子进一步做到 2.1。</p>
<p>地理备份异或编码（XOR coding）方案通过将两个不同的卷（Volume，大小一样）做异或后的结果放在第三个数据中心的方式，提供了数据中心级别的容错。如图9一样，每个数据卷中的数据块和奇偶校验块被与等量的其他数据块或者奇偶校验块（称为<em>哥们块</em>，buddy block）被拿来做异或运算，得到其异或块（XOR block）。这些异或模块的索引也是简单的三备份存储。</p>
<p>一旦某个 datacenter出现问题导致整个 volume 不可用，读取请求会被路由到一个叫做 geo-bakoff node ，然后会从两个 buddy node 和 XOR node 所在数据中心去取对应 BLOB 数据，进行损坏 BLOB的重建。选择XOR编码，当然是简单又能满足需求。</p>
<p>负载因子的计算，(1.4 * 3) &#x2F; 2 &#x3D; 2.1</p>
<h2 id="简单总结"><a href="#简单总结" class="headerlink" title="简单总结"></a>简单总结</h2><p>基本思想大概就这些，剩下的不翻了。但是论文说的有点啰嗦，同一个点在不同地方说了好几遍，但同时一个模块有时又分散在不同模块中，不好连成一个整体，在这里，我简单总结一下。</p>
<p>一个数据单元（cell）存在一个数据中心中，包含 14 个机架。一个逻辑上的卷 （Volume），大约 100G，被分为 100 个 1G 的数据块（Block）；然后每 10 个数据块作为一组（Companion Block）进行数据冗余编码（RS编码）后，产生 4 个新的奇偶校验块（Parity Block），这 14 个数据块+奇偶校验块称为一个条带（stripe），被分别放置在不同机架上以进行容错。其中哪些数据块属于一组的映射关系在名字节点（ Name Node） 中维持着。</p>
<p>在存储节点上，内存中需要维护两个映射作为 index 信息，一个是 BLOB id 到 volume，偏移量和大小的映射，一个是 volume 偏移量到 Block 实际物理位置的映射。当读请求失败的时候，读取请求连同一些元信息（比如所在数据块 id，以及在其上的偏移量）被导向回退节点（Backoff Node）。回退节点会根据 BLOB id 所在的 Block id 在 Name Node 拿到条带上其他数据块位置信息，以及偏移量，只对该 BLOB 的所有对等数据进行解码，还原出该 BLOB 后返回。</p>
<p>此外，协调节点（Coordinator Nodes）会根据探针的心跳信息，得到全局数据分布和状态信息。协调节点据此将损坏的模块交给重建节点（Rebuilder Nodes）进行数据重建；并且平衡、维持条带上的所有块被放在不同的数据容错阈。</p>
<p>最后，在两个不同数据中心的将所有数据块配对后，进行异或（XOR）操作，得到一个异或结果，放在第三个数据中心。这样，这三个数据中心的任何数据条带损坏到 RS 码都无法拯救的情况下（比如有四个以上机架出问题了），就可以通过其他两个数据中心数据进行 XOR 操作来抢救一下。</p>
<h2 id="乱翻对照"><a href="#乱翻对照" class="headerlink" title="乱翻对照"></a>乱翻对照</h2><p><strong>数据文件（data file）</strong>：存储一堆 BLOB 和其元信息的的文件</p>
<p><strong>索引文件（index file）</strong>：记录 BLOB 在数据文件偏移量，长度和简单信息的文件，用来快速 seek 取出 BLOB。</p>
<p><strong>备忘文件（journal file）</strong>：在 Haystack 中，用于记录所有的删除请求。</p>
<p><strong>有效备份因子，有效冗余倍数（effective-replica-factor</strong>）：实际占用的物理空间和要存的逻辑数据大小之间的比值。</p>
<p><strong>兄弟模块，伙伴模块（companion block）</strong>：用于编码的 n+k 个数据块中那 n 个模块的称呼。</p>
<p><strong>奇偶校验块（parity block）</strong>：用于编码 n+k 个数据块中那 k 个模块的称呼</p>
<p><strong>温存储（warm storage）</strong>：相对于热存储，指那些专门针对访问频次不怎么高的数据所构建的存储。</p>
<p><strong>存储节点，存储机器（storage nodes，storage machines）</strong>：都是指的负责存储最终数据的的物理机。</p>
<p><strong>紧缩（compact）</strong>：Haystack 中会定期地检查数据文件，将其复制一遍，但是略过所有重复和已经标记删除的数据，从而回收对应空间。</p>
<p><strong>副本，备份（replica）</strong>：一种冗余策略，廉价通用型机器上免不了出错，为了留有后手进行恢复，最常用策略就是多存几份了，这几份同样的数据成为多副本或者多备份。</p>
<p><strong>秘钥（encryption key）</strong>：用来给 BLOB 进行加密的键</p>
<p><strong>回退模块（backoff node）</strong>：其实我觉得翻译成兜底模块也挺好哈哈，就是应对出错，取 n 个兄弟块来进行恢复的。</p>
<p><strong>数据单元（cell）</strong>：由14个机架，每个机架上有15台机器组成的一个数据部署和回滚的的单元。</p>
<p><strong>数据卷（volume）</strong>：分逻辑卷和物理卷，包含多个数据条带。</p>
<p><strong>数据条带（stripe）</strong>：原始n个数据块和生成的k个奇偶校验块所组成的集合，称为条带。</p>
<p><strong>数据块（block）</strong>：一般是1G左右，被分散在不同容错单元中。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>分布式系统</tag>
        <tag>存储</tag>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title>GFS —— 取舍的艺术</title>
    <url>/2019/05/26/gfs/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/BnLY4kVzAIOX5Si.jpg" alt="write control and data flow"></p>
<h2 id="小引"><a href="#小引" class="headerlink" title="小引"></a>小引</h2><p>GFS 是谷歌为其业务定制开发的，支持弹性伸缩，为海量数据而生的分布式大文件存储系统。它运行于通用廉价商用服务器集群上，具有自动容错功能，支持大量客户端的并发访问。</p>
<p>GFS 是为大文件而生的，针对读多于写的场景。虽然支持对文件修改，但只对追加做了优化。同时不支持 POSIX 语义，但是实现了类似的文件操作的API。它是谷歌在 MapReduce 同时期，为了解决大规模索引等数据存储所实现的具有开创性的工业级的大规模存储系统。</p>
<span id="more"></span>

<p>其主要设计细节如下：</p>
<ul>
<li><strong>简化系统元信息</strong>：Master 中维持了两个重要的映射，分别是文件路径到逻辑数据块，逻辑块与其多副本之间的关系。</li>
<li><strong>较大的数据块</strong>：选择了当时看来相当大的 64M 作为数据存储的基本单位，以此来减少元信息。</li>
<li><strong>放宽的一致性</strong>：允许多副本间内容不一致来简化实现、提高性能，通过读校验来保证损坏数据对用户不可见。</li>
<li><strong>高效副本同步</strong>：在多副本同步时分离控制流和数据流，利用网络拓扑提高同步效率。</li>
<li><strong>租约分散压力</strong>：Master 通过租约将部分权力下放给某个 Chunkserver ，负责某个块的多副本间的读写控制。</li>
<li><strong>追加并发优化</strong>：多客户端对同一文件进行并发追加，保证数据原子性及At Least Once的语义。</li>
<li><strong>快速备份支持</strong>：使用 COW 策略实现快照操作，并通过块的引用计数来进行写时拷贝。</li>
<li><strong>逐节点锁控制</strong>：对于每个操作，需要沿着文件路径逐节点获取读锁，叶子节点获取读锁或者写锁，当然文件路径会进行前缀压缩。</li>
<li><strong>异步垃圾回收</strong>：将数据删除与其他一些主节点的维护操作（损坏块清除，过期数据块移除）统一起来，成为一个定期过程。</li>
<li><strong>版本号标记</strong>：帮助客户端识别过期数据。</li>
<li><strong>数据块校验和</strong>：针对每 64KB 的小块打上 32 bit 的校验和。</li>
</ul>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h3><p>像任何系统一样，其面向的场景需要有一些核心假设，这样其后的所有设计，才能根据这些假设进行取舍。那么 GFS 作为一个分布式的文件系统，其基本假设是什么？可以从几方面来看：错误处理、文件尺寸、修改方式、一致性模型。</p>
<h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>该文件系统的开创之一在于摒弃昂贵工业级的系统硬件，选用普通廉价的商用服务器硬盘集群作为存储介质。于是就必须在软件层面屏蔽这些廉价硬件的不可靠性，为上层应用提供一个可靠的存储服务，这个和 MapReduce 这种计算框架面对的问题是一致的。另外，在软件层面，通常会有成百上千的客户端在同时访问集群，而他们可能又分布在同等规模的其他机器上。</p>
<p>也就是说，在这种存储介质上构建如此尺度的系统，软硬组件出问题不应该被当做异常而应该认为是常态。比如用户代码有bug、操作系统出 bug、硬盘内存网络甚至电源供应，统统有可能出问题。</p>
<p>那么我们在设计系统的时候，就必须在系统内引入持续的监控以监控各个软硬组件的健康状态；整合出错检测、错误容忍、自动恢复机制，以对基本的错误进行告警、处理和自动恢复。</p>
<h4 id="面向大文件"><a href="#面向大文件" class="headerlink" title="面向大文件"></a>面向大文件</h4><p>GFS 设计目标是针对单文件数十M到数G的尺寸。这在当时（2003）看来，已经是很大尺寸的了。当然，随着互联网和通信基础设施的进一步发展，图片和视频等非文本数据的爆炸式增长，现在看来这个假设已经很稀松平常了；不过也由此看出谷歌系统演进的前瞻性。</p>
<p>回到当时的情景，对于数百万计的 KB 尺寸的文件，纵然文件系统可以支持其存储，但是却难以高效地对其管理。因此，GFS 重新对常规文件系统的一些基本设计做了调整：包括文件块（block）的大小，IO操作的流程等等。</p>
<h4 id="追加为主"><a href="#追加为主" class="headerlink" title="追加为主"></a>追加为主</h4><p>在 GFS 针对的场景下，所有的文件修改类型，基本以<strong>追加</strong>为主，很少出现对已经存在的部分的覆盖。至于随机写，虽然支持，但是场景很少。大体上来说，一旦写入完毕，文件就变为只读，并且是<strong>顺序读</strong>。</p>
<p>这样的场景有很多，比如应用持续运行所产生的数据流，比如归档数据，比如一些机器产生的待另一些机器同步或者异步消费的中间数据集。考虑到这些访问模式都是针对大数据文件，如何保证<strong>追加操作</strong>的<strong>并发性</strong>和<strong>原子性</strong>成为文件系统设计的要点；而传统的考虑数据访问局部性而在客户端做cache，在这里就没有那么有吸引力了，并不需要针对其做额外优化。</p>
<h4 id="协同设计"><a href="#协同设计" class="headerlink" title="协同设计"></a>协同设计</h4><p>通过对系统侧和应用侧的联合设计，能够大大提升系统的灵活性。比如 GFS 弱化了一致性模型，在不加重用户代码负担的情况下大大简化了系统设计；又比如，GFS 引入了原子的追加操作，使得多个客户端不用额外的同步操作就可以并发地对同一文件进行追加。</p>
<h4 id="高吞吐"><a href="#高吞吐" class="headerlink" title="高吞吐"></a>高吞吐</h4><p>设计上，高吞吐优先于低延迟。因此为了保证吞吐量，可以适当牺牲延迟。也就是说，GFS 比较适合批量任务而非实时任务。</p>
<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>GFS 虽然并没有实现 POSIX （可移植操作系统接口） 语义，但其 API 和文件系统类似，有 create, delete, open, close, read 和 write。此外，比较特别的一个操作是 record append，这个就比较厉害了，或者说是谷歌针对其场景专门优化的——支持多客户端并发写，在 MapReduce 任务 reduce 落盘阶段能大大提高吞吐。</p>
<p>那 GFS 相对于 POSIX的文件系统语义削减了什么呢？比如细粒度的权限控制，多用户、组用户控制，符号链接等等。</p>
<h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p><img src="https://i.loli.net/2020/03/21/tsEkSRB5vdx27jO.png" alt="gfs-architecture.png"></p>
<p>图画的微言大义，能看出不少信息：</p>
<ol>
<li><strong>物理上</strong>来说，系统有三种<strong>角色</strong>。<strong>客户端（Client），Master 节点和 Chunkserver 节点</strong>。Master 节点只有一个，其他的都有多个。本质上，Chunkserver 和 Client 都表现为 Linux 系统上的一个或一组进程。因此 Client 和 Chunkserver 可能在同一台 Linux 机器上。</li>
<li><strong>逻辑上</strong>来说，系统有两大部分，<strong>元信息和数据</strong>。其中元信息主要包括文件系统命名空间，访问控制信息，文件到其 所包含文件块的映射信息。这部分数据结构存在 Master 上。数据包括一个个文件的实际数据部分，每个文件又被划分为固定大小的 chunk，以某种方式分散在各个 Chunkserver 上。</li>
<li>Client 端包括用户代码和 GFS Client Library 两部分。后者以库代码形式提供，为前者调用。每次进行文件操作，Client 会首先向 Master 询问文件元信息，然后依据获取的数据位置信息去相应 Chunkserver 找对应数据。</li>
</ol>
<p>还有一些东西图中没详细说明，但是实现上却十分重要的：</p>
<ol>
<li>Master 维持一些和 Chunkserver 间的系统事件， 包括租约管理、孤儿块回收、数据块的迁移等等。Master 和 Chunkservers 间通过心跳来收集元信息并下发上述控制信息。</li>
<li>每个文件块（chunk）会在不同机器机架上进行三备份，这是进行容错的最直接粗暴的做法。但是它能带来很多其他的好处，如并发读等等，后面会详细说明。</li>
<li>客户端（Client）和 块服务器（Chunkserver）都没有像计算机的存储体系结构一样，在 GFS 层面对最近访问的数据进行缓存。一来能简化设计，二来数据块太大，缓存也没啥用。三来，可以利用 linux 系统自身的缓存。</li>
</ol>
<h3 id="单点-Master"><a href="#单点-Master" class="headerlink" title="单点 Master"></a>单点 Master</h3><p>都说单点不好，怎么还爱用单点 Master 呢？因为实在太能简化设计了。如果有全局信息的话，可以很方便的实现复杂的全局控制策略。但是缺点当然也是很明显的，最主要的就是，Master 挂了怎么办，Master 对外带宽过小怎么办。</p>
<p>对于前者，可以通过多种方式来做 backup。在 MapReduce paper解读中分析过几种：snapshot+log，主从，状态外存，心跳恢复。GFS 应该1，3，4都用到了。</p>
<p>对于后者，就是尽量减小 Client 端与 Master 的请求交互与数据传输。GFS 的主要做法：</p>
<ol>
<li>Client 不与 Master 发生实际文件数据交互，只请求元信息，比如 Primary 数据块的位置信息，然后就去找相应 Chunkserver。</li>
<li>Client 端会做有限时间内的元信息的缓存，这样对于同客户端的一系列连续请求，对于元信息的请求次数也会降到最低。</li>
</ol>
<p>下面来详细说下读取（filename+offset）流程：</p>
<ol>
<li>Client 将文件内 offset 翻译为 chunk id + chunk 内 offset。</li>
<li>Client 与 Master 交互，通过 filename + chunk id + chunk inner offset 获取该 chunk 所有 replica 的位置。Client 会缓存此信息到 filename+chunk id -&gt; replica locations 的字典中。</li>
<li>Client 于是就近选一个（当然失败了会尝试下一个）replica， 给其发送请求，带上 chunk handle + byte range，读取数据。</li>
</ol>
<p>由于上述缓存存在，只要其不过期，后面同一 chunk 的访问就不必在经过 Master。而且这还可以再继续优化，比如说 Client 一个请求中同时请求多个 chunk 位置；比如说 Master 返回的时候不仅返回该 chunk 的各个 replica 位置，还返回在同一文件中请求的 chunk 后面几个 chunk 的各 replica 位置。这些都能有效减小 Master 的负载。</p>
<h3 id="块尺寸（Chunk-Size）"><a href="#块尺寸（Chunk-Size）" class="headerlink" title="块尺寸（Chunk Size）"></a>块尺寸（Chunk Size）</h3><p><strong>chunk 大小选择是个核心设计点</strong>。选择了当时看来比较大的尺寸 64MB 作为 chunk 的固定大小，每个块物理上是一个 linux 系统下的文件。这么做好处有三：</p>
<ol>
<li><strong>减小 Client 与 Master 的交互次数</strong>：Client 向 Master 请求信息，是以 chunk 为单位的，因此在请求数据量一定的情况下，单个 chunk 越大，请求次数就越少。</li>
<li><strong>减少单个请求的跨 chunk 读取</strong>：也好理解，单个 chunk 越大，同一个请求的 byte range 就越大概率落到单个 chunk 中。</li>
<li><strong>减少总 chunk 的原信息尺寸</strong>：存总大小一定的数据，单个块越大，所需块的数量就越少。而单个块的元信息是相对固定的，因此元信息总量就会变小。在 Master 的内存不变的情况下，就能存下更多的元信息，从而使整个系统的容量上限提高。</li>
</ol>
<p>任何设计都是取舍，选择大块既然有以上好处，就会随之带来以下坏处：</p>
<ol>
<li><strong>内部碎片</strong>。比如需要存储大量小文件，这些小文件的单个文件尺寸小于一个 chunk 大小，但在 GFS 也至少得占一个 chunk，由此带来大量内部碎片。当然每个文件的最后一个 chunk 大概率也会存在一些碎片。</li>
<li><strong>小文件热点</strong>。如果系统中有大量小文件，并且被分配到一个 Chunkserver 上的话，那么该 Chunkserver 就可能会成为热点（因为每个 Chunkserver 可以存的 chunk 一定的话，单个文件占 chunk 少，那么其 serve 的文件数就会多），一般不会有问题。如果真碰到这种问题，可以通过<strong>提高小文件 replica</strong> 个数来临时解决（那么就可以有更多的备胎来分散请求了）。其他可能的办法，谷歌开始开脑洞了：用类似于 p2p 的方式解决，即<strong>一个 Client 可以从其他 Client 上读数据。</strong></li>
</ol>
<p>不过对于 GFS 来说，小文件不是主要目标流量。</p>
<h3 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h3><p>主要包括几大集合和映射，都存在 Master 的内存中。因此 <strong>Master 内存</strong>和<strong>单位尺寸的数据对应的元信息大小</strong>决定了系统的容量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> file <span class="built_in">list</span> 和 logic chunk <span class="built_in">list</span></span><br><span class="line"><span class="number">2.</span> file name -&gt; chunks(identify by <span class="built_in">id</span>)</span><br><span class="line"><span class="number">3.</span> chunk <span class="built_in">id</span> -&gt; chunk replica location</span><br></pre></td></tr></table></figure>

<p>这里 GFS 学了数据库的惯常操作，将对前两个数据结构的任何改动都存在了<strong>操作日志</strong>里，以在必要的时候进行恢复。至于最后一个映射，它采用了另外一种策略：每次 Master 恢复时，通过各个 Chunkserver 的心跳来构建和维持该映射。为什么会有这个不同呢，卖个关子，下面讲。</p>
<h4 id="基于内存的优劣-In-Memory-Data-Structures"><a href="#基于内存的优劣-In-Memory-Data-Structures" class="headerlink" title="基于内存的优劣(In-Memory Data Structures)"></a>基于内存的优劣(In-Memory Data Structures)</h4><p>将所有元信息存放在 Master 内存中，有诸多好处：</p>
<ol>
<li>最直接的就是<strong>简单</strong>。很多时候简单就是强大：意味着好维护，好扩展，性能好等等。</li>
<li>Master 能很方便获取全局信息，从而用来：<strong>回收孤儿 chunk 以释放空间，重新备份 chunk 以应对故障，不断迁移 chunk 以平衡负载</strong>。</li>
<li>内存成为瓶颈了，加内存就好了。</li>
</ol>
<p>坏处就是 Master 内存确实可能成为瓶颈和单点。单点这里不细说。关于容量瓶颈问题，首先当时 GFS 的面对的存储量级还没现在这么大；其次每 64M 文件块可以压缩到只有平均 64 bit 元信息。最后，大多数文件假设都是占好多块的。总体来说，<strong>就是尽量压缩单位数据所对应的元信息，从而在 Master 内存受限的情况下最大化系统容量</strong>。这个上面好像说了，没办法，谷歌的论文就是重复再重复，毕竟，对于写文章来说，呼应就是美嘛。</p>
<h4 id="块位置-Chunk-Locations"><a href="#块位置-Chunk-Locations" class="headerlink" title="块位置(Chunk Locations)"></a>块位置(Chunk Locations)</h4><p>一开始 GFS 也是打算在 Master 上持久化 chunk 的各个副本位置的信息。后来发现，每次被动从各个 Chunkserver 中那里收集更简单直接。因为每个 Chunkserver 天然知道自己一亩三分地的 chunk replica 的信息，每次由他们汇报给 Master 能保持信息最一致。假设这个信息持久化在 Master 中，Master 宕机后恢复时从本地恢复这个信息到内存，但是在这个空当内，好多 Chunkserver 挂了，好多 Chunkserver 又加入了集群，这样信息就不一致了嘛，还得通过心跳来同步达到一致，那么干嘛不一开始就通过心跳来构建呢？</p>
<p>我思考了下，以为这么设计 chunk id -&gt; chunk replica location 的持久化方案的核心点在于，它不像 filename，file -&gt; chunk 这两个映射，<strong>在 Master 宕机的情况下，是无法更新的</strong>；而由于大规模集群的中单个 Chunkserver 的不靠谱性以及各种运维操作的不确定性，是<strong>不断变化</strong>着的。这是分布式集群的一个固有特点，因此这个设计可以说是会心一击。</p>
<h4 id="操作日志-Operation-Log"><a href="#操作日志-Operation-Log" class="headerlink" title="操作日志(Operation Log)"></a>操作日志(Operation Log)</h4><p>操作日志，用来持久化 file namespace 和  file name -&gt; chunk 的映射，有两方面的作用：</p>
<ol>
<li>如前所述，用以持久化上述元信息，并且在 Master 宕机恢复后进行元信息重建。</li>
<li>对于并发操作，用来确定操作顺序，相当于一个’’锁’’的概念。</li>
</ol>
<p>因此，对于 GFS中文件，文件块以及版本号的信息，都可以唯一的由他们写入操作日志的顺序所决定。</p>
<p>操作日志如此重要，因此我们不能只在 Master 硬盘上对其进行备份，万一 Master 整个完蛋了呢？还要将其同步至其他远程机器。之前也提到了，这个日志有点类似于 WAL （Write Ahead Log），所有修改操作必须先要写入操作日志之后，才能应用到 Master 的内存数据结构中，进而暴露给 Client。否则，宕机恢复时，Client 和 Master 拿到的信息的往往不一致。(当然为了避免频繁刷盘影响正常的请求性能，可以将一些操作 batch 后再刷盘，但是也这会带来不一致问题，因此这些考虑需要根据实际业务场景进行灵活调整)</p>
<p><strong>有操作日志的地方就有 checkpoint</strong>。因为一个大型系统面对的请求实在太多，如果每次 Master 恢复时，就从最开始读操作日志进行恢复，这个过程将会相当漫长。为了压缩操作日志，很自然的想法便是定期 checkpoint，将某个时间节点之前的日志所对应的<strong>状态机</strong>或者<strong>内存数据结构</strong>以某种方式持久化下来。GFS 选的是 B 树，因为它可以对应加载到内存中，而不用做一些转化（比如说 通过kv 对构建字典），从而进一步加速恢复时间。</p>
<p>做 snapshot 时，GFS 用了一个小技巧，来避免和当前对操作日志的写入冲突（毕竟同时修改一个文件得加锁）。就是每次到了做 checkpoint 的时间了，就将操作日志切到一个新文件中。然后新启动一个线程，在后台将老文件转化为 checkpoint。</p>
<p>虽然做完最新的 checkpoint 之后老的 snapshot 就可以释放了。但是小心驶得万年船，GFS 在实践中往往会多保留几个 checkpoint。</p>
<h3 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h3><p>这一块是我最初读论文的时候比较难以理解的地方，但是后来想通了发现很巧妙——在系统<strong>满足应用需求</strong>的情况下，适当放宽一致性的限制，会<strong>大大简化实现</strong>。</p>
<p>在详细展开 GFS 的设计之前呢，必须先要搞清楚一个问题，<strong>是什么引出了一致性问题</strong>？如果这个问题不清楚，那么下面所讲 GFS 的一大堆设计，你可能根本不知道它在干嘛，这也是当初我读不懂这一块的原因。答案是<strong>多副本</strong>（replica），凡是有多副本的系统，必然需要面对一致性问题。因为网络的不靠谱性，Client 的不靠谱性，Chunkserver 的不靠谱性，总而言之，就是分布式系统各个节点，以及各个节点间的通信都不靠谱。而将一份内容同步到多个副本是需要时间的（因此该操作<strong>不是原子的</strong>，可能会使系统停在一种蛋疼的中间状态），在这个时间段内，任何一个部件（Client，Chunkserver以及网络）出现问题，就会造成不同副本的不一致，后面的 Client 在读的时候面对不一致的 replica 就会发愁了，以谁为准呢？</p>
<h4 id="GFS-的承诺"><a href="#GFS-的承诺" class="headerlink" title="GFS 的承诺"></a>GFS 的承诺</h4><p>GFS 觉得，不用提供完全的 POSIX 文件系统的语义，只需要以下几个基本承诺，在所面对的场景下，就够用了：</p>
<ol>
<li><strong>文件命名空间的改动（如文件创建操作）是原子的</strong></li>
</ol>
<p>对于第一点，最简单的实现就是在 Master 中文件命名空间的数据结构外加一把大锁，所有操作都是互斥的，也就是对他的任何改动是原子的，通过操作日志能将所有的操作确定一个顺序。但是锁的粒度太大必然影响性能，因此在文件目录树中，其实每个节点都会有锁，具体加锁过程，稍后会详述。</p>
<ol start="2">
<li><strong>修改后的文件块的状态取决于修改类型，修改成功或者失败，是否为并发改动</strong>。</li>
</ol>
<p><img src="https://i.loli.net/2020/02/09/rtYVFlPubGpaSqL.png" alt="修改后的文件状态"></p>
<p>如上图，文件块的状态有三种，一致性级别由高到底：已定义（defined），未定义（undefined）但是一致的（consistent），不一致的。理解这几个级别需要一些背景，论文中不同的地方提到了，这里重新组织一下：</p>
<ol>
<li><strong>修改操作</strong>。包括写操作和追加操作，写操作需要指定文件块+offset。追加操作成功后系统会将追加成功的偏移量返回给客户端。</li>
<li><strong>并发写</strong>。如果两个客户端同时写同一个文件块的同一偏移量，那么就有个先后顺序问题，如果接近同时，系统不保证并发顺序。那么其中客户端再去读，就不一定能读到自己刚写的数据。</li>
<li><strong>追加失败</strong>。追加操作会保证至少成功一次。追加操作时，假设配置三副本，但是只有两个副本写成功，最后一个副本超时了（可能对应块服务器宕机，当然重启后 GFS 会用 chunk version 来标记其过期 stale 了，从而跳过该 offset。），那么追加操作会重试，并且会失败数据<strong>不会删除</strong>，但是 GFS 有对齐操作，即重试成功后，三个副本中该追加数据的起始偏移量是定义的（也就是一致的），那么其中那个上次失败的副本就会有个空洞，系统会用特殊字符填充。</li>
</ol>
<p>明白了这些背景，先说一个结论，<strong>定义未定义针对的是多客户端并发写同一个偏移量的覆盖顺序问题；一致不一致针对的是多个副本相同偏移量的内容是否相同</strong>。再来详细解释这几个名词：</p>
<ol>
<li><strong>已定义（defined）</strong>：客户端写某个偏移量后，再读该偏移量的数据，读到的一定是刚才自己所写。</li>
<li><strong>未定义的但是一致的（undefined but consistent）</strong>：多个客户端并发写同一个偏移量，不确定谁会覆盖谁（这个顺序由 Primary Replica 所在 Chunkserver 来安排，后面将会讲），即写完后再读，不确定是自己写的还是其他人写的。但是保证最终一致性，即并发写完成后，最后几个副本是一致的。</li>
<li><strong>不一致的（inconsistent）</strong>：即修改操作后，所有副本同一偏移量的数据并不完全相同。</li>
</ol>
<p>此外值得一提的是，由于客户端会缓存文件块位置，他可能会读到旧的信息。当然，过期事件和重新打开其所在文件会刷新此信息，但是有一个窗口期会拿到过期信息。但由于GFS大部分场景是追加的，因此一般不会拿到过期数据。</p>
<h4 id="对用户代码的影响"><a href="#对用户代码的影响" class="headerlink" title="对用户代码的影响"></a>对用户代码的影响</h4><p>通过使用其他技术手段：依赖<strong>追加</strong>而非随机写，<strong>检查点技</strong>术以及可以<strong>自校验，自定位</strong>的 Record 写（就是在应用层或者库中做校验和打ID），可以放心使用上面所放宽的一致性模型。下面对这几个技术详细解释一下。</p>
<ol>
<li><p><strong>追加写和检查点</strong></p>
<p>GFS 事实上面对的场景是追加写远多于随机写的，那么在几乎只有追加写的场景下，保持一致性的策略就可以简单的多了。一个典型的场景，就是一个 writer 从头写到结尾，利用两个小手段可以保证一致性：<strong>a. 写完后重命名；b. 定期做检查点。</strong>前者可以保证写文件的原子性，要么完全可以见，要么完全不可见。后者来说，每个检查点其实就是已定义的，自然是一致的，reader 可以放心的读到最后一个检查点。哪怕 writer 故障重启后，也可以从上一个检查点开始增量写。在此过程中，reader 不会读到不一致的数据。</p>
</li>
<li><p><strong>自校验和自定位</strong></p>
<p>另一个经典的场景是多 writer 并发追加以合并分片结果或者充当生产消费队列。之前也提到，对于追加写，GFS 提供<strong>至少成功一次</strong>的语义保证。由于记录写失败了会重试，但是并不会删除，那么就必然存在一些失败记录（表现为一些 replica 上的失败记录和另一些 replica 上的 padding）。</p>
<p>GFS的策略是将对这些错误记录留给 reader 进行处理。具体处理方法是，对于写坏的记录，可以用 writer 写入的校验和进行校验从而跳过；对于写重的记录，writer 提供了 record id，reader 可以在读取的时候根据其进行过滤。</p>
<p>当然，上述逻辑的代码都内置在了库函数中，应用层代码可以很方便的调用。</p>
</li>
</ol>
<h2 id="系统交互"><a href="#系统交互" class="headerlink" title="系统交互"></a>系统交互</h2><p>所有读写流程设计有个基本原则——尽量减少主节点(Master)的参与。因为主节点很容易变成单点瓶颈。接下来详细描述一下客户端、主节点、块服服务器是如何交互来完成<em>数据的变动</em>、<em>原子记录追加</em>以及<em>快照操作</em>的。</p>
<h3 id="租约和修改顺序"><a href="#租约和修改顺序" class="headerlink" title="租约和修改顺序"></a>租约和修改顺序</h3><p>分布式系统上的文件修改包括<strong>元信息的修改</strong>和<strong>文件块的写入、追加</strong>操作。文件块的修改操作会作用于其所有副本上，不同副本写入时需要确定一个顺序。如前所述，我们需要尽可能地减少主节点的参与，那么就不能由主节点来直接做这个决策。GFS 使用了<strong>租约</strong>(lease)的手段，Master 会定期向 chunk 的某个 replica 所在的服务器进行授权（有超时时间，所以称为租约），拿到授权的副本称为<strong>主副本</strong>（primary replica），由其进行写入顺序的安排。这样就将主节点就将<em>某些权力</em>在<em>一段时间</em>内授权给了某个的副本所在的服务器，即，有两个限制：</p>
<ol>
<li><strong>权力范围</strong>。只针对该 Chunk 的所有读写操作。</li>
<li><strong>租约时间</strong>。有超时时间（初始为60s），需要定期续约。一般只要其不死，Master 都会同意其续约请求。不过偶尔 Master 为了防止特定 Chunk 被修改，会主动收回租约，比如说做快照前。</li>
</ol>
<p>使用租约的确减少了客户端与 Master 节点的交互，但是它很依赖<strong>多个节点的时钟同步</strong>。举个例子，假设每个租约会带上其失效的时间戳。此时间戳在 Master 上产生、在主备份节点上被检查，如果主备份节点时钟慢，那么它续约之前 Master 可能就认为该租约超时了，从而将租约授权给另一个备份节点。这时就同时存在了两个备份节点，从而带来一些问题。此外，如果主节点和主备份节点间的网络不连通了，master 将租约授权给另外一个节点，而客户端仍然缓存有原主备份节点地址，并且和该节点可以通信，也会产生问题。</p>
<p>下面来对照流程图来分步骤详细说一下写流程：</p>
<p><img src="https://i.loli.net/2020/02/09/BnLY4kVzAIOX5Si.jpg" alt="write control and data flow"></p>
<ol>
<li>客户端向 Master 询问要写的 Chunk 的<strong>主副本和其他副本的位置</strong>。如果还没有主副本，那么 Master 就通过租约授权一个。</li>
<li>Master 将这些信息发送给客户端后，客户端会将其缓存起来。并且除非主副本不可达或者其租约到期，客户端不会再向 Master 发送请求。</li>
<li>客户端将要写的数据推送给各个副本所在的块服务器。值得一提的设计是，GFS 将<strong>数据流和控制流进行了解耦</strong>，即客户端可以以任何顺序进行数据推送而不用像控制流一样先到主备份再到从备份。这样可以使我们独立优化数据流的推送，甚至可以并行推送；对于大数据块写入是很有好处的，下面章节会详细讨论这个事情。每个 Chunkserver 收到数据后不立即落盘，而是使用 LRU 策略放在缓存里，这也是一个将网络IO和硬盘IO进行解耦的一个操作，一是为了提高效率，一是等待<strong>主备份安排写入顺序</strong>。</li>
<li>当客户端被告知所有副本的数据推送完成后，会向主备份服务器发送写（落盘）请求。主备份所在服务器会把多个并发客户端（如果有的话）的写请求安排一个写入顺序（给每个写请求指定一个<strong>序列号</strong>），并将其写入前面所说的操作日志。</li>
<li>主备份服务器将客户端的写请求以及序列号转给其他副本所在服务器。有了这个唯一对应的序列号，所有副本的落盘顺序就能保持一致。</li>
<li>所有从备份服务器落完盘后给主备份所在服务器复命。</li>
<li>主备份所在服务器回复客户端，如果任何副本写入出现了问题，都会报告给客户端。如果遇到问题，可能有两种：a. 所有副本数据均未落盘。b.部分副本数据落盘成功。对于后者就会出现不一致的状态。客户端的<strong>库代码</strong>（意味着不用应用代码进行处理）检测到错误后会进行重试，因此在真正成功写入之前，步骤 3~7 可能会重复多次。</li>
</ol>
<p>这里需要一提的是一种特殊情况，如果要写入的数据过大，超过一个设计的 Chunk 大小怎么办？答案是将其拆开分成多次写。每次写的流程和上面一样，因此所有副本的数据顺序肯定会保持一致。但是如果同时有其他客户端也在进行写入的话，<strong>那么该次写请求的数据可能会被间隔开，由此造成前面所说一致但是未定义的状态</strong>（consistent but undefined）。</p>
<h3 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h3><p>GFS 将控制流和数据流解耦以充分利用网络带宽。控制流都是从主备份节点到从备份节点，但是数据流就可以根据实际情况来动态调整。主要目标就是最大化利用网络带宽，避免网络瓶颈，最小化数据传输延迟。</p>
<p>GFS 的主要手段有：</p>
<ol>
<li>利用网络拓扑来组织传输顺序</li>
<li>线性的、流水式的传输数据</li>
</ol>
<p>对于第一点，GFS 利用 IP 组织来反应网络拓扑——即根据 IP 的关系可以判断出其节点的网络上的远近关系。</p>
<p>对于第二点，如果是树形传输可能会造成根节点的负载过重，不能均摊负载和网络带宽。但如果只是单纯线性同步而不做流水并行的话，效率又会很低。</p>
<h3 id="记录追加"><a href="#记录追加" class="headerlink" title="记录追加"></a>记录追加</h3><p>GFS 提供一种原子性的追加操作，叫做<strong>记录追加</strong>（<em>Record Append</em>）。不同于需要指定偏移量和数据的写入操作，记录追加操作只需要<strong>指定数据</strong>，在写成功后，写成功的记录偏移量将会返回给客户端。如果多个客户端并发写同一个区域，大概率会造成数据的交叠：即重叠区域的数据部分来自客户端A，另外部分来自客户端B，从而造成不一致的现象。但是对于记录追加操作，系统会通过以下手段来保证写入的数据的<strong>原子性</strong>（即单个记录内容只来自一个客户端）和<strong>可靠性</strong>：</p>
<ol>
<li>如果遇到多客户端并发，由系统统一安排追加顺序，并且单个记录追加时不会被中断。</li>
<li>如果由于节点或者网络故障导致追加失败，会对记录进行重试，即保证至少写成功一次。</li>
</ol>
<p>这个设定有点像 Linux 文件系统中，多个线程使用 O_APPEND 标志进行文件追加操作。设置此标志位后，Linux 的系统调用保证<strong>移动到文件末尾并且进行数据追加</strong>是一个<strong>原子调用</strong>。而对于记录追加操作，GFS 也提供了类似的原子性保证。只不过 Linux 是针对多进程，而 GFS是针对可能跨节点的多个客户端。</p>
<p>GFS 的分布在多台机器上的多个客户端并发写一个文件的应用很依赖此操作。如果 GFS 只支持传统的写入操作，那此类应用就必须要自己进行互斥写以保证数据不产生交叠。比如说分布式锁，但是代码复杂度就上去了，而性能，也大概率会下来。在 GFS 所面对的场景中，就常利用这个记录原子追加的特性，拿 <strong>GFS 上的文件</strong>当多生产者单消费者的队列用，或者充当多个客户端对结果进行合并的媒介（比如 MR 的多个 Paritition Reduce 后的结果归并）。</p>
<p>具体到实现上，只需要在上面图2提到的数据流中稍作改动即可。在数据被推送到各个备份节点之后，客户端会向主备份节点发送落盘请求。主备份节点首先会检查写入数据之后，当前块是否会超过规定块尺寸（64M）。如果超过，则并不落盘，而将当前块剩余空间打满padding（比如说填入特殊字符），然后提醒客户端进行重试。因此追加写对记录的最大大小是有要求的，不能超过块大小的四分之一，这样每次追加写的时候每个块浪费最多不超过四分之一。</p>
<p>如果记录在任何一个备份节点上写入失败，客户端都会对该追加操作进行重试。由此可能会造成某个备份中存在超过一份的该记录数据。如前面一致性一些所说，<strong>GFS 不严格保证所有备份间数据逐字节一致，它仅保证记录作为一个整体被原子的成功的写入一次</strong>，并且各个备份的这份成功数据的所有偏移量保持一致。由此，才能仅返回一个偏移量给客户端，并且下一个操作可以从同一个偏移量进行下一次写。</p>
<p>根据前面所定义的一致性模型，对于记录追加操作来说，成功写入的请求是已定义的，因此也是一致的。而不成功写入的请求，是不一致的即未定义的。至于应用在读取时如何处理这些失败的写入部分，之前讨论过，这里不再详述。</p>
<h3 id="快照操作"><a href="#快照操作" class="headerlink" title="快照操作"></a>快照操作</h3><p>快照操作可以很快的对单个文件或者文件目录树做一个拷贝，注意此接口是会暴露给用户的，而不是像有些系统一样只是系统用来自己做备份的。用户通常使用此操作进行大数据集的拷贝与做实验操作前的备份。</p>
<p>实现上，和 AFS 一样，用的写时复制（copy-on-write）的技术。当要执行快照操作时，Master 会召回所有待拷贝的文件所包含的块的租约，暂时冻结这些文件的写入操作，以进行复制。复制时只是对这些文件的元信息进行拷贝，拷贝后的元信息逻辑上变成新文件， 但是其数据仍然指向原文件。</p>
<p>当进行快照操作后，客户端想对做了快照的文件进行写入时，首先会向 Master 询问租约持有者，Master 注意到该块的<strong>引用数超过1</strong>，于是 Master 先不急进行租约授权，而是通知该数据块 C 及其副本所在的服务器对其各个副本在本地进行数据块复制，产生新数据块 C’。Master 然后修改文件的引用为新数据块，并对其中一个副本进行租约授权，然后将被授权副本返回给客户端。</p>
<p>如此一来，Client 就可以在无感知的情况下以为写了一个新文件。并且所有的写时复制都发生在本地，以加快复制速度，减小网络开销。</p>
<h2 id="主节点操作（Master-Operation）"><a href="#主节点操作（Master-Operation）" class="headerlink" title="主节点操作（Master Operation）"></a>主节点操作（Master Operation）</h2><p>Master 负责所有的文件命名空间的操作。此外，还负责管理全系统范围内的数据块各备份的相关操作。包括：</p>
<ol>
<li>副本放置决策</li>
<li>数据块的创建</li>
<li>各副本的同步</li>
<li>块服务器间的负载均衡</li>
<li>回收无用的资源</li>
</ol>
<p>下面将对上述内容逐一讨论。</p>
<h3 id="命名空间的管理和上锁"><a href="#命名空间的管理和上锁" class="headerlink" title="命名空间的管理和上锁"></a>命名空间的管理和上锁</h3><p>Master 上的有些操作，比如说快照操作是很耗时的，因为它需要收回所有相关块的租约。但是 GFS 不想让这些耗时操作中断其他操作，但同时又要保证操作间互不影响。于是就只能有一种解决方法——<strong>分区域加锁</strong>。当多个操作作用于不同文件区域时，可以并行；当作用于同一文件区域时，需要通过锁来保持互斥。</p>
<p>不同于传统文件系统，GFS 没有专门针对每个目录的数据结构（比如 inode）以列出该目录下的所有文件。GFS 也没有对文件或者目录取别名的操作（对应 Unix-like 文件系统的硬链接和符号链接）。GFS 使用一个查找表来保存<strong>文件路径</strong>到其元信息的映射，并且使用<strong>前缀压缩</strong>（prefix compression）的技术来优化存储（这么看来有可能使用了压缩过的<strong>前缀树</strong>作为数据结构？）。</p>
<p>命名空间树中的有效节点，要么是一个文件路径，要么是一个文件目录路径，GFS 为每个节点都配了一把读写锁，以此作为命名空间互斥操作的数据结构基础。具体来说，每当涉及到命名空间改动（重命名，文件增删等）的操作时，都要顺着文件路径每个节点从前到后依次获取锁。举个例子，针对路径 &#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf，Master 会依次获取 &#x2F;d1，&#x2F;d1&#x2F;d2，…， &#x2F;d1&#x2F;d2&#x2F;..&#x2F;dn 的读锁，然后依据<strong>操作类型</strong>获取  &#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf 读锁或者写锁。当然，leaf 可能是个文件，也可能是个文件目录。</p>
<p>使用此种获取锁的策略可以保证，当 &#x2F;home&#x2F;user 被做快照到 &#x2F;save&#x2F;user 时，&#x2F;home&#x2F;user&#x2F;foo 不能够同时被创建。根据上面的策略描述，GFS 在做快照时，会分别获取 &#x2F;home 和 &#x2F;save 的读锁以及 &#x2F;home&#x2F;user 和 &#x2F;save&#x2F;user 的写锁。而在创建 &#x2F;home&#x2F;user&#x2F;foo 时，会需要获取 &#x2F;home， &#x2F;home&#x2F;user 的读锁以及 &#x2F;home&#x2F;user&#x2F;foo 的写锁。因此这两个操作一定是互斥的，因为他们同时只能有一个操作获取 &#x2F;home&#x2F;user 的锁。</p>
<p>一个问题是，对于路径上的”父级”节点，只需要获取<strong>读锁</strong>就够了。因为 GFS 是没有真正的文件系统层级组织或者说 inode-like 的概念的。因此只需要获取读锁避免”父级”节点被删除就够了，而不需要像传统文件系统一般获取 inode 的写锁，互斥地更改其元信息。这样做有另一个好处，就是多个<strong>客户端可以并发的往一个文件目录写多个文件</strong>，因为每个客户端只需要获取目录的读锁，从而避免目录被<strong>删除，重命名或者做快照等</strong>修改操作，就够了。而对于同一个文件，需要获取写锁，从而将多个客户端的的对同一个文件的修改<strong>请求序列化</strong>（指安排一个特定顺序，而非数据结构序列化反序列化中的序列化）。</p>
<p>另一个很自然的疑问是，每个操作都获取这么多锁，会不会造成死锁？答案是不会，因为针对相同的文件区域（例如同一个文件路径），每个操作获取锁的<strong>顺序是一样</strong>的（按照文件路径的来说，不同层是从上到下，同一层是按照字母序）。因此针对同一块资源，不会发生占有并等待的情况，不满足死锁的条件。由于每个操作都要获取很多锁，GFS 又想保证尽可能的高吞吐高并发，因此需要及时的释放不用的锁避免不必要的等待。</p>
<h3 id="副本放置（Replica-Placement）"><a href="#副本放置（Replica-Placement）" class="headerlink" title="副本放置（Replica Placement）"></a>副本放置（Replica Placement）</h3><p>GFS 面对的物理环境是多层次的：单个 GFS 集群可能分布于多个数据中心的多个机架上的上千台机器，这样就有 数据中心 -&gt; 机架 -&gt; 物理机 三个层次。但一般一个 GFS 集群会局限在一个数据中心中，这样也有两层。这样不同块服务器的通信可能会跨越机架，通过交换机。而机架内网络带宽一般会大于机架间网络带宽。这种多层次的网络拓扑为 GFS 保持可<strong>扩展性（scalability），可靠性（reliability）和可用性（availability）</strong>提出了很大挑战，当然，<strong>这也是任何分布式系统设计所面临的问题</strong>。</p>
<p>基于此，GFS 中的副本放置策略有两大目标：</p>
<ol>
<li>最大化大数据的可靠性和可用性。</li>
<li>最大化网络带宽的利用。</li>
</ol>
<p>为了满足第一点，我们不能把鸡蛋放一个篮子里，即同一个集群的 Chunkserver 不能只放一个机架内，以容忍整个机架故障。同时意味着需要有大量的跨机架的读写请求，一方面可以充分利用网络带宽，但是跨机架间的读写请求又会存在一些性能问题，总之都是<strong>权衡（tradeoff）</strong>。</p>
<h3 id="副本创建（creation），副本补齐（re-replication）和副本平衡（rebalancing）、"><a href="#副本创建（creation），副本补齐（re-replication）和副本平衡（rebalancing）、" class="headerlink" title="副本创建（creation），副本补齐（re-replication）和副本平衡（rebalancing）、"></a>副本创建（creation），副本补齐（re-replication）和副本平衡（rebalancing）、</h3><p>数据块被创建，有三种情况：数据块初始创建时，副本补齐时与跨节点再平衡时。</p>
<p>首先，当 Master 在给一个新创建的数据块副本选择位置时，会考虑以下几个因素：</p>
<ol>
<li><strong>节点的硬盘利用率</strong>。以使得数据分布均衡。</li>
<li><strong>节点最近备份的数量</strong>。 GFS 所面对场景大多是一次写后紧跟多次读，为了均衡负载，需要将最近写入尽量分散到多个节点。</li>
<li><strong>多副本的多机架分散</strong>。</li>
</ol>
<p>其次，当某个数据块的实际存活副本数量小于系统设定值时，就会启动备份补齐流程。造成备份补齐的原因有很多，比如说某些机器宕机，某些硬盘故障，某些数据块设定值增大等等。GFS 中数据块一般都会很多，因此同一时刻可能有很多数据块需要进行再备份，因此我们必须给所有再备份请求安排一个优先级。在安排先后次序时，我们有这么几个要考虑的点：</p>
<ol>
<li><strong>存活数与设定值的差值</strong>。副本数差的越多，优先级就越高，这不难理解，毕竟差的越多，该数据块不可恢复的危险就越大。</li>
<li><strong>文件的活跃状态</strong>。举两个极端例子，如果最近文件很活跃，比如说在创建中，那么就优先对该文件所含文件块进行副本补齐。如果文件刚被删除，那么明显地，我们就不在需要对其进行操作。</li>
<li><strong>是否阻塞当前客户端操作</strong>。如果因为某数据块副本数不足导致某个客户端等待，那么就优先处理此数据块的补齐请求。</li>
</ol>
<p>在对所有副本补齐请求按照上述三个影响因子加权排序后，Master 渐次选择权重最高的请求，指示某个块服务器进行副本的复制，复制后放置策略跟初次创建时放置策略大体相同。为了不影响客户端的正常请求，GFS 会在集群总范围和单个块服务器范围内都限制副本复制的进程数。同时，在也在带宽层面对副本补齐的总带宽进行了限制。</p>
<p>最后，Master 会周期性的进行系统范围内的副本挪动以<strong>充分利用硬盘空间并进行负载均衡</strong>。同时，这种周期性操作也会将一个新加入集群的节点慢慢的填满，而不是直接将所有的写请求打过去以迅速填满该节点。后者很容易造成请求震荡以及系统复杂度的提升。在删除副本时，倾向于对硬盘剩余空间少于平均水平的节点下手；而增加副本时，策略任何创建时大抵相同。</p>
<h3 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h3><p>当 GFS 上的文件被删除后，GFS 不会立即回收相应的物理存储。而是通过周期性的垃圾回收程序在文件层面和数据块层面对这些不用的存储做回收。将删除和回收解耦会使得系统变的简单和健壮。至于为什么，下面一一道来。</p>
<h4 id="基本机制"><a href="#基本机制" class="headerlink" title="基本机制"></a>基本机制</h4><p>和其他操作一样，当 GFS 的用户删除一个文件时，Master 会立即在操作日志上记下一笔。不同的是，GFS 并不会真的立即删除文件并且回收对应资源，而是将该文件重命名为一个隐藏文件，并且带上删除操作的时间戳。GFS 文件系统命名空间有周期性的检查操作，当某个隐藏文件存在超过三天（这是一个运维人员可配置项）时，会将其元信息进行删除，注意，此时该文件对应的数据还在块服务器的的，只不过我们没法找到它们了。</p>
<p>与 Master 上的命名空间（文件路径到逻辑块）周期性检查一样，Master 也会对所有的数据块（逻辑块到物理副本）进行检查，当发现某些逻辑块不能通过任何文件访问时（结合前面 Snapshot 操作可以猜想，逻辑块中应该都维护了文件的引用计数，因此只要引用计数减到0 就说明该逻辑块已经没有文件引用，变成了<strong>孤儿块</strong>），就会删除该该逻辑块的信息。注意，此时仍不会<strong>同步的</strong>去删除块服务器上的数据。</p>
<p>每个块服务器会周期性的上报其所持有的数据块物理副本的信息，Master 收到这些信息后，会去上面提到的数据块到物理副本的集合中逐一查找对应信息，并在心跳 RPC 的回应中将这些信息带回。块服务器拿到本机上所有孤儿物理副本的信息后，才会真正的将这些副本删除（不晓得这一步是不是同步的，大概率不是）。</p>
<h4 id="额外探讨"><a href="#额外探讨" class="headerlink" title="额外探讨"></a>额外探讨</h4><p>虽然对于编程语言来说，垃圾回收是一个复杂的话题。但在 GFS 的设定下，垃圾数据块的定位相当简单，它的追踪主要依据之前提到的<strong>两个数据结构</strong>。一个是文件路径到逻辑块的映射，所有不在该映射中被引用的数据块都是无用数据块。另一个是逻辑块到物理副本（以Linux 文件形式存储）的映射，它们由各个块服务器心跳汇报来构建，所有存在块服务器上，但是不为 Master 所知（即其对应的逻辑数据块不在第一个映射中了），都可以被认为是垃圾。</p>
<p>相比于同步相应删除操作，异步的垃圾回收有诸多好处：</p>
<ol>
<li><strong>在各种出错的大型集群中，垃圾回收更简单可靠</strong>。不可靠的环境下，创建可能会出错，删除可能会出错，更改可能也会出错，因此这些操作都可能会留下垃圾。对于同步删除来说，如果出错还要记下出错数据，不断进行重试。而垃圾回收能够提供一种统一的回收上述出错遗留的垃圾的方法。如果使用同步的删除的方法，处理其他出错留下的垃圾的话还得产生很多冗余相似代码。</li>
<li><strong>垃圾回收将分散的删除操作改为定期集中清理</strong>。批量回收，效率可能更好一些。而且因为所有的垃圾回收操作被集中到了 Master 的周期性检查上，因此就可以对具体的操作时机做选择，以避开用户正常请求的高峰期。</li>
<li><strong>异步、惰性的垃圾回收还能应对误删操作。</strong></li>
</ol>
<p>凡事利弊相随，异步惰性垃圾回收策略在我们真想立即删除某些数据的时候就很捉急了。此外，如果有大量的临时小文件产生，会很影响集群利用率。为了解决这些问题，可以做以下优化：</p>
<ol>
<li>被删除的文件变成隐藏文件后，如果再被显式的删除，我们就会加快其的删除步伐。</li>
<li>按文件命名空间分而治之。比如用户可以指定某些目录下的文件不进行多备份；比如又可以规定另外一些文件目录下的文件删除后就会真正立即删除。</li>
</ol>
<p>当然，这样都会带来额外的逻辑和实现复杂度，如何在不可靠环境中优雅的实现、如何和现有的代码逻辑相洽，那就是另外的，干起来不那么美好的事情了。</p>
<h3 id="过期副本检测（Stale-Replica-Detection）"><a href="#过期副本检测（Stale-Replica-Detection）" class="headerlink" title="过期副本检测（Stale Replica Detection）"></a>过期副本检测（Stale Replica Detection）</h3><p>当数据块服务器宕机恢复时，其存储的一些数据块可能在此间进行了更改操作，这就导致该服务器上存储的对应数据块的副本过期。为了解决这一问题，GFS 引入了针对逻辑块的版本，以此来甄别同一数据块的不同副本是否过期。</p>
<p>具体做法为，每次 Master 对数据块进行租约授权时，都会增加版本号并通知所有副本进行更新，Master 和所有副本都会持久化最新版本号。然后 Master 将持有租约的副本以及更新后的版本号发送给客户端。客户端在读写数据的时，会根据最新版本号逐一检查所有副本是否为最新副本，所有过期副本会被当做不存在，上文提到的垃圾回收程序会周期性的将其清除。</p>
<h2 id="容错和诊断"><a href="#容错和诊断" class="headerlink" title="容错和诊断"></a>容错和诊断</h2><p>GFS 设计和构建的一大挑战就是单个组件不可靠而组件数量又特别多。我们既不能完全信任机器，也不能完全信任硬盘，组件故障会导致系统故障，甚至数据损坏。接下来讲一讲 GFS 在这方面遇到的问题以及应对之道。</p>
<h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>对于数百台机器组成的集群，任何给定时刻都可能出现组件故障。为了应对这些问题，GFS 使用了两条看来简单但是行之有效的策略：<strong>数据备份和快速恢复</strong>。</p>
<h4 id="快速恢复（Fast-Recovery）"><a href="#快速恢复（Fast-Recovery）" class="headerlink" title="快速恢复（Fast Recovery）"></a>快速恢复（Fast Recovery）</h4><p>GFS 系统中总共有三个角色：Master， Chunkserver 和 Client。前两者都设计为无论如何死掉都可以快速恢复其状态，最后一个在遭遇问题是会通过提供的系统库做一些重试策略。事实上，GFS 也不区分是人为关闭，意外退出还是偶尔超时，所有失败组件都会迅速重启，重试和重连（对于客户端来说）。</p>
<h4 id="数据块备份（Chunk-Replication）"><a href="#数据块备份（Chunk-Replication）" class="headerlink" title="数据块备份（Chunk Replication）"></a>数据块备份（Chunk Replication）</h4><p>如前所述，对于数据块我们默认进行三备份，但是应用侧可以按命名空间（比如说某个目录下）来对数据块副本数进行调整。GFS 系统中 Master 会控制保持数据块副本数满足要求，即当数据块副本数因为 Chunkserver 宕机、校验和出错，用户设置等等而小于设定数时，Master 会指定 <strong>Chunkserver 去增加副本</strong>。有时候，哪怕副本数满足容错需求，GFS 为了高并发等需求也会提高副本数量。此外，<strong>还探索了 EC 等方式进行跨机器冗余</strong>。当然，GFS 希望能够松耦合的实现这些额外的设计，毕竟 GFS 的流量是面对追加写和顺序读而不是随机写。</p>
<h4 id="Master-冗余"><a href="#Master-冗余" class="headerlink" title="Master 冗余"></a>Master 冗余</h4><p>Master 的状态会通过操作日志的形式在本机持久化并且同步到多台其他物理机。GFS 中的一个操作，只有在被提交到操作日志后才会被认为是应用到了文件系统中；不过为了不影响正常文件操作和后台工作，这些都是额外进程在做的，如果进程死掉，会很快被重启。如果 Master 硬盘或者系统故障而不能提供服务，GFS 外部的基础设施会及时检测到，在其他机器重启一个 Master，并通过操作日志副本进行状态恢复。那么客户端如何发现新的 Master 呢？ GFS 用了主机名而非具体 IP 来让客户端连接 Master，因此只需要修改内部 DNS，将 Master 主机名指向新的机器 IP 就行。</p>
<p>此外，还可以使用影子 Master 来分流数据读取压力。影子 Master 会在延迟上稍微有些牺牲，通常在一秒左右。因此适用于应对那些不怎么发生改变的文件或者对稍微过期数据不是很敏感的流量。所有决策（主要是各个副本的位置决策）依赖于真正的 Master，影子 Master 只做被动信息同步，即要么通过操作日志加载，要么通过和块服务器握手来获取。</p>
<h3 id="数据完整性（Data-Integrity）"><a href="#数据完整性（Data-Integrity）" class="headerlink" title="数据完整性（Data Integrity）"></a>数据完整性（Data Integrity）</h3><p>块数据服务器使用校验和来发现损坏的数据块。考虑到一个 GFS 集群通常由横跨数百台机器的数千块硬盘组成，读写时遇到损坏的数据块很正常。GFS 会通过其他副本来恢复损坏副本，但是将不同副本逐字节校验来保证数据正确性是不可行的，一来性能受不了，二来 GFS 并不保证多副本的数据逐字节一致（比如说并行追加重试遗留的未完成数据块）。因此每个块服务器通过校验和来分别对自己所管辖的块进行校验。</p>
<p>每个数据块会以64kb 为一个小块（block），构造一个对应的的32bit 的校验和，作为元信息存在内存中，并且通过操作日持进行持久化。即，校验和与真正用户数据是分开存储的。</p>
<p>在读取前，主要包括客户端读取或者其他块服务器读取，块服务器会校验读取的数据范围所对应的所有小块的校验和。如果校验出现不一致，块服务器会返回错误，并且将其报告给 Master，因此数据块损坏并不会在块服务器间进行传播。收到报错后，请求者会去读取其它副本，Master 会指示选定块服务器对其进行拷贝，以维持有效副本数。新副本就位后，损坏副本会被当做垃圾进行回收。校验和对于读取的性能影响并不大，首先其所占的额外存储和计算开销并不大，其次校验和都存在内存中，其计算和验证不耗费额外IO，可以和数据流 IO 进行并行。</p>
<p>写请求包括常规写和并行追加写。后者是 GFS 的主要流量，GFS 针对其做校验和进行了高度优化。每次只需要不断对最后一个小块的校验和进行更新。但是对于指定偏移量覆盖写来说，在写入前必须先对要写范围对应的首尾小块做验证，<strong>因为他们可能是部分写，不经验证直接部分覆盖的话，可能会隐藏原来数据块已经损坏的事实</strong>。</p>
<p>最后，块服务器会周期性的对不活跃的数据块进行校验，检测到任何不一致，会像前面提的流程一样，向 Master 进行报告，重新备份该块，然后删除损坏块。</p>
<h3 id="诊断工具"><a href="#诊断工具" class="headerlink" title="诊断工具"></a>诊断工具</h3><p>GFS 会保存额外的系统日志以进行问题定位，bug调试和性能分析，这样做会带来很小额外空间开销。但如果不保存这些日志，事后可能会很难理解机器间的一些系统行为，由于网络的复杂性和普通商用机的不稳定性，它们当时的情景可能很难复现。当然，如何记录合适的日志事件也需要一些经验和技巧。GFS 会对一些机器关键性（块服务器的上下线）的事件，所有的 RPC 请求和回应等等，在空间允许的情况下，GFS 会尽可能多的保留系统日志。</p>
<p>通过收集所有的 RPC 请求，可以重建 GFS 组件间系统交互的历史，以辅助定位问题。我们也可以通过对日志挖掘来对其负载分布进行追踪。再次强调一遍，记这些日志并不会对正常的客户端请求有太多影响，因为所有日志都是异步的、顺序地记录下来的，所有实时的状态信息都存在内存中并且以监控页面的形式呈现给用户。</p>
<h2 id="名词释义"><a href="#名词释义" class="headerlink" title="名词释义"></a>名词释义</h2><p><strong>Master</strong>：主节点，GFS 集群中用于维护文件系统元信息和中心控制的中央节点，实际表现为 Master 节点上的一组进程。</p>
<p><strong>Client</strong>： 客户端，本文专指连接 GFS 集群进行文件操作的的应用。</p>
<p><strong>Chunkserver</strong>：块服务器，以普通 linux 文件存储数据块的数据节点（实际上是运行于节点上的进程）。</p>
<p><strong>consistent but undefined</strong>：有时候指 chunk 的某个副本；有时候指 chunk 某个副本所在的服务器。</p>
<p><strong>Operation Log</strong>：操作日志，用来进行错误恢复和确定并发写入顺序。</p>
<p><strong>consistent but undefined</strong>：一致但是未定义，指多个客户端并发写入的时候，虽然最终副本的数据顺序一致，但是如果某个客户端再去读数据，并不知道能读到自己写的数据，还是被其他客户端覆盖写的数据。</p>
<p><strong>Primay Replica</strong>：主副本&#x2F;备份，或者主副本&#x2F;备份所在节点。</p>
<p><strong>Re-replication</strong>：翻译成了副本&#x2F;备份补齐</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>GFS 论文：<span class="exturl" data-url="aHR0cHM6Ly9zdGF0aWMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL21lZGlhL3Jlc2VhcmNoLmdvb2dsZS5jb20vemgtQ04vL2FyY2hpdmUvZ2ZzLXNvc3AyMDAzLnBkZg==">https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9tZS5jc2RuLm5ldC9xaWFvamlhbGlu">铁头乔<i class="fa fa-external-link-alt"></i></span> GFS一致性总结： <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FpYW9qaWFsaW4vYXJ0aWNsZS9kZXRhaWxzLzcxNTc0MjAz">https://blog.csdn.net/qiaojialin/article/details/71574203<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>分布式系统</tag>
        <tag>存储</tag>
        <tag>gfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Ray 源码解析（一）：任务的状态转移和组织形式</title>
    <url>/2019/07/28/ray-source-reading-1/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/YqVzB7QvTmcuijo.png" alt="ray-task-state-transfer.png"></p>
<p>之前文章写了 Ray 的论文翻译。后来我花了些时间读了读 Ray 的源码，为了学习和记忆，后续预计会出一系列的源码解析文章。为了做到能持续更新，尽量将模块拆碎些，以保持较短篇幅。另外，阅历所限，源码理解不免有偏颇指出，欢迎大家一块讨论。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Ray 核心的设计之一就是基于资源定制的细粒度、高吞吐的任务调度。为了实现这一点，Ray 将所有输入和输出存在基于共享内存的 Plasma 中；将所有状态存在基于 Redis 的 GCS 中，然后基于此进行<strong>去中心化的调度</strong>。即每个节点都可以拿到全局信息来进行局部调度决策，不过这也是不好做复杂调度策略的原因之一。</p>
<p><strong>Ray 任务分为两种，无状态的 Task 和有状态的 Actor Method</strong>，后者又可以细分为 Actor Create Method  （对应构造函数）和普通 Actor Method（对应成员函数）。</p>
<p>Ray 是可以显式指定任务的资源（主要是 CPU 和 GPU）约束的，因此需要对所有节点的资源在框架层进行量化（ResourcesSet），以感知增加，进行分配、实现回收等等。在调度时，需要找到满足任务资源约束的节点，将任务调度过去。</p>
<p>由于所有 Task 的输入存在<strong>分布式的内存存储</strong> Plasma 中，因此将 Task 调度到某个节点之后，需要对所依赖的输入进行跨节点传输。或者直接将任务调度到满足依赖的节点上，但事实上 Ray 对于一般 Task 并没有这么做，后面会详细讲原因。对于 Actor Method 来说，由于其对应 Actor 常驻某个节点，其相关的所有 Actor Method 定会调度到该节点上。</p>
<p>上面所说的任务所在节点、当前的状态、依赖对象的位置等等信息，都是存在<strong>全局控制存储</strong> GCS 中的。因此每次改变状态后，要和 GCS 交互将状态写入。在由于节点失联或者宕机导致任务失败时，会根据 GCS 存的任务的状态信息对任务进行重试。通过订阅 GCS 的某些状态的变化事件，可以驱动任务状态变化。</p>
<p>其他的还有根据 lineage + snapshot 进行快照恢复，Actor lineage 的构建等等，这里先卖个关子，后面系列文章会详细来说。</p>
<p><strong>本文主要针对所有任务的状态转移和组织形式进行展开</strong>。</p>
<h2 id="状态机"><a href="#状态机" class="headerlink" title="状态机"></a>状态机</h2><p>复杂的任务调度必然需要一个合理的状态机来描述。以下是 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JheS1wcm9qZWN0L3JheS9ibG9iL21hc3Rlci9zcmMvcmF5L3JheWxldC9kZXNpZ25fZG9jcy90YXNrX3N0YXRlcy5yc3Q=">Ray 文档<i class="fa fa-external-link-alt"></i></span> 给出的任务状态定义和转移图。</p>
<h3 id="状态定义"><a href="#状态定义" class="headerlink" title="状态定义"></a>状态定义</h3><ul>
<li><strong>可放置（Placeable）</strong>： 任务准备好了被调度到某个节点上（本地或者远程）。调度决策主要是依据任务资源约束和节点剩余资源的匹配程度。当前没有考虑任务依赖对象的位置信息。如果本地节点满足任务资源需求，那么任务就被安排在本地进行执行，否则将会被<strong>转发</strong>（forward）到其他满足资源需求的节点。不过该状态决策不一定是最终决策，该任务稍后仍然可能被<strong>挤</strong>（spill over）到其他节点（因为调度那一刻满足资源，但是执行时，发现已经执行了其他任务，导致节点不满足资源约束了）。</li>
<li><strong>等待Actor创建（WaitForActorCreation）</strong>：一个 Actor Method 等待其 Actor 实例被创建（大多数发生在Actor 错误恢复时，否则一般来说是 Actor Create Method 先执行）。一旦 Actor 实例被创建，并且通过 GCS 被该 Actor Method 感知到，它就会被调度到 Actor 实例所在的节点。</li>
<li><strong>等待（Waiting）</strong>：任务等待其输入对象被满足，比如，等待任务函数参数对象从其他节点调度到本地的对象存储中。</li>
<li><strong>就绪（Ready）</strong>：任务所依赖的对象都在本地的对象存储中了，因此任务已经准备好在<em><strong>本地</strong></em>（指的是任务当前所在节点，下面也是）运行了。</li>
<li><strong>运行（Running）</strong>：任务已经调度到本地执行了，运行在本地的 Actor 或者 Worker 进程中。</li>
<li><strong>阻塞（Blocked）</strong>：任务某些依赖对象不可用（即不在本地）。不在本地怎么之前能跑呢，这里说明一下，Ray 的任务是支持嵌套调用的（对应远程函数的嵌套调用），那么一个任务 A 在运行时生成了一个任务  B ，并且等待其结果返回的话（<code>ray.get</code>）。任务 A 就会被阻塞（Blocked），等待 B 的执行结束。</li>
<li><strong>不可放置（Infeasible）</strong>：任务的资源需求不能被当前集群内任何一台机器的所有资源（注意不是剩余资源）所满足。但如果有机器新加入集群，就可以试探这些 任务的资源需求是否能够被满足了。</li>
</ul>
<h3 id="状态转移图"><a href="#状态转移图" class="headerlink" title="状态转移图"></a>状态转移图</h3><p><img src="https://i.loli.net/2020/02/09/YqVzB7QvTmcuijo.png" alt="任务状态转移图"></p>
<h3 id="状态枚举类"><a href="#状态枚举类" class="headerlink" title="状态枚举类"></a>状态枚举类</h3><p>状态枚举类定义在 <code>scheduling_queue.h</code> 中：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum class</span> <span class="title class_">TaskState</span> &#123;</span><br><span class="line">  <span class="comment">// The task may be placed on a node.</span></span><br><span class="line">  PLACEABLE,</span><br><span class="line">  <span class="comment">// The task has been placed on a node and is waiting for some object</span></span><br><span class="line">  <span class="comment">// dependencies to become local.</span></span><br><span class="line">  WAITING,</span><br><span class="line">  <span class="comment">// The task has been placed on a node, all dependencies are satisfied, and is</span></span><br><span class="line">  <span class="comment">// waiting for resources to run.</span></span><br><span class="line">  READY,</span><br><span class="line">  <span class="comment">// The task is running on a worker. The task may also be blocked in a ray.get</span></span><br><span class="line">  <span class="comment">// or ray.wait call, in which case it also has state BLOCKED.</span></span><br><span class="line">  RUNNING,</span><br><span class="line">  <span class="comment">// The task has resources that cannot be satisfied by any node, as far as we</span></span><br><span class="line">  <span class="comment">// know.</span></span><br><span class="line">  INFEASIBLE,</span><br><span class="line">  <span class="comment">// The task is an actor method and is waiting to learn where the actor was</span></span><br><span class="line">  <span class="comment">// created.</span></span><br><span class="line">  WAITING_FOR_ACTOR_CREATION,</span><br><span class="line">  <span class="comment">// Swap queue for tasks that are in between states. This can happen when a</span></span><br><span class="line">  <span class="comment">// task is removed from one queue, and an async callback is responsible for</span></span><br><span class="line">  <span class="comment">// re-queuing the task. For example, a READY task that has just been assigned</span></span><br><span class="line">  <span class="comment">// to a worker will get moved to the SWAP queue while waiting for a response</span></span><br><span class="line">  <span class="comment">// from the worker. If the worker accepts the task, the task will be added to</span></span><br><span class="line">  <span class="comment">// the RUNNING queue, else it will be returned to READY.</span></span><br><span class="line">  SWAP,</span><br><span class="line">  <span class="comment">// The number of task queues. All states that precede this enum must have an</span></span><br><span class="line">  <span class="comment">// associated TaskQueue in SchedulingQueue. All states that succeed</span></span><br><span class="line">  <span class="comment">// this enum do not have an associated TaskQueue, since the tasks</span></span><br><span class="line">  <span class="comment">// in those states may not have any associated task data.</span></span><br><span class="line">  kNumTaskQueues,</span><br><span class="line">  <span class="comment">// The task is running but blocked in a ray.get or ray.wait call. Tasks that</span></span><br><span class="line">  <span class="comment">// were explicitly assigned by us may be both BLOCKED and RUNNING, while</span></span><br><span class="line">  <span class="comment">// tasks that were created out-of-band (e.g., the application created</span></span><br><span class="line">  <span class="comment">// multiple threads) are only BLOCKED.</span></span><br><span class="line">  BLOCKED,</span><br><span class="line">  <span class="comment">// The task is a driver task.</span></span><br><span class="line">  DRIVER,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>相对于状态机中的状态，此处多了几个枚举值。包括 SWAP、DRIVER。此外还有个神奇的 kNumTaskQueues，这个先按下不表，说说前两个。</p>
<ul>
<li><strong>SWAP</strong>：任务的分派是异步的，即 Ray 将一个处于 Ready 状态的任务分配给某个 Worker 后。只有在回调函数中才能最终知晓是分配成功了，还是分配失败了，从而将任务状态转移到 Running 或者 Ready。但是在这个空当中，任务应该处于什么状态呢？这就是 Swap 的作用了（但不知道为什么没有显式的作为状态机中的一个状态）。</li>
<li><strong>DRIVER</strong>：这个就是标识某个任务是用户代码进程，从而将所有任务都统一来管理。</li>
</ul>
<h2 id="任务队列-TaskQueue"><a href="#任务队列-TaskQueue" class="headerlink" title="任务队列(TaskQueue)"></a>任务队列(TaskQueue)</h2><p>Ray 将所有任务按<strong>状态</strong>（TaskState）聚集组织在一个个队列中， 这些队列即任务队列（TaskQueue）。每个队列定义了任务增加、删除和查找等基本操作。此外，还有一个重要的接口，就是获取该队列中所有任务所需资源的总和。比如说在调度某个任务时，想要知道某个节点对剩余可用资源，就需要用该节点的总资源，减去正在运行的任务的所需资源和就绪任务的所需资源（需要优先本地调度）。</p>
<p>值得一提的是，在删除任务的时候，如果 removed_tasks 参数不为空指针，则将删除的任务放到里面。这样如果多次删除，可以将任务收集到一个数组中。</p>
<p>还有一个比较冗余的点，即通过 <code>task.GetTaskSpecification.TaskId()</code> 可以获取到 task_id，不知道为什么还在 AppendTask 参数中增加 task_id 呢，为了一致性？</p>
<p>至于具体实现上，用了比较经典的<strong>链表+哈希</strong>方式组织。可以使得增删改查的时间都是O(1)，获取全部任务的时间是 O(n)——遍历链表即可。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueue</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">TaskQueue</span>() &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 任务的增删改查操作</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">AppendTask</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id, <span class="type">const</span> Task &amp;task)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">RemoveTask</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id,</span></span></span><br><span class="line"><span class="params"><span class="function">                          std::vector&lt;Task&gt; *removed_tasks = <span class="literal">nullptr</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">HasTask</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> std::list&lt;Task&gt; &amp;<span class="title">GetTasks</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> Task &amp;<span class="title">GetTask</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取队列中所需资源总和</span></span><br><span class="line">  <span class="function"><span class="type">const</span> ResourceSet &amp;<span class="title">GetCurrentResourceLoad</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  <span class="comment">// 链表+哈希组织，可以快速查找O(1)和线性遍历O(n)</span></span><br><span class="line">  std::list&lt;Task&gt; task_list_;</span><br><span class="line">  std::unordered_map&lt;TaskID, std::list&lt;Task&gt;::iterator&gt; task_map_;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 所有任务所需资源总和</span></span><br><span class="line">  ResourceSet current_resource_load_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>在此基础上针对 Ready 这个状态又造了个 <code>ReadyQueue</code>；主要是增加了 <code>ResourceSet -&gt; Task Ids</code> 的映射：即增加了一个索引，将所有具有相同<strong>资源需求</strong>的就绪任务集合在一块。这样在进行调度（<code>DispatchTasks</code>）时，如果发现某个任务的资源需求本地节点不能满足，那么就跳过所有具有同样资源需求的任务，算是一个调度的优化（对应逻辑在<code>NodeManager::DispatchTasks</code> 中）。</p>
<h3 id="调度队列-SchedulingQueue"><a href="#调度队列-SchedulingQueue" class="headerlink" title="调度队列(SchedulingQueue)"></a>调度队列(SchedulingQueue)</h3><p>按状态集合上述任务队列，再加以不同队列之间的任务换入换出操作，则成为<strong>调度队列</strong>（SchedulingQueue）。当 Ray 发生不同事件时，<strong>驱动任务状态机内状态进行转移</strong>，即调用 <code>SchedulingQueue</code> 暴露的接口，将任务从一个状态队列移到另一个状态队列中，并且做一些上下文的转换工作，以此来实现任务的调度。</p>
<p>需要注意的是，每个节点会维护一个调度队列，存储本节点持有的所有任务。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SchedulingQueue</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">/// 创建一个空的调度队列，初始化各个状态对应的任务队列，就绪队列被单独拿出来用 ReadyQueue 做初始化。</span></span><br><span class="line">  <span class="built_in">SchedulingQueue</span>() : <span class="built_in">ready_queue_</span>(std::<span class="built_in">make_shared</span>&lt;ReadyQueue&gt;()) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span> &amp;task_state : &#123;</span><br><span class="line">             TaskState::PLACEABLE,</span><br><span class="line">             TaskState::WAITING,</span><br><span class="line">             TaskState::READY,</span><br><span class="line">             TaskState::RUNNING,</span><br><span class="line">             TaskState::INFEASIBLE,</span><br><span class="line">             TaskState::WAITING_FOR_ACTOR_CREATION,</span><br><span class="line">             TaskState::SWAP,</span><br><span class="line">         &#125;) &#123;</span><br><span class="line">      <span class="keyword">if</span> (task_state == TaskState::READY) &#123;</span><br><span class="line">        task_queues_[<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(task_state)] = ready_queue_;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        task_queues_[<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(task_state)] = std::<span class="built_in">make_shared</span>&lt;TaskQueue&gt;();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 我觉得名字起得不好，他的实际操作是获取所有就绪任务资源需求之和</span></span><br><span class="line">  <span class="function">ResourceSet <span class="title">GetResourceLoad</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/// 单个任务的增删查</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">HasTask</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id)</span> <span class="type">const</span></span>; </span><br><span class="line">  <span class="function"><span class="type">const</span> Task &amp;<span class="title">GetTaskOfState</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id, TaskState task_state)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">RemoveTask</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id, Task *removed_task, TaskState *removed_task_state = <span class="literal">nullptr</span>)</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 按状态获取任务，对于就绪状态，还需要按资源进行聚集</span></span><br><span class="line">  <span class="type">const</span> std::unordered_map&lt;ResourceSet, ordered_set&lt;TaskID&gt;&gt; &amp;<span class="built_in">GetReadyTasksWithResources</span>() <span class="type">const</span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> std::list&lt;Task&gt; &amp;<span class="title">GetTasks</span><span class="params">(TaskState task_state)</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 一组任务的移来移去</span></span><br><span class="line">  <span class="function">std::vector&lt;Task&gt; <span class="title">RemoveTasks</span><span class="params">(std::unordered_set&lt;TaskID&gt; &amp;task_ids)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">QueueTasks</span><span class="params">(<span class="type">const</span> std::vector&lt;Task&gt; &amp;tasks, TaskState task_state)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">MoveTasks</span><span class="params">(std::unordered_set&lt;TaskID&gt; &amp;tasks, TaskState src_state, TaskState dst_state)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">FilterState</span><span class="params">(std::unordered_set&lt;TaskID&gt; &amp;task_ids, TaskState filter_state)</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/// 这两个函数是按其他维度：Actor 和 Job 来获取一组任务</span></span><br><span class="line">  <span class="function">std::unordered_set&lt;TaskID&gt; <span class="title">GetTaskIdsForJob</span><span class="params">(<span class="type">const</span> JobID &amp;job_id)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function">std::unordered_set&lt;TaskID&gt; <span class="title">GetTaskIdsForActor</span><span class="params">(<span class="type">const</span> ActorID &amp;actor_id)</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/// 阻塞任务和用户进程增删改查</span></span><br><span class="line">  <span class="function"><span class="type">const</span> std::unordered_set&lt;TaskID&gt; &amp;<span class="title">GetBlockedTaskIds</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> std::unordered_set&lt;TaskID&gt; &amp;<span class="title">GetDriverTaskIds</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AddBlockedTaskId</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">RemoveBlockedTaskId</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AddDriverTaskId</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">RemoveDriverTaskId</span><span class="params">(<span class="type">const</span> TaskID &amp;task_id)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// 用来调试和监控</span></span><br><span class="line">  <span class="function">std::string <span class="title">DebugString</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">RecordMetrics</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/// 这个好像没啥用，都没实现</span></span><br><span class="line">  <span class="function">ResourceSet <span class="title">GetReadyQueueResources</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">/// 一个辅助函数，由于调度队列算是有两层索引 task state -&gt; (task id -&gt; task)，</span></span><br><span class="line">  <span class="comment">/// 因此经常需要定位到某个状态对应的任务队列，进而获取其中的某个任务。</span></span><br><span class="line">  <span class="function"><span class="type">const</span> std::shared_ptr&lt;TaskQueue&gt; &amp;<span class="title">GetTaskQueue</span><span class="params">(TaskState task_state)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// 两个辅助函数，用来在指定状态的任务队列中删除或者过滤任务的</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">RemoveTasksFromQueue</span><span class="params">(ray::raylet::TaskState task_state,</span></span></span><br><span class="line"><span class="params"><span class="function">                            std::unordered_set&lt;ray::TaskID&gt; &amp;task_ids,</span></span></span><br><span class="line"><span class="params"><span class="function">                            std::vector&lt;ray::Task&gt; *removed_tasks)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">FilterStateFromQueue</span><span class="params">(std::unordered_set&lt;ray::TaskID&gt; &amp;task_ids,</span></span></span><br><span class="line"><span class="params"><span class="function">                            TaskState task_state)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// kNumTaskQueues 作用便在此，所有int值在其之前的状态都有对应的任务队列</span></span><br><span class="line">  std::array&lt;std::shared_ptr&lt;TaskQueue&gt;, <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(TaskState::kNumTaskQueues)&gt;</span><br><span class="line">      task_queues_;</span><br><span class="line">  <span class="comment">// 调度时候，就绪队列用的比较多，就单独维护一个指针在此</span></span><br><span class="line">  <span class="type">const</span> std::shared_ptr&lt;ReadyQueue&gt; ready_queue_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 这两个状态（blocked 和 driver）没有对应的任务队列，只是用集合来保存id</span></span><br><span class="line">  std::unordered_set&lt;TaskID&gt; blocked_task_ids_;</span><br><span class="line">  std::unordered_set&lt;TaskID&gt; driver_task_ids_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>从上面代码我们可以看出以下几点：</p>
<ol>
<li>所有函数基本是围绕单个任务或者一组任务的增删改查而来的。</li>
<li>所有任务实际上按<strong>二层索引</strong>组织 task state -&gt; (task id -&gt; task)；因此定位到一个任务需要先经过 task state 这一层，于是造了辅助函数来进行这层操作：<code>GetTaskQueue</code>。此外，还有大量的在不同任务队列间倒来倒去的辅助函数。</li>
<li>上面所说的 kNumTaskQueues 是一个假状态，它本质上是一个界标。将其转换为整形后，所有小于它的状态都是按任务队列组织任务，所有大于它的状态只是用集合来存了任务ID（blocked 任务和 driver 任务）。</li>
<li>对于就绪队列，有一些特殊的照顾，因为实际将就绪任务安排到某个 worker 执行时很大的一块调度内容。这些额外照顾包括： <strong>a</strong>. 单独给就绪队列维护了一个指针、 <strong>b</strong>. 提供获取就绪队列资源需求之和接口、 <strong>c</strong>. 提供按同样资源需求聚集所有就绪任务接口。</li>
<li>还有两个按照其他维度获取一组资源的接口：<code>GetTaskIdsForJob</code> 和 <code>GetTaskIdsForActor</code> 可以分别根据给定 JobId 和 ActorId 来获取一组任务。</li>
</ol>
<h2 id="名词释义"><a href="#名词释义" class="headerlink" title="名词释义"></a>名词释义</h2><p><strong>Task Required Resources：</strong>任务资源需求或者任务资源约束，通过在函数上添加注解 <code>ray.remote(num_cpus=xx, num_gpus=xx)</code>  来指定。其中 GPU 还可以指定小数个，以使多个任务共享一个 GPU。</p>
<p><strong>Task argument：</strong>任务输入或者任务参数。如果翻译为输入是相对任务来说的，如果翻译为参数，是相对任务所执行的函数参数来说的。</p>
<p><strong>Object：</strong>这里翻译为了数据对象。</p>
<p><strong>Object Store</strong>：基于内存的不可变对象存储，是分散在各个节点的<strong>节点内、进程间</strong>的共享存储。</p>
<p><strong>Node，Machine</strong>：指的是组成集群的每个机器。如果非要区分的话，Node可能更偏重逻辑上的节点，Machine 更偏重逻辑节点所在的物理机。但是在 Ray 中他们是一一对应的，即一个机器只有一个节点。</p>
<p>本篇就先到这里，下一篇计划写写调度策略或者资源定义。</p>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>Ray</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>source reading</tag>
        <tag>Ray</tag>
        <tag>任务组织</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo Next 主题进阶设置</title>
    <url>/2019/10/16/hexo-theme-landscaping/</url>
    <content><![CDATA[<p>在使用 github pages + hexo + next 搭建了 <a href="https://www.qtmuniao.com/2019/02/17/%E4%BD%BF%E7%94%A8hexo%E5%BC%95%E6%93%8E%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/">Hexo 博客</a> 并用了一段时间后，想对博客进一步进行定制和美化，记录在这里。过程中发现英文文档要比中文文档详细很多，基本上 thems&#x2F;next&#x2F;_config.yaml 中所涉及到的所有设置都有讲解，所以如果英文不错，还是看英文文档吧：<span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZy9kb2NzLw==">https://theme-next.org/docs/<i class="fa fa-external-link-alt"></i></span> 。</p>
<p>此外，每次修改后记得及时用 <code>hexo s</code> 在本地<code>http://localhost:4000/</code>部署查看效果，看是否达到了自己的预期。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="添加“关于”标签"><a href="#添加“关于”标签" class="headerlink" title="添加“关于”标签"></a>添加“关于”标签</h2><p>由于我使用的是 next 主题，两步就够了：</p>
<ol>
<li><p>通过 hexo 引擎新建索引页：<code>hexo new page &quot;about&quot;</code></p>
</li>
<li><p>菜单显示 <code>about</code> 链接，在主题的 <code>_configy.yml</code> 设置中将 <code>menu</code> 中 <code>about</code> 前面的注释去掉即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: / </span><br><span class="line">  archives: /archives || archive</span><br><span class="line">  tags: /tags || tags</span><br><span class="line">  about: /about || user</span><br></pre></td></tr></table></figure></li>
</ol>
<p>在首页添加其他标签页，照猫画虎就行。需要注意的是 <code>||</code> 表示的是 fontawsome 中相应图标的 id。</p>
<h2 id="强制-HTTPS"><a href="#强制-HTTPS" class="headerlink" title="强制 HTTPS"></a>强制 HTTPS</h2><p>https 有诸多<span class="exturl" data-url="aHR0cHM6Ly9kZXZlbG9wZXJzLmdvb2dsZS5jb20vd2ViL2Z1bmRhbWVudGFscy9zZWN1cml0eS9lbmNyeXB0LWluLXRyYW5zaXQvd2h5LWh0dHBz">好处<i class="fa fa-external-link-alt"></i></span>：</p>
<ol>
<li>保护网站完整性，防止恶性入侵。</li>
<li>保护用户隐私和安全。</li>
<li>是未来网络发展方向。</li>
</ol>
<p>因此，我打算让博客强制 https 访问。</p>
<ol>
<li>如果是自己托管的个人站点，需要去申请证书，<span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC50ZW5jZW50LmNvbS9wcm9kdWN0L3NzbA==">腾讯<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly9sZXRzZW5jcnlwdC5vcmcv">Let’s Encrypt<i class="fa fa-external-link-alt"></i></span> 提供免费证书。</li>
<li>但我的博客使用的是 github pages，操作就异常简单，只需要在博客 repo settings 中勾选：Enforce HTTPS  即可。</li>
</ol>
<p><img src="https://i.loli.net/2020/02/09/bvw2FTn8s5Gruxg.png" alt="enforce https"></p>
<h2 id="草稿-amp-amp-布局"><a href="#草稿-amp-amp-布局" class="headerlink" title="草稿&amp;&amp;布局"></a>草稿&amp;&amp;布局</h2><h3 id="草稿布局"><a href="#草稿布局" class="headerlink" title="草稿布局"></a>草稿布局</h3><p>为了避免写了一半的文章发布出去，可以在新建布局的时候选择草稿：<code>hexo new draft &quot;blog title&quot;</code>，但是我发现生成的页面没有日期。经搜索，找到其模板位置：<code>./hexo-folder/scaffolds/draft.md</code>，修改为如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">tags:</span><br><span class="line">categories:</span><br><span class="line">description:</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">点击阅读前文前, 首页能看到的文章的简短描述</span><br></pre></td></tr></table></figure>

<h3 id="广义布局"><a href="#广义布局" class="headerlink" title="广义布局"></a>广义布局</h3><p>更广义上来说，你可以在 scaffolds 中定制任意多个布局，draft 和 page 是最常用的两个：</p>
<ul>
<li><p>post：在这里的会当做文章被发布。</p>
</li>
<li><p>draft：放在这里，避免写了一半的文章被发布。</p>
</li>
<li><p>page：在首页增加标签页。</p>
</li>
</ul>
<p>为了发不同类型的文章，比如说游记、技术等等，完全可以事先创造多个布局（通过嵌入一些默认变量和HTML代码来实现），然后通过 <code>hexo new layout &quot;title&quot;</code>  来新建具有该布局的文章，当然，该文章会默认被创建在 post 文件夹中。</p>
<p>比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">~: <span class="built_in">cp</span> scaffolds/page.md scaffolds/test.md</span><br><span class="line">~: hexo new <span class="built_in">test</span> <span class="string">&#x27;test&#x27;</span></span><br><span class="line">INFO  Created: ~/Code/blog/hexo/source/_posts/2019-10-16-test.md</span><br></pre></td></tr></table></figure>

<p>就会创建一个具有 test 模板的文章：<code>~/Code/blog/hexo/source/_posts/2019-10-16-test.md</code></p>
<p><strong>注</strong>：如果不指定模板，会、默认使用 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL3poLWNuL2RvY3MvY29uZmlndXJhdGlvbg==">_config.yml<i class="fa fa-external-link-alt"></i></span> 中的 <code>default_layout</code> 参数代替，一般来说是 post。</p>
<h3 id="文章移动"><a href="#文章移动" class="headerlink" title="文章移动"></a>文章移动</h3><p>将文章从 draft 移动到 post 或者反之只需要用 shell 的 mv 命令就可以。</p>
<h2 id="专题系列"><a href="#专题系列" class="headerlink" title="专题系列"></a>专题系列</h2><p>由于有些文章有内在的关联性，除了用目录和标签还可以用专题的形式来组织。主要思想是新建一个标签页，然后手动利用站内引用来组织想组织的文章。</p>
<h3 id="新建标签页"><a href="#新建标签页" class="headerlink" title="新建标签页"></a>新建标签页</h3><p>首先利用 hexo 命令新建一个标签页。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page series</span><br></pre></td></tr></table></figure>

<p>然后修改 themes&#x2F;next&#x2F;_config.yaml menu 配置，增加一行：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">series:</span> <span class="string">/series/</span> <span class="string">||</span> <span class="string">reorder</span></span><br></pre></td></tr></table></figure>

<p>最后新增对应中文：修改 themes&#x2F;next&#x2F;languages&#x2F;zh-CN.yml  中的 menu 一项下面添加 series: 专题。</p>
<p>然后新增对应中文：修改 <code>themes/next/languages/zh-CN.yml</code>  中的 menu 一项下面添加 <code>series: 专题</code>。</p>
<h3 id="编辑-index-md-组织专题目录"><a href="#编辑-index-md-组织专题目录" class="headerlink" title="编辑 index.md 组织专题目录"></a>编辑 index.md 组织专题目录</h3><p>像文章一样编辑 index.md 即可，引用站内文章可以用如下 hexo 语法：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">&#123;% post_link post-name post-title %&#125;</span><br></pre></td></tr></table></figure>

<p><em>post_link</em>：为站内文章引用的关键字，照抄就行。</p>
<p><em>post-name</em>：为你的 md 文件的名字，不带日期。</p>
<p><em>post-title</em>：给该文章起的链接标题，为空的话就会从文章中提取。</p>
<h2 id="首页截断设置"><a href="#首页截断设置" class="headerlink" title="首页截断设置"></a>首页截断设置</h2><p>默认首页的文章会显示全文，尤其我有的翻译文章，写的又臭又长，导致主页首屏只能看到一个文章。修改方法：在主题配置文件设置 <code>excerpt_description</code> 为<code>true</code>，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">excerpt_description: true</span><br></pre></td></tr></table></figure>

<p>然后在文章中需要截断的地方加上代码：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- more --&gt;</span> </span><br></pre></td></tr></table></figure>

<p>当然，还有另一种做法。即在写文章时，在元信息中指定<strong>摘要</strong>：description。上面其实有提到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">tags:</span><br><span class="line">categories:</span><br><span class="line">description: 点击阅读前文前, 首页能看到的文章的简短描述</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<p>具体可以看官方文档的<span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZy9kb2NzL3RoZW1lLXNldHRpbmdzL3Bvc3Rz">这里<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="相关文章推荐"><a href="#相关文章推荐" class="headerlink" title="相关文章推荐"></a>相关文章推荐</h2><p>首先需要安装一个 hexo 插件，然后在主题配置中进行相应设置。</p>
<p><strong>安装相关热门文章插件</strong>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-related-popular-posts --save</span><br></pre></td></tr></table></figure>

<p>如果遇到问题可以参考<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RlYTMvaGV4by1yZWxhdGVkLXBvcHVsYXItcG9zdHMjaW5zdGFsbGF0aW9u">这里<i class="fa fa-external-link-alt"></i></span>。</p>
<p><strong>配置 next</strong> </p>
<p>在 themes&#x2F;next&#x2F;_config.yaml 中配置：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">related_posts:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">猜你喜欢</span> <span class="comment"># 自定义标题名字</span></span><br><span class="line">  <span class="attr">display_in_home:</span> <span class="literal">true</span> <span class="comment"># 首页是否增加</span></span><br><span class="line">  <span class="attr">params:</span></span><br><span class="line">    <span class="attr">maxCount:</span> <span class="number">5</span> <span class="comment"># 最多推荐几个</span></span><br><span class="line">    <span class="attr">PPMixingRate:</span> <span class="number">0.4</span> <span class="comment"># 同时推荐火热和相关，两者比率，不能为0</span></span><br><span class="line">    <span class="comment">#isDate: false # 文章时间</span></span><br><span class="line">    <span class="comment">#isImage: false # 文章配图</span></span><br><span class="line">    <span class="comment">#isExcerpt: false # 文章摘要</span></span><br></pre></td></tr></table></figure>



<h2 id="页脚添加访客量"><a href="#页脚添加访客量" class="headerlink" title="页脚添加访客量"></a>页脚添加访客量</h2><p>使用不<span class="exturl" data-url="aHR0cDovL2J1c3VhbnppLmlicnVjZS5pbmZvLw==">蒜子<i class="fa fa-external-link-alt"></i></span>，不同于百度和谷歌那种详细的统计，可以用两行代码，简单的在网页上显示本站访问量和访问人数。</p>
<p>具体到 next 主题来说，在 footer 模板（<code>themes/next/layout/_partials/footer.swig</code>）底部添加以下代码就行：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;powered-by&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">&quot;//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa fa-user-md&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;busuanzi_container_site_uv&quot;</span>&gt;</span></span><br><span class="line">        本站访客数:<span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;busuanzi_value_site_uv&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;post-meta-divider&quot;</span>&gt;</span>|<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;busuanzi_container_site_pv&quot;</span>&gt;</span></span><br><span class="line">        本站访问量<span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">&quot;busuanzi_value_site_pv&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h2 id="博客文章搜索"><a href="#博客文章搜索" class="headerlink" title="博客文章搜索"></a>博客文章搜索</h2><p>首先安装 node 插件： <code>hexo-generator-searchdb</code>，在博客根目录执行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>

<p>然后修改博客站点配置文件（<code>~/hexo/_config.yml</code>），添加以下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post</span><br><span class="line">  format: html</span><br><span class="line">  limit: 10000</span><br></pre></td></tr></table></figure>

<p>最后在主题配置文件（<code>themes/next/_config.yml</code> ）找到  <code>local_search</code> 改为<code>true</code>，其他项目自选：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Local Search</span><br><span class="line"># Dependencies: https://github.com/theme-next/hexo-generator-searchdb</span><br><span class="line">local_search:</span><br><span class="line">  enable: true</span><br><span class="line">  # If auto, trigger search by changing input.</span><br><span class="line">  # If manual, trigger search by pressing enter key or search button.</span><br><span class="line">  trigger: manual</span><br><span class="line">  # Show top n results per article, show all results by setting to -1</span><br><span class="line">  top_n_per_article: 1</span><br><span class="line">  # Unescape html strings to the readable one.</span><br><span class="line">  unescape: false</span><br><span class="line">  # Preload the search data when the page loads.</span><br><span class="line">  preload: false</span><br></pre></td></tr></table></figure>

<p>然后标签页栏目就会出现搜索框了。</p>
<p><strong>注</strong>：<strong>安装 hexo-generator-searchdb 包的时候，如果出现报错，请根据报错提示自行修复相关依赖，否则搜索框可能会显示有问题。</strong></p>
<h2 id="显示浏览进度"><a href="#显示浏览进度" class="headerlink" title="显示浏览进度"></a>显示浏览进度</h2><p>主题设置文件（<code>themes/next/_config.yml</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Reading progress bar</span><br><span class="line">reading_progress:</span><br><span class="line">  enable: true</span><br><span class="line">  # Available values: top | bottom</span><br><span class="line">  position: top</span><br><span class="line">  color: &quot;#37c6c0&quot;</span><br><span class="line">  height: 2px</span><br></pre></td></tr></table></figure>



<h2 id="站点地图"><a href="#站点地图" class="headerlink" title="站点地图"></a>站点地图</h2><p>站点地图的作用向搜索引擎提供你的网站的概要，给你的网站做 SEO。</p>
<p>首先安装下 npm 对应插件，然后在 hexo 和 next 主题中分别打开配置。</p>
<h3 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br></pre></td></tr></table></figure>

<h3 id="Hexo-配置文件"><a href="#Hexo-配置文件" class="headerlink" title="Hexo 配置文件"></a>Hexo 配置文件</h3><p>在 hexo&#x2F;_config.xml 中添加配置项：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Extensions</span></span><br><span class="line">plugins: hexo-generator-sitemap</span><br></pre></td></tr></table></figure>

<h3 id="Next-配置文件"><a href="#Next-配置文件" class="headerlink" title="Next 配置文件"></a>Next 配置文件</h3><p>修改 themes&#x2F;next&#x2F;_config.xml，将对应注释打开：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">    sitemap: /sitemap.xml || sitemap</span><br></pre></td></tr></table></figure>

<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>执行命令重新生成源文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo d -g</span><br></pre></td></tr></table></figure>

<p>上述操作顺利的话，可以发现：</p>
<ol>
<li>首页左侧边栏多了一项站点地图，点进去可以看到以 xml 格式组织的你的所有文章的 url</li>
<li>该站点地图路径应该为： <span class="exturl" data-url="aHR0cDovL3d3dy55b3Vyc2l0ZS5jb20vc2l0ZW1hcC54bWw=">www.yoursite.com/sitemap.xml<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<p>然后，你可以向谷歌：<span class="exturl" data-url="aHR0cHM6Ly9zZWFyY2guZ29vZ2xlLmNvbS9zZWFyY2gtY29uc29sZQ==">https://search.google.com/search-console<i class="fa fa-external-link-alt"></i></span> 提交的该站点地图 URL。</p>
<p>更多可以参考：<span class="exturl" data-url="aHR0cDovL2xpbmRheGlhby1odXN0LmdpdGh1Yi5pby8yMDE2LzA0LzA2L2hleG8tbmV4dC1zaXRlbWFwLw==">http://lindaxiao-hust.github.io/2016/04/06/hexo-next-sitemap/<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="相册"><a href="#相册" class="headerlink" title="相册"></a>相册</h2><p>由于平时没事也拍点东西，于是就想也有个展示的页面。探索了一下，可以利用 next 的插件 <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZy9kb2NzL3RhZy1wbHVnaW5zL2dyb3VwLXBpY3R1cmVz">group picture<i class="fa fa-external-link-alt"></i></span> 来实现，他的原理很简单，就是利用 next 主题的 <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZy9kb2NzL3RhZy1wbHVnaW5zLw==">Tag Plugin<i class="fa fa-external-link-alt"></i></span> 这种语法提供了一种展示图片的布局。</p>
<p>需要以下几步：</p>
<ol>
<li><p>首先 <code>hexo new page photos</code> 新建一个名为 photos 的标签页，并且在 <code>themes/next/languages/zh-CN.yml</code>  中的 menu 一项下面添加 <code>photos: 相册</code>，这样在首页菜单栏才会显示中文相册。</p>
</li>
<li><p>其次，可以直接在  <code>source/photos/index.md</code> 写文章，并在需要插入图片的时候用以下方式来组织你的图片列表：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">## 某某地方玩</span><br><span class="line">&#123;% gp 6-3 %&#125;</span><br><span class="line">  ![](/images/docs/github.png)</span><br><span class="line">  ![](/images/docs/github.png)</span><br><span class="line">  ![](/images/docs/github.png)</span><br><span class="line">  ![](/images/docs/github.png)</span><br><span class="line">  ![](/images/docs/github.png)</span><br><span class="line">  ![](/images/docs/github.png)</span><br><span class="line">&#123;% endgp %&#125;</span><br></pre></td></tr></table></figure>

<p>其中 ‘6-3’ 的意思是改组一共有六张图片，每行排最多三张。</p>
</li>
<li><p>除了图片之外其他的文字和章节标题都可以像往常一样加。</p>
</li>
</ol>
<h2 id="广告"><a href="#广告" class="headerlink" title="广告"></a>广告</h2><p>这里主要针对谷歌广告来说。</p>
<h3 id="开通账号"><a href="#开通账号" class="headerlink" title="开通账号"></a>开通账号</h3><p>众所周知，谷歌是全球最大的广告中间商，让你可以出卖流量来换小钱钱。具体做法是将你有流量的位置告诉谷歌，他会根据浏览你网站的用户行为来动态给他们推广告。</p>
<p>你可以在这里：<span class="exturl" data-url="aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS9hZHNlbnNl">https://www.google.com/adsense<i class="fa fa-external-link-alt"></i></span> 开通，将你的网站提交，然后谷歌会给你审核，<span class="exturl" data-url="aHR0cHM6Ly9nZWVrdHV0dS5jb20vcG9zdC9ibG9nLWV4cGVyaWVuY2UtNC5odG1s">这篇文章<i class="fa fa-external-link-alt"></i></span> 有讲一些申请需要注意的事项，总的来说就是得让谷歌判定你的网站是有价值的，而不是垃圾网站，至于他怎么定义垃圾，上面文章有涉及。</p>
<h3 id="嵌入代码"><a href="#嵌入代码" class="headerlink" title="嵌入代码"></a>嵌入代码</h3><p>审核一般几天内会有结果，如果通过了就可以愉快地在你的博客里做广告了。但这是有个问题，如何兼顾页面美观性和广告数量、大小和位置间的平衡呢？这是个见仁见智的事情，我的做法主要有两点：</p>
<ol>
<li><p><strong>只做展示广告</strong>。如下图，谷歌广告类型提供了三种。我只选择展示广告，因为位置、大小可以受我们严格控制。</p>
<p><img src="https://i.loli.net/2020/02/09/2aVwyDPqcGEpAZN.png"></p>
</li>
<li><p><strong>限制广告尺寸</strong>。在定义广告的时候，在右侧边栏可以定义广告尺寸，如果是自适应的不好控制其页面上的呈现方式。我限制到很小：280px * 100px，并且只放一个。</p>
</li>
<li><p><strong>挑选放置位置</strong>。我选在侧边栏最下面，并且用分割线隔开，这里需要自定义一些样式。定义css 可以新建一个自己的样式集：themes&#x2F;next&#x2F;source&#x2F;css&#x2F;_my&#x2F;mycss.styl ，然后在 themes&#x2F;next&#x2F;source&#x2F;css&#x2F;main.styl 中引用即可： </p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="keyword">@import</span> <span class="string">&quot;_my/mycss&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>我只增加了一个样式：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.sidebar-ads</span> &#123;</span><br><span class="line">  <span class="attribute">border-top</span>: <span class="number">1px</span> dotted <span class="number">#ccc</span>;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">100px</span>;</span><br><span class="line">  <span class="attribute">padding-top</span>: <span class="number">15px</span>;</span><br><span class="line">  <span class="attribute">margin-bottom</span>: <span class="number">5px</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个样式具体可以丰俭由人，我 css 只是略知皮毛，就只能做成这样了，一个比较好的办法是可以在 Chrome 中调好审查元素，定好样式后再抄到样式集中即可。最后的效果可以看我博客首页。</p>
</li>
</ol>
<h2 id="其他设置"><a href="#其他设置" class="headerlink" title="其他设置"></a>其他设置</h2><h3 id="头像"><a href="#头像" class="headerlink" title="头像"></a>头像</h3><p>主题配置文件：<code>avatar: your local/network image path </code></p>
<h3 id="next-配色方案"><a href="#next-配色方案" class="headerlink" title="next 配色方案"></a>next 配色方案</h3><p>文件：<code>themes\next\source\css\_variables\base.styl</code></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] Hexo主题Next美化 <span class="exturl" data-url="aHR0cDovL2plZmZ5YW5nLnRvcC9IZXhvL0hleG8lRTQlQjglQkIlRTklQTIlOThOZXh0JUU3JUJFJThFJUU1JThDJTk2Lw==">http://jeffyang.top/Hexo/Hexo%E4%B8%BB%E9%A2%98Next%E7%BE%8E%E5%8C%96/<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>搭建博客</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next 相册</tag>
        <tag>next 搜索</tag>
        <tag>next 站点地图</tag>
        <tag>next 广告</tag>
        <tag>hexo 专题</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce —— 历久而弥新</title>
    <url>/2019/04/30/map-reduce/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/nKVyYJ7QtaLfIMx.png" alt="MR执行流"></p>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>MapReduce 是谷歌 2004 年（Google 内部是从03年写出第一个版本）发表的论文里提出的一个概念。虽然已经过去15 年了，但现在回顾这个大数据时代始祖级别概念的背景、原理和实现，仍能获得对分布式系统的很多直觉性的启发，所谓温故而知新。</p>
<p>在Google 的语境里，MapReduce 既是一种编程模型，也是支持该模型的一种分布式系统实现。它的提出，让没有分布式系统背景的开发者，也能较轻松的利用大规模集群以高吞吐量的方式来处理海量数据。其解决问题思路很值得借鉴：找到需求的痛点（如海量索引如何维护，更新和排名），对处理关键流程进行高阶抽象（分片Map，按需Reduce），以进行高效的系统实现（所谓量体裁衣）。这其中，如何找到一个合适的计算抽象，是最难的部分，既要对需求有直觉般的了解，又要具有极高的计算机科学素养。当然，并且可能更为接近现实的是，该抽象是在根据需求不断试错后进化出的海水之上的冰山一角。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>谷歌当时作为互联网的最大入口，维护着世界全网索引，最早触到了数据量的天花板。即，哪怕针对很简单的业务逻辑：如从爬虫数据中生成倒排索引、将图状网页集合用不同方式组织、计算每个主机爬取的网页数量、给定日期的高频查询词汇等等，在全球互联网数据的尺度的加成下，也变的异常复杂。</p>
<p>这些复杂性包括：输入数据分散在非常多的主机上、计算耗资源太多单机难以完成、输出数据需要跨主机进行重新组织。为此，不得不针对每个需求重复构造专用系统，并耗费大量代码在分发数据和代码、调度和并行任务、应对机器故障和处理通信失败等问题上。</p>
<h2 id="抽象"><a href="#抽象" class="headerlink" title="抽象"></a>抽象</h2><p>map 和 reduce 的抽象灵感来自于函数式编程语言 Lisp，为什么选定这两个概念呢？这来源于谷歌人对其业务的高度提炼：首先输入可以切分成一个个逻辑的<em>记录 （record）</em>；然后对其每个 <em>record</em> 执行某种<em><strong>映射</strong> （map）</em> 操作，生成一些键值对组成的中间结果（为什么要分键和值呢？为最后一步做铺垫，允许用户将中间结果以任意指定的方式——<em>键</em>，来进行组织规约）；最后在具有相同键的中间结果子集上执行<em>规约</em>（<em>reduce</em> ，包括排序，统计，提取最值等等）操作。</p>
<p>函数式模型的另一个特点在于对 map 操作实现的约束，即规定用户应提供一个无副作用的 map 操作（相关概念有<em>纯函数</em>，<em>确定性</em>，<em>幂等性</em>等等，当然他们的概念并不一样，后面小结会详细讨论）。如此限制，好处有二，可以进行大规模并行执行，可以通过换地儿重试来屏蔽主机故障。</p>
<p>具体到落地上，<em>map</em> 和 <em>reduce</em> 都是用户自定义函数。<em>map</em> 函数接受一个 Record，不过为了灵活，一般也组织为键值对；然后产生 List[key, value]，<em>reduce</em> 函数接受一个 key 和该 key 对应的所有中间结果 List[value]。即：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">map</span> (k1,v1)             -→ <span class="built_in">list</span>(k2,v2)</span><br><span class="line">reduce (k2,<span class="built_in">list</span>(v2))    -→ <span class="built_in">list</span>(v2)</span><br></pre></td></tr></table></figure>

<p>拿由谷歌这篇论文提出，后来成为大数据处理界的 <em>hello world</em> 级别示例程序 <em>Word Count</em> （对一堆文档中的单词计数）来说，<em>map</em> 和 <em>reduce</em> 的实现长这样：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">map</span>(String key, String value):</span><br><span class="line">    <span class="comment">// key: document name</span></span><br><span class="line">    <span class="comment">// value: document contents</span></span><br><span class="line">    <span class="keyword">for</span> each word w in value:</span><br><span class="line">      <span class="built_in">EmitIntermediate</span>(w, <span class="string">&quot;1&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">reduce</span>(String key, Iterator values):</span><br><span class="line">    <span class="comment">// key: a word</span></span><br><span class="line">    <span class="comment">// values: a list of counts</span></span><br><span class="line">    <span class="type">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> each v in values:</span><br><span class="line">      result += <span class="built_in">ParseInt</span>(v);</span><br><span class="line">    <span class="built_in">Emit</span>(<span class="built_in">AsString</span>(result));</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里有两个有意思的点：</p>
<ol>
<li><strong>中间变量需要网络传输，必然会涉及到序列化</strong>。MapReduce 的最初版本选择是一切解释权归<em><strong>运行时的</strong></em>用户代码所有，我只是傻傻的传 string。即，规定用户在 map 中将任何输出的中间结果对象都转换为 string，然后在 reduce 函数中接收该 Iterator[string] 后，自行解析为自己想要的格式。当然，在后来的模仿框架如 Hadoop 中，序列化和解序列化部分被拿了出来，可以由用户来自定义实现来满足功能或性能上的需求。没去查证，谷歌后来相比对此也做了优化。这是一种很自然的<strong>系统演化</strong>思路，初期设计尽量简单粗暴以求快速实现可用原型；在积累使用经验后再对某些不便模块进行扩展设计。</li>
<li><strong>reduce 接受 value 集合被组织为了迭代器（Iterator）</strong>。相信用过 Python 的同学应该对迭代器不陌生，它是一个很简单的接口，包括 <em>next</em> 和 <em>stop</em> 两个语义。配合 <em>for loop</em> ，构成一个很强大的抽象。不管你底层是一个内存中的 List、还是文件内容、还是网络 IO 流，只要能在运行时知道如何得到下一条记录，什么时候时候停止，都能被 for 循环来利用，进行逐一处理。迭代器抽象的一个好处在于，不必将待迭代的内容一次加载到内存，可以对数据增量式的<em><strong>惰性加载</strong></em>。MapReduce 框架的此处实现也正是利用了该特性。</li>
</ol>
<h2 id="实现概览"><a href="#实现概览" class="headerlink" title="实现概览"></a>实现概览</h2><p>抽象定了，那么实现自然可以有不同，这也是<strong>接口和实现分离</strong>的意义所在。前者的抽象是一种思想，谷歌已经给你做了；后者的实现，完全可以根据自己的生产环境进行量体裁衣的来定制实现。谷歌在 paper 中给了一种内部经典版，Hadoop 也提供了一套通用版，当然我们也可以根据自己的业务需求和场景约束来实现一个合身版。</p>
<p>谷歌<strong>发布论文时</strong> 实现 MapReduce 所面对的系统环境长这样：</p>
<ol>
<li>单机双核 x86 架构，2~4G内存，Linux 系统</li>
<li>通用网络硬件，百兆或者千兆以太网</li>
<li>集群含数百或者数千台机器，因此机器故障是常态</li>
<li>用的廉价 IDE 接口硬盘，但是人家有 GFS 来提供容错</li>
<li>多租户支持，因此需要做 Job 级别抽象和资源约束</li>
</ol>
<h3 id="流程概览"><a href="#流程概览" class="headerlink" title="流程概览"></a>流程概览</h3><p>输入由用户指定切分大小后，切分成 <em>M</em> 份，然后分散到不同机器上(由于 GFS 的存在，也可能该输入 Block 本来就在那台机器上）。每个机器上会并行的跑用户定义的 <em>map</em> 。<em>map</em> 输出的中间结果，亦由用户指定，按 <strong>key 值范围</strong>切分为 <em>R</em> 份，对于每个中间结果，通过 <em>node label &#x3D; hash(key) mod R</em> 决定其去处。下面是流程概览图：</p>
<p><img src="https://i.loli.net/2020/02/09/nKVyYJ7QtaLfIMx.png" alt="MR执行流"></p>
<ol>
<li>首先把输入切分成 M 份，通常每份 16 ~ 64M，这个粒度用户按需进行把握；然后把这些分片分散到不同机器上（如果有GFS这种分布式文件系统配合的话，可能本来就分散着），然后在每个机器上 fork 一份用户的代码。对于<strong>用户代码分发</strong>，是一个有意思的话题，对于不同语言可能有不同实现，比如谷歌的C++，可能传输的是动态链接库；比如 Hadoop 的 Java 传的可能是 jar 包 （当然， 所有依赖也得传）；如果是 PySpark 的 Python 呢，可能用的就是神奇的 cloudpickle；总之，不同语言需要考虑的传输机制是不一样的，比如说动态语言和静态语言；此外，全局变量和外部依赖也是需要考虑的点，谷歌虽然在此一笔带过，但是不同语言需要面对的情况可能差别很大。</li>
<li>Master 的这份程序拷贝是不一样的，是负责安排活的。会选空闲的 worker 来安排这 M 个 map 任务和 R 个 reduce 任务。这需要考虑的是，worker 执行每个用户代码是单独启动一个进程，还是插入到系统 loop 中去执行。</li>
<li>执行 map 任务的 Worker，会读取被分配到的输入切片，解析出键值对流，送给用户定义的 map 函数。map 后产生的临时结果首先会缓存在内存中。虽然论文中没有展开，但可以预见的是，如何切片，如何解析出键值对流，不同用户对于同样的输入可能有不同的关注点，因此必然存在定制化解析的需求。这一部分（FileSplit 和 RecordReader）在稍后随着承载业务的增多，估计也会开放出来给用户自定义，事实上 Hadoop 就是这么干的。</li>
<li>缓存的中间结果会被定期在执行 Map Task 的<strong>机器本地</strong>进行刷盘（这也算一个本地性的优化，但是也有后果，就是一旦该机器故障，容错会稍微麻烦点，后面会说），并且按用户指定的 Partition 函数拆分成 R 个块，然后将这些位置信息发给 Master 节点。Master 负责通知相应的 Reduce Worker 以拉取对应数据。</li>
<li>Reduce Worker 收到这些中间结果的位置信息后，会通过 RPC 来拉取其对应的 Partition 的数据。对于某个 Reduce Worker 来说，待<strong>所有数据</strong>拉取完成后，会将其按照 key 来进行排序。这样一来，所有具有同样 key 的数据便挨到了一块。第 4 步和第 5 步的过程合起来就是 <em><strong>shuffle</strong></em>，涉及到外部排序、多机数据传输等<strong>极其耗时</strong>操作；当数据量比较小时，如何实现都不成问题。但是当数据量大到一定程度，这里很容易成为性能瓶颈，因此也有一些优化方法，稍后会针对 shuffle 做详细展开，此处按下不表。</li>
<li>待中间数据排好序之后，Reduce Woker 会对其进行扫描，然后将一个个 key 和其对应的值集合，即 &lt;k2, list(v2)&gt; 传给用户定制的 reduce 函数，然后将生成的结果追加到最终输出文件。对于谷歌来说，一般来说就是支持并行 append 的文件系统 GFS，好处在于可以多进程同时写结果。</li>
<li>当所有 reduce 任务完成后，master 会唤醒用户进程，即在用户代码的视角，MapReduce 任务是阻塞的。</li>
</ol>
<p>一般而言，用户无需将最终结果的 R 个 Partition 进行合并，而是将其直接作为下一个 MapReduce 任务的输入。Spark RDD 的partition 就是将这一特点<strong>概念化</strong>了，并且将每一步 MapReduce 输出也放内存中，不进行落盘，以降低连续 MapReduce 任务的延迟。</p>
<h3 id="局部性"><a href="#局部性" class="headerlink" title="局部性"></a>局部性</h3><p>计算机科学中常用的一个原理，叫做<em><strong>局部性原理</strong></em> （locality reference，这里特指空间局部性），说的是<em>程序在顺序执行时，访问了一块数据，接下来大概率会访问该数据（物理位置上）旁边的一块数据</em>。很朴素的断言，却是一切 cache 发挥作用的基础，计算机存储因此也形成了由慢到快，由贱到贵，由大到小的存储层次体系（硬盘-&gt; 内存 -&gt; 缓存 -&gt; 寄存器）。在分布式环境中，这个层次体系至少还要再罩上一层——网络IO。</p>
<p>在 MapReduce 系统中，我们也会充分利用输入数据的 locality。只不过这次，<em>不是将数据加载过来，而是将程序调度过去</em>（<em><strong>Moving Computation is Cheaper than Moving Data</strong></em>）。如果输入存在 GFS 上，表现形式将为一系列的逻辑 Block，每个 Block 可能会有几个（一般是三个）物理副本。对于输入每个逻辑 Block，我们可以在其某个物理副本所在机器上运行 Map Task（如果失败，就再换一个副本），由此来尽量减小网络数据传输。从而降低了延迟，节约了带宽。</p>
<h3 id="Master-的数据结构"><a href="#Master-的数据结构" class="headerlink" title="Master 的数据结构"></a>Master 的数据结构</h3><p>谷歌的 MapReduce 实现是有<em>作业（Job）</em>级别的封装的，每个 Job 包含一系列<em>任务（Task）</em>，即 Map Task 和 Reduce Task。那么，我们要维护一个正在运行的 Job 的元信息，就势必要保存所有正在执行的 Task 的状态，其所在的机器 ID 等等。而且，Master 事实上充当了  Map Task 输出到 Reduce Task 输入的一个”<em>管道</em>“。每一个 Map Task 结束时，会将其输出的中间结果的位置信息通知 Master，Master 再将其转给对应的 Reduce Task，Reduce Task 再去对应位置拉取对应 size 的数据。注意，由于 Map Task 的结束时间不统一，这个<em><strong>通知-&gt;转发-&gt; 拉取</strong></em> 的过程是增量的。那么不难推测出，reduce 侧对中间数据排序的应该是一个不断 merge 的过程，不大可能是等所有数据就位了再全局排序。</p>
<p>在分布式系统中，一个比较忌讳的问题就是单点。因为是牵一发而动全身，而 Master 就是这样一个单点。当然单个机器的统计平均故障率并不高，但是一旦故障，那么整个集群都将不可用。但同时，有一个 Leader 节点会大大简化分布式系统的的设计；因此采用单点 Master 的系统反而是主流，那势必需要开发一些其他手段来强化 master 的容错能力，比如说记 log + snapshot、比如说主从备份、比如说每次从 worker 心跳进行状态重建、比如说用其他实现了分布式一致性协议的系统来保存元信息等等。</p>
<h3 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h3><p>集群中有 Master 和 Worker 两种机器角色。</p>
<p>Worker 由于数量大，有机器故障概率较大。在分布式系统中，Master 获取 Workers 的信息，最常见便是<strong>心跳</strong>，既可以是 master ping worker，也可以反过来，也可以兼而有之。master 通过心跳发现某些 worker 不可到达后（可能是 worker 死掉了，也可能是网络出问题了等），就会将该 Worker 打个<strong>故障</strong>（failed）的标记。</p>
<p>之前已经调度到该故障 Worker 上的任务（Task） 很显然有两种类型： Map Task 和 Reduce Task。<strong>对于 Map Task</strong>（<em>以下所提的 Task，肯定是从属于未结束的 Job</em>） ，不管成功与否，我们都要进行重试，因为一旦该 Worker 变为不可达，存于其上的中间结果也随之无法被 Reduce Task 获取。当然，我们可以在 Master 中多记点状态来减少对已完成的 Map Task 进行重试的概率。比如记下某个 Map Task 的输出是否已经都被 Reduce Task 拉取，以决定要不要对正常完成的 Map Task 进行重试，但无疑会提高系统复杂度。<em>工程往往会对环境做某些假设， 以简化某些实现；</em>我们假设 worker 失败率不是那么高，或者重试所有 Map Task 的代价可以忍，那么就可以简化一点实现，以保持系统的简约，减少可能的 bug。对于 <strong>Reduce Task</strong>，未完成的无疑要进行重试，已经完成的，由于其输出结果我们假设会写到全局分布式系统文件中（即某些机器挂了也不影响），就不会重试。</p>
<p>具体重试的方法，可以标记需要重试的 Task 的状态为 idle，以告诉调度器，该 Task 可以重新被调度。当然，也可以实现为从一个（工作&#x2F;完成）队列倒腾到另一个（就绪）队列，本质上是一样的，都是合理实现一个 Task 的<strong>状态机</strong>。</p>
<p>至于 master 的故障恢复，上一节稍有提到。如果在实践中 Master 确实很少死掉，并且偶尔死掉造成所有正在运行的任务失败的后果也可以接受，那么就可以粗暴的实现为如果 Master 死掉，就简单通知所有正在运行的任务的用户代码任务失败了（比如返回非 0 值），然后有用户代码自行决定丢弃任务还是待集群重启后进行重试：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">MapReduceResult result;</span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">MapReduce</span>(spec, &amp;result)) <span class="built_in">abort</span>();</span><br></pre></td></tr></table></figure>

<p>如果业务对于宕机时间有要求，或者大面积任务失败不可以忍受，那么就需要增强 Master 的容错性。常用的方法上节有提到，这里展开一下：</p>
<ol>
<li><strong>snapshot + log</strong>：将 Master 的内存数据结构定期做快照（snapshot）同步到一个持久存储，可以写到外部存储，可以同步到其他节点，可以一份也可以多份。但是只做快照的话，时间间隔不好选择：间隔太长容易造成恢复时状态丢失过多；间隔过短会加重系统负载。因此常用的辅助手段是记 log，即对每个会改变系统的状态的操作进行记录。这样就可以选择长一点的快照间隔，恢复时，先加载快照，再叠加上快照点之后的日志。</li>
<li><strong>主从备份</strong>。比如 Hadoop 原先的 secondary namenode，用属于不同容错阈两台机器都作为 Master，只不过一个用来响应请求，另一个用来实时同步状态。等某台机器故障发生时，立即将流量切换到另一个机器上。至于其同步机制，则是另一个可以考量的点。</li>
<li><strong>状态外存</strong>。如果元数据量不大，可以用 Zookeeper 或者 etcd 这种实现了分布式一致性协议的集群来保存。由于这些集群本身具有容错能力，因此可以认为避免了单点故障。</li>
<li><strong>心跳恢复</strong>：重新启动一个 Master 后，利用所有 Worker 报上来的信息进行 Master 数据结构的重建。</li>
</ol>
<p>还值得一提的是，<strong>容错也需要用户侧代码做配合</strong>。因为框架会对不成功的 map&#x2F;reduce 用户代码进行重试。这就要求，用户提供的 map&#x2F;reduce 逻辑符合<strong>确定性</strong>（<strong>Deterministic</strong>）：即函数的输出依赖且仅依赖于输入，而不取决任何其他隐形的输入或者状态。当然，这个蕴含了<strong>幂等性</strong>（<strong>Idempotency</strong>）：多次执行和一次执行效果一样；但是幂等性并不能推出确定性；假设有这么一个函数，它第一次执行造成了一些状态改变（比如某些释放资源的 dispose 函数），而后续发现状态已经改变过了就不再改变该状态，那么它符合幂等性；但是由于其含有隐式状态输入，不是确定性的。</p>
<p>如果 map&#x2F;reudce 函数是确定性的，那么框架就可以放心大胆重试了。某些条件下，幂等性也可以接受，比如保存隐式状态的地方很牢靠。举个栗子，我们依赖于一个文件锁做判断某个函数执行了一次或多次，如果该文件锁所依赖的文件系统很稳定，并且提供分布式一致性，那么就完全可以。如果是用 nfs 的一个文件做锁，来实现的所谓幂等性就值得商榷了。</p>
<p>如果 map&#x2F;reduce 函数是确定性的，框架会通过其输出提交的原子性来进行幂等性保证。即，即使重试了多次，也和只执行了一次一样。具体来说，对于 Map Task，会产生 R 个临时文件，并在结束时将其位置发送给 Master；Master 在收到多次同一分片（split） 的位置信息时，如果该分片前面某次结果来源仍可用或者已经被消费，那么就忽略掉该请求后面的所有请求。对于 Reduce Task，其生成的结果也会先写成临时文件，然后依赖于底层文件系统的原子性的改名操作（<strong>原子性改名</strong>也是一个多进程竞争的经典的操作，因为生成文件过程比较长，不容易做成原子的，但是<strong>判断具有某名字的文件是否存在并改名</strong>却很容易做成原子的），在处理完成时改变为目的文件名。如果发现已经有一个具有该目的文件名的文件了，就放弃改名操作，从而保证了该 Reduce Task只有一个成功输出的最终文件。</p>
<h3 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h3><p>一个 MapReduce Job 中会产生 M+R 个 Task，具体 M 和 R 的值在运行之前可以由人进行配置。不同的系统实现可能会有发挥出最佳系统性能的不同配比；但是同时要兼顾业务需求，比如输入大小，输出文件个数等等。</p>
<h3 id="备份任务"><a href="#备份任务" class="headerlink" title="备份任务"></a>备份任务</h3><p>在实际业务中，由于某些主机原因常会出现<strong>长尾效应</strong>，即少数几个 Map&#x2F;Reduce Task 总是会巨慢的拖到最后，甚至拖得时间甚至是其他任务的几倍。造成这些主机拖后腿的原因可以举出很多，如：某个机器硬盘老化，读写速度几十倍的变慢；又比如调度器调度的有问题，导致某些机器负载太高，具有大量的 CPU、内存、硬盘和网络带宽的争抢；又比如软件 bug 导致某些主机变慢等等。</p>
<p>只要确定这些问题只发生在<strong>少数</strong>某些主机上，那么解决方法也很简单。在<strong>任务接近尾声</strong>的时候（比如统计剩余task的占比小于一个阈值时），对于每个仍然在跑的任务，分别额外调度一份到其他主机上，那么大概率会让这些任务提前完成，同一任务跑多次的处理逻辑，和容错重试造成跑多次是一致的，可以复用。</p>
<p>此外，我们可以通过实际业务检验来微调该阈值（包括怎么判定任务结尾，启用几个备份任务），在耗费额外资源代价和减少任务总用时之前取得一个平衡。</p>
<h2 id="其他细节"><a href="#其他细节" class="headerlink" title="其他细节"></a>其他细节</h2><p><strong>除了 Mapper 和 Reducer 这两个最基本的源语，该系统还提供了一些其他的后来事实上也成为标配的扩展：Partitioner，Combiner 和 Reader&#x2F;Writer</strong>。</p>
<h3 id="Partitioner"><a href="#Partitioner" class="headerlink" title="Partitioner"></a>Partitioner</h3><p>默认来说，对 Map 输出的中间结果进行划分会使用类似于 <em>hash(key) mod R</em> 这种应用无关的划分算法。但是有时候用户有需求将特定的一些 keys 路由到同一个 Reduce Task，比如说中间结果的 key 是 URL， 用户想按网站 host 进行汇总处理。这时候就需要将系统的这部分路由功能开放给用户，以满足用户的定制需求。</p>
<h3 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h3><p>如果该 Job 针对所有中间结果的 reduce 的操作满足<strong>结合律</strong>，那么指定 Combiner 会很能提高效率。拿的 Word Count 来说，数值的加法无疑满足结合律，也就是说，同一个单词的频次，在 Map Task 输出后进行加和（在 Map Work 上），还是在 Reduce Task 中进行加和（在 Reduce Worker上），结果保持一致；而这样一来，由于一些中间结果对进行了 combine，Map Task 到 Reduce Task 间的传输数据量会小很多，从而提高整个 Job 的效率。</p>
<p>也可以看出，combine 函数一般和 reduce 函数是一样的，因为他们本质上是对 value set 执行了同一种操作，只不过执行时，执行的地点不一样，结合的顺序不一样。目的是为了减少中间结果传输量，加速任务执行过程。</p>
<h3 id="Reader-x2F-Writer"><a href="#Reader-x2F-Writer" class="headerlink" title="Reader&#x2F;Writer"></a>Reader&#x2F;Writer</h3><p>如果不将定制输入输出的能力开放给用户，那么系统显然只能处理有限几种默认约定的格式。因此，<em>reader</em> 和 <em>writer</em>  接口本质上是系统和现实繁杂的业务之间的<strong>适配器（Adaptor）</strong>。它们让用户可以自行指定数据的<em>来源和去处</em>、<em>按需要理解输入内容</em>和<em>自由定制输出格式</em>。</p>
<p>有了这两个 Adaptor，系统才能适配更多的业务。一般来说，系统会内置提供一些常见的 Reader 和 Writer 的实现；包括按行读文本文件，读文件中键值，读数据库等等。然后用户可以实现这两个接口，进行更具体的定制。<em>系统常通过类似这种常用脚手架+进一步定制能力来提供API</em>，下面的 Counter 也是如此。</p>
<h3 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h3><p>有些用户实现的 map&#x2F;reduce 函数会有一些副作用，比如说在执行任务中间输出一些文件、写一些数据库条目等等。一般来说这些副作用的原子性和幂等性需要用户自己来处理。因为如果输出介质不纳入 MapReduce 系统，系统是没有办法保证这些输出的幂等性和原子性的。不过有的系统就这么干的，提供一些某种类型&#x2F;介质的状态或者数据存储，纳入系统中，并且提供一些容错和幂等的性质。好像 MillWheel 有类似的做法。但这样会大大加重系统的复杂性。</p>
<h3 id="跳过坏记录"><a href="#跳过坏记录" class="headerlink" title="跳过坏记录"></a>跳过坏记录</h3><p>如果用户代码有 bug 或者某些输入有问题，会导致 Map 或者 Reduce 任务在运行时崩溃。当然这些 bug 或者输入能修则修，但是有些情况由于第三方库或者输入的原因，不能够进行修复。而在某些类型的任务，比如说训练数据集清洗、大型统计任务，丢几个是可以容忍的。针对这种情况，系统会提供一种模式，在这种模式中会跳过这些 Record 记录的执行。</p>
<p>具体实现上来说，也比较简单。可以给每个输入 Record 给个<strong>唯一编号</strong>（单次任务内唯一就行）；如果某个 Record 处理时挂掉了，就将其编号汇报给 Master。如果 Master 收到了某个 Record 超过一次的处理失败信息，就将其跳过。做的再细一点，还可以记下错误类型和信息进行比对，来确定这是否是一个确定性（deterministic）的错误，进而决定是否将其跳过。</p>
<h3 id="单机执行"><a href="#单机执行" class="headerlink" title="单机执行"></a>单机执行</h3><p>众所周知，分布式系统很难跟踪、调试；因为一个 Job 可能同时分散在数千台机器上进行执行。因此系统提供了本地运行 Job 的能力。可以针对小数据集输入对代码的正确性进行测试。由于在单机运行，<strong>就可以比较方便通过调试工具进行断点追踪</strong>。</p>
<p>实现一个本地 mock 系统，一般来说比较简单。因为不需要考虑网络间状态通信，代码多节点分发，多机调度等一系列分布式系统的问题。但却能极大方便代码调试，性能测试和小数据集测试。</p>
<h3 id="状态信息"><a href="#状态信息" class="headerlink" title="状态信息"></a>状态信息</h3><p>对于分布式执行的 Job，一个任务进度等<strong>信息可视化界面</strong>（给系统集成一个 HTTP 服务，实时拉取系统信息进行展示）有时候是至关重要的，它是系统易用性的关键。如果系统用户不能够很方便的实时监控任务的运行进度、执行速度、资源用量、输出位置，出错信息以及其他一些任务的元信息，就不能对任务的执行状况有个感性的把握。尤其是如果写 MapReduce 程序的人和跑这些程序的不是一个人时，会更为依赖这些状态的实时呈现。</p>
<p>因此，<strong>对于分布式系统来说，其易用性有一大半落在一个良好的系统信息呈现上</strong>。使用者需要据此来预测任务的完成时间、资源的吃紧程度等等，从而做出相应决策。</p>
<p>此外，对与集群机器状态信息，也需要进行跟踪，因为机器的负载信息、故障信息、网络状况等等对用户任务的执行也有不同程度的影响。给出这些机器状态信息，有助于对用户代码甚至系统代码进行出错诊断。</p>
<h3 id="全局计数器"><a href="#全局计数器" class="headerlink" title="全局计数器"></a>全局计数器</h3><p>系统提供了一种计数服务，以统计某种事件的发生频次。比如用户想统计 Word Count 示例中所处理的全大写单词的总数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Counter* uppercase;</span><br><span class="line">uppercase = <span class="built_in">GetCounter</span>(<span class="string">&quot;uppercase&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">map</span>(String name, String contents):</span><br><span class="line">  <span class="keyword">for</span> each word w in contents:</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">IsCapitalized</span>(w)):</span><br><span class="line">      uppercase-&gt;<span class="built_in">Increment</span>();</span><br><span class="line">    <span class="built_in">EmitIntermediate</span>(w, <span class="string">&quot;1&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>从代码可以大致猜测其实现：定义的时候，需要给 Counter 指定一个 Id。然后在 Map&#x2F;Reudce 代码中可以通过该 Id 获取该 Counter 然后进行计数。每个 worker 机器上的计数信息会汇总到 Master 上，然后按 Counter 的 ID 进行加和，并且最终返回给用户。同时，前述展示状态信息页面也会将这些计数器进行可视化（比如说打折线图）。其中有个点需要注意，就是多次对重试的任务（由于<em>机器死掉</em>或者<em>避免长尾</em>进行的重试）的计次进行去重；可以按照 Map&#x2F;Reduce ID 来进行去重，即我们假定同一输入的重试任务共享一个 Task ID（事实上为了满足重试需求和任务管理需求，<strong>分布式系统肯定会对所有任务进行唯一编号的</strong>），针对具有相同 Task ID 内部的 Counter 的计次，Master 只保留第一次<strong>成功</strong>的那一份；但是如果计数需要在页面上实时显示，可能就需要做适当信息保留，并且在该 Task 重试时进行计数回退之类的操作。</p>
<p><strong>系统会自动维持一些计数器</strong>，比如说所有已经处理的键值对的数量和所有已经产生的键值对数量。全局计数操作对于某些应用用处很大，比如说有的应用要求所有输入键值对和输出键值对的数量一样，如果没有全局计数，就无从验证；或者统计一些数据的全局比例等等。</p>
<h2 id="重排（shuffle）-操作"><a href="#重排（shuffle）-操作" class="headerlink" title="重排（shuffle） 操作"></a>重排（shuffle） 操作</h2><p>自 Spark 成名之后，shuffle 这个 MapReduce 中的语义得到了很多研究和实践。这是一个多机传输的耗时操作，其实现的高效性对系统的性能有着至关重要的作用，因此单独拿出一节来聊聊。</p>
<p>在 MapReduce 中就是指 Map Task 分片输出到 Reduce Task 按需拉取的这么一个过程。还拿 Word Count 为例，你想统计某个单词在所有文档中的总频次，但是这些单词分布在不同机器上的不同的 Map Task 输出里；而只有将所有同样单词的频次对聚集到同一台机器上，才能对其加和。<strong>这种将机器和子数据集对应关系按key打乱重组的操作，我们姑且称之为 shuffle。</strong></p>
<p>在 Spark 中，基本上继承了该语义，并且更通用化了。一个常见的例子是 join，即将两个 Table 间具有相同 key 的记录路由到同一台机器上，从而在所有机器上按 key 分片进行并行 join，从而大幅提高效率。类似于 join 这样的高阶操作，会使得底层的 Partition 不能继续在本机运行而不与其他 Partition 发生联系，因此 shuffle 也是 Spark 中划分 Stage 的一个分水岭。</p>
<p>对于 MapReduce 系统来说，使用的 shuffle 策略类似于 Spark 中基于排序的 shuffle。Map 首先将中间结果写到内存中，然后定期刷盘，刷盘时进行归并排序。然后 Reducer 端按需拉取，从多个 Mapper 端拉取数据后，再次进行归并排序，然后传给 Reduce 函数。这样的好处在于可以进行大规模数据处理，<strong>因为可以做外部排序，也可以做迭代惰性加载</strong>。对于 Hadoop 的实现来说，将包含 shuffle 的整个流程分为了明显的几个阶段：map(), spill, merge, shuffle, sort, reduce() 等。</p>
<h2 id="其他的一些点"><a href="#其他的一些点" class="headerlink" title="其他的一些点"></a>其他的一些点</h2><p><strong>一些缺点</strong>：通过 MapReduce 的系统设计可以看出，它是一个高吞吐，但是也高延迟的批量处理系统。并且不支持迭代。这也是后续 Spark，Flink 这样系统火热的动机。</p>
<p><strong>文件系统</strong>： MapReduce 只有和 GFS 这样支持分块、多进程并发写的大文件系统配合才能发挥出更大的优势，优化输入和输出的性能。此外，这种分布式文件系统还会屏蔽底层节点故障。</p>
<p><strong>组织形式</strong>： MapReduce 是一个系统，需要部署到集群上，但它同时又是一个库，让用户代码和分布式集群进行交互而不太用关心分布式环境中的问题的一个库。每个任务需要写任务描述（<em>MapReduceSpecification</em>），然后提交给系统——这是库常用的一种提交任务的手段。</p>
<p><strong>代码分发</strong>：谷歌的 MapReduce 具体实现不得而知。猜测可以有两种方式：一是将 MapReduce 库代码 + 用户代码整体在不同机器上 fork ，然后根据角色不同来执行不同分支。二是将各个机器上的服务先启动起来，然后执行任务时只会将用户自定义函数序列化后传输到不同机器。</p>
<h2 id="名词释义"><a href="#名词释义" class="headerlink" title="名词释义"></a>名词释义</h2><p><strong>Intermediate result</strong>：map 函数产生的中间结果，以键值对形式组织。</p>
<p>**Map Task **：这个应该都是指的 Worker 机器上，执行 map 函数的工作进程。</p>
<p><strong>Map Worker</strong>：Map Task  所运行的 Worker 机器。所有 Worker 应该是没有角色标记的，既可以执行 Map Task，也可以执行 Reduce Task，以充分的利用机器性能。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Jeffrey Dean and Sanjay Ghemawat， <span class="exturl" data-url="aHR0cHM6Ly9zdGF0aWMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL21lZGlhL3Jlc2VhcmNoLmdvb2dsZS5jb20vemgtQ04vL2FyY2hpdmUvbWFwcmVkdWNlLW9zZGkwNC5wZGY=">MapReduce: Simplified Data Processing on Large Clusters<i class="fa fa-external-link-alt"></i></span></p>
<p>[2] Alexey Grishchenko， <span class="exturl" data-url="aHR0cHM6Ly8weDBmZmYuY29tL3NwYXJrLWFyY2hpdGVjdHVyZS1zaHVmZmxlLw==">Spark Architecture: Shuffle<i class="fa fa-external-link-alt"></i></span></p>
<p>[3] <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0plcnJ5TGVhZA==">JerryLead<i class="fa fa-external-link-alt"></i></span>， <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0plcnJ5TGVhZC9TcGFya0ludGVybmFscy9ibG9iL21hc3Rlci9tYXJrZG93bi80LXNodWZmbGVEZXRhaWxzLm1k">Spark internals<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>分布式系统</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>煮红果记</title>
    <url>/2019/10/20/boil-hawthorn/</url>
    <content><![CDATA[<p>季秋时节，各种果子纷至沓来。山楂，我们那叫山里红，北京好像称红果。老北京一道有名的菜便是“炒红果”。这天去菜市场，发现今年的个大成色好，便赶紧买了些来。</p>
<span id="more"></span>

<p>馅老满的炒红果吃过两次，初吃很爽口，多吃几颗便发腻。于是早就想着自己也做点吃，自然要少糖！少糖！少糖！去年做过一次，但是山楂小且成色差，去籽手法也不好，做出来的差强人意。</p>
<p>近两年还和山楂还有过几次缘分。一次是在微软时，茶水间的阿姨有时候会熬一点山楂汤，有时候是雪梨汤。但印象最深的还是山楂汤：酸口、微甜，汤汁粘稠，如缎子一般，每次我会偷偷喝好几杯。一次是在哈尔滨在坐飞机，在去登机口路过的小店里，见识了不下几十种山楂制品，是在有点开眼，忍不住买了几样。不过，我是个老想不起吃零食的人，最后都在角落里落了灰。</p>
<p>我采取微软阿姨的做法——熬。原料也盘算好了：山楂、黄冰糖和蜂蜜。下面逐个来说。</p>
<p>山楂，比较发麻烦的是去籽。去年是先剜去山楂下面剩余的黑黢黢的花蒂，继而掰开，最后用水果刀将籽一粒粒挑出来。这样处理后，最后做出来的山楂汁总是有很多渣，而且煮熟的山楂也不美观。今年突发灵感，感觉可以用不锈钢筷子的粗头，将山楂籽捅出来。一拍大腿，说干就干。摸索了一下，主要分两步。首先，用水果刀将上面的梗和下面的花蒂都剜去，上面开口小，下面开口稍大。然后，用不锈钢筷子的较大的一头，从上往下捅，这个顺序很重要，如果反过来，山楂很容易碎。如果籽弄不干净就多捅几次。</p>
<p><img src="https://i.loli.net/2020/02/09/vLobhJHtO4uGV9S.jpg" alt="山楂上面，原梗一侧"></p>
<p><img src="https://i.loli.net/2020/02/09/xr3oyT9cdhlXSFi.jpg" alt="山楂下面，原花蒂一侧"></p>
<p>最后剥了一小盘，看着就很有食欲。</p>
<p><img src="https://i.loli.net/2020/02/09/GjTtVEMZLkvXuNo.jpg"></p>
<p>冰糖，我选的多晶黄冰糖。制法是盆晶法，里面没有线。黄冰糖没有经过漂白，感觉要舒服一些。</p>
<p>蜂蜜，为了增加味道的厚度，还加了点桂花蜂蜜。自从去了南方，被桂花的清香击中之后，便备了桂花蜂蜜常放家中，各种甜食都可以加点。曾经吃了西贝莜面的桂花黄米凉糕，惊为天物，便买了黄米和江米想给妹子点惊喜，无奈太繁复，我又懒，便作罢。</p>
<p>至于水、冰糖和蜂蜜的比例，就是很个性化的事情。我多加了点水，可以不那么甜，还能多喝点汤；妹子不让吃太甜的，冰糖加了两块小的。蜂蜜加了一小勺。一股脑放进电饭煲后，选了煲汤的选项。大约一个半小时后，用勺舀了一些到杯子中喝，酸甜相宜，口感浓厚。卖相也是相当不错：</p>
<p><img src="https://i.loli.net/2020/02/09/rjqO5nJ7TuK3QPd.jpg"></p>
<p><img src="https://i.loli.net/2020/02/09/Ldf2mwrky8FznhS.jpg"></p>
<p>去年的时候，还加了雪梨一块炖，出来的汤汁也是相当有层次感。</p>
]]></content>
      <categories>
        <category>生活</category>
        <category>美食</category>
      </categories>
      <tags>
        <tag>hawthorn</tag>
        <tag>山楂</tag>
      </tags>
  </entry>
  <entry>
    <title>Ray 源码解析（二）：资源抽象和调度策略</title>
    <url>/2019/08/10/ray-source-reading-2/</url>
    <content><![CDATA[<p>上一篇讲了待调度任务的组织形式，这一篇来继续挑软骨头啃：节点资源抽象和调度策略。</p>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>由于 Ray 支持对任务进行<strong>显式的资源约束</strong>，因此需要对所有节点的资源进行硬件无关的抽象，将所有资源归一化管理，以在逻辑层面对资源进行增删。当有节点加入，需要感知其资源总量大小；当有任务调度，需要寻找满足约束节点；当任务调度成功，可以获取剩余可用资源等等。</p>
<p>Ray 除了对标准资源如 CPU，GPU 的支持，还支持对用户自定义 label 的资源的调度。用户在启动节点（<code>ray start --resources &lt;resources&gt;</code>）指定该节点具有<strong>某种类别的资源</strong>（比如说 memory，bandwidth，某种型号的 GPU 等等）的总量，在定义 remote 函数时指定任务使用多少该类别的资源，Ray 的调度器在调度该任务时，就会按照用户自定义的资源需求将其调度到特定的机器上去。这是一种<strong>用户代码和调度器交互的一种有趣设计</strong>。</p>
<p>对于调度策略，由于 Ray 是去中心化的调度，很容易存在不一致状态。最简单的在实践中反而是统计最优的——对于每个任务找到符合资源约束的节点，随机选择一个，将任务调度过去。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="调度资源抽象-SchedulingResources"><a href="#调度资源抽象-SchedulingResources" class="headerlink" title="调度资源抽象(SchedulingResources)"></a>调度资源抽象(SchedulingResources)</h2><p>最基本的四个类是 <code>FractionalResourceQuantity</code> 、 <code>ResourceSet</code> 、  <code>ResourceIds</code> 和 <code>ResourceIdSet</code>。各个类的特点概述一下：</p>
<ul>
<li><code>FractionalResourceQuantity</code>  定义了某种资源的<strong>量值</strong></li>
<li><code>ResourceSet</code> 是一组不同种类资源及其量值的<strong>集合</strong></li>
<li><code>ResourceIds</code> 对资源量按分数进行了标号——0, 1 … quantity-1 。</li>
<li><code>ResourceIdSet</code> 是一组标号后的资源的集合。</li>
</ul>
<p>前两者是在<strong>多少</strong>层面上对资源进行描述，后两者是在<strong>索引</strong>层面对资源进行解构。</p>
<p><strong>后两者是在前两者基础上的细化</strong>。他们都定义了<strong>单个量值</strong>和集合不同种类量值构成的<strong>集合量</strong>。</p>
<p>此外，很重要的一点是，在 <code>FractionalResourceQuantity</code> 名字中也有体现，Ray 支持<strong>小数量值</strong>，但是只支持纯小数量值。为什么会有这种设计呢？举个最简单的例子，GPU 很贵嘛，于是就想多个 Task 共用一个 GPU，以提高 GPU 的利用率。那么每个 Task 在定义 GPU 需求的时候，就可以写需要零点几个 GPU。在这种场景下，一点几个和二点几个的非纯小数值就没什么意思了，毕竟要么独占一个，要么与他人共享一个。</p>
<h3 id="资源量值（FractionalResourceQuantity）"><a href="#资源量值（FractionalResourceQuantity）" class="headerlink" title="资源量值（FractionalResourceQuantity）"></a>资源量值（FractionalResourceQuantity）</h3><p><code>FractionalResourceQuantity</code> 是对 double 的包装，表示 Ray 中对资源度量的<strong>量</strong>。但为了计算不损失精度，其内部实际实现为 64bit 的整型——<strong>实际值</strong>乘以 <code> kResourceConversionFactor = 10000</code> 取整。其目的很明显：</p>
<ol>
<li>对于 Ray 的资源使用场景下，四五位小数左右的精度就够了</li>
<li>在这个精度内提供精确的运算</li>
</ol>
<p>在此基础上重载了可度量的量的一些基本操作——加减运算和布尔运算。在 Ray 的场景下，只有节点加入（增加资源），判断是否可调度（比较资源）、调度任务（减小资源）等操作，因此乘除操作是不需要的。</p>
<p>当然也可以从另外一个角度来理解，或许更好理解一点，其内部表示将 <strong>量纲&#x2F;单位</strong> 从逻辑的 <code>1</code>，缩小为了 <code>1/kResourceConversionFactor</code> 。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FractionalResourceQuantity</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// 默认构造函数：resource_quantity_ = 0</span></span><br><span class="line">  <span class="built_in">FractionalResourceQuantity</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 基本构造函数：指定资源量</span></span><br><span class="line">  <span class="built_in">FractionalResourceQuantity</span>(<span class="type">double</span> resource_quantity);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// 加减运算</span></span><br><span class="line">  <span class="type">const</span> FractionalResourceQuantity <span class="keyword">operator</span>+(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span>;</span><br><span class="line">  <span class="type">const</span> FractionalResourceQuantity <span class="keyword">operator</span>-(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span>;</span><br><span class="line">  <span class="type">void</span> <span class="keyword">operator</span>+=(<span class="type">const</span> FractionalResourceQuantity &amp;rhs);</span><br><span class="line">  <span class="type">void</span> <span class="keyword">operator</span>-=(<span class="type">const</span> FractionalResourceQuantity &amp;rhs);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// 布尔运算</span></span><br><span class="line">  <span class="type">bool</span> <span class="keyword">operator</span>==(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span>;</span><br><span class="line">  <span class="type">bool</span> <span class="keyword">operator</span>!=(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span>;</span><br><span class="line">  <span class="type">bool</span> <span class="built_in">operator</span>&lt;(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span>;</span><br><span class="line">  <span class="type">bool</span> <span class="keyword">operator</span>&gt;(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span>;</span><br><span class="line">  <span class="type">bool</span> <span class="keyword">operator</span>&lt;=(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span>;</span><br><span class="line">  <span class="type">bool</span> <span class="keyword">operator</span>&gt;=(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// 浮点型的实际值</span></span><br><span class="line">  <span class="function"><span class="type">double</span> <span class="title">ToDouble</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 以 1/kResourceConversionFactor 为单位的资源量大小</span></span><br><span class="line">  <span class="type">int64_t</span> resource_quantity_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>这类运算实现的时候有个基本思想：尽量<strong>复用</strong>，即定义<strong>最小数量的正交操作</strong>，然后用这些操作来实现另外的操作。这样有两个好处：</p>
<ol>
<li>代码简洁，因为复用了。</li>
<li>改动方便，将来如果要改变实现只需改变最基本的操作实现。</li>
</ol>
<p>具体到本例子中的布尔操作集，首先定义<strong>等于和小于</strong>操作符作为基本操作集，然后以此实现其他几个操作符。后面 <code>ResourceSet</code> 中也有类似的思想：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 两个基本操作</span></span><br><span class="line"><span class="type">bool</span> FractionalResourceQuantity::<span class="keyword">operator</span>==(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> resource_quantity_ == rhs.resource_quantity_;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> FractionalResourceQuantity::<span class="keyword">operator</span>&lt;(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> resource_quantity_ &lt; rhs.resource_quantity_;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下调用基本操作完成定义</span></span><br><span class="line"><span class="type">bool</span> FractionalResourceQuantity::<span class="keyword">operator</span>!=(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> !(*<span class="keyword">this</span> == rhs);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> FractionalResourceQuantity::<span class="keyword">operator</span>&gt;(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> rhs &lt; *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> FractionalResourceQuantity::<span class="keyword">operator</span>&lt;=(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> !(*<span class="keyword">this</span> &gt; rhs);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> FractionalResourceQuantity::<span class="keyword">operator</span>&gt;=(<span class="type">const</span> FractionalResourceQuantity &amp;rhs) <span class="type">const</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> !(*<span class="keyword">this</span> &lt; rhs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="资源集合-ResourceSet"><a href="#资源集合-ResourceSet" class="headerlink" title="资源集合(ResourceSet)"></a>资源集合(ResourceSet)</h3><p><code>ResourceSet</code> 是一系列不同种类的资源及其量值的集合，实现上是对字典（<code>unordered_map</code>）包装。在物理意义上，一般用来表示一个节点的总资源量、已经使用的资源量、剩余可用的资源量等等。</p>
<p>基本操作包括对单个资源的增删，以及资源集合间的运算；详细见代码内注释。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResourceSet</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">ResourceSet</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 三个构造函数：</span></span><br><span class="line">  <span class="comment">// 根据一个字典或者一个键值对列表构建 label(string)-&gt;amount(FractionalResourceQuantity) 的字典。</span></span><br><span class="line">  <span class="built_in">ResourceSet</span>(</span><br><span class="line">      <span class="type">const</span> std::unordered_map&lt;std::string, FractionalResourceQuantity&gt; &amp;resource_map);</span><br><span class="line">  <span class="built_in">ResourceSet</span>(<span class="type">const</span> std::unordered_map&lt;std::string, <span class="type">double</span>&gt; &amp;resource_map);</span><br><span class="line">  <span class="built_in">ResourceSet</span>(<span class="type">const</span> std::vector&lt;std::string&gt; &amp;resource_labels,</span><br><span class="line">              <span class="type">const</span> std::vector&lt;<span class="type">double</span>&gt; resource_capacity);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 析构函数</span></span><br><span class="line">  ~<span class="built_in">ResourceSet</span>();</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 判断资源集合 A 是否为 B 的子集(A 中所有 label 的 amount 都不大于 B 中对应 label 的 amount)</span></span><br><span class="line">  <span class="comment">// 以该操作作为基本操作，可以实现接下来三个操作</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">IsSubset</span><span class="params">(<span class="type">const</span> ResourceSet &amp;other)</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 下面函数中，前两个函数的实现一毛一样</span></span><br><span class="line">  <span class="type">bool</span> <span class="keyword">operator</span>==(<span class="type">const</span> ResourceSet &amp;rhs) <span class="type">const</span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">IsEqual</span><span class="params">(<span class="type">const</span> ResourceSet &amp;other)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">IsSuperset</span><span class="params">(<span class="type">const</span> ResourceSet &amp;other)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 类似于字典的一些增删改查操作，即对某个种类的资源数量进行增删改查</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AddOrUpdateResource</span><span class="params">(<span class="type">const</span> std::string &amp;resource_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> FractionalResourceQuantity &amp;capacity)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">DeleteResource</span><span class="params">(<span class="type">const</span> std::string &amp;resource_name)</span></span>;</span><br><span class="line">  <span class="function">FractionalResourceQuantity <span class="title">GetResource</span><span class="params">(<span class="type">const</span> std::string &amp;resource_name)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">IsEmpty</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 两个集合间的加减运算。需要注意的是，在增加的时候有时候不能超过一个上界：比如节点的资源总量大小，于是有了</span></span><br><span class="line">  <span class="comment">// AddResourcesCapacityConstrained; 在减小的时候，资源量不能减小为负值，于是有了 </span></span><br><span class="line">  <span class="comment">// SubtractResourcesStrict。这是两个上下界保护的函数。</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AddResourcesCapacityConstrained</span><span class="params">(<span class="type">const</span> ResourceSet &amp;other,</span></span></span><br><span class="line"><span class="params"><span class="function">                                       <span class="type">const</span> ResourceSet &amp;total_resources)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AddResources</span><span class="params">(<span class="type">const</span> ResourceSet &amp;other)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SubtractResources</span><span class="params">(<span class="type">const</span> ResourceSet &amp;other)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SubtractResourcesStrict</span><span class="params">(<span class="type">const</span> ResourceSet &amp;other)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 由于所有节点必然存在 CPU，所有任务调度是也必然需要 CPU 资源，因此单独拿出来作为一个函数。</span></span><br><span class="line">  <span class="comment">// 其对应的 label name 为：kCPU_ResourceLabel = &quot;CPU&quot;</span></span><br><span class="line">  <span class="function"><span class="type">const</span> ResourceSet <span class="title">GetNumCpus</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回字典形式组织的资源列表和对应数量；一个是 double 形式表示，一个是 FractionalResourceQuantity</span></span><br><span class="line">  <span class="comment">// 形式表示</span></span><br><span class="line">  <span class="function"><span class="type">const</span> std::unordered_map&lt;std::string, <span class="type">double</span>&gt; <span class="title">GetResourceMap</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> std::unordered_map&lt;std::string, FractionalResourceQuantity&gt;</span></span><br><span class="line"><span class="function">      &amp;<span class="title">GetResourceAmountMap</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">const</span> std::string <span class="title">ToString</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 内部资源及其数量字典</span></span><br><span class="line">  std::unordered_map&lt;std::string, FractionalResourceQuantity&gt; resource_capacity_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>集合间加减运算时，有两个额外的带上下界检查的函数。应该是为了避免小数不精确运算导致的后果？</p>
<h3 id="资源标号-ResourceIds"><a href="#资源标号-ResourceIds" class="headerlink" title="资源标号(ResourceIds)"></a>资源标号(ResourceIds)</h3><p><code>ResourceIds</code> 解决的问题是为某种资源打上标号，并且以某种方式拆分资源。</p>
<p>对于<strong>资源标号</strong>，即给系统所有资源打上一个逻辑 ID（0~n-1）。比如说 GPU 0, GPU 1 等等。以使用户代码能够对资源进行定位，从而要求某段代码具体使用某个资源。</p>
<p>对于<strong>资源拆分</strong>，Ray 要求 API （<code>ray.remote(label=amount)</code>）只能以两种形式使用资源：</p>
<ol>
<li>amount &gt;&#x3D; 1 且必须是整数。</li>
<li>amount &lt; 1，即是纯小数。</li>
</ol>
<p>对应到物理意义上，即要么<strong>独占</strong>一到多个整份资源，要么和其他人<strong>共享</strong>单份资源。前者的经典例子是 CPU，后者经典例子是 GPU。</p>
<p>在内部实现上，<code>ResourceIds</code> 维护了两个列表。一个列表是整整型列表（<code>vector&lt;int64_t&gt; whole_ids_</code>）代表所有的整数份资源的 ID 列表。一个列表是键值对列表（<code>vector&lt;pair&lt;int64_t, FractionalResourceQuantity&gt;&gt;</code>），代表所有小数份资源 ID 及其对应的剩余份数。值得一提的是，对于一个节点，初始来说应该都是整数份资源（除非有某种特殊用途，比如不想让集群用满该节点资源啦）。然后随着需要小数份资源的任务的调度，一部分资源被切分，实现上表现为从整份资源列表中拿出一个资源，切分后，分出去一块给任务，剩下的放到小数份资源列表中。因此，<strong>两个列表中不会有相同的 ID</strong>，因为每个 ID 都最多对应一整份资源。如果由于任务完成，导致某些小数份资源释放，使得小数份资源列表中的具有同样 ID，这样的资源在还回时候会被合并，如果等于1之后，就会被拿到整数份资源列表中。</p>
<p>在资源分配的时候有些小原则。比如说要求小数份资源，我们优先去小数份资源列表里去找符合要求的，不能满足要求的话再去整数份资源列表中拆。</p>
<p>拆分的另一个问题是，我们不能将属于两个 ID 的两个小数份资源（比如说标号0 的有 0.5 份，标号 1 的有 0.5份）合到一块分配给一个要求较大的资源任务（比如说一个要求 0.75 份资源的任务）。举个例子来说，有两个 GPU 还剩一半用量，你不能将他们合起来分配给一个要求 0.75 份 GPU的任务。</p>
<p>还有一个变量 <code>decrement_backlog_ </code>用来记录所有超额资源请求。等待其他人 <code>Release</code> 了，会优先满足这些请求。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResourceIds</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">ResourceIds</span>();</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 通过给定份数的资源构建 ResourceIds。resource_quantity 要么是个整数，要么是纯小数</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ResourceIds</span><span class="params">(<span class="type">double</span> resource_quantity)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 在内部实现上，整数份的资源列表用 vector&lt;int&gt; 来表示所有对应的 ID，每个具有一整份资源。</span></span><br><span class="line">  <span class="comment">// 对于小数份资源，使用一个 vector&lt;pair&gt; 来表示某个 ID 和其对应的资源量值</span></span><br><span class="line">  <span class="comment">// 因此有以下三个构造函数。</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ResourceIds</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">int64_t</span>&gt; &amp;whole_ids)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ResourceIds</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> std::vector&lt;std::pair&lt;<span class="type">int64_t</span>, FractionalResourceQuantity&gt;&gt; &amp;fractional_ids)</span></span>;</span><br><span class="line">  <span class="built_in">ResourceIds</span>(</span><br><span class="line">      <span class="type">const</span> std::vector&lt;<span class="type">int64_t</span>&gt; &amp;whole_ids,</span><br><span class="line">      <span class="type">const</span> std::vector&lt;std::pair&lt;<span class="type">int64_t</span>, FractionalResourceQuantity&gt;&gt; &amp;fractional_ids);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 看是否有足够的要求的 resource_quantity 份资源。如果 resource_quantity 是整数，则只需看所有</span></span><br><span class="line">  <span class="comment">// 整数份资源列表。需要注意的是如果 resource_quantity 是小数，那么必须要有单个 ID 的资源量大于</span></span><br><span class="line">  <span class="comment">// resource_quantity 才可以(或者有不小于一份的整数资源，或者有大于resource_quantity的小数）</span></span><br><span class="line">  <span class="comment">// 而不能将两个小数凑在一块去大于 resource_quantity。因为分属于两个资源 ID 的量不能合到一块</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">Contains</span><span class="params">(<span class="type">const</span> FractionalResourceQuantity &amp;resource_quantity)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 根据上面的原则切下来一块资源 或者 回收一块资源。</span></span><br><span class="line">  <span class="comment">// 分配资源时，适当地进行拆分</span></span><br><span class="line">  <span class="comment">// 回收资源时，适当地进行合并。</span></span><br><span class="line">  <span class="function">ResourceIds <span class="title">Acquire</span><span class="params">(<span class="type">const</span> FractionalResourceQuantity &amp;resource_quantity)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Release</span><span class="params">(<span class="type">const</span> ResourceIds &amp;resource_ids)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 虽然语义不一样，但是和 Release 实现一样：将两个 resource_ids 加和</span></span><br><span class="line">  <span class="function">ResourceIds <span class="title">Plus</span><span class="params">(<span class="type">const</span> ResourceIds &amp;resource_ids)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取整数份/小数份资源 ID 列表</span></span><br><span class="line">  <span class="function"><span class="type">const</span> std::vector&lt;<span class="type">int64_t</span>&gt; &amp;<span class="title">WholeIds</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="type">const</span> std::vector&lt;std::pair&lt;<span class="type">int64_t</span>, FractionalResourceQuantity&gt;&gt; &amp;<span class="built_in">FractionalIds</span>()</span><br><span class="line">      <span class="type">const</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 看是不是该ID集合中没有任何资源</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">TotalQuantityIsZero</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 所有资源加和以 FractionalResourceQuantity 形式返回</span></span><br><span class="line">  <span class="function">FractionalResourceQuantity <span class="title">TotalQuantity</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">std::string <span class="title">ToString</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 通过 IncreaseCapacity 和 DecreaseCapacity 更新到指定资源量；这个是为了满足用户对</span></span><br><span class="line">  <span class="comment">// 对自定义资源动态调整而做的。</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">UpdateCapacity</span><span class="params">(<span class="type">int64_t</span> new_capacity)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 判断 resource_quantity 是不是一个整数</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">IsWhole</span><span class="params">(<span class="type">double</span> resource_quantity)</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">IncreaseCapacity</span><span class="params">(<span class="type">int64_t</span> increment_quantity)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">DecreaseCapacity</span><span class="params">(<span class="type">int64_t</span> decrement_quantity)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 两个列表</span></span><br><span class="line">  std::vector&lt;<span class="type">int64_t</span>&gt; whole_ids_;</span><br><span class="line">  std::vector&lt;std::pair&lt;<span class="type">int64_t</span>, FractionalResourceQuantity&gt;&gt; fractional_ids_;</span><br><span class="line">  <span class="comment">// 追踪总量，总量即用 FractionalResourceQuantity 表示，也说明了该类是 FractionalResourceQuantity </span></span><br><span class="line">  <span class="comment">// 的细化</span></span><br><span class="line">  FractionalResourceQuantity total_capacity_;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 暂时性记下超额资源请求</span></span><br><span class="line">  <span class="type">int64_t</span> decrement_backlog_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="资源标号集合-ResourceIdSet"><a href="#资源标号集合-ResourceIdSet" class="headerlink" title="资源标号集合(ResourceIdSet)"></a>资源标号集合(ResourceIdSet)</h3><p><code>ResourceIdSet</code> 表示一组带标号的可用资源的集合。实现上用了一个字典  <code>unordered_map&lt;string, ResourceIds&gt; available_resources_</code> ，表示资源种类到其数量（标号过的）映射，并在其上定义了和 <code>ResourceIds</code> 差不多的接口。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResourceIdSet</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// 各种构造函数，就是构建 unordered_map</span></span><br><span class="line">  <span class="built_in">ResourceIdSet</span>();</span><br><span class="line">  <span class="built_in">ResourceIdSet</span>(<span class="type">const</span> ResourceSet &amp;resource_set);</span><br><span class="line">  <span class="built_in">ResourceIdSet</span>(<span class="type">const</span> std::unordered_map&lt;std::string, ResourceIds&gt; &amp;available_resources);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 是否包含，索要和放回。和 ResourceIds 对应操作语义相同，只不过有单类资源变为了一组总资源。</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">Contains</span><span class="params">(<span class="type">const</span> ResourceSet &amp;resource_set)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function">ResourceIdSet <span class="title">Acquire</span><span class="params">(<span class="type">const</span> ResourceSet &amp;resource_set)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Release</span><span class="params">(<span class="type">const</span> ResourceIdSet &amp;resource_id_set)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">ReleaseConstrained</span><span class="params">(<span class="type">const</span> ResourceIdSet &amp;resource_id_set,</span></span></span><br><span class="line"><span class="params"><span class="function">                          <span class="type">const</span> ResourceSet &amp;resources_total)</span></span>;</span><br><span class="line">  <span class="comment">// 与 Release 实现一样</span></span><br><span class="line">  <span class="function">ResourceIdSet <span class="title">Plus</span><span class="params">(<span class="type">const</span> ResourceIdSet &amp;resource_id_set)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// 对于某类资源数量的增删查</span></span><br><span class="line">  <span class="comment">// 给某类资源增加指定数量</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">AddOrUpdateResource</span><span class="params">(<span class="type">const</span> std::string &amp;resource_name, <span class="type">int64_t</span> capacity)</span></span>;</span><br><span class="line">  <span class="comment">// 删除某类资源</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">DeleteResource</span><span class="params">(<span class="type">const</span> std::string &amp;resource_name)</span></span>;</span><br><span class="line">  <span class="comment">// 清空所有资源</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Clear</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="comment">// 获取所有可用资源，就是返回内部的散列表</span></span><br><span class="line">  <span class="function"><span class="type">const</span> std::unordered_map&lt;std::string, ResourceIds&gt; &amp;<span class="title">AvailableResources</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// cpu 所有任务都得用，所以单独拿出来</span></span><br><span class="line">  <span class="function">ResourceIdSet <span class="title">GetCpuResources</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将带标号的资源集合转变为只有数量描述的资源集合</span></span><br><span class="line">  <span class="function">ResourceSet <span class="title">ToResourceSet</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 打印和序列化</span></span><br><span class="line">  <span class="function">std::string <span class="title">ToString</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function">std::vector&lt;rpc::ResourceIdSetInfo&gt; <span class="title">ToProtobuf</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 从资源种类到带标号的资源集合的映射</span></span><br><span class="line">  std::unordered_map&lt;std::string, ResourceIds&gt; available_resources_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<h3 id="调度资源类（SchedulingResource）"><a href="#调度资源类（SchedulingResource）" class="headerlink" title="调度资源类（SchedulingResource）"></a>调度资源类（SchedulingResource）</h3><p>该类是最终对外负责的类，记录了<strong>某个节点上</strong>所有可供调度或者使用中的资源信息（<code>resources_total_</code>），待使用的资源信息（<code>resources_load_</code>）以及剩余可用的资源（<code>resources_available_</code>）。上面三个字段皆为 <code>ResourceIdSet</code> 类型。</p>
<p>三者关系为：</p>
<ol>
<li><code>resources_total_ = resouces_used_by_running_tasks + resources_available_</code></li>
<li><code>resources_load_ is part of resources_available_</code></li>
</ol>
<p>第二个关系可能看起来比较奇怪，后面会详细讲。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SchedulingResources</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// 默认构造函数和指定总量的构造函数</span></span><br><span class="line">  <span class="built_in">SchedulingResources</span>();</span><br><span class="line">  <span class="built_in">SchedulingResources</span>(<span class="type">const</span> ResourceSet &amp;total);</span><br><span class="line"></span><br><span class="line">  ~<span class="built_in">SchedulingResources</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 总量，负载量和可用量的 getter</span></span><br><span class="line">  <span class="function"><span class="type">const</span> ResourceSet &amp;<span class="title">GetAvailableResources</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> ResourceSet &amp;<span class="title">GetLoadResources</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> ResourceSet &amp;<span class="title">GetTotalResources</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 负载量和可用量的 setter，总量在构造时确定</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetLoadResources</span><span class="params">(ResourceSet &amp;&amp;newset)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetAvailableResources</span><span class="params">(ResourceSet &amp;&amp;newset)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取或者释放一组资源：在可用资源量上做增删</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Release</span><span class="params">(<span class="type">const</span> ResourceSet &amp;resources)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Acquire</span><span class="params">(<span class="type">const</span> ResourceSet &amp;resources)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 动态调整节点资源总量：更新某种种类的资源总量 or 删除某种种类资源</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">UpdateResource</span><span class="params">(<span class="type">const</span> std::string &amp;resource_name, <span class="type">int64_t</span> capacity)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">DeleteResource</span><span class="params">(<span class="type">const</span> std::string &amp;resource_name)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">std::string <span class="title">DebugString</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  ResourceSet resources_total_;</span><br><span class="line">  ResourceSet resources_available_;</span><br><span class="line">  ResourceSet resources_load_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>有意思的是，单从该源码来看， <code>Release</code>  和 <code>Require</code> 只对 <code>resources_available_</code> 进行了操作；而 <code>resources_load_</code> 只有整体 set 和 get 的操作，当然也可以通过 <code>GetLoadResources</code> 获取其引用后，直接对其进行加减。</p>
<p>结合其他源码思忖了一下，Ray 似乎想用 <code>resources_load_</code> 描述所有 <code>SchedulingQueue::ready_queue_</code> 需求总量，而非正在运行的任务的需求总量。正在运行的任务需求量应为 <code>resources_total_ - resources_available_</code>。也就是说 <strong><code>resources_load_</code> 是 <code>resources_available_</code> 的一部分，用来描述所有准备好的任务的资源需求总量</strong>。</p>
<p>作为一个典型的实现代表，贴一下 <code>UpdateResource</code> 的代码实现，该操作是对某类资源总量的更新；</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">SchedulingResources::UpdateResource</span><span class="params">(<span class="type">const</span> std::string &amp;resource_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         <span class="type">int64_t</span> capacity)</span> </span>&#123;</span><br><span class="line">  <span class="type">const</span> FractionalResourceQuantity new_capacity = <span class="built_in">FractionalResourceQuantity</span>(capacity);</span><br><span class="line">  <span class="type">const</span> FractionalResourceQuantity &amp;current_capacity =</span><br><span class="line">      resources_total_.<span class="built_in">GetResource</span>(resource_name);</span><br><span class="line">  <span class="keyword">if</span> (current_capacity &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 如果该类资源存在，则将其总容量以及可用量进行相应更新</span></span><br><span class="line">    <span class="type">const</span> FractionalResourceQuantity capacity_difference =</span><br><span class="line">        new_capacity - current_capacity;</span><br><span class="line">    <span class="type">const</span> FractionalResourceQuantity &amp;current_available_capacity =</span><br><span class="line">        resources_available_.<span class="built_in">GetResource</span>(resource_name);</span><br><span class="line">    FractionalResourceQuantity new_available_capacity =</span><br><span class="line">        current_available_capacity + capacity_difference;</span><br><span class="line">    <span class="keyword">if</span> (new_available_capacity &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      new_available_capacity = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    resources_total_.<span class="built_in">AddOrUpdateResource</span>(resource_name, new_capacity);</span><br><span class="line">    resources_available_.<span class="built_in">AddOrUpdateResource</span>(resource_name, new_available_capacity);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 如果不存在，则直接添加</span></span><br><span class="line">    resources_total_.<span class="built_in">AddOrUpdateResource</span>(resource_name, new_capacity);</span><br><span class="line">    resources_available_.<span class="built_in">AddOrUpdateResource</span>(resource_name, new_capacity);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="调度策略（SchedulingPolicy）"><a href="#调度策略（SchedulingPolicy）" class="headerlink" title="调度策略（SchedulingPolicy）"></a>调度策略（SchedulingPolicy）</h2><p>前面提到，Ray 使用去中心化的调度策略，即每个节点独立的对自己所看到的任务进行调度。<code>SchedulingPolicy</code> 就是描述单个节点的调度策略的，它通过构造函数拿到上一篇文章中提到的 <code>SchedulingQueue</code> 引用 ，从而拿到本节点所有的任务，然后通过 GCS 获取一组节点的资源概况（本节点的通过配置加载，对于其他节点，在感知到其加入集群的时候，从 GCS 中拉取），以 <code>unordered_map&lt;ClientID, SchedulingResources&gt; &amp;cluster_resources</code> 表示。从而根据任务资源需求与节点资源存量的适配情况，进行调度决策。</p>
<p>此外，还有个 <code>SpillOver</code> 方法，其中 <code>Schedule</code> 方法是针对所有状态为   <code>TaskState::PLACEABLE</code> 的任务在<strong>一组节点</strong>中进行决策，所谓<strong>调度</strong>；<code>SpillOver</code> 方法是针对所有状态为 <code>TaskState::INFEASIBLE</code> 和 <code>TaskState::READY</code> 的任务在新加入的<strong>单个节点</strong>进行尝试，所谓挤出。只是后来随着本地资源也可以动态调整，也会在本地资源调整后使用此策略。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SchedulingPolicy</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// 构造函数：拿到本节点所有任务的引用</span></span><br><span class="line">  <span class="built_in">SchedulingPolicy</span>(<span class="type">const</span> SchedulingQueue &amp;scheduling_queue);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 根据集群资源分布以及任务资源需求做调度决策，返回任务与其所调度到的节点的集合</span></span><br><span class="line">  <span class="function">std::unordered_map&lt;TaskID, ClientID&gt; <span class="title">Schedule</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      std::unordered_map&lt;ClientID, SchedulingResources&gt; &amp;cluster_resources,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> ClientID &amp;local_client_id)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 在感知到新节点加入或者本地资源动态调整之后，对原先不可放置的任务进行尝试，并且匀出</span></span><br><span class="line">  <span class="comment">// 至多一个 READY 的任务到新节点。</span></span><br><span class="line">  <span class="function">std::vector&lt;TaskID&gt; <span class="title">SpillOver</span><span class="params">(SchedulingResources &amp;remote_scheduling_resources)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">SchedulingPolicy</span>();</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 任务队列的引用</span></span><br><span class="line">  <span class="type">const</span> SchedulingQueue &amp;scheduling_queue_;</span><br><span class="line">  <span class="comment">/// 一个随机种子</span></span><br><span class="line">  std::mt19937_64 gen_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="Schedule"><a href="#Schedule" class="headerlink" title="Schedule"></a>Schedule</h4><p>对于 <code>Schedule</code> 函数，大概伪码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> task <span class="keyword">in</span> placeable_tasks_list:</span><br><span class="line">  clients = find_all_available_resources_statisfied_clients() <span class="comment"># available not include load</span></span><br><span class="line">  <span class="keyword">if</span> cliens.is_not_empty():</span><br><span class="line">    decision[task] = random_select_one(clients)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    clients = find_all_total_resources_statisfied_clients() <span class="comment"># node whole resource</span></span><br><span class="line">    <span class="keyword">if</span> clients.is_not_empty():</span><br><span class="line">      decision[task] = random_select_one(clients)</span><br><span class="line"><span class="keyword">return</span> decision</span><br></pre></td></tr></table></figure>

<p>其中有两个值得注意的点：</p>
<ol>
<li>对于每个任务，会按次序对所有节点筛选两遍。第一次针对每个节点的 <strong>真正可用</strong> （<code>resources_available_ - resources_load_</code>）资源，第二次是针对节点所有资源（<code>resources_total</code>）。</li>
<li>虽然注释里写着TODO：<strong>按权重进行节点选择</strong>。但是注释过去一年多了，现在代码中的策略仍然是对满足资源要求的节点集合随机选择一个节点，将任务调度过去。我猜其中有个可能的原因是在去中心化的调度决策下，一致性很难保证，随机选择反而能取得更好的性能。举个例子，如果按<strong>空闲资源量作为权重</strong>进行节点选择，如果某个节点加入了，那么剩余节点在调度的时候可能一哄而上的将任务调度到该节点上，造成新加入的很快过载，然后该节点再将过载的任务调度出去，从而来回<strong>拉风车</strong>式调度。</li>
</ol>
<p>其中对于资源增删的操作稍稍复杂一些，贴在这里：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span> &amp;t : scheduling_queue_.<span class="built_in">GetTasks</span>(TaskState::PLACEABLE)) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> &amp;spec = t.<span class="built_in">GetTaskSpecification</span>();</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> &amp;resource_demand = spec.<span class="built_in">GetRequiredPlacementResources</span>();</span><br><span class="line">    <span class="type">const</span> TaskID &amp;task_id = spec.<span class="built_in">TaskId</span>();</span><br><span class="line"></span><br><span class="line">    std::vector&lt;ClientID&gt; client_keys;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span> &amp;client_resource_pair : cluster_resources) &#123;</span><br><span class="line">      ClientID node_client_id = client_resource_pair.first;</span><br><span class="line">      <span class="type">const</span> <span class="keyword">auto</span> &amp;node_resources = client_resource_pair.second;</span><br><span class="line">      ResourceSet available_node_resources = <span class="built_in">ResourceSet</span>(node_resources.<span class="built_in">GetAvailableResources</span>());</span><br><span class="line">      <span class="comment">// 1. 获取节点真正可用资源（resources_available_ - resources_load_）。</span></span><br><span class="line">      available_node_resources.<span class="built_in">SubtractResources</span>(node_resources.<span class="built_in">GetLoadResources</span>());</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 检测资源约束</span></span><br><span class="line">      <span class="keyword">if</span> (resource_demand.<span class="built_in">IsSubset</span>(available_node_resources)) &#123;</span><br><span class="line">        client_keys.<span class="built_in">push_back</span>(node_client_id);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!client_keys.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="comment">// 随机选一个 index</span></span><br><span class="line">      <span class="function">std::uniform_int_distribution&lt;<span class="type">int</span>&gt; <span class="title">distribution</span><span class="params">(<span class="number">0</span>, client_keys.size() - <span class="number">1</span>)</span></span>;</span><br><span class="line">      <span class="type">int</span> client_key_index = <span class="built_in">distribution</span>(gen_);</span><br><span class="line">      <span class="type">const</span> ClientID &amp;dst_client_id = client_keys[client_key_index];</span><br><span class="line">      decision[task_id] = dst_client_id;</span><br><span class="line">      <span class="comment">// 2. 更新对应节点负载资源</span></span><br><span class="line">      <span class="function">ResourceSet <span class="title">new_load</span><span class="params">(cluster_resources[dst_client_id].GetLoadResources())</span></span>;</span><br><span class="line">      new_load.<span class="built_in">AddResources</span>(resource_demand);</span><br><span class="line">      cluster_resources[dst_client_id].<span class="built_in">SetLoadResources</span>(std::<span class="built_in">move</span>(new_load));</span><br><span class="line">    &#125;</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure>



<h3 id="SpillOver"><a href="#SpillOver" class="headerlink" title="SpillOver"></a>SpillOver</h3><p>该函数比较简单，伪码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">spill_over</span>(<span class="params">remote_scheduling_resources</span>):</span><br><span class="line">  decision = []</span><br><span class="line">  new_load = ResourceSet()</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 尝试原先不可放置的任务</span></span><br><span class="line">  <span class="keyword">for</span> task <span class="keyword">in</span> infeasible_task_list:</span><br><span class="line">    <span class="keyword">if</span> task.required_res.is_subset_of(remote_scheduling_resources):</span><br><span class="line">      decision.append(task.<span class="built_in">id</span>)</span><br><span class="line">      new_load.add(task.required_res)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 匀出至多一个 ready 任务</span></span><br><span class="line">  <span class="keyword">for</span> task <span class="keyword">in</span> ready_task_list:</span><br><span class="line">    <span class="keyword">if</span> task.required_res.is_subset_of(remote_scheduling_resources):</span><br><span class="line">      decision.append(task.<span class="built_in">id</span>)</span><br><span class="line">      new_load.add(task.required_res)</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 设置其节点资源负载</span></span><br><span class="line">  remote_scheduling_resources.set_load(new_load)</span><br><span class="line">  <span class="keyword">return</span> decision</span><br></pre></td></tr></table></figure>

<p>该函数<strong>开始时</strong>应对的场景是，当感知到一个新节点上线时，会检测本机的某些任务能不能被调度过去。包括<strong>不可放置的任务</strong>（该节点上线前没有满足该任务资源需求的节点）和<strong>至多一个</strong>准备好的任务，我猜测这么干是为了弥补随机调度的不足，当一个新节点上线时，<strong>其他所有节点都将自己的任务匀给它一个</strong>（这个策略也比较有意思哈），以使得负载相对缓慢的从其他节点转移到新加入的节点。</p>
<p>后来随着版本迭代，节点<strong>静态</strong>资源变成<strong>动态</strong>资源。如果一个节点在启动时，通过配置加载其拥有的资源总量，此后维持不变，是为<strong>静态</strong>；如果在运行时资源总量仍然可设置，则为<strong>动态</strong>。在这种设计下，如果本节点资源总量被重新设置，那么也可能会调用此函数，对不可放置任务进行再尝试。至于匀任务这个操作，在此情景下，其实没什么意义。</p>
<p>最后，不要忘记的是，需要给被调度的节点设置资源负载，进行”占坑”，以使得其他调度决策及时感知到到本次调度所带来的节点资源负载变化。</p>
<h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ol>
<li>逻辑和实现：逻辑表示类对外的抽象；实现表示类在内部的实际组织。</li>
<li>resouce_label&#x2F;resource_name: 或者说资源名称，标记某一种类的资源的标记，比如 GPU，CPU，Memory 等等</li>
<li>ResourceId: 资源标号，给所有资源按照 0, 1, … , n-1 打上标记，以对某个资源进行索引。典型的如 GPU0, GPU1 ..</li>
<li>静态和动态资源：这是针对节点资源总量来说的，如果一个节点在启动时通过配置加载其拥有的资源总量，此后维持不变，是为<strong>静态</strong>；如果在运行时资源总量仍然可设置，则为<strong>动态</strong></li>
</ol>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>Ray</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>Ray</tag>
        <tag>调度策略</tag>
      </tags>
  </entry>
  <entry>
    <title>Python3 生成器（Generator）概念浅析</title>
    <url>/2019/11/03/python3-generator/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/eUrTyHxMR9POsJh.png" alt="python-generator.png"></p>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>某次面试问候选人：Python 中生成器是什么？答曰：有 yield 关键字的函数。而在我印象中此种函数返回的值是生成器，而函数本身不是。如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">def</span> <span class="title function_">get_nums</span>(<span class="params">n</span>): </span><br><span class="line">   ...:     <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): </span><br><span class="line">   ...:         <span class="keyword">yield</span> i </span><br><span class="line">   ...:                                                                                                                                                                  </span><br><span class="line">In [<span class="number">2</span>]: <span class="built_in">type</span>(get_nums)</span><br><span class="line">Out[<span class="number">2</span>]: function</span><br><span class="line">  </span><br><span class="line">In [<span class="number">3</span>]: nums = get_nums(<span class="number">10</span>)   </span><br><span class="line">  </span><br><span class="line">In [<span class="number">4</span>]: <span class="built_in">type</span>(nums)</span><br><span class="line">Out[<span class="number">4</span>]: generator</span><br></pre></td></tr></table></figure>

<p>但看候选人那么笃定，隐隐然感觉哪里不对，于是有了以下探究。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>要弄清楚 Python3 中这些概念的区别，最权威的当然是去看官方的<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9nbG9zc2FyeS5odG1s">术语对照表<i class="fa fa-external-link-alt"></i></span>：</p>
<blockquote>
<p><strong>generator</strong></p>
<p>​	A function which returns a <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9nbG9zc2FyeS5odG1sI3Rlcm0tZ2VuZXJhdG9yLWl0ZXJhdG9y">generator iterator<i class="fa fa-external-link-alt"></i></span>. It looks like a normal function except that it contains 	<a href="https://docs.python.org/3/reference/simple_stmts.html#yield"><code>yield</code></a> expressions for producing a series of values usable in a for-loop or that can be retrieved one  	at a time with the <a href="https://docs.python.org/3/library/functions.html#next"><code>next()</code></a> function.</p>
<p>​	Usually refers to a generator function, but may refer to a <em>generator iterator</em> in some contexts. In cases 	where the intended meaning isn’t clear, using the full terms avoids ambiguity.</p>
<p><strong>generator iterator</strong></p>
<p>​	An object created by a <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9nbG9zc2FyeS5odG1sI3Rlcm0tZ2VuZXJhdG9y">generator<i class="fa fa-external-link-alt"></i></span> function.</p>
<p>​	Each <a href="https://docs.python.org/3/reference/simple_stmts.html#yield"><code>yield</code></a> temporarily suspends processing, remembering the location execution state (including 	local variables and pending try-statements). When the <em>generator iterator</em> resumes, it picks up where it 	left off (in contrast to functions which start fresh on every invocation).</p>
<p><strong>generator expression</strong></p>
<p>​	An expression that returns an iterator. It looks like a normal expression followed by a <code>for</code> clause  defining a loop variable, range, and an optional <code>if</code> clause. </p>
</blockquote>
<p>可以看出，Python generator 相关的概念主要有三个，分别是 <strong>generator</strong>，<strong>generator expression</strong>，<strong>generator iterator</strong>。上面也特别指出了， genrator 在有的上下文中指的是 generator function（如候选人所说），但在另外一些上下文中却指的是 generator iterator（如上面例子解释器告诉我们的）。为了避免歧义，大家在表达时可以尽量说全称。</p>
<p>结合我的一些经验，可以将其归纳为以下三个概念：</p>
<ul>
<li>Generator Function：含有 yield 关键字的<strong>函数</strong>，会返回一系列值，可以使用 next() 对其返回值进行迭代。</li>
<li>Generator Iterator：generator function 返回的<strong>对象</strong>。可以进行一次性地迭代。</li>
<li>Generator Expression：可以求值为 generator iterator 的<strong>表达式</strong>。使用小括号和 for 来定义，如下面例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: a = (i*i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))                                                                                                                                                                                                                                     </span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: <span class="built_in">type</span>(a)                                                                                                                                                                                                                                                          </span><br><span class="line">Out[<span class="number">6</span>]: generator</span><br></pre></td></tr></table></figure>



<h2 id="深入"><a href="#深入" class="headerlink" title="深入"></a>深入</h2><h3 id="生成器-vs-迭代器"><a href="#生成器-vs-迭代器" class="headerlink" title="生成器 vs 迭代器"></a>生成器 vs 迭代器</h3><p>从中文字面可能不好理解它们的关系，但是从上文提到的英文术语来分析：generator iterator。他们的关系就一目了然了：</p>
<blockquote>
<p>迭代器（Iterator）是一种更宽泛的概念，生成器（generator Iterator）是一种迭代器，但反过来不成立。</p>
</blockquote>
<p>迭代器是任何实现了 <code>__next__</code> 方法的<strong>对象</strong>（object），可以通过 <code>next(iterator)</code> 对其进行迭代，迭代结束时会抛出 <code>StopIteration</code> 异常。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    x = <span class="built_in">next</span>(an_iterator)</span><br><span class="line">    do_sth_with(x)</span><br><span class="line">  <span class="keyword">except</span> StopIteration:</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"> </span><br></pre></td></tr></table></figure>

<p>通常我们会使用 <code>for in</code> 来对其进行简化迭代：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> an_iterator:</span><br><span class="line">  do_sth_with(x)</span><br></pre></td></tr></table></figure>

<h3 id="yield-原理"><a href="#yield-原理" class="headerlink" title="yield 原理"></a>yield 原理</h3><p><strong>yield</strong> 是一个神奇的关键字，它会临时挂起当前函数，记下其上下文（包括局部变量、待决的 try catch 等），将控制权返回给函数调用者。当下一次再调用其所在 generator function 时，会恢复保存的上下文，继续执行剩下的语句，直到再遇到 yield 或者退出为止。</p>
<p>我们常见的 <strong>return</strong> 是与之相对的关键字，但 return 会结束函数调用，销毁上下文（弹出栈帧），将控制权返回给调用者。</p>
<p> 因此，以 yield 进行执行流控制的函数称为 generator function，以 return 进行执行流控制的函数，就是普通的 function 喽~</p>
<p>当然，由于可以临时挂起函数的执行，yield 还有更高阶的用法，即充当其调用者和被挂起函数间交互的桥梁：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: <span class="keyword">def</span> <span class="title function_">dynamic_step_seq</span>(<span class="params">size, start=<span class="number">0</span>, default_step=<span class="number">1</span></span>): </span><br><span class="line">    ...:   x = start </span><br><span class="line">    ...:   <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(size): </span><br><span class="line">    ...:     given_step = <span class="keyword">yield</span> x </span><br><span class="line">    ...:     <span class="keyword">if</span> given_step <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: </span><br><span class="line">    ...:       x += given_step </span><br><span class="line">    ...:     <span class="keyword">else</span>: </span><br><span class="line">    ...:       x += default_step </span><br><span class="line">    ...:                                                                                                                                                                                                                                                                 </span><br><span class="line"></span><br><span class="line">In [<span class="number">2</span>]: <span class="keyword">for</span> x <span class="keyword">in</span> dynamic_step_seq(<span class="number">10</span>): </span><br><span class="line">    ...:     <span class="built_in">print</span>(x, end=<span class="string">&#x27; &#x27;</span>) </span><br><span class="line">    ...: <span class="built_in">print</span>()                                                                                                                                                                                                                                                         </span><br><span class="line"><span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span> </span><br><span class="line">In [<span class="number">3</span>]: dss = dynamic_step_seq(<span class="number">10</span>)                                                                                                                                                                                                                                      </span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: <span class="built_in">next</span>(dss) <span class="comment"># 注                                                                                                                                                                                                                                                </span></span><br><span class="line">Out[<span class="number">5</span>]: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: dynamic_step = <span class="number">1</span> </span><br><span class="line">    ...: <span class="keyword">while</span> <span class="literal">True</span>: </span><br><span class="line">    ...:     <span class="keyword">try</span>: </span><br><span class="line">    ...:         x = dss.send(dynamic_step) </span><br><span class="line">    ...:         dynamic_step += <span class="number">1</span> </span><br><span class="line">    ...:         <span class="built_in">print</span>(x, end=<span class="string">&#x27; &#x27;</span>) </span><br><span class="line">    ...:     <span class="keyword">except</span> StopIteration: </span><br><span class="line">    ...:         <span class="built_in">print</span>() </span><br><span class="line">    ...:         <span class="keyword">break</span> </span><br><span class="line">    ...:                                                                                                                                                                                                                                                                 </span><br><span class="line"><span class="number">1</span> <span class="number">3</span> <span class="number">6</span> <span class="number">10</span> <span class="number">15</span> <span class="number">21</span> <span class="number">28</span> <span class="number">36</span> <span class="number">45</span> </span><br><span class="line">  </span><br></pre></td></tr></table></figure>

<p><strong>注</strong>：此处初看有些奇怪，但是通过 yield 作用我们能推断出原理：需要首先调用 next 将函数运行至 yield 处，才能通过 <code>generator.send</code> 给 generator 传送对象。</p>
<h2 id="效用"><a href="#效用" class="headerlink" title="效用"></a>效用</h2><p>那么使用生成器有什么好处呢？简单来说，主要有两大好处：</p>
<ul>
<li>精简代码</li>
<li>提高性能</li>
</ul>
<h3 id="精简代码"><a href="#精简代码" class="headerlink" title="精简代码"></a>精简代码</h3><p>使用 yield 关键字或者生成器表达式可以很方便的生成一个迭代器对象。为了说明这一点，我们来比较一下对于一个需求的不同实现。该需求很简单：获取前 n 个自然数。</p>
<p>最直观的方法为，构造一个数组然后返回：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Build and return a list</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">firstn</span>(<span class="params">n</span>):</span><br><span class="line">    num, nums = <span class="number">0</span>, []</span><br><span class="line">    <span class="keyword">while</span> num &lt; n:</span><br><span class="line">        nums.append(num)</span><br><span class="line">        num += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> nums</span><br><span class="line"></span><br><span class="line">sum_of_first_n = <span class="built_in">sum</span>(firstn(<span class="number">1000000</span>))</span><br></pre></td></tr></table></figure>

<p>当 n 很小的时候，该实现没有什么问题，但是当 n 变得很大，你的机器内存是吃不消的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">4</span>]: a = firstn(<span class="number">10000000000000000000</span>)                                                                                                                                                                                                                                 </span><br><span class="line">Killed</span><br></pre></td></tr></table></figure>

<p>IPython 直接内存爆掉被 kill 了。</p>
<p>于是，我们很自然的想起可以用<strong>生成器模式</strong>，但是你仍然不想用 yield，于是你需要构造一个对象，并实现<code> __iter__</code> 和 <code>__next__ </code>方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Using the generator pattern (an iterable)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">firstn</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n</span>):</span><br><span class="line">        self.n = n</span><br><span class="line">        self.num, self.nums = <span class="number">0</span>, []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__next__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.num &lt; self.n:</span><br><span class="line">            cur, self.num = self.num, self.num+<span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> cur</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> StopIteration()</span><br><span class="line"></span><br><span class="line">sum_of_first_n = <span class="built_in">sum</span>(firstn(<span class="number">1000000</span>))</span><br></pre></td></tr></table></figure>

<p><strong>注</strong>：在 Python3 中，如果你的类实现了<code>__iter__</code> ，则成为一个可迭代对象，可以调用 <strong>iter</strong>(instance) 得到一个迭代器。如果你的类实现了 <code>__next__</code>，那么你的类实例本身就成为了一个迭代器，可以通过 <strong>next</strong>(instance) 来调用，进行迭代。</p>
<p>这些代码终于实现了我们的要求。但是，它有如下问题：</p>
<ol>
<li>为了实现一个简单的需求却不得不构造冗长的代码。</li>
<li>使用了很多语言约定，读起来不直观。</li>
<li>逻辑表达的绕来绕去。</li>
</ol>
<p>于是，你忍不住了，终于使用了 yield：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># a generator that yields items instead of returning a list</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">firstn</span>(<span class="params">n</span>):</span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> num &lt; n:</span><br><span class="line">        <span class="keyword">yield</span> num</span><br><span class="line">        num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">sum_of_first_n = <span class="built_in">sum</span>(firstn(<span class="number">1000000</span>))</span><br></pre></td></tr></table></figure>

<p>于是你使用了寥寥几行，构造出了一个生成器函数。</p>
<p>其实[坏笑]，Python 3 中，就有该函数： <code>range(n)</code>。</p>
<p>利用此函数以及 Iterator expression，你可以用很紧凑的代码构造出很多<strong>迭代数列</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">squares = (x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n))</span><br><span class="line">evens = (<span class="number">2</span> * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n))</span><br></pre></td></tr></table></figure>

<p>注意，他们都只能迭代一次。</p>
<h3 id="提高性能"><a href="#提高性能" class="headerlink" title="提高性能"></a>提高性能</h3><p>这一条主要是针对内存使用上来说的。因为迭代器不会保存所有值，而是在运行中动态的计算出数列的各个值，并将之前的数值扔掉，因此是很省内存的，这点在前面的例子也有体现。这里举另外一个更实际一点例子。</p>
<p>假设我们有一个很大的文件（比如说 8G） ，但是你的电脑只有 4G 内存，你如何利用 Python 对其进行处理？</p>
<p>答案是使用 yield 构造 generator Iterator：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_by_chunks</span>(<span class="params">file, chunk_size=<span class="number">1024</span></span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = file.read(chunk_size)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">yield</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;your_big_file.dat&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> read_by_chunks(f):</span><br><span class="line">    process_chunk(chunk)</span><br></pre></td></tr></table></figure>

<p>这种通过构造 generator 逐块读取的方法又叫<strong>惰性加载</strong>，也叫<strong>流式读取</strong>，是处理大文件的一种常见方式。如果你的是文本文件，可以按行读取，那代码就更简单了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;your_big_file.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f: </span><br><span class="line">        process_line(line)</span><br></pre></td></tr></table></figure>

<p>Python3 文件类句柄就是一个迭代器，默认会将文件按行分割以惰性加载。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><p>Python 3 术语对照表：<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvMy9nbG9zc2FyeS5odG1s">https://docs.python.org/3/glossary.html<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>Python 3 wiki：<span class="exturl" data-url="aHR0cHM6Ly93aWtpLnB5dGhvbi5vcmcvbW9pbi9HZW5lcmF0b3Jz">https://wiki.python.org/moin/Generators<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>Iterator vs Iterable: <span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvNTIwNTYxNDYvc2VwYXJhdGluZy10aGUtaXRlci1hbmQtbmV4dC1tZXRob2RzLzUyMDU2Mjkw">https://stackoverflow.com/questions/52056146/separating-the-iter-and-next-methods/52056290<i class="fa fa-external-link-alt"></i></span> </p>
</li>
<li><p>Lazy read big file：<span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvNTE5NjMzL2xhenktbWV0aG9kLWZvci1yZWFkaW5nLWJpZy1maWxlLWluLXB5dGhvbg==">https://stackoverflow.com/questions/519633/lazy-method-for-reading-big-file-in-python<i class="fa fa-external-link-alt"></i></span></p>
</li>
</ol>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>generator</tag>
        <tag>生成器</tag>
        <tag>iterator</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法（三）：拆分二叉搜索树</title>
    <url>/2019/10/26/split-bst/</url>
    <content><![CDATA[<h2 id="小引"><a href="#小引" class="headerlink" title="小引"></a>小引</h2><p>二叉树（Binary Tree）是数据结构中很好玩的一种，可以把玩的地方非常之多。而二叉搜索树（Binary  Serach Tree，下面简称 BST，当然也有叫二叉查找树、查找二叉树等等）又是其中常用的一种，它有很多有趣的<strong>性质</strong>：</p>
<ol>
<li>左皆小，右皆大。</li>
<li>中序遍历有序。</li>
<li>投影升序。</li>
</ol>
<p>当然，加上<strong>平衡</strong>会引入更多的特性，这里先按下不表。今天先从个小题入手把玩一番。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="入题"><a href="#入题" class="headerlink" title="入题"></a>入题</h2><p>给定一个二叉搜索树 <em>t</em> （树中没有相同值的节点）以及其中的一个节点的值 <em>val</em>，请以 <em>val</em> 为界，将 <em>t</em> 拆为两棵新的二叉树 <em>s</em> 和 <em>l</em>，要求：</p>
<ol>
<li><em>val</em> 扔掉即可。</li>
<li>树 <em>s</em> 和 <em>l</em> 仍然是二叉排序树。</li>
<li>树 <em>s</em> 值皆小于 <em>val</em> ，树 <em>l</em> 值皆大于 <em>val</em>。</li>
<li><em>s</em> 和 <em>l</em> 须为原地（in-place）拆解，不能重新构造。</li>
</ol>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>一般我们一上来的思路是这样的：</p>
<blockquote>
<p>先利用搜索树的性质，找到这个节点 val  –&gt;  这个点不要了，其左子树肯定放 s 中，右子树肯定放 l 中 –&gt; 再考虑其父节点，如果其父节点是节点就好说了，balala </p>
</blockquote>
<p>那如果父节点不是根节点呢？如果在很深的地方呢？没有父指针你如何进行回溯呢？</p>
<p>一般人面对三连问，直接就懵逼了。</p>
<h3 id="一个简单解法"><a href="#一个简单解法" class="headerlink" title="一个简单解法"></a>一个简单解法</h3><p>解法其实很简单，将思维逆向一下即可。即，我们仍是要寻找该节点，但是不是最后才思考拆分树，而是在找该节点的时候边找边拆分。即：</p>
<ol>
<li>从根节点二分查找 val，会形成一条查找路径。</li>
<li>对于该路径上的节点 a：<ol>
<li>如果 a &gt; val，则 a 连同其右子树都大于 val。</li>
<li>如果 a &lt; val，则 a 连同其右子树都小于 val。</li>
<li>如果 a &#x3D;&#x3D; val（即找到该点），则其左子树小于 val，右子树大于 val。</li>
</ol>
</li>
<li>自根向下，每次切分路径上一节点，连带相应分支。找到该节点时，分别切分下其左右分支。</li>
</ol>
<p>即得到所有大于 val 的分支集合，和所有小于 val 的分支集合，val 被扔掉。</p>
<p>如下图，寻找树中 <strong>val &#x3D; 11</strong> 节点示意图。</p>
<p><img src="https://i.loli.net/2020/02/09/UyimaLw1FGVnBuS.jpg" alt="bst-split"></p>
<p>下一个问题是，如何将切下来的树枝合到一块得到结果？</p>
<p>易证明（同学们可以思考一下），<strong>同侧切下来的“分枝”，都是可以通过“切口”合在一块</strong>。如上图中以 10 为根的分支可以合到 8 的右枝。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>最近写 Python 多，而且 Python 表达比较简洁：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> typing <span class="keyword">as</span> T</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TreeNode</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, val: <span class="built_in">int</span>, left: <span class="string">&#x27;TreeNode&#x27;</span> = <span class="literal">None</span>, right: <span class="string">&#x27;TreeNode&#x27;</span> = <span class="literal">None</span></span>):</span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_bst</span>(<span class="params">root: TreeNode, target: <span class="built_in">int</span></span>) -&gt; T.<span class="type">Tuple</span>[TreeNode, TreeNode]:</span><br><span class="line">    small_root, large_root = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> small_root, large_root</span><br><span class="line"></span><br><span class="line">    small_root, large_root = TreeNode(<span class="number">0</span>), TreeNode(<span class="number">0</span>) <span class="comment"># dummy root</span></span><br><span class="line">    small_tmp, large_tmp = small_root, large_root</span><br><span class="line"></span><br><span class="line">    curr = root</span><br><span class="line">    <span class="keyword">while</span> curr.val != target:</span><br><span class="line">        <span class="comment"># curr root with left branch is small than target</span></span><br><span class="line">        <span class="keyword">if</span> curr.val &lt; target:</span><br><span class="line">            small_tmp.right = curr</span><br><span class="line">            small_tmp = curr</span><br><span class="line">            curr = curr.right</span><br><span class="line">        <span class="comment"># curr root with right branch is larger than target</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            large_tmp.left = curr</span><br><span class="line">            large_tmp = curr</span><br><span class="line">            curr = curr.left</span><br><span class="line"></span><br><span class="line">    small_tmp.right = curr.left</span><br><span class="line">    large_tmp.left = curr.right</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> small_root.right, large_root.left</span><br></pre></td></tr></table></figure>

<p>为了验证这段代码的正确性，给出构造搜索二叉树、验证搜索二叉树和打印二叉树的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给出上下边界，折半构造。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">construct_bst</span>(<span class="params">start: <span class="built_in">int</span>, end: <span class="built_in">int</span></span>) -&gt; TreeNode:</span><br><span class="line">    <span class="keyword">if</span> start &gt; end:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> start == end:</span><br><span class="line">        <span class="keyword">return</span> TreeNode(start)</span><br><span class="line"></span><br><span class="line">    mid = (start+ end) // <span class="number">2</span></span><br><span class="line">    root = TreeNode(mid)</span><br><span class="line">    root.left = construct_bst(start, mid-<span class="number">1</span>)</span><br><span class="line">    root.right = construct_bst(mid+<span class="number">1</span>, end)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用中序遍历有序的性质</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">valid_bst</span>(<span class="params">root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    prev: TreeNode = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">valid</span>(<span class="params">curr: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> curr <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> valid(curr.left):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">nonlocal</span> prev</span><br><span class="line">        <span class="keyword">if</span> prev <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> prev.val &gt; curr.val:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        prev = curr</span><br><span class="line">        <span class="keyword">return</span> valid(curr.right)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> valid(root)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逆中序遍历，空格个数 = 层深 * factor</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_tree</span>(<span class="params">root: TreeNode</span>):</span><br><span class="line">    SPACING = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_util</span>(<span class="params">curr: TreeNode, space: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">if</span> curr <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        space += SPACING</span><br><span class="line">        print_util(curr.right, space)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; &#x27;</span> * space, curr.val)</span><br><span class="line">        print_util(curr.left, space)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Empty Tree&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print_util(root, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    t = construct_bst(<span class="number">1</span>, <span class="number">15</span>)</span><br><span class="line">    print_tree(t)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;above tree is bst:&#x27;</span>, valid_bst(t))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> split_point <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">11</span>):</span><br><span class="line">        t = construct_bst(<span class="number">0</span>, <span class="number">16</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>*<span class="number">50</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;current split point is&#x27;</span>, split_point)</span><br><span class="line">        s, l = split_bst(t, split_point)</span><br><span class="line">        print_tree(s)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;above tree is bst:&#x27;</span>, valid_bst(s))</span><br><span class="line">        print_tree(l)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;above tree is bst:&#x27;</span>, valid_bst(l))</span><br></pre></td></tr></table></figure>

<p>其中打印二叉树的实现是侧着打印，每一行输出一个值，每一列同属一层，算是一种 tricky 的简易打印方法（想想为什么）。可以歪着脑袋看:)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 截取两个典型结果：</span></span><br><span class="line">current split point <span class="keyword">is</span> <span class="number">8</span></span><br><span class="line">             <span class="number">7</span></span><br><span class="line">          <span class="number">6</span></span><br><span class="line">       <span class="number">5</span></span><br><span class="line">          <span class="number">4</span></span><br><span class="line">    <span class="number">3</span></span><br><span class="line">          <span class="number">2</span></span><br><span class="line">       <span class="number">1</span></span><br><span class="line">          <span class="number">0</span></span><br><span class="line">above tree <span class="keyword">is</span> bst: <span class="literal">True</span></span><br><span class="line">             <span class="number">16</span></span><br><span class="line">          <span class="number">15</span></span><br><span class="line">       <span class="number">14</span></span><br><span class="line">          <span class="number">13</span></span><br><span class="line">    <span class="number">12</span></span><br><span class="line">          <span class="number">11</span></span><br><span class="line">       <span class="number">10</span></span><br><span class="line">          <span class="number">9</span></span><br><span class="line">above tree <span class="keyword">is</span> bst: <span class="literal">True</span></span><br><span class="line">==============================</span><br><span class="line">current split point <span class="keyword">is</span> <span class="number">9</span></span><br><span class="line">    <span class="number">8</span></span><br><span class="line">                <span class="number">7</span></span><br><span class="line">             <span class="number">6</span></span><br><span class="line">          <span class="number">5</span></span><br><span class="line">             <span class="number">4</span></span><br><span class="line">       <span class="number">3</span></span><br><span class="line">             <span class="number">2</span></span><br><span class="line">          <span class="number">1</span></span><br><span class="line">             <span class="number">0</span></span><br><span class="line">above tree <span class="keyword">is</span> bst: <span class="literal">True</span></span><br><span class="line">             <span class="number">16</span></span><br><span class="line">          <span class="number">15</span></span><br><span class="line">       <span class="number">14</span></span><br><span class="line">          <span class="number">13</span></span><br><span class="line">    <span class="number">12</span></span><br><span class="line">          <span class="number">11</span></span><br><span class="line">       <span class="number">10</span></span><br><span class="line">above tree <span class="keyword">is</span> bst: <span class="literal">True</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构</category>
        <category>algorithms</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>algorithms</tag>
        <tag>BST</tag>
      </tags>
  </entry>
  <entry>
    <title>继Spark之后，UC Berkeley 推出新一代AI计算引擎——Ray</title>
    <url>/2019/04/06/ray/</url>
    <content><![CDATA[<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><p>继 Spark 之后，UC Berkeley AMP 实验室又推出一重磅高性能AI计算引擎——Ray，号称支持每秒数百万次任务调度。那么它是怎么做到的呢？在试用之后，简单总结一下：</p>
<ol>
<li><em><strong>极简 Python API 接口</strong></em>：在函数或者类定义时加上  <code>ray.remote</code>  的装饰器并做一些微小改变，就能将单机代码变为分布式代码。这意味着不仅可以远程执行<strong>纯函数</strong>，还可以远程注册一个类（<strong>Actor模型</strong>），在其中维护大量context（成员变量），并远程调用其成员方法来改变这些上下文。</li>
<li><em><strong>高效数据存储和传输</strong></em>：每个节点上通过<strong>共享内存</strong>（多进程访问无需拷贝）维护了一块局部的<strong>对象存储</strong>，然后利用专门优化过的 <strong>Apache Arrow</strong>格式来进行不同节点间的数据交换。</li>
<li><em><strong>动态图计算模型</strong></em>：这一点得益于前两点，将远程调用返回的 future 句柄传给其他的远程函数或者角色方法，即通过远程函数的嵌套调用构建复杂的计算拓扑，并基于对象存储的<strong>发布订阅</strong>模式来进行动态触发执行。</li>
<li><em><strong>全局状态维护</strong></em>：将全局的控制状态（而非数据）利用 Redis 分片来维护，使得其他组件可以方便的进行平滑扩展和错误恢复。当然，每个 redis 分片通过 <strong>chain-replica</strong> 来避免单点。</li>
<li><em><strong>两层调度架构</strong></em>：分本地调度器和全局调度器；任务请求首先被提交到本地调度器，本地调度器会尽量在本地执行任务，以减少网络开销。在资源约束、数据依赖或者负载状况不符合期望时，会转给全局调度器来进行全局调度。</li>
</ol>
<p>当然，还有一些需要优化的地方，比如 Job 级别的封装（以进行多租户资源配给），待优化的垃圾回收算法（针对对象存储，现在只是粗暴的 LRU），多语言支持（最近支持了Java，但不知道好不好用）等等。但是瑕不掩瑜，其<em><strong>架构设计</strong></em>和<em><strong>实现思路</strong></em>还是有很多可以借鉴的地方。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="动机和需求"><a href="#动机和需求" class="headerlink" title="动机和需求"></a>动机和需求</h2><p>（<em>开发 Ray 的动机始于<strong>强化学习（RL）</strong>，但是由于其计算模型强大表达能力，使用绝不限于 RL。这一小节是以描述 RL 系统需求为契机，引出 Ray 的初始设计方向。但是由于不大熟悉强化学习，一些名词可能表达翻译不准确。如果只对其架构感兴趣，完全可以跳过这一节</em>）</p>
<p><img src="https://i.loli.net/2020/02/09/3WdenGAt7vhRkKL.png" alt="RL system example"></p>
<p><em>图1：一个 RL 系统的例子</em></p>
<p>我们从考虑 RL 系统的基本组件开始，逐渐完善 Ray 的需求。如<em>图1</em>所示，在一个 RL 系统的的设定中，<em>智能体（agent）</em>会反复与<em>环境（environment）</em>进行交互。智能体的目标是学习出一种最大化<em>奖励（reward）</em>的策略。<em>策略（policy）</em>本质上是从环境中状态到<em>行为抉择（action）</em>的一种映射。至于环境，智能体，状态，行为和奖励值的详细定义，则是由具体的应用所决定的。</p>
<p>为了学习策略，智能体通常要进行两步操作：1）<em>策略评估（policy evaluation）</em>和 2）<em>策略优化（policy improvement）</em>。为了评估一个策略，智能体和环境持续进行交互（一般是仿真的环境）以产生<em>轨迹（trajectories）</em>。轨迹是在当前环境和给定策略下产生的一个二元组（状态，奖励值）序列。然后，智能体根据这些轨迹来反馈优化该策略，即，向最大化奖励值的梯度方向更新策略。<em>图2</em>展示了智能体用来学习策略一个例子的伪码。该伪码通过调用 <code>rollout(environment, policy)</code> 来评估策略，进而产生仿真轨迹。<code>train_policy()</code> 接着会用这些轨迹作为输入，调用 <code>policy.update(trajectories)</code> 来优化当前策略。会重复迭代这个过程直到策略收敛。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// evaluate policy by interacting with env. (e.g., simulator) </span></span><br><span class="line">rollout(policy, environment):</span><br><span class="line">    trajectory = []</span><br><span class="line">    state = environment.initial_state()</span><br><span class="line">    <span class="keyword">while</span> (not environment.has_terminated()):</span><br><span class="line">        action = policy.compute(state) <span class="comment">// Serving</span></span><br><span class="line">        state, reward = environment.step(action) <span class="comment">// Simulation </span></span><br><span class="line">        trajectory.append(state, reward)</span><br><span class="line">    <span class="keyword">return</span> trajectory</span><br><span class="line">    </span><br><span class="line"><span class="comment">// improve policy iteratively until it converges </span></span><br><span class="line">train_policy(environment):</span><br><span class="line">    policy = initial_policy()</span><br><span class="line">    <span class="keyword">while</span> (policy has not converged):</span><br><span class="line">        trajectories = [] </span><br><span class="line">        <span class="keyword">for</span> i from <span class="number">1</span> to k:</span><br><span class="line">            <span class="comment">// evaluate policy by generating k rollouts </span></span><br><span class="line">            trajectories.append(rollout(policy, environment)) </span><br><span class="line">            <span class="comment">// improve policy</span></span><br><span class="line">            policy = policy.update(trajectories) <span class="comment">// Training </span></span><br><span class="line">    <span class="keyword">return</span> policy</span><br></pre></td></tr></table></figure>

<p><em>图2：一段用于学习策略的典型的伪代码</em></p>
<p>由此看来，针对 RL 应用的计算框架需要高效的支持模型训练（training），<em>在线预测（serving）</em>和<em>平台仿真（simulation）</em>（如图1所示）。接下来，我们简要说明一下这些工作负载（workloads）。</p>
<p><em>模型训练</em>一般会涉及到在分布式的环境中跑随机梯度下降模型（stochastic gradient descent，SGD）来更新策略。而分布式 SGD 通常依赖于 allreduce 聚合步骤或参数服务器（parameter server）.</p>
<p><em>在线预测</em> 使用已经训练好的策略并基于当前环境来给出动作决策。预测系统通常要求降低预测延迟，提高决策频次。为了支持扩展，最好能够将负载均摊到多节点上来协同进行预测。</p>
<p>最后，大多数现存的 RL 应用使用<em>仿真（simulations）</em> 来对策略进行评估——因为现有的 RL 算法不足以单独依赖从与物理世界的交互中高效的进行取样。这些仿真器在复杂度上跨度极大。也许只需要几毫秒（如模拟国际象棋游戏中的移动），也许会需要几分钟（如为了一个自动驾驶的车辆模拟真实的环境）。</p>
<p>与模型训练和在线预测可以在不同系统中进行处理的监督学习相比， RL 中<em>所有三种工作负载都被紧耦合在了单个应用中</em>，并且对不同负载间的延迟要求很苛刻。现有的系统中还没有能同时支持三种工作负载的。理论上，可以将多个专用系统组合到一块来提供所有能力，但实际上，子系统间的结果传输的延迟在 RL 下是不可忍受的。因此，RL 的研究人员和从业者不得不针对每个需求单独构建多套一次性的专用系统。</p>
<p>这些现状要求为 RL 开发全新的分布式框架，可以有效地支持训练，预测和仿真。尤其是，这样的框架应具有以下能力：</p>
<p><em>支持细粒度，异构的计算</em>。RL 计算的运行持续时间往往从数毫秒（做一个简单的动作）到数小时（训练一个复杂的策略）。此外，模型训练通常需要各种异构的硬件支持（如CPU，GPU或者TPU）。</p>
<p><em>提供灵活的计算模型</em>。RL 应用同时具有有状态和无状态类型的计算。无状态的计算可以在系统中的任何节点进行执行，从而可以方便的进行负载均衡和按需的数据传输。因此，无状态的计算非常适合细粒度的仿真和数据处理，例如从视频或图片中提取特征。相比之下，有状态的计算适合用来实现参数服务器、在支持 GPU 运算的数据上进行重复迭代或者运行不暴露内部状态参数的第三方仿真器。</p>
<p><em>动态的执行能力</em>。RL 应用中的很多模块要求动态的进行执行，因为他们计算完成的顺序并不总是预先确定（例如：仿真的完成顺序），并且，一个计算的运行结果可以决定是否执行数个将来的计算（如，某个仿真的运行结果将决定我们是否运行更多的仿真）。</p>
<p>除此之外，我们提出了两个额外的要求。首先，为了高效的利用大型集群，框架必须支持<em>每秒钟数百万次的任务调度</em>。其次，框架不是为了支持从头开始实现深度神经网络或者复杂的仿真器，而是必须和现有的仿真器（OpenAI gym等）和深度学习框架（如TensorFlow，MXNet，Caffe， PyTorch）无缝集成。</p>
<h2 id="语言和计算模型"><a href="#语言和计算模型" class="headerlink" title="语言和计算模型"></a>语言和计算模型</h2><p>Ray 实现了动态任务图计算模型，即，Ray 将应用建模为一个在运行过程中动态生成依赖的任务图。在此模型之上，Ray 提供了角色模型（Actor）和并行任务模型（task-parallel）的编程范式。Ray 对混合计算范式的支持使其有别于与像 <span class="exturl" data-url="aHR0cDovL3d3dy5jcy5wcmluY2V0b24uZWR1L2NvdXJzZXMvYXJjaGl2ZS9mYWxsMTMvY29zNTE4L3BhcGVycy9jaWVsLnBkZg==">CIEL<i class="fa fa-external-link-alt"></i></span> 一样只提供并行任务抽象和像 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RvdG5ldC9vcmxlYW5z">Orleans<i class="fa fa-external-link-alt"></i></span> 或 <span class="exturl" data-url="aHR0cHM6Ly9ha2thLmlvLw==">Akka<i class="fa fa-external-link-alt"></i></span> 一样只提供角色模型抽象的系统。</p>
<h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><p><strong>任务模型（Tasks）</strong>。一个<em>任务</em>表示一个在无状态工作进程执行的远程函数（remote function）。当一个远程函数被调用的时候，表示任务结果的 <em><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvRnV0dXJlJUU0JUI4JThFcHJvbWlzZQ==">future<i class="fa fa-external-link-alt"></i></span></em> 会立即被返回（也就是说所有的远程函数调用都是异步的，调用后会立即返回一个任务句柄）。可以将 Futures传给 <code>ray.get()</code>  以阻塞的方式获取结果，也可以将 Futures 作为参数传给其他远程函数，以非阻塞、事件触发的方式进行执行（后者是构造动态拓扑图的精髓）。Futures 的这两个特性让用户在构造并行任务的同时指定其依赖关系。下表是 Ray 的所有 API（相当简洁而强大，但是实现起来会有很多坑，毕竟所有装饰有 <code>ray.remote</code> 的函数或者类及其上下文都要序列化后传给远端节点，序列化用的和 PySpark 一样的 cloudpickle）。</p>
<table>
<thead>
<tr>
<th>Name</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td><em>futures</em> &#x3D; f.remote(<em>args</em>)</td>
<td align="left">Execute function <em>f</em> remotely. f.remote() can take objects or futures as inputs and returns one or more futures. This is non-blocking.</td>
</tr>
<tr>
<td><em>objects</em> &#x3D; ray.get(<em>futures</em>)</td>
<td align="left">Return the values associated with one or more futures. This is blocking.</td>
</tr>
<tr>
<td><em>ready futures</em> &#x3D; ray.wait(<em>futures</em>, <em>k</em>, <em>timeout</em>)</td>
<td align="left">Return the futures whose corresponding tasks have completed as soon as either <em>k</em> have completed or the timeout expires.</td>
</tr>
<tr>
<td><em>actor</em> &#x3D; Class.remote(<em>args</em>)<br/><em>futures</em> &#x3D; <em>actor</em>.method.remote(<em>args</em>)</td>
<td align="left">Instantiate class <em>Class</em> as a remote actor, and return a handle to it. Call a method on the remote actor and return one or more futures. Both are non-blocking.</td>
</tr>
</tbody></table>
<p><em>表1 Ray API</em></p>
<p>远程函数作用于不可变的物体上，并且应该是无状态的并且没有副作用的：这些函数的输出仅取决于他们的输入（<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3poLWhhbnMvJUU3JUJBJUFGJUU1JTg3JUJEJUU2JTk1JUIw">纯函数<i class="fa fa-external-link-alt"></i></span>）。这意味着幂等性（<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvSWRlbXBvdGVuY2U=">idempotence<i class="fa fa-external-link-alt"></i></span>），获取结果出错时只需要重新执行该函数即可，从而简化容错设计。</p>
<p><strong><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU4JUE3JTkyJUU4JTg5JUIyJUU2JUE4JUExJUU1JTlFJThC">角色模型<i class="fa fa-external-link-alt"></i></span>（Actors）</strong>。一个<em>角色对象</em>代表一个有状态的计算过程。每个角色对象暴露了一组可以被远程调用，并且按调用顺序依次执行的成员方法（即在同一个角色对象内是串行执行的，以保证角色状态正确的进行更新）。一个角色方法的执行过程和普通任务一样，也会在远端（每个角色对象会对应一个远端进程）执行并且立即返回一个 future；但不同的是，角色方法会运行在一个<em>有状态（stateful）</em>的工作进程上。一个角色对象的<em>句柄（handle）</em>可以传递给其他角色对象或者远程任务，从而使他们能够在该角色对象上调用这些成员函数。</p>
<table>
<thead>
<tr>
<th align="center">Tasks</th>
<th align="center">Actors</th>
</tr>
</thead>
<tbody><tr>
<td align="center">细粒度的负载均衡</td>
<td align="center">粗粒度的负载均衡</td>
</tr>
<tr>
<td align="center">支持对象的局部性（对象存储cache）</td>
<td align="center">比较差的局部性支持</td>
</tr>
<tr>
<td align="center">微小更新开销很高</td>
<td align="center">微小更新开销不大</td>
</tr>
<tr>
<td align="center">高效的错误处理</td>
<td align="center">检查点（checkpoint）恢复带来较高开销</td>
</tr>
</tbody></table>
<p><em>表2 任务模型 vs. 角色模型的对比</em></p>
<p><em>表2</em> 比较了任务模型和角色模型在不同维度上的优劣。任务模型利用<em>集群节点的负载信息</em>和<em>依赖数据的位置信息</em>来实现细粒度的负载均衡，即每个任务可以被调度到存储了其所需参数对象的空闲节点上；并且不需要过多的额外开销，因为不需要设置检查点和进行中间状态的恢复。与之相比，角色模型提供了极高效的细粒度的更新支持，因为这些更新作用在内部状态（即角色成员变量所维护的上下文信息）而非外部对象（比如远程对象，需要先同步到本地）。后者通常来说需要进行序列化和反序列化（还需要进行网络传输，因此往往很费时间）。例如，角色模型可以用来实现参数服务器（<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MuY211LmVkdS9+bXVsaS9maWxlL3BhcmFtZXRlcl9zZXJ2ZXJfb3NkaTE0LnBkZg==">parameter servers<i class="fa fa-external-link-alt"></i></span>）和基于GPU 的迭代式计算（如训练）。此外，角色模型可以用来包裹第三方仿真器（simulators）或者其他难以序列化的对象（比如某些模型）。</p>
<p>为了满足异构性和可扩展性，我们从三个方面增强了 API 的设计。首先，为了处理长短不一的并发任务，我们引入了 <code>ray.wait()</code> ，它可以等待前 k 个结果满足了就返回；而不是像 <code>ray.get()</code> 一样，必须等待所有结果都满足后才返回。其次，为了处理对不同资源纬度（ resource-heterogeneous）需求的任务，我们让用户可以指定所需资源用量（例如装饰器：<code>ray.remote(gpu_nums=1)</code>），从而让调度系统可以高效的管理资源（即提供一种交互手段，让调度系统在调度任务时相对不那么盲目）。最后，为了提灵活性，我们允许构造<em>嵌套远程函数（nested remote functions）</em>，意味着在一个远程函数内可以调用另一个远程函数。这对于获得高扩展性是至关重要的，因为它允许多个进程以分布式的方式相互调用（这一点是很强大的，通过合理设计函数，可以使得可以并行部分都变成远程函数，从而提高并行性）。</p>
<h3 id="计算模型"><a href="#计算模型" class="headerlink" title="计算模型"></a>计算模型</h3><p>Ray 采用的动态图计算模型，在该模型中，当输入可用（即任务依赖的所有输入对象都被同步到了任务所在节点上）时，远程函数和角色方法会自动被触发执行。在这一小节，我们会详细描述如何从一个用户程序（<em>图3</em>）来构建计算图（<em>图4</em>）。该程序使用了<em>表1</em> 的API 实现了<em>图2</em> 的伪码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_policy</span>():</span><br><span class="line"><span class="comment"># Initialize the policy randomly. return policy</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote(<span class="params">num_gpus=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Simulator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">  <span class="comment"># Initialize the environment. self.env = Environment()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rollout</span>(<span class="params">self, policy, num_steps</span>):</span><br><span class="line">      observations = []</span><br><span class="line">      observation = self.env.current_state()</span><br><span class="line">      <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_steps):</span><br><span class="line">        action = policy(observation)</span><br><span class="line">        observation = self.env.step(action)</span><br><span class="line">        observations.append(observation)</span><br><span class="line">      <span class="keyword">return</span> observations</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote(<span class="params">num_gpus=<span class="number">2</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update_policy</span>(<span class="params">policy, *rollouts</span>):</span><br><span class="line">  <span class="comment"># Update the policy.</span></span><br><span class="line">  <span class="keyword">return</span> policy</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_policy</span>():</span><br><span class="line">  <span class="comment"># Create a policy.</span></span><br><span class="line">  policy_id = create_policy.remote()</span><br><span class="line">  <span class="comment"># Create 10 actors.</span></span><br><span class="line">  simulators = [Simulator.remote() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)] <span class="comment"># Do 100 steps of training.</span></span><br><span class="line">  <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">      <span class="comment"># Perform one rollout on each actor.</span></span><br><span class="line">      rollout_ids = [s.rollout.remote(policy_id)</span><br><span class="line">                     <span class="keyword">for</span> s <span class="keyword">in</span> simulators]</span><br><span class="line">      <span class="comment"># Update the policy with the rollouts.</span></span><br><span class="line">      policy_id =</span><br><span class="line">          update_policy.remote(policy_id, *rollout_ids)</span><br><span class="line">   <span class="keyword">return</span> ray.get(policy_id)</span><br></pre></td></tr></table></figure>

<p><em>图3：在 Ray 中实现图2逻辑的代码，注意装饰器  @ray.remote 会将被注解的方法或类声明为远程函数或者角色对象。调用远程函数或者角色方法后会立即返回一个 future 句柄，该句柄可以被传递给随后的远程函数或者角色方法，以此来表达数据间的依赖关系。每个角色对象包含一个环境对象  self.env ，这个环境状态为所有角色方法所共享。</em></p>
<p>在不考虑角色对象的情况下，在一个计算图中有两种类型的点：数据对象（data objects）和远程函数调用（或者说任务）。同样，也有两种类型的边：数据边（data edges）和控制边（control edges）。数据边表达了数据对象任务间的依赖关系。更确切来说，如果数据对象 <em>D</em> 是任务 <em>T</em> 的输出，我们就会增加一条从 <em>T</em> 到 <em>D</em> 的边。类似的，如果 <em>D</em> 是 任务 <em>T</em> 的输入，我们就会增加一条 <em>D</em> 到 <em>T</em> 的边。控制边表达了由于远程函数嵌套调用所造成的计算依赖关系，即，如果任务 <em>T1</em> 调用任务 <em>T2</em>， 我们就会增加一条 <em>T1</em> 到 <em>T2</em> 的控制边。</p>
<p>在计算图中，角色方法调用也被表示成了节点。除了一个关键不同点外，他们和任务调用间的依赖关系基本一样。为了表达同一个角色对象上的连续方法调用所形成的状态依赖关系，我们向计算图添加第三种类型的边：在同一个角色对象上，如果角色方法 <em>Mj</em> 紧接着 <em>Mi</em> 被调用，我们就会添加一条 <em>Mi</em> 到 <em>Mj</em> 的状态边（<em>即 Mi 调用后会改变角色对象中的某些状态，或者说成员变量；然后这些变化后的成员变量会作为 Mj 调用的隐式输入；由此，Mi 到 Mj 间形成了某种隐式依赖关系</em>）。这样一来，作用在同一角色对象上的所有方法调用会形成一条由状态边串起来的调用链（chain，见<em>图4</em>）。这条调用链表达了同一角色对象上方法被调用的前后相继的依赖关系。</p>
<p><img src="https://i.loli.net/2020/02/09/EKbF13u4v5hOZra.png" alt="task graph"></p>
<p><em>图4</em>：<em>该图与图3 <code>train_policy.remote()</code> 调用相对应。远程函数调用和角色方法调用对应图中的任务（tasks）。该图中显示了两个角色对象A10和A20，每个角色对象的方法调用（被标记为 A1i 和 A2i 的两个任务）之间都有状态边（stateful edge）连接，表示这些调用间共享可变的角色状态。从 <code>train_policy</code> 到被其调用的任务间有控制边连接。为了并行地训练多种策略，我们可以调用 <code>train_policy.remote()</code> 多次</em>。</p>
<p>状态边让我们将角色对象嵌入到无状态的任务图中，因为他们表达出了共享状态、前后相继的两个角色方法调用之间的隐式数据依赖关系。状态边的添加还可以让我们维护谱系图（lineage），如其他数据流系统一样，我们也会跟踪数据的谱系关系以在必要的时候进行数据的重建。通过显式的将状态边引入数据谱系图中，我们可以方便的对数据进行重建，不管这些数据是远程函数产生的还是角色方法产生的（小节4.2.3中会详细讲）。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>Ray 的架构组成包括两部分：</p>
<ol>
<li>实现 API 的应用层，现在包括 Python 和 Java分别实现的版本。</li>
<li>提供高扩展性和容错的系统层，用 C++ 写的，以CPython的形式嵌入包中。</li>
</ol>
<p><img src="https://i.loli.net/2020/02/09/4Hkz5GqyQutLJRV.png" alt="ray architecture"></p>
<p><em>图5：Ray 的架构包括两部分：系统层和应用层。前者实现了API和计算模型，后者实现了任务调度和数据管理，以满足性能要求和容错需求</em></p>
<h3 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h3><p>应用层包括三种类型的进程：</p>
<ul>
<li><strong>驱动进程（Driver</strong>）： 用来执行用户程序。</li>
<li><strong>工作进程（Worker）</strong>：用来执行 Driver 或者其他 Worker 指派的任务(remote functions，就是用户代码中装饰了<code>@ray.remote</code> 的那些函数)的<strong>无状态进程</strong>。工作进程在节点启动时被自动启动，一般来说会在每个物理机上启动与 CPU 同样数量的 Worker（这里还有些问题：如果节点是容器的话，获取的仍然是其所在物理机的 CPU 数）。当一个远程函数被声明时，会被注册到全局，并推送到所有 Worker。每个 Worker 顺序的执行任务，并且不维护本地状态。</li>
<li><strong>角色进程（Actor）</strong>：用来执行角色方法的有状态进程。与 Worker 被自动的启动不同，每个 Actor 会根据需求（即被调用时）被工作进程或者驱动进程显示启动。和 Worker 一样，Actor 也会顺序的执行任务，不同的是，下一个任务的执行依赖于前一个任务生成或改变的状态(即 Actor 的成员变量)。</li>
</ul>
<h3 id="系统层"><a href="#系统层" class="headerlink" title="系统层"></a>系统层</h3><p>系统层包括三个主要组件：全局控制存储(GCS，global control store)，分布式调度器（distributed scheduler）和分布式对象存储(distributed object store)。所有组件都可以进行水平扩展并且支持容错。</p>
<h4 id="全局控制存储-GCS"><a href="#全局控制存储-GCS" class="headerlink" title="全局控制存储(GCS)"></a>全局控制存储(GCS)</h4><p>全局状态存储维护着系统全局的控制状态信息，是我们系统独创的一个部件。其核心是一个可以进行发布订阅的键值对存储。我们通过分片(sharding)来应对扩展，每片存储通过<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MuY29ybmVsbC5lZHUvaG9tZS9ydnIvcGFwZXJzL09TREkwNC5wZGY=">链式副本<i class="fa fa-external-link-alt"></i></span>（将所有数据副本组织成链表，来保证强一致性，见04年的一篇论文）来提供容错。提出和设计这样一个GCS的动机在于使系统能够每秒进行数百万次的任务创建和调度，并且延迟较低，容错方便。</p>
<p>对于节点故障的容错需要一个能够记录谱系信息(lineage information)的方案。现有的基于谱系的解决方法侧重粗粒度（比如 Spark 的 rdd）的并行，因此可以只利用单个节点（如Master or Driver）存储谱系信息，而不影响性能。然而，这种设计并不适合像仿真（simulation）一样的细粒度、动态的作业类型(workload)。因此我们将谱系信息的存储与系统其它模块解耦，使之可以独立地动态扩容。</p>
<p>保持低延迟意味着要尽可能降低任务调度的开销。具体来说，一个调度过程包括选择节点，分派任务，拉取远端依赖对象等等。很多现有的信息流系统，将其所有对象的位置、大小等信息集中存储在调度器上，使得上述调度过程耦合在一块。当调度器不是瓶颈的时候，这是一个很简单自然的设计。然而，考虑到 Ray 要处理的数据量级和数据粒度，需要将中心调度器从关键路径中移出（否则如果所有调度都要全局调度器经手处理，它肯定会成为瓶颈）。对于像 allreduce 这样的（传输频繁，对延迟敏感）分布式训练很重要的原语来说，每个对象传输时都经手调度器的开销是不可容忍的。 因此，我们将对象的元数据存储在 GCS 中而不是中央调度器里，从而将任务分派与任务调度完全解耦。</p>
<p>总的来说，GCS 极大地简化了 Ray 的整体设计，因为它将所有状态揽下，<em>从而使得系统中其他部分都变成无状态</em>。这不仅使得对容错支持简化了很多（即，每个故障节点恢复时只需要从 GCS 中读取谱系信息就行），也使得分布式的对象存储和调度器可以进行独立的扩展（因为所有组件可以通过 GCS 来获取必要的信息）。还有一个额外的好处，就是可以更方便的开发调试、监控和可视化工具。</p>
<h4 id="自下而上的分布式调度系统-Bottom-up-Distributed-Scheduler"><a href="#自下而上的分布式调度系统-Bottom-up-Distributed-Scheduler" class="headerlink" title="自下而上的分布式调度系统(Bottom-up Distributed Scheduler)"></a>自下而上的分布式调度系统(Bottom-up Distributed Scheduler)</h4><p>如前面提到的，Ray 需要支持每秒数百万次任务调度，这些任务可能只持续短短数毫秒。大部分已知的调度策略都不满足这些需求。常见的集群计算框架，如 <span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9zeXN0ZW0vZmlsZXMvY29uZmVyZW5jZS9uc2RpMTIvbnNkaTEyLWZpbmFsMTM4LnBkZg==">Spark<i class="fa fa-external-link-alt"></i></span>， <span class="exturl" data-url="aHR0cDovL3d3dy5jcy5wcmluY2V0b24uZWR1L2NvdXJzZXMvYXJjaGl2ZS9mYWxsMTMvY29zNTE4L3BhcGVycy9jaWVsLnBkZg==">CIEL<i class="fa fa-external-link-alt"></i></span>， <span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9sZWdhY3kvZXZlbnQvb3NkaTA4L3RlY2gvZnVsbF9wYXBlcnMveXVfeS95dV95LnBkZg==">Dryad<i class="fa fa-external-link-alt"></i></span> 都实现了一个中心的调度器。这些调度器具有很好的局部性（局部性原理）的特点，但是往往会有数十毫秒的延迟。像 <span class="exturl" data-url="aHR0cDovL3N1cGVydGVjaC5jc2FpbC5taXQuZWR1L3BhcGVycy9zdGVhbC5wZGY=">work stealing<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly9jcy5zdGFuZm9yZC5lZHUvfm1hdGVpL3BhcGVycy8yMDEzL3Nvc3Bfc3BhcnJvdy5wZGY=">Sparrow<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9oY2kuc3RhbmZvcmQuZWR1L2NzdHIvcmVwb3J0cy8yMDE2LTAxLnBkZg==">Canary<i class="fa fa-external-link-alt"></i></span> 一样的的分布式调度器的确能做到高并发，但是往往不考虑数据的局部性特点，或者假设任务(tasks)属于不同的作业(job)，或者假设计算拓扑是提前知道的。</p>
<p>为了满足上述需求，我们设计了一个两层调度架构，包括一个<em>全局调度器（global scheduler）</em>和每个节点上的<em>本地调度器（local scheduler）</em>。为了避免全局调度器过载，每个节点(node）上创建的任务会被先提交到本地调度器。本地调度器总是先尝试将任务在本地执行，除非其所在机器过载(比如任务队列超过了预定义的阈值)或者不能满足任务任务的资源需求(比如，缺少 GPU)。如果本地调度器发现不能在本地执行某个任务，会将其转发给全局调度器。由于调度系统都倾向于首先在本地调度任务（即在调度结构层级中的叶子节点），我们将其称为自下而上的调度系统（可以看出，本地调度器只是根据本节点的局部负载信息进行调度，而全局调度器会根据全局负载来分派任务；当然前提是资源约束首先得被满足）。</p>
<p><img src="https://i.loli.net/2020/02/09/cFVRq9BxZgpOhyi.png" alt="ray distributed scheduler"></p>
<p><em>图6 这是调度系统示意图，任务自下而上被提交：任务首先被驱动进程（Drivers）或者工作进程(Workers)提交到本地调度器，然后在需要的时候会由本地调度器转给全局调度器进行处理。图中箭头的粗细程度代表其请求的繁忙程度。</em></p>
<p>全局调度器根据每个节点的负载状况和资源请求约束来决定调度策略。细化一下就是，全局调度器首先确定所有满足任务资源要求的节点，然后在其中选择具有最小<em>预估排队时间</em>(estimated waiting time)的一个，将任务调度过去。在给定的节点上，<em>预估排队时间</em>是下述两项时间的和：1）任务在节点上的排队时间 (任务队列长度乘上平均执行时间)； 2）任务依赖的远程对象的预估传输时间(所有远程输入的大小除以平均带宽)。全局调度器通过心跳获取到每个节点的任务排队情况和可用资源信息，从 GCS 中得到任务所有输入的位置和大小。然后，全局调度器通过<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU3JUE3JUJCJUU1JThCJTk1JUU1JUI5JUIzJUU1JTlEJTg3">移动指数平均<i class="fa fa-external-link-alt"></i></span>(exponential averaging)的方法来计算任务平均执行时间和平均传输带宽。如果全局调度器成为了系统瓶颈，我们可以实例化更多的副本来分摊流量，它们通过 GCS来共享全局状态信息。如此一来，我们的调度架构具有极高可扩展性。</p>
<h5 id="任务生命周期"><a href="#任务生命周期" class="headerlink" title="任务生命周期"></a>任务生命周期</h5><p>(注：这部分是从代码中的设计文档翻译而来，注意这只是截止到2019.04.21 的设计)</p>
<p>在实现的时候，每个任务具有以下几种状态。任意时刻，任务都会处在这几种状态之一。</p>
<ul>
<li>**可放置(Placeable)**：任务已经准备好被调度到（本地或者远程）节点上，具体如何调度，前一段已经说明。注意该状态不表示放置位置已经最终确定，还可能被再一次被从某处调度出去。</li>
<li>**等待角色创建(WaitActorCreation)**：一个角色方法（task）等待其所在角色实例化完毕。一旦角色被创建，该任务会被转给运行该角色的远端机器进行处理。</li>
<li>**等待中(Waiting)**：等待该任务参数需求被满足，即，等待所有远端参数对象传送到本地对象存储中。</li>
<li>**准备好(Ready)**：任务准备好了被运行，也就说所有所需参数已经在本地对象存储中就位了。</li>
<li>**运行中(Running)**：任务已经被分派，并且正在本地工作进程(worker)或者角色进程(actor)中运行。</li>
<li>**被阻塞(Blocked)**：当前任务由于其依赖的数据不可用而被阻塞住。如，嵌套调用时，该任务启动了另外的远程任务并且等待其完成，以取得结果。</li>
<li>**不可行(infeasible)**：任务的资源要求在任何一台机器上都得不到满足。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">                                  ---------------------------------</span><br><span class="line">                                 |                                 |</span><br><span class="line">                                 |     forward                     | forward</span><br><span class="line">                                 |----------------                 |</span><br><span class="line">node with                  ------|                |   arguments    |</span><br><span class="line">resources          forward|      |   resource     |     local      |   actor/worker</span><br><span class="line">joins                     |      v  available     |    --------&gt;   |    available</span><br><span class="line">  ---------------------- Placeable ----------&gt; Waiting           Ready ---------&gt; Running</span><br><span class="line">|                       | |  ^                    ^    &lt;--------   ^               |   ^</span><br><span class="line">|             |---------  |  |                    |    local arg   |               |   |</span><br><span class="line">|             |           |  |                    |     evicted    |        worker |   | worker</span><br><span class="line">|             |     actor |  |                    |                |       blocked |   | unblocked</span><br><span class="line">|   resources |   created |  | actor              | ---------------                |   |</span><br><span class="line">|  infeasible |           |  | created            | actor                          |   |</span><br><span class="line">|             |           |  | (remote)           | created                        v   |</span><br><span class="line">|             |           v  |                    | (local)                              Blocked</span><br><span class="line">|             |     WaitForActorCreation----------</span><br><span class="line">|             v</span><br><span class="line"> ----Infeasible</span><br></pre></td></tr></table></figure>

<h4 id="基于内存的分布式对象存储"><a href="#基于内存的分布式对象存储" class="headerlink" title="基于内存的分布式对象存储"></a>基于内存的分布式对象存储</h4><p>为了降低任务的延迟，我们实现了一个基于内存的分布式存储系统以存储每个任务（无状态的计算过程）的输入和输出。在每个节点上，我们以<em>共享内存</em>(shared memory)的方式实现了对象存储。这使得同一节点上的不同任务以零拷贝的代价进行数据共享。至于数据格式，我们选择了 <span class="exturl" data-url="aHR0cHM6Ly9hcnJvdy5hcGFjaGUub3JnLw==">Apache Arrow<i class="fa fa-external-link-alt"></i></span>。</p>
<p>如果一个任务的输入（即函数的参数对象）不在本地，在该任务执行之前，输入会被拷贝到本地的对象存储中。同时，任务执行完毕后，会将输出也写到本地得对象存储中。对象拷贝消除了热数据所造成的潜在的瓶颈，并且通过将任务的数据读写都限制在本地内存中以缩短执行时间。这些做法增加了计算密集型工作任务的吞吐量，而很多 AI 应用都是计算密集型的。为了降低延迟，我们将用到的对象全部放在内存中，只有在内存不够的时候才通过 LRU 算法将一些对象挤出内存（从API 可以看出，每个节点的内存上限可以在启动节点时通过参数指定。此外用 LRU 作为垃圾回收算法还是有点粗暴，如果不同类型的任务负载跑在同一个 ray 集群上，可能导致资源的互相争抢，从而有大量的资源换出然后重建，从而严重影响效率）。</p>
<p>和现有的计算框架的集群(如Spark， Dryad)一样，对象存储只接受<em>不可变数据</em>(immutable data)。这种设计避免了对复杂的一致性协议的需求（因为对象数据从来不需要进行更新），并且简化了数据的容错支持。当有节点出现故障时，Ray 通过重新执行对象谱系图来恢复任意<em>所需</em>对象（也就是说不用整个恢复该宕机节点所有状态，只需要按需恢复后面计算所需数据，用不到的数据丢了就丢了吧）。在工作开始之前，存放在 GCS 的谱系信息追踪了所有无状态的任务和有状态的角色；我们利用前者对丢失对象进行重建（结合上一段，如果一个任务有大量的迭代，并且都是远程执行，会造成大量的中间结果对象，将内存挤爆，从而使得较少使用但是稍后可能使用的全局变量挤出内存，所以 LRU 有点粗暴，听说现在在酝酿基于引用计数的GC）。</p>
<p>为了简化实现，我们的对象存储不支持分布式的对象。也就是说，每个对象必须能够在单节点内存下，并且只存在于单节点中。对于大矩阵、树状结构等大对象，可以在应用层来拆分处理，比如说实现为一个集合。</p>
<h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><p>Ray 是一个由加州大学伯克利分校开发的一个活跃的开源项目。Ray 深度整合了 Python，你可以通过 <code>pip install ray</code> 来安装 ray。整个代码实现包括大约 40K 行，其中有 72% C++ 实现的系统层和 28% 的 Python 实现的应用层（截止目前，又增加了对 Java 的支持）。GCS 的每个分片使用了一个 Redis 的 key-val 存储，并且只设计单个键值对操作。GCS 的表通过按任务ID、数据对象集合进行切分来进行平滑扩展。每一片利用<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MuY29ybmVsbC5lZHUvaG9tZS9ydnIvcGFwZXJzL09TREkwNC5wZGY=">链式冗余策略<i class="fa fa-external-link-alt"></i></span>(chained-replcated)来容错。我们将本地调度器和全局调度器都实现为了单线程、事件驱动的进程。本地调度器缓存了本地对象元信息，被阻塞的任务队列和等待调度的任务队列。为了在不同节点的对象存储之间无感知的传输超大对象，我们将大对象切片，利用多条 TCP 连接来并行传。</p>
<h3 id="将所有碎片捏一块"><a href="#将所有碎片捏一块" class="headerlink" title="将所有碎片捏一块"></a>将所有碎片捏一块</h3><p><em>图 7</em> 通过一个简单的 <code>a</code> 加 <code>b</code> （<code>a，b</code>可以是标量，向量或者矩阵）然后返回 <code>c</code> 的例子展示了 Ray 端到端的工作流。远程函数 <code>add()</code> 在初始化 ( <code>ray.init</code> ) 的时候，会自动地被注册到 GCS 中，进而分发到集群中的每个工作进程。（<em>图7a</em> 的第零步）</p>
<p><em>图7a</em> 展示了当一个驱动进程（driver）调用 <code>add.remote(a, b)</code> ，并且 <code>a, b</code> 分别存在节点 <em>N1</em> 和 <em>N2</em> 上时 ，Ray 的每一步操作。驱动进程将任务 <code>add(a, b)</code> 提交到本地调度器（步骤1），然后该任务请求被转到全局调度器（步骤2）（<strong>如前所述，如果本地任务排队队列没有超过设定阈值，该任务也可以在本地进行执行</strong>）。接着，全局调度器开始在 GCS  中查找 <code>add(a, b)</code> 请求中参数 <code>a, b</code> 的位置（步骤3），从而决定将该任务调度到节点 <em>N2</em> 上（因为 <em>N2</em> 上有其中一个参数 <code>b</code>）（步骤4）。<em>N2</em> 节点上的本地调度器收到请求后（<em>发现满足本地调度策略的条件，如满足资源约束，排队队列也没超过阈值，就会在本地开始执行该任务</em>），会检查本地对象存储中是否存在任务  <code>add(a, b)</code> 的所有输入参数（步骤5）。由于本地对象存储中没有对象 <code>a</code>，工作进程会在 GCS 中查找 <code>a</code> 的位置（步骤6）。 这时候发现 <code>a</code> 存储在 <em>N1</em> 中，于是将其同步到本地的对象存储中（步骤7）。由于任务 <code>add()</code> 所有的输入参数对象都存在了本地存储中，本地调度器将在本地工作进程中执行 <code>add()</code> （步骤8），并通过共享存储访问输入参数（步骤9）。 </p>
<p><img src="https://i.loli.net/2020/02/09/Fq6Vwvf1Thg5Ayc.png" alt="ray execute example"></p>
<p>图 7b 展现了在 <em>N1</em> 上执行 <code>ray.get()</code>  和在 <em>N2</em> 上执行 <code>add()</code>后所触发的逐步的操作。一旦 <code>ray.get(id)</code>被调用，<em>N1</em> 上的用户驱动进程会在本地对象存储中查看该 id （<em>即由远程调用 <code>add()</code> 返回的 future 值，所有 object id 是全局唯一的，GCS 可以保证这一点</em>）对应的对象 <code>c</code> 是否存在（步骤1）。由于本地对象存储中没有 <code>c</code> , 驱动进程会去 GCS 中查找 <code>c</code> 的位置。在此时，发现 GCS 中并没有 c 的存在，因为 c 根本还没有被创建出来。 于是，<em>N1</em> 的对象存储向 GCS 中的对象表（Object Table）注册了一个回调函数，以监听 <code>c</code> 对象被创建事件（步骤2）。与此同时，在节点 <em>N2</em> 上，add() 任务执行完毕，将结果 <code>c</code> 存到其本地对象存储中（步骤3），同时也将 <code>c </code> 的位置信息添加到 GCS 的对象存储表中（步骤4）。GCS 监测到 <code>c</code> 的创建，会去触发之前 <em>N1</em> 的对象存储注册的回调函数（步骤5）。接下来，<em>N1</em> 的对象存储将 <code>c</code> 从 <em>N2</em> 中同步过去（步骤6），从而结束该任务。</p>
<p><img src="https://i.loli.net/2020/02/09/hqzG1DUIvf2i4LV.png" alt="ray execute example b"></p>
<p>尽管这个例子中涉及了大量的 RPC调用，但对于大部分情况来说，RPC 的数量会小的多，因为大部分任务会在本地被调度执行，而且 GCS 回复的对象信息会被本地调度器和全局调度器缓存（但是另一方面，执行了大量远程任务之后，本地对象存储很容易被撑爆）。</p>
<h2 id="名词对照"><a href="#名词对照" class="headerlink" title="名词对照"></a>名词对照</h2><p><strong>workloads</strong>：工作负载，即描述任务需要做的工作。</p>
<p><strong>GCS</strong>： Global Control Store，全局控制信息存储。</p>
<p><strong>Object Table</strong>：存在于 GCS 中的对象表，记录了所有对象的位置等信息（objectId -&gt; location）。</p>
<p><strong>Object Store</strong>：本地对象存储，在实现中叫 Plasma，即存储任务所需对象的实例。</p>
<p><strong>Lineage</strong>：血统信息，谱系信息；即计算时的数据变换前后的相继关系图。</p>
<p><strong>Node</strong>：节点；Ray 集群中的每个物理节点。</p>
<p><strong>Driver、Worker</strong>：驱动进程和工作进程，物理表现形式都是 Node 上的进程。但前者是用户侧使用 <code>ray.init</code> 时候生成的，随着 <code>ray.shutdown</code> 会进行销毁。后者是 ray 在启动的时在每个节点启动的无状态的驻留工作进程，一般和物理机 CPU 数量相同。</p>
<p><strong>Actor</strong>：角色对象，语言层面，就是一个类；物理层面，表现为某个节点上的一个角色进程，维护了该角色对象内的所有上下文（角色成员变量）。</p>
<p><strong>Actor method</strong>：角色方法，语言层面，就是类的成员方法；其所有输入包括显式的函数参数和隐式的成员变量。</p>
<p><strong>Remote function</strong>：远程函数，即通过 @ray.remote 注册到系统的函数。在其被调度时，称为一个任务(Task)。</p>
<p><strong>Job，Task</strong>：文中用到了不少 Job 和 Task 的概念，但是这两个概念在 CS 中其实定义比较模糊，不如进程和线程一般明确。Task 在本论文是对一个远程函数(remote action)或者一个 actor 的远程方法(remote method)的封装。而 Job 在当前的实现中并不存在，只是一个逻辑上的概念，其含义为运行一次用户侧代码所所涉及到的所有生成的 Task 以及产生的状态的集合。</p>
<p><strong>Scheduler</strong>：paper 中统一用的 scheduler，但是有的是指部分(local scheduler 和 global scheduler)，这时我翻译为<strong>调度器</strong>，有时候是指 Ray 中所有调度器构成的整体，这时我翻译为<strong>调度系统</strong>。</p>
<p><strong>exponential averaging</strong>：我翻译成了移动指数平均，虽然他没有写移动。对于刚过去的前 n 项，以随着时间渐进指数增长的权重做加权平均。计算时候可以通过滑动窗口的概念方便的递推计算。</p>
<p><strong>Future</strong>：这个不大好翻译，大概意思就是对于异步调用中的返回值句柄。相信信息可以参见维基百科 <span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvRnV0dXJlJUU0JUI4JThFcHJvbWlzZQ==">Future 和 promise<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>[1] 官方文档：<span class="exturl" data-url="aHR0cHM6Ly9yYXkucmVhZHRoZWRvY3MuaW8vZW4vbGF0ZXN0Lw==">https://ray.readthedocs.io/en/latest/<i class="fa fa-external-link-alt"></i></span></p>
<p>[2] 系统论文：<span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9zeXN0ZW0vZmlsZXMvb3NkaTE4LW1vcml0ei5wZGY=">https://www.usenix.org/system/files/osdi18-moritz.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>[3] 系统源码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JheS1wcm9qZWN0L3JheQ==">https://github.com/ray-project/ray<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>分布式系统</tag>
        <tag>Ray</tag>
        <tag>AI引擎</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka —— 弥合日志系统和消息队列的鸿沟</title>
    <url>/2019/12/22/kafka/</url>
    <content><![CDATA[<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>Kafka （该论文发表于2011年6月**[1]**）是日志处理和消息队列系统的集大成者。较低的延迟、极高的容量和吞吐，使其可以应用于在线服务和离线业务。为了兼顾性能和可扩展性，Kafka 做了一些看起来反直觉但是却很实用的设计。例行总结一下其设计特点：</p>
<ol>
<li><p><strong>面向存储的消息队列</strong>：意味在近实时的情况下能够将传统消息队列的存储增加几个数量级。实现原理是充分利用了磁盘的顺序写和操作系统自身的缓存；此外为了提高访盘、传输效率，使用了文件分段、段首索引、零拷贝和批量拉取等技术。</p>
</li>
<li><p><strong>灵活的生产消费方式</strong>：总体而言是基于主题粒度的发布订阅式架构，并且既支持<strong>组内多消费者</strong>互斥消费，也支持不同<strong>消费者组</strong>间的重复消费。这里面涉及到消息队列的两个核心设计选择：<em>pull</em> 式消费以及客户端侧存储消费进度。拉式消费可能会导致空轮询以及稍微的延迟，好处在于灵活；客户端存储消费进度可以使的 broker 无状态，以进行灵活伸缩和容错。为了简化实现，消费时，每个分区最多为一个消费者所消费。</p>
</li>
<li><p><strong>Zookeeper 存储元信息</strong>：利用分布式一致性组件 Zookeeper 以注册表的形式存储系统元信息，包括 broker 和消费者的存活信息、消费者和分区间的对应关系、每个分区的消费进度等等。Zookeeper 作为一个前缀树形式组织 KV、支持发布订阅的高可用组件，可以满足 Kafka 进行消费协调和进度保存的协作需求。</p>
</li>
<li><p><strong>分区级别的多副本设计</strong>：这一点在论文中还没实现，应该是后来系统开源演进时加上的。利用该条可以实现对 broker 的容错。</p>
</li>
<li><p><strong>简洁强大的消费接口</strong>：Kafka 的客户端一般提供两层接口抽象。包括无需关注<strong>分区</strong>和<strong>偏移量</strong>信息的高层（high-level）<em>简单读写</em>接口，以及可以灵活控制分区组织和消费进度的低层（low-level）接口。论文中只提到了前者，以表现其简洁。</p>
</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>任何互联网公司都会产生大量的”日志”数据，这些数据主要包括：</p>
<ol>
<li><strong>用户行为事件</strong>。如社交网站中登录、浏览、点击、喜欢、分享、评论等等。</li>
<li><strong>系统运维数据</strong>。如某个服务的调用栈、调用延迟、错误报告以及一些机器运行指标：CPU、网络或者硬盘的使用率。</li>
</ol>
<p>长期以来，这些数据只是用来做后台分析或者系统瓶颈定位。但现在的一个趋势是，这些数据被越来越多的用到<strong>线上</strong>业务，包括：</p>
<ol>
<li>搜索相关性分析</li>
<li>数据驱动的推荐</li>
<li>广告精准投放</li>
<li>服务黑名单过滤</li>
<li>用户首页 Feed 流</li>
</ol>
<p>等等，不胜枚举。这些行为数据通常比用户本身元数据的多几个数量级，因此其实时分析需求给数据系统带来了新的挑战。比如搜索、推荐和广告都需要细粒度的点击率的数据，这就要求不仅要统计所有的用户点击事件，还要去统计那些没有被点击的页面的数据。</p>
<p>早期的一些系统为了实现类似的需求都是直接去线上环境扒系统日志来进行分析，不过最近一些公司建了很多专有系统来干这件事。比如 Facebook 的 Scribe，Yahoo 的 Data Highway 和 Cloudera 的 Flume。这些系统的目标都在于将日志数据收集起来，然后导入像 Hadoop 等数据仓库来进行离线处理。然而在 LinkedIn，我们除了<strong>离线分析</strong>的需求，还有不少上述提到的要求延迟不高于数秒的<strong>实时处理</strong>需求。</p>
<p>我们构建了一个崭新的针对日志处理的消息系统，名为 <strong>Kafka</strong>。Kafka 兼顾了<strong>日志聚合</strong>需求和<strong>消息队列</strong>需求。一方面来说，Kafka 是一个支持平滑扩展，支持高吞吐的分布式系统；另一方面，Kafka 提供了类似于消息队列的 API，并且允许应用对日志消息进行实时消费。论文发表时，Kafka 已经在 LinkedIn 上线了六个多月，只用一个系统就满足了我们两大方面的需求，从而极大简化了我们的基础设施。</p>
<p>接下来，论文在第二部分会再次回顾消息队列系统（messaging system）和日志聚合系统（logging aggregators）的传统形态。在第三部分，我们首先介绍 Kafka 的基本架构，继而讨论它设计的基本原则。然后在第四部分，我们将看一下 Kafka 在 LinkedIn 的部署情况和性能指标。</p>
<h2 id="相关系统"><a href="#相关系统" class="headerlink" title="相关系统"></a>相关系统</h2><p>传统的企业级消息系统（如activemq， IBM Websphere MQ， Oracle Enterprise Messaging Service，TIBCO Enterprise Message Service）已经存在很长时间了，主要作用是<strong>消息总线</strong>和<strong>异步解耦</strong>。但它们并不能无缝适配日志处理需求，主要有以下几点原因：</p>
<ul>
<li><strong>语义侧重点不同</strong></li>
</ul>
<p>传统消息队列侧重于提供灵活的消息送达保证，比如多个队列的事务问题、消息送达的 ACK 确认、消息的严格保序等等。这些功能在日志处理系统中需求并不是那么高，但是他们大大增加了 API 复杂性和系统实现的难度。</p>
<ul>
<li><strong>高吞吐支持差</strong></li>
</ul>
<p>大部分传统的消息队列都不将高吞吐作为第一设计目标。比如 JMS 连 batch 接口都没有，因此每发一个消息都会使用一个新的 TCP 连接，显然不能满足我们日志系统高吞吐的需求。</p>
<ul>
<li><strong>不支持分布式存储</strong></li>
</ul>
<p>这些传统消息系统通常不容易进行切片（partition）以存储到多台机器上。因此在数据量大时，不能支持平滑扩容。</p>
<ul>
<li><strong>面向实时而非累积</strong></li>
</ul>
<p>这些消息系统的另一个特点是假设消费类型是<strong>近实时消费</strong>（near immediate），因而未被消费的消息的量总是和。一旦消息产生累积，这小消息系统的性能将大大下降。因此他们难以支持离线消费和大批量消费的任务类型。说白了，传统的消息系统的设计思路并不面向<strong>存储</strong>。</p>
<p>近些年也涌现了一些专用的日志聚合系统。</p>
<p>如 Facebook 的 Scribe。系统产生的日志通过 socket 写入远程的 Scribe 机器，每个 Scribe 机器将收集到的日志定期刷（dump）到 HDFS 或 NFS 机器集群中。</p>
<p>又如 Yahoo，其数据高速公路（data highway）也是类似的数据流模式。一群机器将从客户端收集来的日志按分钟聚集成一个个文件，然后将其写入 HDFS 中。</p>
<p>再如 Cloudera，他们构建了一个比较新颖的日志聚合系统：Flume。Flume 提供了扩展语义的<em>管道</em>(“pipes” )，和<em>汇聚槽</em>（sinks），可以让用户灵活的对日志流进行消费。此外，该系统还引入更多的分布式特性。</p>
<p>但是，大部分的这些系统都是面向离线消费的，并且暴露太多不必要的实现细节（也就是没有抽象好，不够灵活，比如 Yahoo 还暴露了分钟文件 <em>minutes file</em> 这种东西）。此外，这些系统基本采用”推”（<em>push</em>）的模式，即 broker 将消息推送给消费者（consumers）。</p>
<p>在 LinkedIn，经研究发现，”拉” (pull) 的模式更适合我们的业务场景。在该模式下，每个消费者可以按照自己的<em>喜好</em>来决定消费速度，而不用担心被快的消费者淹没，或者被慢的消费者拖累**[2]**。”拉”模式也很容易实现消费重试（rewind），稍后我们会详细讨论这个问题。</p>
<p>最近，Yahoo 研究院开发了一个叫做 HedWig 的支持发布&#x2F;订阅的分布式系统，它易于扩展，高可用，并且支持消息的持久化。然而，该系统更多的作为一个日志存储系统而存在。</p>
<h2 id="Kafka-架构和设计原则"><a href="#Kafka-架构和设计原则" class="headerlink" title="Kafka 架构和设计原则"></a>Kafka 架构和设计原则</h2><h3 id="概念体系"><a href="#概念体系" class="headerlink" title="概念体系"></a>概念体系</h3><p>由于上述系统的诸多限制，我们开发了一个基于消息的日志聚合系统——Kafka。首先介绍一些 Kafka 的概念体系。<strong>主题</strong>（<em>topic</em>） 定义了某种<strong>消息</strong>（message）流的类型，<strong>生产者</strong>（<em>producer</em>）会将消息发布到某个主题下，这些被发布的消息会暂时屯在一组叫做<strong>代理商</strong>（<em>broker</em>）的服务器中。一个<strong>消费者</strong>（<em>consumer</em>）可以从代理商那同时订阅一到多个主题，然后以拉取的方式进行消费。</p>
<h3 id="接口设计"><a href="#接口设计" class="headerlink" title="接口设计"></a>接口设计</h3><p>消息系统应该是很简单的，为了表达这种简单，我们将 Kafka 的接口（API）设计的很简约。为了避免枯燥的描述这些 API，我们用两个很简单的小例子来说明 Kafka 的 API 长啥样。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Sample producer code:</span></span><br><span class="line">producer = <span class="keyword">new</span> <span class="title class_">Producer</span>(…);</span><br><span class="line">message = <span class="keyword">new</span> <span class="title class_">Message</span>(“test message str”.getBytes());</span><br><span class="line">set = <span class="keyword">new</span> <span class="title class_">MessageSet</span>(message);</span><br><span class="line">producer.send(“topic1”, set);</span><br></pre></td></tr></table></figure>

<p>如代码所示，一条消息的格式很简单，就是一组字节，用户可以根据喜好来对数据进行序列化（即将对象实例编码成一组字节）。为了提高效率，可以一次发送一组消息。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Sample consumer code:</span></span><br><span class="line">streams[] = Consumer.createMessageStreams(“topic1”, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> (message : streams[<span class="number">0</span>]) &#123;</span><br><span class="line">    bytes = message.payload();</span><br><span class="line">    <span class="comment">// do something with the bytes</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>消费者通过创建一个或多个流来订阅 topic，被发布到相应 topic 的消息会渐次进入这些消费者创建的订阅流。接口就这么简单，至于 Kafka 如何来实现，卖个关子，稍后讨论。在语言层面，我们将每个消息流抽象为一个迭代器（Iterator）， 消费者利用该迭代器取出一条条消息的消息体以进行处理。和一般的迭代器不同，我们的迭代器永不停止，当无新消息到来时，迭代器就会一直阻塞。我们同时支持两种消费模式，既可以一组消费者对某个 topic 进行<strong>互斥</strong>消费，也可以每个消费者对同一个主题进行<strong>独立</strong>消费。</p>
<h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p>Kafka 的架构图如下：</p>
<p><img src="https://i.loli.net/2020/02/09/6dbS1ypqo79Pigm.png" alt="kafka-architecture.png"></p>
<p>Kafka 是分布式系统，因此一个 Kafka 集群中会包含多个 broker 机器。为了均摊负载，每个 topic 被切分成多个分片（Partition），每个 broker 机器持有其中的一个或多个分片。多个生产者和消费者可以同时进行消息的生产和消费。在 3.1 节，我们会介绍 broker 上的单个分片的布局，讨论为了使单个分片高效的被消费的一些设计上的推敲和选择。3.2 节，会描述生产者和消费者如何在分布式环境中与多个 broker 进行交互。最后在 3.3 节，会讨论 Kafka 的数据交付保证。</p>
<h3 id="单个分区的效率"><a href="#单个分区的效率" class="headerlink" title="单个分区的效率"></a>单个分区的效率</h3><p>我们做了一系列的设计上的决策来保证系统的高效性。</p>
<p><strong>极简的存储设计</strong>。一个 topic 的每个分区就是逻辑上的一段日志。具体到物理上，为了防止分区文件过大，我们会将其进一步分成数据段（segment）。每次数据往最新的数据段中写，写到设定容量（比如说 1G）后，就会新建一个段文件继续写。此外，为了提高写入性能，我们会将日志记录在内存中进行缓存，只有日志数量达到设定值或者缓存数据的大小达到设定值时，才会将数据刷到外存中。为了保证可靠性，只有数据刷到了外存后，才会将其暴露给消费者。</p>
<p>和传统的消息系统不同，Kafka 存储的每条消息没有<strong>显式</strong>的消息 ID，而仅通过该条消息在分片中的偏移量（offset）来定位。这样我们省却了为了随机查找而建立的索引的额外开销。值得一提的是，我们的偏移量并不是连续的，而是类似于 TCP 中的 SEQ 的字节 offset——为了计算下一条消息的偏移量，我们需要将当前消息偏移量加上当前消息长度。下面可能会 ID 与偏移量混用，但是说的都是一个东西。</p>
<p>每个消费者总是<strong>顺序的</strong>去消费每个分区的数据，如果消费者每<strong>确认</strong>（ack）一个偏移量，就意味着该偏移量前面的所有消息都被消费过了。实现上来说，消费者端的库代码会向 broker 发一系列请求来拉取数据到消费者的缓冲区中供应用代码来消费**[3]<strong>。每个拉取请求包含了起始便宜地址和可以接受的字节尺寸。每个 Broker 在内存中维护了数据段首偏移量到数据段物理地址的映射（应该是用查找树组织的，因为需要范围定位）。当一个读取请求到来时，broker 根据</strong>请求偏移量<strong>来定位到相应的段，然后根据</strong>请求尺寸**来读出指定的数据量，然后返回给消费者。消费者收到消息后，计算出下一条消息的偏移量，以进行下一次拉取请求。Kafka 中硬盘中日志和内存中索引的布局如下图（每个框框中数据即表示某条消息的偏移量）：</p>
<p><img src="https://i.loli.net/2020/02/09/ZdGU4QYE9Iaz7OW.jpg" alt="kafka-log.jpg"></p>
<p><strong>高效的传输优化</strong>。由于网络传输开销会比较高，因此我们小心的设计了 Kafka 和外界数据交互的流程。如前所述，对于<strong>生产者</strong>，我们在 API 层面允许一次发送一批消息。对于消费者，虽然在 API 层面看起来是逐条消息进行消费，但在底层也是会批量拉取，比如每次都一次拉取数百 KB。</p>
<p>另一个与众不同的设计决策在于，我们不在 Kafka 系统层面进行<strong>显式</strong>的消息缓存。也就是说，我们仅仅利用文件系统层面的页缓存（page cache）来实现加速硬盘读写的目的。这样做好处有二：</p>
<ol>
<li>避免消息的多次缓存</li>
<li>broker 进程重启后缓存不丢失</li>
</ol>
<p>由于不在 Kafka 层面做缓存，内存层面的垃圾回收策略就可以做的很简单。因此，可以简化使用自带 VM 的编程语言进行系统实现的难度。</p>
<p>在 Kafka 的应对的场景中，生产者和消费者都是顺序的访问段文件，并且消费者通常只是稍落后生产者。操作系统默认的写穿透（write-through）和预读取（read-ahead）等启发式的缓存策略天然适配该场景。我们发现不论消费者还是生产者的读写速率都是随着数据尺寸线性增长，直到数 TB 级别（继续往后论文就没说了）。</p>
<p>此外，我们还优化了消费者远程数据访问过程。因为 Kafka 是一个支持多次订阅的系统，一条消息可能被不同的消费者消费多次，因此远程数据访问的优化能够极大提升系统性能。传统上，一条数据从本地文件送到 socket 上通常包含以下几个过程：</p>
<ol>
<li>从外存中读入数据到操作系统的页缓存（page cache）。</li>
<li>从页缓存拷贝数据到应用缓冲区（application buffer）中。</li>
<li>从应用缓冲区拷贝到内核缓冲区（kernel buffer）。</li>
<li>从内核缓冲区拷贝到 socket。</li>
</ol>
<p>这些过程涉及四次数据拷贝和两次系统调用，可以说非常冗余浪费。在 Linux 和其他一些操作系统中，存在一个 sendfile （zero copy，零拷贝技术）的 API，能够直接将数据从文件传送到 socket 中。利用此 API，可以省去步骤（2）（3）中引入的两次数据拷贝和一次系统调用，由此使得 Kafka 可以将数据从 broker 的段文件中高效的传输给消费者。</p>
<p><strong>无状态的 Broker</strong>。与其他消息队列不同，在 Kafka 中，broker 不负责保存每个消费者的消费进度。也就说是，每个消费者需要自己保存自己的消费偏移量等信息，从而使 broker 的设计可以相对简化，不用维护过多状态。但如此一来，由于 broker 不知道所有订阅者的消费进度，就难以决定何时对某条消息进行删除。Kafka 使用了一个看似 tricky 的策略——按时间窗口对消息进行保存。比如说，只保存最近七天的数据。当然，每个 topic 可以设置不同的策略。这个简单的策略大部分情况下都很够用，即使是离线消费者也通常会每天，每小时甚至近实时进行消费，七天足以。Kafka 并不会随着数据量增大而显著降低性能，这个保证是允许 Kafka 使用如此简单的策略的关键所在。</p>
<p>这种大量存储+拉取的设计带来的另外一个重要的好处是——消费者可以主动选择进行回退（rewind）消费。这个需求看起来违背了通常消息队列的定义，然而在很多情况下却非常有必要。随便举两个例子：</p>
<ol>
<li>当消费者进程由于错误而挂掉后，可以在恢复后有选择的对挂掉前后的数据重新消费。这对将 ETL 数据导入 Hadoop 等数据仓库之类的场景非常重要。</li>
<li>消费者会定期的将拉取的数据刷到持久化的存储中（比如倒排索引系统中）。如果消费者宕机，那部分已经从 消息系统拉取但是未持久化的数据就会被丢失。但是对于 Kafka 来说，消费者只需要记住 flush 到的 offset 即可，下次重启后再从该 offset 后开始拉取。但是对于传统没有大量缓存的消息队列来说，可能这部分数据就永远的丢了，或者得在消费端做某种错误备份和恢复的复杂策略。</li>
</ol>
<h3 id="多机协调"><a href="#多机协调" class="headerlink" title="多机协调"></a>多机协调</h3><p>下面我们来讨论多个生产者和消费者在分布式环境中的行为。对于生产者，其发送数据时，可以将其随机发送到一个分区所在 broker；也可以根据 Key 以及作用于 Key 上的路由函数，将其发送到某特定分区机器（broker）上。对于消费者，行为稍复杂，接下来将会详细说明。</p>
<p>Kafka 有个概念叫做<em>消费者组</em>（consumer groups）。同一个消费者组中包含多个消费者，这些消费者会<strong>互斥</strong>的消费一组 topic，即，对于一条消息，仅会被同组消费者中的一个所消费。不同的消费者组会进行独立消费，即每个消费者组维护自己的消费进度，不需要进行协同。一个消费者组内的每个消费者可以分属不同进程甚至不同机器，我们目标是在不引入过多额外开销的情况下将消息均匀的分发到每个消费者。</p>
<p>第一个决策是将每个<strong>分片作为最小的并行粒度</strong>。即每个分区最多为一个消费者所消费，如果我们允许多个消费者消费同一个分区，势必会引入锁之类的协调机制并且记录下一些状态以跟踪每个消费者的消费状态，这会加大实现难度。而在我们的设计中，只有在消费者数量变动，需要重新平衡流量的时候才需要协调。为了能使每个消费者流量更均衡，建议是让分区个数远大于消费者个数，这点很容易实现，只需要给 topic 配置更多分区即可。</p>
<p>第二个决策是<strong>不引入中心的主节点</strong>，代之以让所有消费者以去中心化的形式进行协调。如果使用中心节点，我们还得去关心其容错问题，又引入了不必要的复杂度。为了让消费者更好的进行协调，我们引入了一个高可用的一致性服务——Zookeeper。Zookeeper 的 API 很像文件系统，是以前缀树的形式组织的 KV （<em>K是路径，以 ‘&#x2F;‘ 来区分层次，V 可以是任何可序列化的值</em>）存储。该 API 支持创建一个路径、给一个路径设置值、读取路径的值、删除一个路径、列出某个路径下所有子节点的值。此外，Zookeeper 还具有以下特性：</p>
<ol>
<li>客户端可以向某个路径注册一个回调函数，以监听该路径的值或其孩子节点的变动。</li>
<li>路径可以被创建为易失的（ephemeral），即当所有该路径的客户端消失后，该路径及值会被自动的移除。</li>
<li>Zookeeper 使用一致性协议将其数据进行多机备份，使其服务具有高可靠性和高可用性。</li>
</ol>
<p>Kafka 使用 Zookeeper 干了以下几件事情：</p>
<ol>
<li>监控 brokers 和消费者的增删。</li>
<li>当出现 brokers 或者消费者的增删时，启动消费再平衡任务。</li>
<li>维护消费者的间关系状态，跟踪每个分区的消费偏移量。</li>
</ol>
<p>具体来说，当一个 broker 或消费者启动时，它会将元信息存在 Zookeeper 中的注册表（registry）中。</p>
<ol>
<li>broker 的注册表包括 broker 的主机名和端口号、以及存于其上的 topics 和分区。</li>
<li>消费者的注册表包括其所属的消费者组以及订阅的 topic。</li>
</ol>
<p>每个消费者组都在 Zookeeper 中有一个相关联的所有权注册表和偏移量注册表。</p>
<ol>
<li>我们将消费者消费某个分区的行为称为占有，所有权注册表（ownership registry）即记录了消费者与其占有的分区间的对应关系。其中，路径名标识一个分区，记录值是该分区的拥有者。</li>
<li>偏移量记录表记录了该消费者组所有订阅的 topic 对应的每个分区的消费进度（即偏移量）。</li>
</ol>
<p>Zookeeper 中 broker 的注册表、消费者的注册表和拥有关系的注册表是<strong>易失的</strong>，而偏移量注册表是<strong>永久的</strong>（persistent）。当一个 broker 死掉时，其上所有分区会自动从 broker 注册表中删除。当一个消费者死掉时，其在消费者注册表的条目会被删除，在拥有关系的注册表中所拥有的分区关系条目也会被删除。每个消费者都会监听  broker 注册表和消费者注册表，当有 broker 变动或者消费者组中成员变动的时候，就会接收到通知。</p>
<p>当某个消费者加入或者消费者组中有成员变化时，该消费者就会启动一个再平衡（re-balance）的进程以决定他需要消费哪个分区集。伪码如下：</p>
<figure class="highlight pascal"><table><tr><td class="code"><pre><span class="line">Algorithm <span class="number">1</span>: rebalance process <span class="keyword">for</span> consumer Ci <span class="keyword">in</span> group G</span><br><span class="line"><span class="keyword">For</span> each topic T that Ci subscribes <span class="keyword">to</span> <span class="comment">&#123;</span></span><br><span class="line"><span class="comment">    remove partitions owned by Ci from the ownership registry</span></span><br><span class="line"><span class="comment">    read the broker and the consumer registries from Zookeeper</span></span><br><span class="line"><span class="comment">    compute PT = partitions available in all brokers under topic T</span></span><br><span class="line"><span class="comment">    compute CT = all consumers in G that subscribe to topic T</span></span><br><span class="line"><span class="comment">    sort PT and CT</span></span><br><span class="line"><span class="comment">    let j be the index position of Ci in CT and let N = |PT|/|CT|</span></span><br><span class="line"><span class="comment">    assign partitions from j*N to (j+1)*N - 1 in PT to consumer Ci</span></span><br><span class="line"><span class="comment">    for each assigned partition p &#123;</span></span><br><span class="line"><span class="comment">        set the owner of p to Ci in the ownership registry</span></span><br><span class="line"><span class="comment">        let Op = the offset of partition p stored in the offset registry</span></span><br><span class="line"><span class="comment">        invoke a thread to pull data in partition p from offset Op</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>算法如上，简单来说就是该消费者去 Zookeeper 拿到所有 topic。对于每个 topic ，拿到分区集合 set(Pt) 以及所属消费者组的消费者集合 Ct。然后将分区集尽量等分为 |Ct| 块，该消费者按照一个确定性算法挑去其中一块，比如说按某种特定方式对 Ct 和 Pt 进行排序。之后，每个消费者对于每个属于自己分区启动一个线程进行拉取，并且从偏移量注册表中保存的偏移量开始消费。随着分区中的数据被不断的消费，消费者会不断的在注册表中更新偏移量。</p>
<p>当消费者或者 broker 出现变动时，同一个消费者组中的所有消费都会收到通知，由于网络等原因，每个消费者收到通知的时间会有先后关系。当先收到通知的消费者在运行上述算法去拿新的分区的数据时，很可能发现该分区还被其他消费者占有。对于这种情况，我们采用一个很简单的策略：该消费者将自己占有的分区释放掉，并且等一小会，然后进行重试。在实际运行中，一般再平衡程序在几次重试后就能达到稳定。</p>
<p>当一个新的消费者组创建时，注册表中没有任何的偏移量记录。这时，使用 broker 提供的 API，该消费者组可以针对每个分区选择从<em>最小的偏移量</em>或者<em>最大的偏移量</em>进行消费（这取决于消费者组的配置）。</p>
<h3 id="数据交付保证"><a href="#数据交付保证" class="headerlink" title="数据交付保证"></a>数据交付保证</h3><p>原则上，Kafka 仅提供”至少一次”（at-least-once）[4] 的交付语义。恰好一次（exactly-once）交付语义可以通过两阶段提交来保证，但是在我们应用场景中，这并不是必须的。其实大部分时候，在网络状况良好的一般机房中，大部分消息都都会被消费者组恰好消费一次，仅在消费者进程异常退出没有做正常的清理工作时（比如没有将最后消费到的 offset 更新到 Zookeeper），那么新的消费者在启动时，就会重复的消费那部分 offset 没有提交的数据。如果应用不能够容忍这种情况，就必须在应用逻辑中增加消息去重的逻辑，可以用一个字典来存储最近消费过的数据的 id 进行去重，该 id 可以是 Kafka 中给 message 的 offset，也可以是用户自定义的和消息一一对应的某个 key。这种方法的性能要好于在 Kafka 层面使用两阶段提交的方法来保证恰好一次的语义。</p>
<p>Kafka 保证来自于同一个分区的消息是保序的，即 offset 大小顺序，但是不同分区之间的顺序是不保证的。为了避免数据出错，Kafka 在每个消息中保存了一个 CRC 校验和。当 broker 遇到 IO 问题时，在恢复时，可以把 CRC 校验不一致的消息给删掉。由于 CRC 保存在消息中，生产和消费的环节都可以检查一下 CRC 来规避网络传输带来的错误。</p>
<p>当一个 broker 宕机时，其上面所有消息将会变为不可用。进一步，如果 broker 的存储系统完全坏掉，其上面的未消费消息将永远丢失。将来，我们计划提供内置的多机冗余备份，以容忍单个 broker 节点偶然出现问题（当然现在2019也早已经实现了）。</p>
<h2 id="LinkedIn-中-Kafka-的使用"><a href="#LinkedIn-中-Kafka-的使用" class="headerlink" title="LinkedIn 中 Kafka 的使用"></a>LinkedIn 中 Kafka 的使用</h2><p>在本节，简要说明一下 LinkedIn 中是如何使用 Kafka 的。下图是一个我们的简化部署图：</p>
<p><img src="https://i.loli.net/2020/02/09/KIBHRzNQStClj6m.jpg" alt="kafka-deployment.jpg"></p>
<p>我们在每个数据中心部署了一套服务于用户业务的 Kafka 集群，前端业务将产生的各种日志数据批量发送到 Kafka 集群中。我们使用硬件（load balancer）将流量尽量均匀的分发到各个 broker 上去。为了减少网络开销，我们将在线消费者业务和 Kafka 部署在一个物理集群中。</p>
<p>我们还在靠近 Hadoop 集群等其他数据仓库基件的另一个数据中心部署了一套负责离线数据分析的 Kafka 集群。一方面，该Kafka 集群中内置了一组消费者进程，会定期的去从在线 Kafka 集群拉取数据，写入本集群中。另一方面，该集群运行着数据加载作业，定期地从 Kafka 集群中拉取数据，处理后载入 Hadoop 集群和数据仓库中以进行汇总和分析工作。我们还将此集群用来进行原型建模以及一些即时查询分析工作。在不用特别调优的情况下，端到端大概能有 10s 左右的平均延迟，这对我们的需求来说够用了。</p>
<p>当前，我们的 Kafka 集群中每天会产生数以亿计的日志消息，总量大约在数百G字节。一旦我们将现有系统全部转向 Kafka，可以预见到，Kafka 中的数据量级将会迎来一个更显著的增长，并且需要适配更多的数据类型。当运维人员由于软硬件原因将 broker 停机时，再平衡（re-balance）进程能够自动的将消费在多个 broker 中进行重新平衡。</p>
<p>我们还有一套审计系统来检查整个流水线中是否有数据丢失。具体来说，对于每条消息，在生产时会被打上时间戳和生产者主机名的标记；对于数据生产的元信息，即特定的时间窗口内产生的消息个数事件，会定期的被提交到另外的用于监控的 topic 上。于是消费者就可以利用每条消息中的额外信息统计特定时间窗口内该 topic 下收到的消息数量，与监控 topic 中读取的监控消息作比对，以确定是否进行了正确的消费。</p>
<p>我们给 Hadoop 定制了一种 Kafka 的输入格式**[5]<strong>，使得 MapReduce 任务能够以 Kafka 作为数据来源。MapReduce 任务将从 Kafka 中读出的原始数据进行分类聚集、适当压缩等操作，以备将来对这些数据进行高效的处理。MapReduce 任务要求对 Kafka 的消费任务是幂等的，而 Kafka broker 的无状态以及让消费侧</strong>[6]**存储偏移量等特点，让我们可以在 Map 任务失败重启时，从上一次的消费结束处继续消费，从而做到消息消费的不重不漏。 当任务完成时，数据和偏移量都被存储在了 HDFS 上。</p>
<p>我们使用 Avro 作为序列化框架**[7]**，它效率较高且支持类型推导。对于每条信息，我们将消息数据类型对应的模式标识(schema id)以及序列化过后的字节作为 Kafka 的消息净核一起发送。这种模式可以让我们很灵活的对同一个消息主题使用多种消息类。消费者在收到消息时，根据模式标识来获取对应的 Avro 实际编码类型，以将实际数据解码成具体的对象实例。这个转换过程很简单，因为对于每个对象类型，只需要查找一次。</p>
<h2 id="译注"><a href="#译注" class="headerlink" title="译注"></a>译注</h2><p><strong>[1]</strong> Kafka 的论文发表于 2011 年，因此文中的好多现状都是针对当时来说的，到现在（2019年末）消息队列的情况肯定又不一样。</p>
<p><strong>[2]</strong> 在推的模式就有这个问题，如果两个消费者（比如 A 快，B 慢）消费速度差太多，Broker 必然要维护 A 消费完但是 B 还没有消费的那些消息。由于传统消息队列缓存都不太大（因为一般要存内存里），必然很快要达到上限，要么系统爆掉，要么限制快的消费者。但拉的问题在于要保证实时性就得不断地轮询，推拉问题也是一个经典的 tradeoff 问题了。</p>
<p><strong>[3]</strong> 这里的设计明显借鉴了 TCP 的思想，可以说是在应用层实现了<strong>保序</strong>、<strong>确认</strong>和<strong>滑动窗口缓冲区</strong>的设计。</p>
<p><strong>[4]</strong> 一般来说，数据在交付时，由于系统意外宕机、网络抖动等问题，会出现数据条目丢失的情况。在这个情况下，如果我们不进行介入，那么所有就是提供至多一次的语义（at-most-once）。如果我们对丢失的数据条目进行重试，就有可能造成多次交付的情况，因为发送端无法确定接收端是在<strong>接收到数据后</strong>网络出了问题，还是接受前出了问题，无脑重试的话，就有可能造成同一条数据的多次处理，这种情况下我们提供的是至少一次（at-least-once）的交付语义。如果想强行实现恰好一次（exactly-once）的交付语义也不是不可以，比如使用两阶段提交等一致性方法保证数据消费和偏移量更新的原子性，以提供恰好消费一次的语义。但是这样仍有可能出问题，并且使系统复杂度变高，时间耗费也较多。所以一般如果对丢少量数据不敏感，用 at-most-once 就够了，如果敏感，可以用 at-least-once 并在应用层去重。</p>
<p><strong>[5]</strong> 输入格式，input format，是 Haddop MapReduce 适配不同数据源的一个接口，相当于一个转换层。</p>
<p><strong>[6]</strong> 可以依赖 Zookeeper，也可以依赖 Hadoop 对 offset 进行持久化，结合上下文感觉这里说的是后者。</p>
<p><strong>[7]</strong> 这种序列化方式在当时应该是个用户侧的选择而非 Kafka 框架所提供的功能。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>Kafka</tag>
        <tag>日志系统</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark 系统的理论基石 —— RDD</title>
    <url>/2019/11/14/rdd/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>RDD，学名可伸缩的分布式数据集（Resilient Distributed Dataset）。是一种对数据集形态的抽象，基于此抽象，使用者可以在集群中执行一系列计算，而不用将中间结果落盘。而这正是之前 MR 抽象的一个重要痛点，每一个步骤都需要落盘，使得不必要的开销很高。</p>
<p>对于分布式系统，容错支持是必不可少的。为了支持容错，RDD 只支持粗粒度的变换。即，输入数据集是 immutable （或者说只读）的，每次运算会产生新的输出。不支持对一个数据集中细粒度的更新操作。这种约束，大大简化了容错支持，并且能满足很大一类的计算需求。</p>
<span id="more"></span>

<p>初次接触 RDD 的概念的时候，不大能够理解为什么要以数据集为中心做抽象。后来随着不断深入的了解，对数据集的一致性抽象正是计算流水线（pipeline）得以存在和优化的精髓所在。在定义了数据集的基本属性（不可变，分区，依赖关系，存放位置等）后，就可以在此基础上施加各种高阶算子，以构建 DAG 执行引擎，并做适当优化。从这个角度来说，RDD 实在是一种精妙设计。</p>
<p>例行总结一下 RDD 论文的主要设计点有：</p>
<ol>
<li><strong>显式抽象</strong>。将运算中的数据集进行显式抽象，定义了其接口和属性。由于数据集抽象的统一，从而可以将不同的计算过程组合起来进行统一的 DAG 调度。</li>
<li><strong>基于内存</strong>。相较于 MapReduce 中间结果必须落盘，RDD 通过将结果保存在内存中，从而大大降低了单个算子计算延迟以及不同算子之间的加载延迟。</li>
<li><strong>宽窄依赖</strong>。在进行 DAG 调度时，定义了宽窄依赖的概念，并以此进行阶段划分，优化调度计算。</li>
<li><strong>谱系容错</strong>。主要依赖谱系图计算来进行错误恢复，而非进行冗余备份，因为内存实在是有限，只能以计算换存储了。</li>
<li><strong>交互查询</strong>。修改了 Scala 的解释器，使得可以交互式的查询基于多机内存的大型数据集。进而支持类 SQL 等高阶查询语言。</li>
</ol>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="小引"><a href="#小引" class="headerlink" title="小引"></a>小引</h2><p>Dryad 和 MapReduce 是业已流行的大数据分析工具。它们给用户提供了一些高阶算子来使用，而不用去关心底层的分布式和容错细节。但它们都缺少对分布式内存的抽象，不同计算过程之间只能够通过外存来耦合：前驱任务将计算结果写到外存上去，后继任务再将其作为输入加载到内存，然后才能接着执行后继计算任务。这样的设计有两个很大的劣势：复用性差、延迟较高。这对于像 Page-Rand，K-Means，LR 等要求迭代式计算的机器学习算法（需要数据复用）极其不友好；对于一些随机的交互式查询（要求延迟低）也是个灾难。因为他们将大部分的时间都耗费在数据备份、硬盘 IO 和数据序列化之上。</p>
<p>在 RDD 之前，为了解决数据复用的问题，业界已有诸多尝试。包括将中间结果放在内存中的迭代式图计算系统——Pregel，以及将多个 MR 串在一块，缓存循环不变量的 HaLoop。但这些系统只支持受限的计算模型（比如MR），而且只进行隐式[1]的数据复用。如何进行更通用的数据复用，以支持更复杂的查询计算，仍是一个难题。</p>
<p>RDD 正是为解决这个问题而设计，高效地复用数据的一个<strong>数据结构抽象</strong>。RDD 支持数据容错、数据并行；在此之上，能够让用户利用多机内存、控制数据分区、构建一系列运算过程。从而解决很多应用中连续计算过程对于数据复用的需求。</p>
<p>其中比较难的一个设计是如何针对内存数据进行<strong>高效的容错</strong>。现有的一些基于集群内存的系统，比如分布式KV、共享内存、Piccolo 都提供一种可以细粒度的修改的可变数据集抽象。为了支持这种抽象之上的容错，就需要进行数据多机冗余或者操作日志备份。这些操作都会导致多机间大量的数据传输，由于网络带宽远慢于 RAM，使得分布式利用内存这件事失去其优势。</p>
<p>与之相对，RDD 只提供粗粒度的、基于整个数据集的计算接口，即数据集中的所有条目都施加同一种操作。这样一来，为了容错，我们只需要<strong>备份每个操作而非数据本身</strong>（因为是整体更新的）；在某个分区数据出现问题进行错误恢复时，只需要从原始数据集出发，按顺序再算一遍即可。</p>
<p>初看起来，这种计算抽象很受限，但它其实能满足现有的一大类的集群计算需求，包括 MR、 DryadLINQ、 SQL、Pregel 和 HaLoop。并且能满足一些其他计算需求，比如说交互式计算。RDD 的实现系统 Spark，提供类似 DryadLINQ 的高阶算子，应该是第一个提供交互式的集群运算接口。</p>
<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>本节首先给出 RDD 的详细定义，然后介绍下 Spark 的中针对 RDD 的操作接口，继而对比了 RDD 与提供细粒度更新接口的共享内存抽象优劣。最后就 RDD 的局限性讨论一下。</p>
<h3 id="RDD-抽象"><a href="#RDD-抽象" class="headerlink" title="RDD 抽象"></a>RDD 抽象</h3><p>RDD  是一个基于分区的、只读的数据记录集抽象。RDD 只可以通过对持久存储或其他 RDD 进行确定性运算得来，这种运算被称为<strong>变换</strong>。常用的<strong>变换</strong>算子包括：map，filter 和 join。</p>
<p>RDD 没有选择不断的做检查点以进行容错，而是会记下 RDD 从最初的外存的数据集变化而来的变化路径，也就是其<strong>谱系</strong>（lineage）。理论上所有的 RDD 都可以在出错后从外存中依据谱系图进行重建。一般来说，重建的粒度是分区（Partition）而非整个数据集，一来代价更小，二来不同分区可能在不同机器上。</p>
<p>用户可以对 RDD 的两个方面进行控制：持久化和分区控制。对于前者，如果某些 RDD 需要复用，那么用户可以指示系统按照某种策略将其进行持久化。后者来说，用户可以定制分区路由函数，将数据集合中的记录按照某个键值路由到不同分区。比如进行 Join 操作的时候，可以讲待 Join 数据集按照相同的策略进行分区，以并行 Join。</p>
<h3 id="Spark-编程接口"><a href="#Spark-编程接口" class="headerlink" title="Spark 编程接口"></a>Spark 编程接口</h3><p>Spark 通过暴露与编程语言集成的算子来提供操作 RDD 的接口。 其中 RDD 表现为编程语言中的类，而 RDD 的算子为作用于这些类上的函数。之前的系统如 DryadLINQ 和 FlumeJava 也使用了类似的形式。 </p>
<p>用户使用 RDD 时，首先将数据从持久化存储中通过<em>变换</em>（<strong>Transformations</strong>，如 <em>map</em> 或者 <em>filter</em>）将其载入内存，然后可以对 RDD 施加任何系统支持的一系列变换，最后利用<em>动作</em>（<strong>Action</strong>）算子，将 RDD 重新持久化到外存中或者将控制权交还用户。和 DryadLINQ 一样，这个加载-变换-落盘的过程是<strong>声明式</strong>（Declarative，或者说是惰式[2]）的，Spark 在拿到整个拓扑后会利用执行引擎进行执行优化（比如将并行化、流水线化，之后会进一步讨论）。</p>
<p>此外很重要的一个接口是 <em>persist</em>，可以由用户来告诉系统<strong>哪些</strong> RDD 需要持久化，<strong>如何</strong>持久化（本机硬盘还是跨机器存储），如果有多个 RDD 需要持久化，那么<strong>优先级</strong>如何确定。Spark 默认将 RDD 保存在内存中，如果内存不够用了会根据用户配置将数据溢出（spill）到硬盘上。</p>
<h4 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h4><p>假设我们相对存在于 HDFS 上的日志文件，找出错误条目，针对出现 hdfs 关键字的具体条目进行分析。利用 Spark 接口，使用 Scala 语言实现，代码如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">lines = spark.textFile(<span class="string">&quot;hdfs://...&quot;</span>)</span><br><span class="line">errors = lines.filter(_.startsWith(<span class="string">&quot;ERROR&quot;</span>))</span><br><span class="line">errors.persist()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Return the time fields of errors mentioning</span></span><br><span class="line"><span class="comment">// HDFS as an array (assuming time is field</span></span><br><span class="line"><span class="comment">// number 3 in a tab-separated format):</span></span><br><span class="line">errors.filter(_.contains(<span class="string">&quot;HDFS&quot;</span>))</span><br><span class="line">      .map(_.split(’\t’)(<span class="number">3</span>))</span><br><span class="line">      .collect()</span><br></pre></td></tr></table></figure>

<p>第一行基于某个 hdfs 上的文件定义一个 rdd（每一行作为集合中的一个条目）。第二行通过 filter 变换生成新的 rdd，第三行请求 spark 将其结果进行暂存。最后一行是链式操作，以一个 collect 的动作结尾，求出包含 HDFS 关键字的所有行数的各个字段。</p>
<p>其计算的谱系图（lineage）如下：</p>
<p><img src="https://i.loli.net/2020/02/09/dPmJ2nb1zUNGuAo.jpg" alt="rdd-example-lineage.jpg"></p>
<p>有两点需要注意：</p>
<ol>
<li>直到遇到 collect 这个<strong>动作</strong>（Action）之前都没有发生实际的运算。</li>
<li>链式操作时不保存中间结果；</li>
</ol>
<p>由于第三行将结果在内存中进行了缓存，因此还可以基于此做其他动作。比如，计算包含 ‘MySQL’ 关键字的错误条数：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Count errors mentioning MySQL:</span></span><br><span class="line">errors.filter(_.contains(<span class="string">&quot;MySQL&quot;</span>)).count()</span><br></pre></td></tr></table></figure>



<h3 id="RDD-模型的优点"><a href="#RDD-模型的优点" class="headerlink" title="RDD 模型的优点"></a>RDD 模型的优点</h3><p>为了理解 RDD 带来的好处，可以看下面一个表，将 RDD 与 DSM （Distributed Shared Memory）做了详细对比。DSM 在这里是一个很宽泛的抽象，不仅包括一般的内存共享系统，还包括其他支持细粒度的状态更新的框架，比如说 Piccolo、分布式数据库等。</p>
<p><img src="https://i.loli.net/2020/02/09/Jj8GFN5qP3aWZHY.jpg" alt="rdd-compare-dsm-table.jpg"></p>
<p>首先， DSM 和 RDD 最主要的区别在于，DSM 支持对数据集细粒度的更新。即，可以对任意内存位置进行更新。而 RDD 舍弃了这一点，只允许批量的写入数据，从而提高了容错效率：</p>
<ol>
<li>使用 lineage 来按需恢复数据，而不用定期 snapshot，减小了不必要开销。</li>
<li>每个 Partition 出错后可以单独进行恢复，而不用进行全数据集的重建。</li>
</ol>
<p>其次，RDD 的不可变的特点允许系统叫较容易的对某些计算进行迁移。比如说 MR 中的某些 Stragger 任务就可以很方便的迁移到其他计算节点上去，因为其输入数据一定不会被改变，因此不用考虑一致性的问题。</p>
<p>最后还有两个好处值得一提：</p>
<ol>
<li>由于只支持批量计算，因此调度系统可以比较好的利用数据局部性的特点加快运算速度。</li>
<li>如果集群内存不够的话，只要数据支持迭代，就可以分批加载到内存进行运算，或者分批将结果 spill 到外存。如此一来，在内存不够时能提供很优雅的退化操作，并不太损失性能。</li>
</ol>
<h3 id="RDD-不适用的场景"><a href="#RDD-不适用的场景" class="headerlink" title="RDD 不适用的场景"></a>RDD 不适用的场景</h3><p>如前所述，RDD 适用于针对全数据集统一处理的粗粒度变换的抽象。相对的，就不适用于要求对数据进行细粒度的、异步更新的数据集。比如说 web 应用，再比如说爬虫等等。对于这些引用类型，传统的快照+操作日志的容错方式可能更适合一些。如数据库 RAMCloud , Percolator 和 Piccolo。 RDD 的目标在于批量分析型应用，而将这些异步应用的需求留给那些专有系统。</p>
<h2 id="Spark-编程接口-1"><a href="#Spark-编程接口-1" class="headerlink" title="Spark 编程接口"></a>Spark 编程接口</h2><p>Spark 利用 Scala 语言作为 RDD 抽象的接口，因为 Scala 兼顾了精确（其函数式语义适合交互式场景）与高效（使用静态类型）。当然，对于 RDD 本身来说，不限定于任何特定的语言表达。下面从<strong>执行流程</strong>与<strong>代码分发</strong>两个方面来详细说明下 Spark 是如何执行用户代码的。</p>
<p><img src="https://i.loli.net/2020/02/09/aiyjrGJ8IkwtWRY.jpg" alt="rdd-spark-runtime.jpg"></p>
<p>开发者利用 Spark 提供的库编写<em>驱动程序</em> （driver programe）以使用 Spark。驱动程序会定义一到多个 RDD，并对其进行各种变换。Spark 提供的库会连接 Spark 集群，生成计算拓扑，并将拓扑分散到多个 workers 上去进行执行，同时记下变换的谱系（lineage）。这些 workers 是分散在 Spark 集群内各个机器上的常驻进程，它们在内存里保存计算过程中生成的 RDD 的各个分区。</p>
<p>像前面举的例子一样，开发者需要将函数作为参数传给 map 等 Spark 算子。Spark 会将这些函数（或者说<strong>闭包</strong>）序列化为 Java 对象，然后分发给执行节点进行加载。闭包所涉及的变量会被当做上述生成对象的字段值。RDD 本身会被包装成静态类型的参数进行传递。由于 Scala 支持类型推断，大部分例子都省掉了 RDD 数据类型。</p>
<p>尽管 Spark 暴露的 Scala 的 RDD 接口在概念上看起来很简单，但实在实现上有一些很脏的角落，比如说 Scala 的闭包得使用反射， 比如说尽量避免修改 Scala 的解释器。</p>
<h3 id="Spark-中的-RDD-操作"><a href="#Spark-中的-RDD-操作" class="headerlink" title="Spark 中的 RDD 操作"></a>Spark 中的 RDD 操作</h3><p>下表列出了 Spark 中支持的 RDD 操作。如前面所说，<strong>变换</strong>（transformations）是生成新 RDD 的惰性算子，而<strong>动作</strong>（actions）是触发调度的算子，它会返回一个结果或者将数据写到外存中。</p>
<p><img src="https://i.loli.net/2020/02/09/6U1yOcZELsTH5uC.jpg" alt="rdd-operations-table.jpg"></p>
<p>需要注意的是：</p>
<ol>
<li>有些操作如 <em>join</em>，要求操作数 RDD 必须是键值对（key value pairs）。</li>
<li><em>map</em> 是一对一的映射，而 <em>flatMap</em> 是类似于 MapReduce 中一对一或者一对多的映射。</li>
<li><em>save</em> 会将 RDD 进行持久化。</li>
<li><em>groupByKey</em>，<em>reduceByKey</em> 和 <em>sort</em> 都会导致 RDD 中不同分区进行再哈希或者重排。</li>
</ol>
<h2 id="RDD-的表示"><a href="#RDD-的表示" class="headerlink" title="RDD 的表示"></a>RDD 的表示</h2><p>提供 RDD 抽象的一个难点在于，如何高效的<strong>跟踪谱系</strong>并能提供丰富的<strong>变换支持</strong>。最后我们选用了基于图的调度模型，将调度和算子进行了解耦。从而能够在不改变调度模块逻辑的前提下，很方便的增加算子支持。具体来说，RDD 抽象的核心组成主要有以下五个部分：</p>
<ol>
<li><strong>分区集</strong>（partition set）。分区是每个 RDD 的最小构成单元。</li>
<li><strong>依赖集</strong>（dependencies set）。主要是 RDD 间的父子依赖关系。</li>
<li><strong>变换函数</strong>（compute function）。作用于分区上的变换函数，可以由几个父分区计算得到一个子分区。</li>
<li><strong>分区模式</strong>（partition scheme）。该 RDD 的分区是基于<strong>哈希分片</strong>的还是<strong>直接切分</strong>的。</li>
<li><strong>数据放置</strong>（data placement）。知道分区的存放位置可以进行计算优化。</li>
</ol>
<p><img src="https://i.loli.net/2020/02/09/6KVtu2qrYFSMv84.jpg" alt="RDD 抽象接口组成"></p>
<p>在 RDD 的接口设计中最有趣的一个点是如何对 RDD 间的<strong>依赖关系</strong>进行规约。最后发现可以将所有依赖归纳为两种类型：</p>
<ol>
<li><strong>窄依赖</strong>（narrow dependencies）：父 RDD 的分区最多被一个子 RDD 的分区所依赖，比如 <em>map</em>。</li>
<li><strong>宽依赖</strong>（wide dependencies）：父 RDD 的分区可能被多个子 RDD 的分区所依赖，比如 <em>join</em>。</li>
</ol>
<p><img src="https://i.loli.net/2020/02/09/SaPvyV2LtiAhezJ.jpg" alt="宽依赖和窄依赖"></p>
<p>如此归纳的原因主要有两点。</p>
<p><strong>调度优化</strong>。对于窄依赖，可以对分区间进行并行<strong>流水化</strong>调度，先计完成某个窄依赖算子（比如说 map）的分区不用等待其他分区而直接进行下一个窄依赖算子（比如 filter ）的运算。与之相对，宽依赖的要求父 RDD 的所有分区就绪，并进行跨节点的传送后，才能进行计算。类似于 MapReduce 中的 shuffle。</p>
<p><strong>数据恢复</strong>。在某个分区出现错误或者丢失时，窄依赖的恢复更为高效。因为涉及到的父分区相对较少，并且可以并行恢复。而对于宽依赖，由于依赖复杂（如上图，子 RDD 的每个分区都会依赖父 RDD 的所有分区），一个分区的丢失可能就会引起全盘的重新计算。</p>
<p>这样将调度和算子解耦的设计大大简化了变换的实现，大部分变换都可以用20余行代码来实现。由于不需要了解调度细节，任何人都可以很快的上手实现一个新的变换。试举几例：</p>
<p><strong>HDFS 文件</strong>：<em>partitions</em> 函数返回 HDFS 文件的所有 block，每个 block 被当做一个 partition。 <em>preferredLocations</em> 返回每个 block 所在的位置，<em>Iterator</em> 会对每个 block 进行读取。</p>
<p><strong>map</strong>：在任意 RDD 上调用 map 会返回一个 MappedRDD 对象，该对象的 <em>partitions</em> 函数和 <em>preferredLocations</em> 与父 RDD 保持一致。对于 <em>iterator</em>，只需要将传给 map 算子的函数以此作用到其父 RDD 的各个分区即可。</p>
<p><strong>union</strong>: 在两个 RDD 上调用 union 会返回一个新的 RDD，该 RDD 的每个分区由对应的两个父 RDD 通过窄依赖计算而来。</p>
<p><strong>sample</strong>：抽样函数和 map 大体一致。但该函数会给每个分区保存一个随机数种子来决定父 RDD 的每个记录是否保留。</p>
<p><strong>join</strong>：在两个 RDD 上调用 join 操作可能会导致两个窄依赖（比如其分区都是按待 join 的key 哈希的），两个宽依赖，或者混合依赖。每种情况下，子 RDD 都会有一个 <em>partitioner</em> 函数，或继承自父分区，或是默认的hash 分区函数。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>Spark 最初版本（论文里提到的），只有 1.4w 行 Scala 代码，由 mesos 管理资源分配，可以和 Hadoop 生态共用资源，并从 Hadoop&#x2F;Hbase 中加载数据。对于 Spark 的实现，有几个值得一说的点： Job 调度，交互式解释器，内存管理和检查点机制（checkpointing）。</p>
<h3 id="Job-调度"><a href="#Job-调度" class="headerlink" title="Job 调度"></a>Job 调度</h3><p>Spark 调度设计依赖于上一节提到的 RDD 的抽象。它的调度策略和 Dryad 有点像，但又不尽相同。在用户在某个 RDD 上调用 Action 类型（count，save 等等）的算子时，调度器就会根据用户代码中调用算子的顺序生成计算拓扑。我们把每一个变换前后的 RDD 当做<em>点</em>，算子产生的 RDD 间的依赖&#x2F;父子关系当做<em>边</em>，如此构成一个<em>有向无环图</em>（DAG）。为了减小传输，调度器会将几个连续的计算进行归并，称为<em>阶段</em>（Stage），进行阶段归并的依据为是否需要 shuffle，也即是否为宽依赖。这样，会形成一个新的由阶段组成的更精简的 DAG。</p>
<p><img src="https://i.loli.net/2020/02/09/EYIeyaDqo3cmdFu.png" alt="RDD 阶段划分"></p>
<p>之后，调度器会从目标 RDD 出发，沿着 DAG 图中的边往前遍历，对每个不在内存中的<strong>分区</strong>进行计算。如果需要计算的分区已经在内存中了，则直接利用结果即可，如上图所示。</p>
<p>然后，调度器会将任务调度到离其依赖 RDD 的 Partition 近的地方去：</p>
<ol>
<li>如果 Partition 在某节点的内存中，则将任务的调度到该节点上。</li>
<li>如果 Partition 还在硬盘上，则将任务调度到 preferredLocations 函数返回的地方去（如 HDFS 文件）。</li>
</ol>
<p>对于宽依赖，Spark 和 MR 一样，会将其中间结果输出持久化起来，以简化容错。如果某个 Stage 的父 RDD 不可用，调度器就会新提交一些<strong>并行运行</strong>的任务，来生成这些缺失的分区。不过现在 Spark 还不能对调度器本身故障进行恢复，虽然看起来对 RDD 的谱系图进行冗余备份或许是一个简单可行的方案。</p>
<p>最后，现在仍是由用户 Driver 程序调用 Action 算子来触发调度任务。但我们正在探索维持一些周期性的检查性任务，对 RDD 中某些缺失的分区进行补足。</p>
<h3 id="解释器集成"><a href="#解释器集成" class="headerlink" title="解释器集成"></a>解释器集成</h3><p>像 Python 和 Ruby 一样，Scala 提供交互式的 shell 环境。由于 Spark 将数据保存在内存中，我们希望可以借助 Scala 的这个交互式环境让用户对大数据集进行交互式实时的查询。</p>
<p>Scala 的解释器对用户代码进行解释执行的通常做法是，将用户键入的每一行 Scala 命令编译成一个 Java Class 字节码，然后将其加载到 JVM 中。该类包含一个初始化过的单例实例，实例中包含用户定义的变量和函数。比如，用户输入：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> x = <span class="number">5</span></span><br><span class="line">println(x)</span><br></pre></td></tr></table></figure>

<p>Scala 解释器会针对第一行生成一个叫做 <code>Line1</code> 的类，其中有一个 x 的字段，并且将第二行编译为：<code>println(Line1.getInstance().x)</code></p>
<p>为了让 Scala 解释器能在分布式环境运行，我们在 Spark 中对其进行了以下修改：</p>
<ol>
<li><strong>类代码传输（Class shipping）</strong>：为了让工作节点（Worker Nodes）可以拉取驱动节点（Driver Node）上解释器用户输入编译成的字节码，我们让解释器可以通过 HTTP 将每个类的访问开放出来。</li>
<li><strong>代码生成修改（Modified  code generation）</strong>：Scala 解释器在处理不同行的访问时，会通过一个静态方法来获取其<strong>初始化后</strong>单例，进而访问上一行的变量 <code>Line.x</code>。但是我们只能通过 HTTP 传字节码而没有将初始化后实例（即 x 已经被赋值）传过来，因此工作节点不能访问到 x。因此我们改变了代码生成逻辑，使得不同行之间能够直接引用实例。</li>
</ol>
<p>下图反映了我们修改后的 Scala 解释器生成 Java 对象的过程：</p>
<p><img src="https://i.loli.net/2020/02/09/f1pw8jLhYeNtEoO.png" alt="spark 解释器"></p>
<p>我们发现解释器在对大型数据集进行交互式查询时很有帮助，我们计划对更高级的查询语言进行支持，如 SQL。</p>
<h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><p>Spark 提供了三种存储 RDD 的方式：</p>
<ol>
<li>内存中没有序列化过的 Java 对象</li>
<li>内存中序列化过的数据</li>
<li>磁盘</li>
</ol>
<p>由于 Spark 跑在 JVM 上，因此第一种存储方式访问最快，第二种允许用户牺牲一点性能以换取更高效的内存利用。当数据尺度太大以至于内存装不下的时候，第三种方式很有用。</p>
<p>为了有效的利用有限的内存，我们在 RDD 分区级别上进行 LRU 式的驱逐策略。即，当我们新计算出一个 RDD 的分区时，如果发现内存不够用，就会从内存中驱逐出去一个最久没有使用过的 RDD 的分区。但是，如果这个最久没有使用过的分区和新计算出的分区属于同一个 RDD，我们会接着寻找，直到找到一个和当前分区不属于一个 RDD 并且最久没用过的分区。因为 Spark 的大部分计算会施加于整个 RDD 上，这样做可以防止这些分区被反复的计算-驱逐。这个策略在论文成文时用的很好，不过，我们仍然提供给了用户进行深度控制的接口——指定存储优先级。</p>
<p>现在每个 Spark 实例拥有自己的分立的内存空间，我们计划将来提供跨 Spark 实例的统一的内存管理。</p>
<h3 id="检查点机制"><a href="#检查点机制" class="headerlink" title="检查点机制"></a>检查点机制</h3><p>尽管所有失败的 RDD 都可以通过谱系（lineage）来重新计算得出，但是对于某些谱系特别长的 RDD 来说，这将是一个很耗时间的操作，因此提供 RDD 级别的外存检查点（checkpointing）可能会很有用。</p>
<p>对于具有很长谱系图，并且谱系图中存在很多宽依赖的 RDD，在外存上做检查点会很有帮助，因为某一两个的分区可能会引起全盘的重算，对于这种又臭又长的计算拓扑来说，依据谱系图重算无疑非常浪费时间。而对于只有窄依赖的、不那么长谱系图来说，在外存做检查点可能有些得不偿失，因为他们可以很简单的并行计算出来。</p>
<p>Spark 现阶段提供检查点的 API （给 persist 函数传 REPLICATE 标志），然后由用户来决定是否对其持久化。但我们在思考，是否可以进行一些自动的检查点计算。由于调度器知道每个数据集的内存占用以及计算使用时间，我们或许可以选择性的对某些关键 RDD进行持久化以最小化宕机恢复时间。</p>
<p>最后，由于 RDD 的只读特性，我们在做检查点时不用像通用共享内存模型那样过分考虑一致性的问题，因此可以用后台线程默默地干这些事情而不用影响主要工作流，也不用使用复杂的分布式的快照算法来解决一致性问题。</p>
<h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><p>[1] <strong>隐式与显示显式</strong>：在这里可以理解为，显式是把数据集这个概念完整的构造出来，定义他的内涵和边界，并基于其上做一些外延拓展。而隐式只是事实上复用了数据，但并没有定义被复用的数据格式。</p>
<p>[2] <strong>声明式（Declarative）语言与命令式（Imperative）语言</strong>：前者例子有 SQL，HTML；后者例子最常见的有 Shell，其他的常见编程语言 C，Java，Python 也属于此列。前者的好处在于将”干什么”和”怎么干”这两件事解耦，这样一来就可以开发不同的执行引擎，针对不同场景来优化”怎么干”这件事。而后者会告诉机器以特定的顺序执行特定的操作，与直觉一致，是一般编程语言的路子。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>spark</tag>
        <tag>rdd</tag>
        <tag>数据处理</tag>
      </tags>
  </entry>
  <entry>
    <title>Bazel 构建 Golang 项目</title>
    <url>/2019/12/07/bazel-build-golang/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/DKg7uSkQoP9U2db.png" alt="bazel-golang.png"></p>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p><span class="exturl" data-url="aHR0cHM6Ly9iYXplbC5idWlsZC8=">Bazel<i class="fa fa-external-link-alt"></i></span> 是一款谷歌开源的非常优秀的构建系统。它的定位，用官方的话来说是：</p>
<blockquote>
<p>a fast, scalable, multi-language and extensible build system</p>
</blockquote>
<p>大意为：</p>
<blockquote>
<p>一款<strong>速度极快</strong>、<strong>可伸缩</strong>、<strong>跨语言</strong>并且<strong>可扩展</strong>的构建系统</p>
</blockquote>
<p>使用 Bazel 构建 golang 项目，除了 Bazel 本身特性外，还需要了解针对 golang 的扩展包 <em><strong>rules_go</strong></em>。另外，可以使用 <em><strong>bazel gazelle</strong></em> 来进行一些自动生成的工作。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="Bazel-特点概要"><a href="#Bazel-特点概要" class="headerlink" title="Bazel 特点概要"></a>Bazel 特点概要</h2><p>对于官方给出的 Bazel 四个特点，下面来依次探讨。</p>
<h3 id="快-Fast"><a href="#快-Fast" class="headerlink" title="快(Fast)"></a>快(Fast)</h3><p>Bazel 的构建过程很快，它集合了之前构建系统的加速的一些常见做法。包括：</p>
<ol>
<li><strong>增量编译</strong>。只重新编译必须的部分，即通过依赖分析，只编译修改过的部分及其影响的路径。</li>
<li><strong>并行编译</strong>。将没有依赖的部分进行并行执行，可以通过 <code>--jobs</code> 来指定并行流的个数，一般可以是你机器 CPU 的个数。遇到大项目马力全开时，Bazel 能把你机器的 CPU 各个核都吃满。</li>
<li><strong>分布式&#x2F;本地缓存</strong>。Bazel 将构建过程视为<strong>函数式</strong>的，只要输入给定，那么输出就是一定的。而不会随着构建环境的不同而改变（当然这需要做一些限制），这样就可以分布式的缓存&#x2F;复用不同模块，这点对于超大项目的速度提升极为明显。</li>
</ol>
<h3 id="可伸缩-scalable"><a href="#可伸缩-scalable" class="headerlink" title="可伸缩(scalable)"></a>可伸缩(scalable)</h3><p>Bazel 号称无论什么量级的项目都可以应对，无论是超大型单体项目（monorepo）、还是超多库的分布式项目（multirepo）。Bazel 还可以很方便的集成 CD&#x2F;CI ，并在云端利用分布式环境进行构建。</p>
<p>它使用<strong>沙箱机制</strong>进行编译，即将所有编译依赖隔绝在一个沙箱中，比如编译 golang 项目时，不会依赖你本机的 GOPATH，从而做到同样源码、跨环境编译、输出相同，即构建的确定性。</p>
<h3 id="跨语言-multi-language"><a href="#跨语言-multi-language" class="headerlink" title="跨语言(multi-language)"></a>跨语言(multi-language)</h3><p>如果一个项目不同模块使用不同的语言，利用 Bazel 可以使用<strong>一致的风格</strong>来管理项目外部依赖和内部依赖。典型的项目如 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JheS1wcm9qZWN0L3JheQ==">Ray<i class="fa fa-external-link-alt"></i></span>。该项目使用 C++ 构建 Ray 的核心调度组件、通过 Python&#x2F;Java 来提供多语言的 API，并将上述所有模块用单个 repo 进行管理。如此组织使其项目整合相当困难，但 Bazel 在此处理的游刃有余，大家可以去该 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JheS1wcm9qZWN0L3JheQ==">repo<i class="fa fa-external-link-alt"></i></span> 一探究竟。</p>
<h3 id="可扩展-extensible"><a href="#可扩展-extensible" class="headerlink" title="可扩展(extensible)"></a>可扩展(extensible)</h3><p>Bazel 使用的语法是基于 Python 裁剪而成的一门语言：Startlark。其<strong>表达能力强大</strong>，往小了说，可以使用户自定义一些 rules （类似一般语言中的函数）对构建逻辑进行复用；往大了说，可以支持第三方编写适配新的语言或平台的 rules 集，比如 rules go。 Bazel 并不原生支持构建 golang 工程，但通过引入 rules go ，就能以比较一致的风格来管理 golang 工程。</p>
<h2 id="Bazel-主要文件"><a href="#Bazel-主要文件" class="headerlink" title="Bazel 主要文件"></a>Bazel 主要文件</h2><p>使用 Bazel 管理的项目一般包含以下几种 Bazel 相关的文件：<em>WORKSPACE</em>，<em>BUILD(.bazel)<em>，</em></em>.bzl* 和 *.bazelrc *等。其中 WORKSPACE 和 .bazelrc 放置于项目的根目录下，BUILD.bazel 放项目中的每个文件夹中（包括根目录）， *.bzl 文件可以根据用户喜好自由放置，一般可放在项目根目录下的某个专用文件夹（比如 build）中。</p>
<h3 id="WORKSPACE"><a href="#WORKSPACE" class="headerlink" title="WORKSPACE"></a>WORKSPACE</h3><ol>
<li>定义项目根目录和项目名。</li>
<li>加载 Bazel 工具和 rules 集。</li>
<li>管理项目外部依赖库。</li>
</ol>
<h3 id="BUILD-bazel"><a href="#BUILD-bazel" class="headerlink" title="BUILD.(bazel)"></a>BUILD.(bazel)</h3><p>该文件主要针对其所在文件夹进行<strong>依赖解析</strong>（label）和<strong>目标定义</strong>（bazel target）。拿 go 来说，构建目标可以是 go_binary、go_test、go_library 等。</p>
<p>Bazel 的之前版本用的文件名是 <em>BUILD</em> ，但是在一些大小写不区分的系统上，它很容易跟 build 文件混淆，因此后来改为了显式的 <em>BUILD.bazel</em> 。如果项目中同时存在两者，Bazel 更倾向于使用后者。对于所有的新项目，都推荐使用显式的 <em>BUILD.bazel</em>。github 上有一些讨论在<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JhemVsYnVpbGQvcnVsZXNfZ28vaXNzdWVzLzg2Ng==">这里<i class="fa fa-external-link-alt"></i></span>。</p>
<p>为了引用一个依赖，Bazel 使用 <em>label</em> 语法对所有的包进行唯一标识，其格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@workerspace_name//path/of/package:target</span></span><br></pre></td></tr></table></figure>

<p>比如，go 中常用的一个日志库 logrus 的 label 为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@com_github_sirupsen_logrus//:go_default_library</span></span><br></pre></td></tr></table></figure>

<p>如果是本项目中的包路径，可以将 <code>//</code> 之前的 workspace 名字省去。 </p>
<h3 id="自定义-rule-bzl"><a href="#自定义-rule-bzl" class="headerlink" title="自定义 rule (*.bzl)"></a>自定义 rule (*.bzl)</h3><p>如果你的项目有一些复杂构造逻辑、或者一些需要复用的构造逻辑，那么可以将这些逻辑以函数形式保存在 .bzl 文件，供 WORKSPACE 或者 BUILD 文件调用。其语法跟 Python 类似：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">third_party_http_deps</span>():</span><br><span class="line">    http_archive(</span><br><span class="line">        name = <span class="string">&quot;xxxx&quot;</span>,</span><br><span class="line">        ...</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    http_archive(</span><br><span class="line">        name = <span class="string">&quot;yyyy&quot;</span>,</span><br><span class="line">        ...</span><br><span class="line">    )</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="配置项-bazelrc"><a href="#配置项-bazelrc" class="headerlink" title="配置项 .bazelrc"></a>配置项 .bazelrc</h3><p>其中 rc 后缀的命名方式是个计算机中经典的小习俗，感兴趣可以看看 StackOverflow <span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvMTEwMzA1NTIvd2hhdC1kb2VzLXJjLW1lYW4taW4tZG90LWZpbGVz">这个回答<i class="fa fa-external-link-alt"></i></span>。简单的说，该文件用来配置对应的命令运行时的一些参数。常见的如 .vimrc，.bashrc 等。</p>
<p>对于 Bazel 来说，如果某些构建动作都需要某个参数，就可以将其写在此配置中，从而省去每次敲命令都重复输入该参数。举个 Go 的例子：由于国情在此，构建、测试和运行时可能都需要 GOPROXY，则可以配置如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># set GOPROXY</span></span><br><span class="line"><span class="built_in">test</span> --action_env=GOPROXY=https://goproxy.io</span><br><span class="line">build --action_env=GOPROXY=https://goproxy.io</span><br><span class="line">run --action_env=GOPROXY=https://goproxy.io</span><br></pre></td></tr></table></figure>



<h2 id="Bazel-构建-golang-项目"><a href="#Bazel-构建-golang-项目" class="headerlink" title="Bazel 构建 golang 项目"></a>Bazel 构建 golang 项目</h2><p>在有了上面 Bazel 的基础知识后，构建 golang 项目还需要了解两个概念：rules_go 和 bazel gazelle。</p>
<h4 id="rules-go"><a href="#rules-go" class="headerlink" title="rules_go"></a>rules_go</h4><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JhemVsYnVpbGQvcnVsZXNfZ28=">rules_go<i class="fa fa-external-link-alt"></i></span> 是一个 Bazel 的扩展包，Bazel 可以编译 Go。它由一系列的 rule 构成，包括 go_libray\go_binary\go_test，支持 vendor、交叉编译；可以方便集成 protobuf 、cgo 、gogo、nogo等工具。</p>
<p>它会在 Bazel 的沙箱中进行编译，不依赖本地 GOROOT&#x2F;GOPATH，而是自动下载对应 Go 版本，从而可以在不同平台上进行一致性的编译。</p>
<h4 id="bazel-gazelle"><a href="#bazel-gazelle" class="headerlink" title="bazel gazelle"></a>bazel gazelle</h4><p>Gazelle 是一个自动生成 Bazel 编译文件工具，包括给 WORKSPACE 添加外部依赖、扫描源文件依赖自动生成 BUILD.bazel 文件等。Gazelle 原生支持 Go 和 protobuf，当然可以通过扩展来支持其他语言和规则。Gazelle 可以使用  bazel 命令结合 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JhemVsYnVpbGQvYmF6ZWwtZ2F6ZWxsZSNiYXplbC1ydWxl">gazelle rule<i class="fa fa-external-link-alt"></i></span> 运行，也可以下载使用单独的 Gazelle 的命令行工具。</p>
<ul>
<li><strong>自动添加外部依赖</strong></li>
</ul>
<p>用 <code>bazel run //:gazelle update-repos  repo-uri</code>  可以从 go.mod 导入对应依赖包。</p>
<p>比如想要往项目中增加 Kafka 的 segmentio 的 go client 包，只需要在项目根目录下执行命令： <code>bazel run //:gazelle update-repos  github.com/segmentio/kafka-g</code></p>
<p>Gazelle 便会自动增加一条依赖到 WORKSPACE 文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">go_repository(</span><br><span class="line">    name = &quot;com_github_segmentio_kafka_go&quot;,</span><br><span class="line">    importpath = &quot;github.com/segmentio/kafka-go&quot;,</span><br><span class="line">    sum = &quot;h1:Mv9AcnCgU14/cU6Vd0wuRdG1FBO0HzXQLnjBduDLy70=&quot;,</span><br><span class="line">    version = &quot;v0.3.4&quot;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>自动生成构建文件</strong></li>
</ul>
<p>Gazelle 能够自动生成每个目录下的 BUILD.bazel 文件，只需要简单的两步：</p>
<ol>
<li><p>在项目根目录的 BUILD.bazel 中配置<strong>加载</strong>并<strong>配置</strong> Gazelle：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">load(&quot;@bazel_gazelle//:def.bzl&quot;, &quot;gazelle&quot;)</span><br><span class="line"></span><br><span class="line"># gazelle:prefix your/project/url</span><br><span class="line">gazelle(</span><br><span class="line">    name = &quot;gazelle&quot;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>需要注意的是 <code>#</code> 后面的内容对于 Bazel 而言是注释，对于 Gazelle 来说却是一种语法，会被 Gazelle 运行时所使用。当然 Gazelle 除了可以通过 bazel rule 运行，也可以单独在命令行中执行。</p>
</li>
<li><p>在根目录下执行 <code>bazel run //:gazelle</code></p>
</li>
</ol>
<h3 id="一些实践"><a href="#一些实践" class="headerlink" title="一些实践"></a>一些实践</h3><p>Bazel 有一些比较实用的实践，比如使用 http_archive 下载确定版本的外部依赖包、使用 stamp 变量注入、打包和发布等等。可以多去一些有很好的 Bazel 构建项目实践的开源项目中去看看：</p>
<ul>
<li><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVybmV0ZXMvdGVzdC1pbmZyYQ==">github.com&#x2F;kubernetes&#x2F;test-infra<i class="fa fa-external-link-alt"></i></span>（go 语言项目最佳实践，比较全面的 bazel 深度使用）</p>
</li>
<li><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVybmV0ZXMvcmVwby1pbmZyYQ==">github.com&#x2F;kubernetes&#x2F;repo-infra<i class="fa fa-external-link-alt"></i></span>（go 语言项目最佳实践，配置和脚本非常精妙）</p>
</li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Bazel</tag>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>构建系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang 笔记（一）：值方法和指针方法（Value Methods vs Pointer Methods）</title>
    <url>/2020/01/06/go-value-pointer-method/</url>
    <content><![CDATA[<h2 id="小引"><a href="#小引" class="headerlink" title="小引"></a>小引</h2><p>最近在写 Go 代码时需要给某个 struct 定制一个字符串转换方法 </p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ms MyStruct)</span></span> String() <span class="type">string</span></span><br></pre></td></tr></table></figure>

<p>但是在实现是考虑选用 value methods 还是 pointer methods 方式时纠结了起来。</p>
<p> Go 的语法糖使得这两种方式在调用上是一致的，这让我一时难以抉择孰优孰劣，于是决定深入探究一下其背后原理以便之后能写出更<strong>地道</strong>（idiomatic）的 Go 代码。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h2><p>在官方 <span class="exturl" data-url="aHR0cHM6Ly9nb2xhbmcub3JnL2RvYy9lZmZlY3RpdmVfZ28uaHRtbCNwb2ludGVyc192c192YWx1ZXM=">effective go<i class="fa fa-external-link-alt"></i></span> 文档中，对两者区别其实是有精确描述的：</p>
<blockquote>
<p>The rule about pointers vs. values for receivers is that value methods can be invoked on pointers and values, but pointer methods can only be invoked on pointers.</p>
</blockquote>
<blockquote>
<p>There is a handy exception, though. When the value is addressable, the language takes care of the common case of invoking a pointer method on a value by inserting the address operator automatically.</p>
</blockquote>
<p>大意如下：</p>
<ol>
<li>值方法（value methods）可以通过指针和值调用，但是指针方法（pointer methods）只能通过指针来调用。</li>
<li>但有一个例外，如果某个值是可寻址的（addressable，或者说<em>左值</em>），那么编译器会在值调用指针方法时自动插入取地址符，使得在此情形下看起来像指针方法也可以通过值来调用。</li>
</ol>
<p>看了这个解释心里有一句 mmp，不值当讲不当讲。Go 的语法糖初用起来很爽，但是用的越多反而发现会引入很多的语义上的复杂性，给你的心智带来极大负担。比如说 type assertion、embedding、自动解引用、自动插入取地址符、自动插入分号等等，不一一吐槽。只能说都是 trade off，做人不能太贪，不能既要又要是吧。</p>
<p>多言易成妄语，直接上小例子：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">&quot;fmt&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Foo <span class="keyword">struct</span> &#123;</span><br><span class="line">  name <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *Foo)</span></span> PointerMethod() &#123;</span><br><span class="line">  fmt.Println(<span class="string">&quot;pointer method on&quot;</span>, f.name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f Foo)</span></span> ValueMethod() &#123;</span><br><span class="line">  fmt.Println(<span class="string">&quot;value method on&quot;</span>, f.name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewFoo</span><span class="params">()</span></span> Foo &#123; <span class="comment">// 返回一个右值</span></span><br><span class="line">  <span class="keyword">return</span> Foo&#123;name: <span class="string">&quot;right value struct&quot;</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  f1 := Foo&#123;name: <span class="string">&quot;value struct&quot;</span>&#125;</span><br><span class="line">  f1.PointerMethod() <span class="comment">// 编译器会自动插入取地址符，变为 (&amp;f1).PointerMethod()</span></span><br><span class="line">  f1.ValueMethod()</span><br><span class="line"></span><br><span class="line">  f2 := &amp;Foo&#123;name: <span class="string">&quot;pointer struct&quot;</span>&#125;</span><br><span class="line">  f2.PointerMethod() </span><br><span class="line">  f2.ValueMethod() <span class="comment">// 编译器会自动解引用，变为 (*f2).PointerMethod()</span></span><br><span class="line"></span><br><span class="line">  NewFoo().ValueMethod()</span><br><span class="line">  NewFoo().PointerMethod() <span class="comment">// Error!!!</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>最后一句报错如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">./pointer_method.<span class="keyword">go</span>:<span class="number">34</span>:<span class="number">10</span>: cannot call pointer method on NewFoo()</span><br><span class="line">./pointer_method.<span class="keyword">go</span>:<span class="number">34</span>:<span class="number">10</span>: cannot take the address of NewFoo()</span><br></pre></td></tr></table></figure>

<p>看来编译器首先试着给 <code>NewFoo() </code>返回的右值调用 pointer method，出错；然后试图给其插入取地址符，未果，就只能报错了。</p>
<p>至于左值和右值的区别，大家感兴趣可以自行搜索一下。大致来说，最重要区别就是<strong>是否可以被寻址</strong>，可以被寻址的是左值，既可以出现在赋值号左边也可以出现在右边；不可以被寻址的即为右值，比如函数返回值、字面值、常量值等等，只能出现在赋值号右边。</p>
<h2 id="取舍"><a href="#取舍" class="headerlink" title="取舍"></a>取舍</h2><p>对于某个特定场景，两者如何取舍其实和另一个问题等价：就是你在定义函数时如何传参——是传值还是传指针。</p>
<p>比如上述例子：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *Foo)</span></span> PointerMethod() &#123;</span><br><span class="line">  fmt.Println(<span class="string">&quot;pointer method on &quot;</span>, f.name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f Foo)</span></span> ValueMethod() &#123;</span><br><span class="line">  fmt.Println(<span class="string">&quot;value method on&quot;</span>, f.name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以转换为下面两个函数进行考虑：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">PointerMethod</span><span class="params">(f *Foo)</span></span> &#123;</span><br><span class="line">  fmt.Println(<span class="string">&quot;pointer method on &quot;</span>, f.name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ValueMethod</span><span class="params">(f Foo)</span></span>  &#123;</span><br><span class="line">  fmt.Println(<span class="string">&quot;value method on&quot;</span>, f.name)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>用 Go 的术语来说，就是将函数的 receiver 看做是 argument。</p>
<p>那么传值还是传指针呢？这几乎是各个语言都会遇到的一个灵魂拷问。当然， Java 第一个表示不服，这里不展开，感兴趣自行 google。</p>
<p>在定义 receiver 为值还是指针时，主要有以下几个考虑点：</p>
<ol>
<li><strong>方法是否需要修改 receiver 本身</strong>。如果需要，那 receiver 必然要是指针了。</li>
<li><strong>效率问题</strong>。如果 receiver 是值，那在方法调用时一定会产生 struct 拷贝，而大对象拷贝代价很大哦。</li>
<li><strong>一致性</strong>。对于同一个 struct 的方法，value method 和 pointer method 混杂用肯定是不优雅的啦。</li>
</ol>
<p>那啥时候用 value method 呢？很简单的不可变对象使用 value method可以减轻 gc 的负担，貌似也就这些好处了。因此请记住：</p>
<blockquote>
<p>遇事不决请用 pointer method.</p>
</blockquote>
<p>当然，Go 大大们怕你还是有疑问，于是帮你详细列了一些常见的 case，请看这里：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvbGFuZy9nby93aWtpL0NvZGVSZXZpZXdDb21tZW50cyNyZWNlaXZlci10eXBl">https://github.com/golang/go/wiki/CodeReviewComments#receiver-type<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>effective go：<span class="exturl" data-url="aHR0cHM6Ly9nb2xhbmcub3JnL2RvYy9lZmZlY3RpdmVfZ28uaHRtbCNwb2ludGVyc192c192YWx1ZXM=">https://golang.org/doc/effective_go.html#pointers_vs_values<i class="fa fa-external-link-alt"></i></span></li>
<li>golang faq：<span class="exturl" data-url="aHR0cHM6Ly9nb2xhbmcub3JnL2RvYy9mYXEjbWV0aG9kc19vbl92YWx1ZXNfb3JfcG9pbnRlcnM=">https://golang.org/doc/faq#methods_on_values_or_pointers<i class="fa fa-external-link-alt"></i></span></li>
<li>golang code review comments: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvbGFuZy9nby93aWtpL0NvZGVSZXZpZXdDb21tZW50cyNyZWNlaXZlci10eXBl">https://github.com/golang/go/wiki/CodeReviewComments#receiver-type<i class="fa fa-external-link-alt"></i></span></li>
<li>stackoverflow: <span class="exturl" data-url="aHR0cHM6Ly9zdGFja292ZXJmbG93LmNvbS9xdWVzdGlvbnMvMjc3NzUzNzYvdmFsdWUtcmVjZWl2ZXItdnMtcG9pbnRlci1yZWNlaXZlcg==">https://stackoverflow.com/questions/27775376/value-receiver-vs-pointer-receiver<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>value method</tag>
        <tag>pointer method</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 2020 Raft 实现细节备忘</title>
    <url>/2020/01/18/raft-implement-points/</url>
    <content><![CDATA[<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>18年的时候做过一些 6.824，旧文<a href="https://www.qtmuniao.com/categories/courses/">在此</a>，无奈做到 Part 2C，无论如何也跑不过测试，便一直搁置起来。但在后来的日子，却时时念起此门神课，心下伤感。拖到今日，终于可以来还愿了。</p>
<p>这次能跑过所有测试，原因有三：一来，之前做过一次，很多原理还留有印象；二来，这一年多在工作上有了很多分布式系统的实践；三来，golang 的驾驭上也精进了一些。但是在做的过程中，仍然遇到了大量令人纠结的细节，为了方便日后回顾，将这些细节梳理一下，记在此处。若能好巧对其他做此门课的人有些微启发，则又是快事一件了。</p>
<h2 id="6-824-与-Raft"><a href="#6-824-与-Raft" class="headerlink" title="6.824 与 Raft"></a>6.824 与 Raft</h2><p><span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQv">6.824<i class="fa fa-external-link-alt"></i></span> 是一门关于分布式系统的非常棒的公开课，做课程实验的过程中时时惊叹于其构思之精巧、材料准备之翔实。MIT 的大师们能将这样精华的课程开放出来，实乃名校和大师们的气度，更是我们计算机人的幸事。</p>
<p>Raft 是一个面向理解的分布式共识（consensus）协议。分布式共识算法是分布式领域非常非常经典的问题，同时也是分布式系统中非常难的一块，直观的说，就如同流沙上打下分布式系统大楼的地基。不可靠的网络、易故障的主机，造成的状态变化之复杂，实在不是一般人能在脑中模拟得了的。本人愚钝，只能是感性把握加细节堆叠，堪堪有些认识。说回 Raft，有同领域 Paxos 珠玉在前，何以 Raft 仍能脱颖而出？应该是抓住了以下两点：</p>
<ol>
<li><strong>易于理解</strong>。Paxos 是出了名的难以理解，因此也就难以飞入寻常百姓家。而 Raft 通过解耦出多个模块，将算法复杂度进行降维，大大降低了一般人的理解难度。此外，Raft 还有很多精巧的设计，以尽可能避免引入复杂度，从而进一步减轻大家的心智负担。</li>
<li><strong>易于实现</strong>。易于理解客观上会导致利于实现，但不等同于就能据此产出优秀系统。如果理解流于感性，则实现成空中楼阁。Raft 论文的厉害之处就在于既有感性把握又有细节组织，几乎就是一个系统的设计文档，还是详细设计文档。</li>
</ol>
<p>要想做好该<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9sYWItUmFmdC5odG1s">实验<i class="fa fa-external-link-alt"></i></span>，需要涉猎大量的材料，我把实验中提到的和我看到的汇总在文末。当然，还有英文劝退。虽然我最后测试用例都过了，但仍有很多没实现好的点以及不理解之处。</p>
<p>注：后续，2023 年<span class="exturl" data-url="aHR0cHM6Ly9hdjZodWYyZTFrLmZlaXNodS5jbi9kb2N4L0pDc3NkbGdGNG9SQURjeHhMcW5jUHBSQ241Yg==">又做了一次<i class="fa fa-external-link-alt"></i></span>，终于理清楚了大部分点。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h2><p>该实验（2020年版本）分为三个部分，分别是 Part 2A：leader 选举、Part 2B： 日志同步、lab2C：状态备份。</p>
<p>我在实现的时候没有用过多的 channel，状态都是通过加锁来阻塞式改变的。我注意到网上有一些实现将所有状态变化都用 channel 控制，这样异步实现可能会效率高些，但可读性稍差。我的实现基本遵从论文叙述，在代码组织上可以概括为<strong>三个状态</strong>和<strong>三个 Loop</strong>。</p>
<h3 id="三个状态"><a href="#三个状态" class="headerlink" title="三个状态"></a><strong>三个状态</strong></h3><p><em>Follower</em>、<em>Candidate</em>、<em>Leader</em>。并据此定义了三个函数：<em>becomeFollower</em>、<em>becomeCandidate</em>、<em>becomeLeader</em>，分别封装了一些 Raft Peer 内部的状态变化。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> becomeCandidate() &#123;</span><br><span class="line">  rf.role = CANDIDATE</span><br><span class="line">  rf.currentTerm++</span><br><span class="line">  rf.votedFor = rf.me</span><br><span class="line">  rf.persist()</span><br><span class="line">  DPrintf(<span class="string">&quot;%s change to candidate&quot;</span>, rf)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> becomeFollower(term <span class="type">int</span>) &#123;</span><br><span class="line">  rf.role = FOLLOWER</span><br><span class="line">  rf.currentTerm = term</span><br><span class="line">  <span class="keyword">if</span> rf.currentTerm &gt; term &#123;</span><br><span class="line">    rf.votedFor = <span class="number">-1</span></span><br><span class="line">  &#125;</span><br><span class="line">  rf.persist()</span><br><span class="line">  rf.electionTimer.Reset(getRandElectTimeout())</span><br><span class="line">  DPrintf(<span class="string">&quot;%s change to follower with term %d&quot;</span>, rf, term)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> becomeLeader() &#123;</span><br><span class="line">  rf.role = LEADER</span><br><span class="line">  rf.leaderID = rf.me</span><br><span class="line">  rf.persist()</span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; rf.PeersNum; i++ &#123;</span><br><span class="line">    rf.matchIndex[i] = <span class="number">0</span></span><br><span class="line">    rf.nextIndex[i] = <span class="built_in">len</span>(rf.log)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  rf.pingTimer.Reset(heartbeatInterval)</span><br><span class="line">  <span class="keyword">go</span> rf.pingLoop()</span><br><span class="line">  DPrintf(<span class="string">&quot;%s change to leader&quot;</span>, rf)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="三个循环"><a href="#三个循环" class="headerlink" title="三个循环"></a><strong>三个循环</strong></h3><p>三个 goroutine：<em>electionLoop</em>，<em>pingLoop</em>，<em>applyLoop</em>。其中，前两个 loop 都由 timer 驱动， <em>electionLoop</em> 只在 Peer 不为 Leader 时执行选举逻辑，而 <em>pingLoop</em> 是在每次 Peer 当选为 Leader 时启动，并在失去 Leader 身份后及时退出的。也就是说，对于同一个 Peer，这两个 Loop 实现为了互斥的。</p>
<p><strong>electionLoop</strong> 是 Follower 超时变为 Candidate 后进行选举的 Loop。它为后台常驻 goroutine，但是检测到自己是 Leader 时会跳过执行循环体（跳过选举），毕竟谁也不会主动发起选举推翻自己。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> electionLoop() &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    &lt;-rf.electionTimer.C</span><br><span class="line">    rf.electionTimer.Reset(getRandElectTimeout())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> rf.role == LEADER &#123;</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    rf.mu.Lock()</span><br><span class="line">    rf.becomeCandidate()</span><br><span class="line">    <span class="comment">// request vote from each Peer except itself</span></span><br><span class="line">    rf.mu.Unlock()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>pingLoop</strong> 是 Candidate 当选为 Leader 后进行心跳的 Loop，并在心跳的来回中完成日志同步。该 Loop 是在 becomeLeader 函数中被启动的 goroutine，一旦检测到自己不为 Leader 后便立即退出，毕竟 Peer 都是高度自觉的，若是人人欺诈，就永远达不成一致了。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> pingLoop() &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    rf.mu.Lock()</span><br><span class="line">    <span class="keyword">if</span> rf.role != LEADER &#123;</span><br><span class="line">      rf.mu.Unlock()</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// append entries to each Peer except itself</span></span><br><span class="line">    rf.mu.Unlock()</span><br><span class="line"></span><br><span class="line">    &lt;-rf.pingTimer.C</span><br><span class="line">    rf.pingTimer.Reset(heartbeatInterval)</span><br><span class="line">    DPrintf(<span class="string">&quot;%v start next ping round&quot;</span>, rf)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>applyLoop</strong> 最简单，就是将已经 commit 的 log 不断应用到状态机，也是个后台常驻 goroutine。如此设计的妙处在于解耦。即不是每次 commit 后立即 apply，而是由额外的 goroutine 统一执行，以避免多次 commit 同一个 index（由于大多数 Peer 响应后就可以 commit，之后再收到其他 Peer 的响应，就可能造成多次 commit），进而导致多次 apply。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> applyLoop() &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    time.Sleep(<span class="number">10</span> * time.Millisecond)</span><br><span class="line">    rf.mu.Lock()</span><br><span class="line">    <span class="keyword">for</span> rf.lastApplied &lt; rf.commitIndex &#123;</span><br><span class="line">      rf.lastApplied++</span><br><span class="line">      rf.apply( rf.lastApplied，rf.log[rf.lastApplied]) <span class="comment">// put to applyChan in the function</span></span><br><span class="line">    &#125;</span><br><span class="line">    rf.mu.Unlock()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="加锁原则"><a href="#加锁原则" class="headerlink" title="加锁原则"></a>加锁原则</h3><p>我是按照<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9SYWZ0LWxvY2tpbmcudHh0">实验材料<i class="fa fa-external-link-alt"></i></span>中建议的，用的比较粗暴，基本都是函数粒度的。仅在发生长耗时操作（网络IO）前会释放锁：即每次 RPC （<em>sendRequestVote</em> 和 <em>sendAppendEntries</em>）前。因此效率不会太高，但是易于实现和理解。同时为了保证这次发送过程是原子的（不被中断），使用了一个 channel 来同步，保证给下个 Peer 发送 RPC 前，前一个 RPC 已经准备完了 Args；当然也可以将准备 Args 的过程，拿到 goroutine 之外。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> pingLoop() &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    rf.mu.Lock()</span><br><span class="line">    <span class="keyword">if</span> rf.role != LEADER &#123;</span><br><span class="line">      rf.mu.Unlock()</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    prepareFinish := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">bool</span>)</span><br><span class="line">    <span class="keyword">for</span> PeerID := <span class="keyword">range</span> rf.Peers &#123;</span><br><span class="line">      <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(id <span class="type">int</span>, pf <span class="keyword">chan</span> <span class="type">bool</span>)</span></span> &#123;</span><br><span class="line">        <span class="comment">// prepare the append entries arguments</span></span><br><span class="line">        pf &lt;- <span class="literal">true</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// [send rpc] -&gt; [wait] -&gt;[handle the reply]</span></span><br><span class="line">      &#125;(PeerID, prepareFinish)</span><br><span class="line"></span><br><span class="line">      &lt;-prepareFinish</span><br><span class="line">    &#125;</span><br><span class="line">    rf.mu.Unlock()</span><br><span class="line"></span><br><span class="line">    &lt;-rf.pingTimer.C</span><br><span class="line">    rf.pingTimer.Reset(heartbeatInterval)</span><br><span class="line">    DPrintf(<span class="string">&quot;%v start next ping round&quot;</span>, rf)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><p>我给主要结构体都实现了 <code>String()</code> 函数，以方便返回当前 Peer 的关键状态、 RPC 前后的参数和返回值，从而易于跟踪、调试。以 Raft 结构体为例：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> String() <span class="type">string</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;[%s:%d;Term:%d;VotedFor:%d;logLen:%v;Commit:%v;Apply:%v]&quot;</span>,</span><br><span class="line">    rf.role, rf.me, rf.currentTerm, rf.votedFor, <span class="built_in">len</span>(rf.log), rf.commitIndex, rf.lastApplied)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="领导者选举（Part-2A-leader-election）"><a href="#领导者选举（Part-2A-leader-election）" class="headerlink" title="领导者选举（Part 2A: leader election）"></a>领导者选举（Part 2A: leader election）</h2><p>Raft 中的任何 Peer（或者说 server） 都处在三种状态之一：Follower、Candidate、Leader。其状态转移图如下：</p>
<p><img src="https://i.loli.net/2020/02/09/mfESApyVoB1cPRe.png" alt="raft-server-state.png"></p>
<p>其中所有 Peer 在启动时都是 Follower，经过一个随机超时后先后变为 Candidate。Candidate 是一个为竞选 Leader 而设计的中间过渡状态。所有的任期（ term） 始于 Candidate（即变成 Candidate 时 term+1），如果能当选则持续到 Leader结束。</p>
<p>Raft 中有一条铁律，就是不论出于什么状态，只要发现自己所处 term 落后于人，就立即改变自己 term 变成 Follower。 term 即为事实上的逻辑时钟，所有投票行为（Candidate 和 Voter[1]）和日志同步（Leader 和 Follower）动作需要所涉及双方在同一个 term 中。</p>
<p>Raft 使用<strong>强势</strong> Leader，只能由 Leader 向 Follower 同步日志，而不能反过来。并且 Leader 本身的日志只会由 Client 进行 Append，不会更改或者删除；由于 Leader 权势巨大，必须为选举设置严苛的门槛，即保证当选的 Candidate 的 log 比过半数的 Peer 更 up-to-date 。因此需要在选举阶段逐一比较 Candidate 和其他 Peer 谁更 up-to-date。根据论文中这段描述：</p>
<blockquote>
<p>Raft determines which of two logs is more up-to-date by comparing the index and term of the last entries in the logs. If the logs have last entries with different terms, then the log with the later term is more up-to-date. If the logs end with the same term, then whichever log is longer is more up-to-date.</p>
</blockquote>
<p>只考虑两组日志的最后一条日志的 index 和 term 即可：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">notLessUpToDate</span><span class="params">(currTerm, currIndex <span class="type">int</span>, dstTerm, dstIndex <span class="type">int</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> currTerm != dstTerm &#123;</span><br><span class="line">    <span class="keyword">return</span> currTerm &gt; dstTerm</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> currIndex &gt;= dstIndex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实现的详细描述可以看论文图二，该描述要当做编程语言而非自然语言来对待，因为它十分精确，尤其要特别注意不要遗漏其状态转换时的触发条件。这里不再赘述，仅列出我觉得在实现时，可能有困惑的一些点：</p>
<ol>
<li><p><code>RequestVoteArgs</code> 结构体的字段都要大写，这是测试程序所要求的。</p>
</li>
<li><p><code>AppendEntries</code> 请求、回应结构体、以及发送RPC 的实现，需要自己比对  <code>RequestVote</code> 依样画葫芦。</p>
</li>
<li><p><code>logEntry</code> 也需要自己定义，我实现的就只包含 Term 和 Command 两个字段。</p>
</li>
<li><p>Peer 每一轮（term）至多投一次票，可以通过在给出投票前判断 <code>rf.votedFor</code> 是否为 null [5] 来保证；但同时有另一层意思，即每一轮至少可以投一次票，这就要求在发生 term 改变时，需要及时改变 votedFor 。分两种情况：一是 Follower&#x2F;Candidate  超时变为 Candidate 时，term 会增加 1，这时候先无脑投自己（<code>rf.votedFor = rf.me</code>），然后发起选举；二是在收到其他 Peer 的 RPC 时（包括 Request 和 Reply），发现别人 term 高，变为 Follower 时，也需要及时清空自己之前投票结果（<code>rf.votedFor = -1</code>）以使本轮次可以继续投票。但同 term 的 Candidate 变回 Follower 时，记得不要重置 <code>rf.votedFor</code>。 </p>
</li>
<li><p>Peer 在实现 AppendEntries 时，只要本 Peer 的 term 不高于发起心跳的 Leader 的 term，都要及时变为 Follower，这包含以下几种情况：a. 如果 Peer 较小，则需 term 跟上，然后变 Follower；b. 本来为 Candidate 且 term 相同，要停止选举变为 Follower；c. 本来就是 Follower 且 term 相同 ，便重置下 electionTimer。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> args.Term &lt; rf.currentTerm &#123;</span><br><span class="line">  DPrintf(<span class="string">&quot;%v reject append entry rpc from %v for (term)&quot;</span>, rf, args)</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rf.becomeFollower(args.Term) <span class="comment">// become follower with term args.Term and reset timer</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>关于 <code>electionTimer</code> 的重置：每次变为 Follower 时，可以重置下 timer。此外，对于Follower&#x2F;Candidate ，还有两种情况需要重置：一是收到 AppendEntries RPC 时；一是投票给某个 Candidate 时。这个推断从图二中 Followers 中这句话来：</p>
<blockquote>
<p>If election timeout elapses without receiving AppendEntries RPC from current leader or granting vote to candidate: convert to candidate</p>
</blockquote>
</li>
<li><p>每次在收到 RPC 的 reply 时，（Candidate 和 Leader）都要检查一下此时是否和发送 RPC 之前状态一致，如果不一致，需要及时退出 goroutine，不在其位，不谋其政。term + role 可以唯一确定某个 Peer 的状态。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// in pingLoop()</span></span><br><span class="line"><span class="keyword">if</span> rf.role != LEADER || rf.currentTerm != args.Term &#123;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// in electionLoop()</span></span><br><span class="line"><span class="keyword">if</span> rf.role != CANDIDATE || rf.currentTerm != args.Term &#123;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<p>在做的时候我还想到了一种极端情况，做了下推演。某个 Peer A 与其他 Peer 产生了网络隔离，于是不断超时-选举-超时，从而不断更新 term 到一个很大的值 T。某个时刻 A 与其他 Peer 恢复通信，它发起选举，向每个 Peer 要票。于是剩下的所有 Peer 包括 Leader 发现更大 term：T，就会立即变为 Follower。不过由于 up-to-date 的保证，A 也是成不了 Leader 的。所以这样场景的唯一后果就是 A 一下把大家带入了更高的 term，且成就了别人（可能选出一个不为 A 、不为原 Leader 的其他 Peer）。当然，工程上通常通过 prevVote 来避免 Leader 老被隔离很久的 Peer 中断。</p>
<h2 id="日志同步（Part-2B-log-replication）"><a href="#日志同步（Part-2B-log-replication）" class="headerlink" title="日志同步（Part 2B: log replication）"></a>日志同步（Part 2B: log replication）</h2><p>Leader 接收到 client 请求到应用其包含 command 到状态机大概需要这么几个过程：</p>
<ol>
<li>收到 client 的请求，包含一个 command 参数（<code>Start(command interface&#123;&#125;)</code>）。</li>
<li>Leader 把该请求追加到本地日志（<code>rf.log = append(rf.log, &amp;logEntry&#123;rf.currentTerm, command&#125;)</code>）。</li>
<li>通过心跳并行通知所有 Follower 写入该日志（AppendEntries RPC）。</li>
<li>待大多数 Follower 成功写入后，提交该日志。</li>
<li>通过下次的心跳把 LeaderCommit 广播给所有的 Follower。</li>
<li>每个 Follower 各自 Apply。</li>
</ol>
<p>心跳是定时的，而<strong>同步日志</strong>则是在定时的心跳的过程中完成的。如果 RPC 参数中不携带日志条目，则就是一个简单心跳；如果  RPC 参数中携带日志条目，则是 Leader 告诉该 Follower，我认为你需要同步这些日志。</p>
<p>那么 Leader 是如何得知每个 Follower 需要同步哪些日志呢？</p>
<p>试探。</p>
<p>通过试探得到匹配点，Leader 在匹配点之后的日志便是需要同步给 Follower 的部分。试探匹配点即是 Leader 会依照自己的日志条目，从后往前，不断询问，你有没有存这一条日志？只要发现某条日志 Follower 存了，那么它就是个匹配点，其之前的日志必然一样 [2]。为了实现这个逻辑，raft 论文主要使用了这几个变量： matchIndex[]、nextIndex[] 和 prevLogIndex、prevLogTerm。</p>
<h3 id="matchIndex-和-nextIndex"><a href="#matchIndex-和-nextIndex" class="headerlink" title="matchIndex 和 nextIndex"></a>matchIndex 和 nextIndex</h3><p>这两个数组只对 Leader 有用。其中，<code>matchIndex[]</code> 跟踪 Leader 和每个 Follower 匹配到的日志条目， <code>nextIndex[]</code> 保存要发送每个 Follower 的下一个日志条目。</p>
<p>Candidate 在当选为 Leader 时，会将所有 <code>matchIndex</code> 初始化为 0 [3]，表示现在我不知道每个 Peer 的进度；同时会将所有 <code>nextIndex</code> 初始化为 <code>len(rf.log)</code>，表示要从其前面，即最后一条日志，开始<strong>试探</strong>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> becomeLeader() &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; rf.peersNum; i++ &#123;</span><br><span class="line">    rf.matchIndex[i] = <span class="number">0</span></span><br><span class="line">    rf.nextIndex[i] = <span class="built_in">len</span>(rf.log)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// in function pingLoop: construct AppendEntriesArgs</span></span><br><span class="line">prevLogIndex := rf.nextIndex[id] - <span class="number">1</span></span><br><span class="line">args := &amp;AppendEntriesArgs&#123;</span><br><span class="line">  Term:         rf.currentTerm,</span><br><span class="line">  LeaderID:     rf.me,</span><br><span class="line">  PrevLogIndex: prevLogIndex,</span><br><span class="line">  PrevLogTerm:  rf.log[prevLogIndex].Term,</span><br><span class="line">  Entries:      rf.log[rf.nextIndex[id]:], <span class="comment">// start from next to the end</span></span><br><span class="line">  LeaderCommit: rf.commitIndex,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里面隐含一个情况，即第一次试探时 <code>args.Entries</code> 是空的，因此对应论文中图二所说的心跳：</p>
<blockquote>
<p>Upon election: send initial empty AppendEntries RPCs (heartbeat) to each server; repeat during idle periods to prevent election timeouts (§5.2)</p>
</blockquote>
<p>以后随着不断向前试探，心跳中携带的日志条目将会越来越多，在实际工程中可能会引发性能问题。</p>
<h3 id="prevLogIndex-和-prevLogTerm"><a href="#prevLogIndex-和-prevLogTerm" class="headerlink" title="prevLogIndex 和 prevLogTerm"></a>prevLogIndex 和 prevLogTerm</h3><p>每次心跳会带上试探信息：<code>prevLogIndex</code> 和 <code>prevLogTerm</code>。Follower 在收到该 RPC时，会看自己是否有这这条日志。如果没有，则其 <code>prevLogIndex</code> 以及之后的日志必然也不匹配，可以删掉。如果有，那 RPC 参数中携带的日志条目就有用了，将其追加到匹配点之后，同时根据 Leader 要求更新 commit 信息 。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> args.PrevLogIndex &gt;= <span class="built_in">len</span>(rf.log) || rf.log[args.PrevLogIndex].Term != args.PrevLogTerm &#123;</span><br><span class="line">  <span class="keyword">if</span> args.PrevLogIndex &lt; <span class="built_in">len</span>(rf.log) &#123; </span><br><span class="line">    rf.log = rf.log[<span class="number">0</span>:args.PrevLogIndex] <span class="comment">// delete the log in prevLogIndex and after it</span></span><br><span class="line">    rf.persist()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rf.log = <span class="built_in">append</span>(rf.log[<span class="number">0</span>:args.PrevLogIndex+<span class="number">1</span>], args.Entries...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.LeaderCommit &gt; rf.commitIndex &#123;</span><br><span class="line">  prevIndex := rf.commitIndex</span><br><span class="line">  rf.commitIndex = minInt(args.LeaderCommit, <span class="built_in">len</span>(rf.log)<span class="number">-1</span>)</span><br><span class="line">&#125;</span><br><span class="line">reply.Success = <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h3 id="Leader-处理回应"><a href="#Leader-处理回应" class="headerlink" title="Leader 处理回应"></a>Leader 处理回应</h3><p>当 Leader 收到该 Follower 的回复时，如果发现匹配上了，则更新 matchIndex 和 nextIndex；否则，继续试探前一条，当然，为了加快匹配速度，我们采用了大跨步向前策略，每次跳过一个 term 而非一个 index[4]。不这么优化，有个测试就跑不过去。<br>当然，有可能这样也过不了，还得给 Follower 的回复增加一些字段，提示 Leader 快速向前。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> reply.Success &#123;</span><br><span class="line">  rf.matchIndex[id] = args.PrevLogIndex + <span class="built_in">len</span>(args.Entries) <span class="comment">// do not depend on len(rf.log)</span></span><br><span class="line">  rf.nextIndex[id] = rf.matchIndex[id] + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  majorityIndex := getMajoritySameIndex(rf.matchIndex)</span><br><span class="line">  <span class="keyword">if</span> rf.log[majorityIndex].Term == rf.currentTerm &amp;&amp; majorityIndex &gt; rf.commitIndex &#123;</span><br><span class="line">    rf.commitIndex = majorityIndex</span><br><span class="line">    DPrintf(<span class="string">&quot;%v advance commit index to %v&quot;</span>, rf, rf.commitIndex)</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  prevIndex := args.PrevLogIndex</span><br><span class="line">  <span class="keyword">for</span> prevIndex &gt; <span class="number">0</span> &amp;&amp; rf.log[prevIndex].Term == args.PrevLogTerm &#123;</span><br><span class="line">    prevIndex--</span><br><span class="line">  &#125;</span><br><span class="line">  rf.nextIndex[id] = prevIndex + <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="一些点"><a href="#一些点" class="headerlink" title="一些点"></a>一些点</h3><p>照例，列出我实现中遇到的一些问题 or Bug：</p>
<ol>
<li><p>如何决定哪些日志可以提交，即根据 matchIndex 数组得到大多数 Peer 的匹配点（<code>getMajoritySameIndex</code>）？我的实现比较粗暴，复制一份，从大到小排个序，取 <code>len/2</code> 处的值。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getMajoritySameIndex</span><span class="params">(matchIndex []<span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">  tmp := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="built_in">len</span>(matchIndex))</span><br><span class="line">  <span class="built_in">copy</span>(tmp, matchIndex)</span><br><span class="line"></span><br><span class="line">  sort.Sort(sort.Reverse(sort.IntSlice(tmp)))</span><br><span class="line"></span><br><span class="line">  idx := <span class="built_in">len</span>(tmp) / <span class="number">2</span></span><br><span class="line">  <span class="keyword">return</span> tmp[idx]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>rf.applyCh</code> 不要忘记在 <code>Make</code> 函数中使用传入的参数 <code>applyCh</code> 进行赋值。</p>
</li>
<li><p>Leader&#x2F;Candidate&#x2F;Follower 在接收到比自己大的 term 的 RequestVote RPC，需要立即转为 Follower，并且重置 electionTimer。</p>
</li>
<li><p>在 Leader 收到 AppendEntries 的 Reply 时，需要先判断 term，然后再判断状态是否变了，即下面两个 if 语句顺序不能换。否则可能由于某种原因，该  Peer 状态变了（即不再是 Leader 或者 term 发生了更改），就直接返回了， 但有可能其更改后 Term 仍然比 reply.Term 小，从而没有及时变成 Follower。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> reply.Term &gt; rf.currentTerm &#123;</span><br><span class="line">  rf.becomeFollower(reply.Term)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rf.role != LEADER || rf.currentTerm != args.Term &#123;</span><br><span class="line">  DPrintf(<span class="string">&quot;%v is not leader or changes from previous term: %v&quot;</span>, rf, args.Term)</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>每次 Leader 丢掉领导者身份后，其 <code>commitIndex</code> 需不需要回退？以及每次 Candidate 上位 Leader 时，需不需要对 <code>commitIndex = 0</code>？答案是都不需要，因为根据论文中 <strong>Leader Completeness</strong> 特性，所有被提交了日志必定会出现在后面的 Leader 的日志中。</p>
</li>
<li><p>AppendEntries 收回 reply 的时候更新 <code>rf.matchIndex 和 rf.nextIndex</code> 需要注意，不能依赖 <code>len(rf.log)</code>，因为他可能被改变，比如由于客户端请求，被追加新的日志条目了。最好用发出RPC 请求时的参数中的字段值： <code>args.PrevIndex + len(arg.Entnries)</code>，上面代码有相应注释。</p>
</li>
<li><p>TestRPCBytes2B 这个测试用例我一开始老过不了，后来发现是我心跳的时间间隔太小了，后来发现是单位写错了，将毫秒写成了微秒。从而导致对于同一个 Follower，同样的 AppendEntries 包发了太多次（稍微多发一两次测试程序是可以忍的）。</p>
</li>
<li><p>随机种子用 <code>rand.Seed(time.Now().UnixNano())</code> 好一些。</p>
</li>
<li><p>发送 AppendEntries RPC 时，当 peerID 是 Leader 自己时，也要注意更新 nextIndex 和 matchIndex：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> peerID == rf.me &#123;</span><br><span class="line">  rf.nextIndex[peerID] = <span class="built_in">len</span>(rf.log)</span><br><span class="line">  rf.matchIndex[peerID] = <span class="built_in">len</span>(rf.log) - <span class="number">1</span></span><br><span class="line">  <span class="keyword">continue</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="状态备份（Part-2C-state-persist）"><a href="#状态备份（Part-2C-state-persist）" class="headerlink" title="状态备份（Part 2C: state persist）"></a>状态备份（Part 2C: state persist）</h2><p>光从实现上来说 2C 比较简单，就是实现序列化（<code>rf.persist()</code>）和反序列化（<code>rf.readPersist()</code>）的函数，以对需要持久化的状态进行保存或者加载。并且在这些状态发生改变的时候，及时调用 <code>rf.persist()</code>。</p>
<p>但却很容易跑不过，我前年做的时候，就是卡在这了好久。因为这一个部分的测试用例更加复杂，很容易将前两个部分没实现好的点测试出来。</p>
<h3 id="序列化和反序列化"><a href="#序列化和反序列化" class="headerlink" title="序列化和反序列化"></a>序列化和反序列化</h3><p>需要持久化的状态论文中图二说的很清楚，labgob 的用法，注释中也给的很详细。需要注意的就是 rf.log 这个 Slice 不用区别对待，和普通变量一样处理即可，以序列化为例：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> persist() &#123;</span><br><span class="line">  w := <span class="built_in">new</span>(bytes.Buffer)</span><br><span class="line">  e := labgob.NewEncoder(w)</span><br><span class="line">  </span><br><span class="line">  err := e.Encode(rf.currentTerm)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    DPrintf(<span class="string">&quot;%v encode currentTerm error: %v&quot;</span>, rf, err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  err = e.Encode(rf.votedFor)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    DPrintf(<span class="string">&quot;%v encode votedFor error: %v&quot;</span>, rf, err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  err = e.Encode(rf.log)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    DPrintf(<span class="string">&quot;%v encode log error: %v&quot;</span>, rf, err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  data := w.Bytes()</span><br><span class="line">  rf.persister.SaveRaftState(data)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="状态改变"><a href="#状态改变" class="headerlink" title="状态改变"></a>状态改变</h3><p>代码中涉及到状态改变的主要有四个地方：</p>
<ol>
<li>发起选举，更新 term 和 votedFor 时。</li>
<li>调用 Start 追加日志，rf.log 改变时。</li>
<li>RequestVote 和 AppendEntries 两个 RPC handler 改变相关状态时。</li>
<li>Candidate&#x2F;Leader 收到 RPC 的 reply 更新自身状态时。</li>
</ol>
<p>但是测试用例 TestFigure8Unreliable2C 就是过不了。Google 一番后发现<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NwcmluZ2ZpZWxka2luZy9taXQtNi44MjQtZ29sYWJzLTIwMTgvaXNzdWVzLzE=">别人<i class="fa fa-external-link-alt"></i></span>也有这个问题。将 pingInterval 再改小一些，拉大其与 electionTimeout 的差距可解决。最后我将参数改为如下值，该用例就过了。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  electionTimeoutMin = <span class="number">150</span></span><br><span class="line">  electionTimeoutMax = <span class="number">300</span></span><br><span class="line">  heartbeatInterval  = <span class="number">50</span> * time.Millisecond</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>但我开始将心跳间隔设置得比较大，是因为看到了材料中这么一句话：</p>
<blockquote>
<p>The paper’s Section 5.2 mentions election timeouts in the range of 150 to 300 milliseconds. Such a range only makes sense if the leader sends heartbeats considerably more often than once per 150 milliseconds. Because the tester limits you to <strong>10 heartbeats per second</strong>, you will have to use an election timeout larger than the paper’s 150 to 300 milliseconds, but not too large, because then you may fail to elect a leader within five seconds.</p>
</blockquote>
<p>但是我改成 <code>heartbeatInterval  = 50 * time.Millisecond</code>  tester 也让过了，这里我暂时有些不解。</p>
<h2 id="参考材料"><a href="#参考材料" class="headerlink" title="参考材料"></a>参考材料</h2><ol>
<li><p>Raft 论文：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvcGFwZXJzL3JhZnQtZXh0ZW5kZWQucGRm">https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>Lab2 Raft 课程材料页：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9sYWItcmFmdC5odG1s">https://pdos.csail.mit.edu/6.824/labs/lab-raft.html<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>助教总结往年经验：<span class="exturl" data-url="aHR0cHM6Ly90aGVzcXVhcmVwbGFuZXQuY29tL2Jsb2cvc3R1ZGVudHMtZ3VpZGUtdG8tcmFmdC8lRUYlQkMlOEMlRTklQTElQkElRTQlQkUlQkYlRTglQUYlQjQlRTQlQjglODAlRTUlOTglQjQlRUYlQkMlOEMlRTglQkYlOTklRTQlQjglQUElRTUlOEElQTklRTYlOTUlOTklRTclOUElODQlRTUlOEQlOUElRTUlQUUlQTIlRTQlQjklOUYlRTYlOEMlQkElRTQlQjglOEQlRTklOTQlOTklRTMlODAlODI=">https://thesquareplanet.com/blog/students-guide-to-raft/，顺便说一嘴，这个助教的博客也挺不错。<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>助教 Q&amp;A：<span class="exturl" data-url="aHR0cHM6Ly90aGVzcXVhcmVwbGFuZXQuY29tL2Jsb2cvcmFmdC1xYS8=">https://thesquareplanet.com/blog/raft-qa/<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>Raft 用锁建议：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9yYWZ0LWxvY2tpbmcudHh0">https://pdos.csail.mit.edu/6.824/labs/raft-locking.txt<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>Raft 实现结构组织建议：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbGFicy9yYWZ0LXN0cnVjdHVyZS50eHQ=">https://pdos.csail.mit.edu/6.824/labs/raft-structure.txt<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>Raft 主页，上面有个可视化动图，能帮你直观的感受下 raft，并且具有一定的交互性。此外还有更多 raft 相关的材料，也可以参考：<span class="exturl" data-url="aHR0cHM6Ly9yYWZ0LmdpdGh1Yi5pby8=">https://raft.github.io/<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>某个网上同学实现：<span class="exturl" data-url="aHR0cHM6Ly93aWVzZW4uZ2l0aHViLmlvL3Bvc3QvbWl0LTYuODI0LWxhYjItcmFmdC1jb25zZW5zdXMtYWxnb3JpdGhtLWltcGxlbWVudGF0aW9uLw==">https://wiesen.github.io/post/mit-6.824-lab2-raft-consensus-algorithm-implementation/<i class="fa fa-external-link-alt"></i></span></p>
</li>
</ol>
<h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><p>[0] Raft 中的每个 Server 文中统一称为 Peer。</p>
<p>[1] 投票者可能为 Follower，也可能为 Candidate。</p>
<p>[2]  参考论文 Figure 3 的 Log Matching 性质。</p>
<p>[3] 0 其实表示 nil，因为<code>rf.log[0]</code> 是一个无意义的空日志条目，起到<strong>哨兵</strong>的作用，可以减少一些判断，类似于链表中的 dummy Head node。</p>
<p>[4] <span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvcGFwZXJzL3JhZnQtZXh0ZW5kZWQucGRm">raft 论文<i class="fa fa-external-link-alt"></i></span> 7~8 页的引用文字有提到该策略。</p>
<p>[5] 我在实现时， votedFor 用的 int 类型，并且用的 -1 代表 null。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>Raft</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>分布式系统</tag>
        <tag>Raft</tag>
        <tag>实现</tag>
      </tags>
  </entry>
  <entry>
    <title>真香——MacBook Pro 2016 Genius Bar 更换键盘小记</title>
    <url>/2020/01/21/mac-fix-keyboard/</url>
    <content><![CDATA[<p>研究生毕业时，去网易游戏实习攒了点钱，便想入手垂涎了好久的程序员生产力工具—— MacBook Pro。适逢新版发售，等到 2016 年底，新版甫一上市，便从官网下单了一台 pro 入门版：13 寸两口不带 bar 。不过哪怕是入门版，也要一万多大洋，还两个口，还不带 bar。</p>
<p><img src="https://i.loli.net/2020/02/09/AYgbZJ7Du1TWn4q.png" alt="mac-buy-info.png"></p>
<p>不带 bar 尚可接受，毕竟 vim 党还是喜欢能按的下去的 Esc 。但两个口——于是默默了去京东下单了几个扩展口，彼时 tpye c 尚不流行，选择无几。</p>
<p>到货后满心欢喜打开，惊艳异常，是醉人的新配色——深空灰、是史无前例的轻薄、是类 Unix 系统加上舒服的 UI。于是将之前的小嘀咕抛诸脑后，嗯，真香。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<p>然而，过了两天就发现屏幕出了一条横线，重启大法也无能为力。于是新电脑还没焐热走上了漫漫维修之路。当然，后面买了越来越多的苹果产品之后，才知道，这远不是最后一次。</p>
<p><img src="https://i.loli.net/2020/02/09/dCBROMGslpEa4jA.png" alt="mac-keyboard.png"></p>
<p>经过客服、预约、天才吧三联操作后，电脑便交了出去。维修倒是很快，隔天就好了。去西单大悦城取货，一台崭新电脑呈到面前：外面罩了一层保护膜、光面的 logo 被薄塑料覆盖起来、机身擦的一尘不染，屏幕自然已完好如初，还给你 show 了一下不菲费用：</p>
<p><img src="https://i.loli.net/2020/02/09/dqSGlDFJZA6XMuT.png" alt="mac-screen-fee.png"></p>
<p>但是你一分钱不用掏哦。嗯，复香。</p>
<p>于是又和我的 MacBook Pro 过上了摩擦摩擦、指指点点、没羞没臊的开心小日子。</p>
<p>至于后来大家持续吐槽，苹果为了 MacBook Pro 的轻薄开发的新型蝶式键盘键程太短、故障率很高等问题，都没有引起我内心涟漪。键程太短我没有太多感觉，反而还觉得打字快了。所谓故障率很高，亦无体验。</p>
<p>就这么开开心心处了三年，直到 19 年中的某一天，Z 键开始时不时的，哔——哔——，突然心下一凉，这就是传说中的连键吗？莫非我也是 The chosen one？在重启、重装、扣键帽三联操作后，彻底缴枪。虽然还研究了好久扣键帽-酒精清洁-还原的姿势，虽有好转，但无力回天。</p>
<p>无奈我懒，适应性又强，就这么拖着，拖着，直到——X 键也罢工了。然后我不在家的时候，妹子看我之前扣键帽很爽，试图自己操作一番。晚上回来时候，看着妹子委屈的眼神、针脚两断的键帽，心下转过千头百绪，哈哈哈，我又该送修了。</p>
<p>之前听说苹果有个针对新版 MacBook Pro 的键盘<span class="exturl" data-url="aHR0cHM6Ly9zdXBwb3J0LmFwcGxlLmNvbS96aC1jbi9rZXlib2FyZC1zZXJ2aWNlLXByb2dyYW0tZm9yLW1hYy1ub3RlYm9va3M=">更换计划<i class="fa fa-external-link-alt"></i></span>，哪怕你不在保。但是键帽的问题，着实让我心下忐忑，于是做好了大出血的准备。又是电话-预约-天才吧检测三联后，天才吧小姐姐轻斥我道：你这个键帽算外观损坏啊，以后键帽再有问题直接拿过来，可以免费更换，不要自己扣。这次就算了，我先给你换上，然后按连键的问题走流程，符合键盘更换计划，应该可以免费更换。</p>
<p>说到键帽，我羞的无从辩驳；听到仍然可以走键盘更换计划，大喜过望，赶紧岔开键帽问题，感谢连连。检测其他硬件没问题后，做了个登记，说修好后通知我。</p>
<p>又是很快，第二天便通知我好了可以去取货。于是下班后怀着期待的小心情赶到王府井，店员核验信息后，从工作间取出我的 mac。</p>
<p><img src="https://i.loli.net/2020/02/09/VzjmQkyx29l8heA.png" alt="mac-topcase.png"></p>
<p>打开的一瞬间，对，就是这个味，真香！小哥还说，键盘换了最新版，跟新出的 16寸 pro 的一样。用了一下发现，屏幕外壳清洁一新、键盘触感十足。在维修单签名时，又发现：top case with battery，什么？电池也换了？！ 在系统信息里查了一下：</p>
<p><img src="https://i.loli.net/2020/02/09/wtemMIGYoUHpgnx.png" alt="mac-system-info.png"></p>
<p>真香三联。</p>
<p>总体来说，用了 mac 之后，悲喜交加，但是两次天才吧的体验都是真香，看着焕然一新的 mac ，感叹着这细节处理之到位、服务流程之贴心，专做此文来给个好评。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>macbook pro</tag>
        <tag>更换键盘</tag>
      </tags>
  </entry>
  <entry>
    <title>初冬日暮什刹海</title>
    <url>/2020/01/31/shichahai-sunset/</url>
    <content><![CDATA[<p><img src="https://photo.tuchong.com/15470921/f/488359358.jpg"></p>
<p>初冬一个晴朗的午后，从地坛出发，经交道口三条，过圆恩寺胡同，一路走到什刹海。当天天气出奇的好，在太阳的透照下，整个胡同片区懒洋洋的，心里也不由的很轻快。</p>
<span id="more"></span>

<p>在某胡同拐角处，几棵大树从四合院中高耸而出，在高处的天空中呈合围之势。识的一棵是臭椿，春日勃发之时当臭不可闻，此刻味道早已杳无觅处，空余一挂挂干枯的翅果。另外两棵树枝叉繁多，像极生物课本上的神经网络。我总喜欢看冬天的这些树，其树干枝丫线条的走向、大小的变换、细密的交织，佐以胡同中的光影，总有种莫名的力量，让人沉静、让人思考、让人贪恋的难以移步。没有树的胡同，也就失掉了灵魂。我突然明白，为什么那些仿古建筑群落总让人有一种疏离感——正是缺少这些沉淀了时光、阅尽了沧桑的古木。</p>
<p><img src="https://tuchong.pstatp.com/15470921/f/357287642.jpg"></p>
<p>转过几个街区，日头渐渐西沉，反而焕发出了一种灿灿的金黄，与小区楼面姜黄色的涂装相映，煞是好看。头顶的上拉面似的一条条电线，串起一个个古旧的电线杆，像歌一样，消失在了远方胡同尽头。光与影的旋律，在电线勾勒出的线谱上跳动，撩人心弦。本是杂乱的景象，在这曲调下，却和谐地组织到一起，慢慢的浸润到心里，一点点的挤出平日残留的疲累。</p>
<p><img src="https://photo.tuchong.com/15470921/f/488359358.jpg"></p>
<p>转眼到了南锣片区，抬头瞥见一弯新月挂在东南方，天色虽尚明，但太阳已被远方的矮房所遮挡。因此头顶仍是大片深蓝，但西边却开始被橘色浸染。胡同中发现一株弯出院墙的泡桐树，一串串来年开春才能开的骨朵笔直向上,一挂挂杏仁模样的种子弯腰向下，极富张力。</p>
<p><img src="https://tuchong.pstatp.com/15470921/f/467650428.jpg"></p>
<p>复前行，沿玉河，到什刹海。岸柳层层，千万发丝静静垂下，说不出的轻柔。走上金锭桥，往湖面望去，太阳渐没。此时天空极美，由紫蓝到橘黄乃至绯红层层晕染，然后融入远方的起起伏伏的古老民居所勾勒出的天际线。近处的湖面，将地上的景色偷映下来，上下天光，实在沁人心脾。</p>
<p><img src="https://photo.tuchong.com/15470921/f/189645894.jpg"></p>
<p><img src="https://photo.tuchong.com/15470921/f/453364394.jpg"></p>
]]></content>
      <categories>
        <category>生活</category>
        <category>摄影</category>
      </categories>
      <tags>
        <tag>摄影</tag>
        <tag>什刹海</tag>
      </tags>
  </entry>
  <entry>
    <title>（译）请不要再称数据库为 CP 和 AP</title>
    <url>/2020/02/16/not-cp-or-ap/</url>
    <content><![CDATA[<blockquote>
<p>本文缘起于Lu Pan 的个人博客文章：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLnRoZS1wYW5zLmNvbS9jYXAv">https://blog.the-pans.com/cap/<i class="fa fa-external-link-alt"></i></span> ，是他经过 Martin Kleppmann 授权并且翻译的博文”Please stop calling databases CP or AP”中文版本。但译文中不少句子读来颇为古怪，我对照<span class="exturl" data-url="aHR0cHM6Ly9tYXJ0aW4ua2xlcHBtYW5uLmNvbS8yMDE1LzA1LzExL3BsZWFzZS1zdG9wLWNhbGxpbmctZGF0YWJhc2VzLWNwLW9yLWFwLmh0bWw=">英文原文<i class="fa fa-external-link-alt"></i></span>，按照自己理解，逐句校验、重译了一遍。这篇文章探讨了为什么不应该滥用 <strong>CAP定理</strong> 这个概念，旁征博引，入木三分，值得一读。更值得称道的是，Martin 文中所有关键观点都给出了来源，并在最后推荐了一些学习资料，都是不错的阅读材料。以下是正文。</p>
</blockquote>
<p>在 Jeff Hodges 的精彩博文<span class="exturl" data-url="aHR0cHM6Ly93d3cuc29tZXRoaW5nc2ltaWxhci5jb20vMjAxMy8wMS8xNC9ub3Rlcy1vbi1kaXN0cmlidXRlZC1zeXN0ZW1zLWZvci15b3VuZy1ibG9vZHMv">给年轻人关于分布式系统的笔记 <i class="fa fa-external-link-alt"></i></span>中，他建议我们用<span class="exturl" data-url="aHR0cDovL3d3dy50aGUtcGFwZXItdHJhaWwub3JnL3BhZ2UvY2FwLWZhcS8=">CAP定理<i class="fa fa-external-link-alt"></i></span>来评判系统。不少人听从了这个建议，将他们的系统称为”CP” （提供一致性但在网络分区时不可用），“AP”（高可用但是在网络分区时不一致） 或者干脆 “CA” （说明还没有读过Coda的<span class="exturl" data-url="aHR0cHM6Ly9jb2RhaGFsZS5jb20veW91LWNhbnQtc2FjcmlmaWNlLXBhcnRpdGlvbi10b2xlcmFuY2Uv">五年前的文章<i class="fa fa-external-link-alt"></i></span>）。</p>
<p>我同意 Jeff 的所有其他观点，但其关于 CAP 定理的使用建议，我不能表示赞同。CAP 定理本身太过简化而且存在广泛的误解，以至于在界定系统时不能有效的起到作用。因此我请求大家不要再引用CAP定理， 不要再讨论CAP定理。取而代之，我们应该用更精确的术语来表述我们对系统的取舍。</p>
<p>（当然，讽刺的是我不希望别人再讨论这个话题，自己却正在写一篇关于这个话题的文章。不过至少以后别人问我为什么不喜欢讨论CAP定理的时候，我可以把这篇文章的链接给他。还有，抱歉这篇文章会有些吐槽，但是至少这些吐槽给出了文献引用）</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/02/16/not-cp-or-ap">https://www.qtmuniao.com/2020/02/16/not-cp-or-ap</a>, 转载请注明出处</em></p>
<h2 id="CAP-使用了十分狭义的定义"><a href="#CAP-使用了十分狭义的定义" class="headerlink" title="CAP 使用了十分狭义的定义"></a>CAP 使用了十分狭义的定义</h2><p>如果你想当做一个定理来引用 CAP（而不是作为一个模糊的、用来做数据库营销的噱头），你必须要精确，数学需要严谨。只有当你使用和该<span class="exturl" data-url="aHR0cHM6Ly93ZWJwYWdlcy5jcy5sdWMuZWR1L35wbGQvMzUzL2dpbGJlcnRfbHluY2hfYnJld2VyX3Byb29mLnBkZg==">定理证明<i class="fa fa-external-link-alt"></i></span>一样的术语时，这个证明才有意义。该证明用了非常特殊的定义：</p>
<ul>
<li><em>一致性（Consistency）</em> 在 CAP 中是<span class="exturl" data-url="aHR0cDovL2NzLmJyb3duLmVkdS9+bXBoL0hlcmxpaHlXOTAvcDQ2My1oZXJsaWh5LnBkZg==">可线性化<i class="fa fa-external-link-alt"></i></span>的意思（linearizability）。这是一个非常特殊（而且非常强）的一致性。需要说明的是，虽然 ACID 中的 C 也是一致性（Consistency），但它和这里的一致性没有任何关系，我会在后面解释可线性化是什么意思。</li>
<li><em>可用性（Availability）</em>在CAP中被定义为”<strong>所有</strong>工作中的[数据库]节点对于每一个收到的请求，都必须返回一个[非错误]的响应（response）”。只有部分节点能处理请求是不够的：所有工作中的节点都必须能正确处理请求。所以很多自称”高度可用”（如，系统总体很少宕机）的系统其实并没有满足这里的可用性的定义。</li>
<li><em>分区容错（Partition Tolerance，这个名字误导性很强）</em> 基本上是说你在一个消息可能会被延迟发送或者干脆丢失的<span class="exturl" data-url="aHR0cDovL3d3dy50aGUtcGFwZXItdHJhaWwub3JnL3BhZ2UvY2FwLWZhcS8=">异步网络<i class="fa fa-external-link-alt"></i></span>中通信。互联网和数据中心都有这个<span class="exturl" data-url="aHR0cHM6Ly9hcGh5ci5jb20vcG9zdHMvMjg4LXRoZS1uZXR3b3JrLWlzLXJlbGlhYmxl">特性<i class="fa fa-external-link-alt"></i></span>，所以在这件事上我们没得选。</li>
</ul>
<p>还注意到，CAP不仅仅在描述旧的系统，而且是一个系统的某种特定模型：</p>
<ul>
<li>简单来说，CAP系统模型就是一个支持读写的单寄存器。CAP没有提到任何关于跨多个对象（object）的事务（transaction）相关的问题，这些问题不在定理的讨论范围内，除非你可以把这些问题简化为一个单个寄存器的问题。</li>
<li>CAP定理只考虑了网络分区这一种故障情况（比如节点们还在运行，但是它们之间的网络出现了问题）。这种故障<span class="exturl" data-url="aHR0cHM6Ly9hcGh5ci5jb20vcG9zdHMvMjg4LXRoZS1uZXR3b3JrLWlzLXJlbGlhYmxl">肯定会发生<i class="fa fa-external-link-alt"></i></span>，但远不是会发生的唯一一种故障：节点可以整个崩溃（crash）或重启、可能没有足够的磁盘空间、可能会遇到一个软件故障（bug）等等。在构建分布式系统时，你需要考虑更加复杂的权衡取舍，如果太过关注 CAP 定理容易导致忽略其他重要问题。</li>
<li>此外， CAP 没有提到延迟（latency）。相对可用性，人们其实<span class="exturl" data-url="aHR0cDovL2RibXNtdXNpbmdzLmJsb2dzcG90LmNvbS8yMDEwLzA0L3Byb2JsZW1zLXdpdGgtY2FwLWFuZC15YWhvb3MtbGl0dGxlLmh0bWw=">更关心延迟<i class="fa fa-external-link-alt"></i></span>。事实上，满足<em>CAP可用性</em>**[1]**的系统可以花任意长的时间来回复一个请求，且仍然具有“可用性”。可以肯定的说，如果你的系统要花两分钟来加载一个页面，你的用户断不会称它为“可用的”。</li>
</ul>
<p>如果你使用与 CAP定理证明中的精确定义相符的性质，那么该定理对你适用。但如果你的“一致性”和“可用性”还有其他意思，就不能指望 CAP 仍然适用。当然，这并不意味着你通过重新定义概念就可以做到一些不可能的事情！我只是想说你不能靠 CAP 定理来提供指导方向，也不能使用 CAP 定理为你的观点来辩解。</p>
<p>如果 CAP 定理对你不适用，那就意味着你必须自己来思考如何进行取舍。你可以用自己的概念来阐释你系统中的一致性和可用性，当然，如果你能进一步给出定理的证明就更棒了。但是请不要称它为 CAP定理，因为这个名字已经被使用了（有其特定内涵和指称）。</p>
<h2 id="可线性化"><a href="#可线性化" class="headerlink" title="可线性化"></a>可线性化</h2><p>以防你对可线性化**[2]**这个性质不熟（即CAP中的一致性），我来简要地解释一下。<span class="exturl" data-url="aHR0cDovL2NzLmJyb3duLmVkdS9+bXBoL0hlcmxpaHlXOTAvcDQ2My1oZXJsaWh5LnBkZg==">可线性化的正式定义<i class="fa fa-external-link-alt"></i></span>不是很直观，但其关键思想比较简单：</p>
<blockquote>
<p>如果B操作始于 A 操作成功结束之后，那么对B操作来说，<em>整个系统</em>必须表现为一种 A 操作已经完成了或者更新的状态。</p>
</blockquote>
<p>为了解释的更清楚些，来看一个非可线性化系统的例子。请看下面这张图 （来自于我<span class="exturl" data-url="aHR0cDovL2RhdGFpbnRlbnNpdmUubmV0Lw==">尚未发行的书<i class="fa fa-external-link-alt"></i></span>中的预览）：</p>
<p><img src="https://martin.kleppmann.com/2015/05/linearizability.png" alt="img"></p>
<p>这张图展示了同在一个房间的 Alice 和 Bob，同时在用手机关注 2014年<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmJjLmNvLnVrL3Nwb3J0LzAvZm9vdGJhbGwvMjgxODE2ODk=">世界杯的决赛结果<i class="fa fa-external-link-alt"></i></span>。在最终结果刚发布时，Alice 刷新了页面，看到了冠军结果，然后很兴奋地告诉了Bob。Bob 满脸不信的刷新一下他的手机页面，但由于他的请求被打到了一个较慢数据库副本上，导致他的手机显示决赛尚在进行。</p>
<p>如果 Alice 和 Bob 同时刷新页面，拿到了不一样的结果，并不太会令人意外。因为不能准确知道服务器先处理了他们中哪一个请求。但在这个例子中， Bob 明显知道他是在 Alice 告诉了他最终结果<em>之后</em>刷新的页面，因此他预期他得到的结果一定不会比 Alice 的更旧。但他的确拿到了旧的结果，这就违反了可线性化性质。</p>
<p>由于 Bob 从系统之外的其他渠道（ Alice 通过语言直接告诉他的）获取到了 Alice 的查询结果，我们可以判定 Bob 的请求一定落后于 Alice 的请求（即，两个请求不是并行的）。如果 Bob 没有从 Alice 那里得知比赛已经结束了，他就不会知道他看到的结果是旧的。</p>
<p>如果你在构建一个数据库系统，并且不知道用户们会有什么样的额外沟通渠道，这时，如果你想提供可线性化的语义（<em>CAP一致性</em>），就需要让数据库看起来只有一个副本，即使系统实际上可能在多个位置有多个备份。</p>
<p>这是一个非常昂贵的属性，因为它要求你做特别多的协调工作。代价大到甚至单机上的 CPU 都 <span class="exturl" data-url="aHR0cHM6Ly93d3cuY2wuY2FtLmFjLnVrL35wZXMyMC93ZWFrbWVtb3J5L2NhY20ucGRm">不提供本地内存的线性化访问<i class="fa fa-external-link-alt"></i></span>！ 在如今的 CPU 上，你需要使用<span class="exturl" data-url="aHR0cHM6Ly9tZWNoYW5pY2FsLXN5bXBhdGh5LmJsb2dzcG90LmNvbS8yMDExLzA3L21lbW9yeS1iYXJyaWVyc2ZlbmNlcy5odG1s">memory barrier 指令<i class="fa fa-external-link-alt"></i></span>才能进行线性访存，甚至检测一个系统是不是可线性化本身也是很<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2plcHNlbi1pby9rbm9zc29z">困难的<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="CAP可用性"><a href="#CAP可用性" class="headerlink" title="CAP可用性"></a>CAP可用性</h2><p>下面来简单讨论一下为什么在有网络分区时，我们要放弃可用性和一致性二者之一。</p>
<p>举个例子，你的数据库在不同的数据中心的各有一个副本。在这里，副本间选择什么样的同步策略并不重要，可以是single-leader（主从），或者multi-leader（多主），或者基于quorum**[3]**的备份（<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLnRoZS1wYW5zLmNvbS9jYXAvd3d3LmFsbHRoaW5nc2Rpc3RyaWJ1dGVkLmNvbS9maWxlcy9hbWF6b24tZHluYW1vLXNvc3AyMDA3LnBkZg==">Dynamo风格<i class="fa fa-external-link-alt"></i></span> ）。我们只要求数据被写到一个数据中心时，它要被同步到另外一个数据中心。假设客户端只连接到其中一个数据中心，并且存在一条网络通路使得两个数据中心间可以进行数据同步。</p>
<p>假设现在该网络通路断了，也就是出现了我们所说的网络分区，将会发生什么?</p>
<p><img src="https://blog.the-pans.com/content/images/2018/07/cap-availability.png" alt="cap-availability"></p>
<p>显然你只能二择其一：</p>
<ol>
<li>数据库仍然允许应用进行写入操作，则两个副本仍各自可用。然而，由于两个副本间的同步链路断了，一个数据中心的写入的更改就不会反映到另外一个，这就违反了可线性化（就之前例子而言，可能的情况是，Alice 连接到了 DC1，而 Bob 连接到了 DC2）。</li>
<li>如果你不想失去可线性化，就必须保证所有的读写操作都发生在同一个数据中心，也就是 leader。另一个数据中心（由于网络同步链路断了而不能保证最新），在网络恢复并能同步数据之前，就必须停止响应读写操作。尽管非 Leader 的数据库副本服务器在正常运行，却不能处理请求，因此这不符合 <em>CAP可用性</em>。</li>
</ol>
<p>（BTW，这本质上就是 CAP 定理的全部证明，仅此而已。这里的例子用到了两个数据中心，但对于一个数据中心内的网络故障也同样适用，但我觉得使用两个数据中心可以更容易的理解这个问题）</p>
<p>注意到上面第二种情况，就算系统违反了<em>CAP可用性</em>，我们还是在其中一个数据中心里成功地处理着请求。所以当一个系统选择了可线性化（也就是放弃了 <em>CAP可用性</em>），并不一定意味着网络分区必定导致应用中断。如果系统可以把所有用户流量暂时迁移到 Leader 数据库副本，那么客户端根本不会注意到存在系统宕机时间。</p>
<p>实际应用中的可用性和<em>CAP可用性</em> <span class="exturl" data-url="aHR0cDovL2Jsb2cudGhpc2xvbmdydW4uY29tLzIwMTUvMDQvY2FwLWF2YWlsYWJpbGl0eS1oaWdoLWF2YWlsYWJpbGl0eS1hbmRfMTYuaHRtbA==">并不完全等价<i class="fa fa-external-link-alt"></i></span>。你应用的可用性大概率是通过某些 SLA来衡量的（比如99.9%的格式正确的请求必须在一秒钟之内成功响应），但是一个系统无论是否满足<em>CAP可用性</em>其实都可以达到要求的 SLA。</p>
<p>在实践中，跨多个数据中心的系统通常使用异步同步策略（asynchronous replication），因此是不可线性化的。但这种选择选择通常是因为广域网延迟过大，而不仅是为了对数据中心和网络故障进行容错。</p>
<h2 id="很多系统既不是可线性化的也不是CAP可用的"><a href="#很多系统既不是可线性化的也不是CAP可用的" class="headerlink" title="很多系统既不是可线性化的也不是CAP可用的"></a>很多系统既不是可线性化的也不是CAP可用的</h2><p>在CAP定理对可用性和一致性（可线性化）严格的定义下，系统如何运作？</p>
<p>例如，使用单个 Leader 来管理多副本数据库，是关系型数据库进行数据备份的典型做法。在该配置下，如果客户端和 Leader 发生了网络隔离，就不能写数据到数据库。即便客户端还能从某个 Follower 那里读到数据，它也不能写任何数据，这就说明该配置下的多副本数据库不是<em>CAP可用</em>的。反而此种配置还常常声称自己是“高可用的（high availablity）”。</p>
<p>如果这种单主的配置方法不是<em>CAP可用</em>的，那它是不是 CP 系统？先不要着急下结论，如果你允许应用从 Follower那里读取数据，并且数据备份是异步的（大多数数据库的默认做法），因此当你从 Follower 处读数据时，可能会读到稍微落后于 Leader 一点的数据。在这种情况下，你的系统的读操作是不可线性化的，即不满足<em>CAP一致性</em>。</p>
<p>而且支持<span class="exturl" data-url="aHR0cDovL3Jlc2VhcmNoLm1pY3Jvc29mdC5jb20vcHVicy82OTU0MS90ci05NS01MS5wZGY=">snapshot isolation<i class="fa fa-external-link-alt"></i></span>&#x2F;MVCC的数据库是故意设计为不可线性化的，否则会降低其本能提供的并发性。比如<span class="exturl" data-url="aHR0cHM6Ly9kcmtwLm5ldC9wYXBlcnMvc3NpLXZsZGIxMi5wZGY=">PostgreSQL的SSI<i class="fa fa-external-link-alt"></i></span>提供可串行化而不是可线性化，<span class="exturl" data-url="aHR0cDovL2RiLmNzLmJlcmtlbGV5LmVkdS9jczI4Ni9wYXBlcnMvc3NpLXRvZHMyMDA1LnBkZg==">Oracle两者都不提供<i class="fa fa-external-link-alt"></i></span>。数据库标榜自己是 ACID 并不意味着它一定满足CAP定理中关于一致性的定义。</p>
<p>所以这些系统既不满足<em>CAP一致性</em>，也不满足<em>CAP可用性</em>。他们既不是 CP 系统也不是 AP 系统，他们只是满足了 P 而已，不管这是什么意思。（是的，CAP 定理中 “三选二” 允许你只从三个中选一个，甚至一个都不选）</p>
<p>那 NoSQL 呢？拿 MongoDB 来说：（如果不发生 split-brain 的话）每个 shard 都只有一个 Leader，根据前面的探讨，它不满足 <em>CAP可用性</em>。而且<span class="exturl" data-url="aHR0cHM6Ly9hcGh5ci5jb20vcG9zdHMvMzIyLWNhbGwtbWUtbWF5YmUtbW9uZ29kYi1zdGFsZS1yZWFkcw==">Kyle最近发现<i class="fa fa-external-link-alt"></i></span>，即使在最高级别一致性的配置下，MongoDB 仍然允许非线性读，所以它也不满足CAP一致性。</p>
<p>至于 Dynamo 及其派生出的 Riak、Cassandra 和 Voldemort 这些专门为高可用做出了优化而被称为 AP 的系统们，他们是不是真的符合 CAP 中的 AP 特性呢？答案是取决于你的配置。如果你接受读写请求都落到一个副本（R&#x3D;W&#x3D;1），那么他们确实满足 <em>CAP可用性</em>。但如果你要求 quorum读写（R+W&gt;N），并且存在网络分区，那些落在少数派分区的副本就不能达成共识，所以 quorum 的读写方式不满足 <em>CAP可用性</em>（至少是偶尔不可用的，直到给少数派分区内加入了足够多的节点）。</p>
<p>有时候会看到人们声称 quorum读写能保证可线性化，但真的去依赖这个条件就不明智了。因为在一些<span class="exturl" data-url="aHR0cDovL2Jhc2hvLmNvbS9wb3N0cy90ZWNobmljYWwvcmlha3MtY29uZmlnLWJlaGF2aW9ycy1wYXJ0LTMv">复杂的情况下<i class="fa fa-external-link-alt"></i></span>，read repair 操作和 sloppy quorum 同时发生，就有可能导致已经被删除了的数据重新出现；或者备份数（replicas）已经低于原来的 W 值（违反了quorum的条件），或者备份数增加到了高于原来的N值（也违反了quorum 的条件），这些都会导致非线性化的访问。</p>
<p>这些都不是失败的系统，人们一直很成功地将其用于线上环境。但到目前为止，我们并不能把他们严格分类为AP 或者 CP，要么是因为需要依赖特定的配置和操作，要么是因为这个系统既不满足 <em>CAP可用性</em>、也不满足 <em>CAP一致性</em>。</p>
<h2 id="案例分析：ZooKeeper"><a href="#案例分析：ZooKeeper" class="headerlink" title="案例分析：ZooKeeper"></a>案例分析：ZooKeeper</h2><p>ZooKeeper 又是什么情况呢？他用了<span class="exturl" data-url="aHR0cDovL2RzLnFjcmkub3JnL3Blb3BsZS9tc2VyYWZpbmkvemFiLnBkZg==">共识算法<i class="fa fa-external-link-alt"></i></span>，所以人们<span class="exturl" data-url="aHR0cHM6Ly93ZWIuYXJjaGl2ZS5vcmcvd2ViLzIwMTYwNTExMjMwNDIxL2h0dHA6Ly90ZWNoLmtuZXd0b24uY29tL2Jsb2cvMjAxNC8xMi9ldXJla2Etc2hvdWxkbnQtdXNlLXpvb2tlZXBlci1zZXJ2aWNlLWRpc2NvdmVyeS8=">很自然的认定其选择了一致性而放弃了可用性<i class="fa fa-external-link-alt"></i></span>（即他是 CP系统）。</p>
<p>但是如果你读过 ZooKeeper的<span class="exturl" data-url="aHR0cDovL3pvb2tlZXBlci5hcGFjaGUub3JnL2RvYy9yMy40LjYvem9va2VlcGVyUHJvZ3JhbW1lcnMuaHRtbCNjaF96a0d1YXJhbnRlZXM=">文档<i class="fa fa-external-link-alt"></i></span>，里面很清楚地说了 ZooKeeper 默认不支持可线性化的读取操作。每个客户端只连接到一个服务器节点，当客户端要读的时候，即使别的节点有更新的数据，也只能看到其直连的服务器节点的数据。这样做可以使其读性能比每次读都去收集多数票（quorum）或者访问 Leader 要高很多，但这也说明 ZooKeeper 在默认配置下不满足<em>CAP一致性</em>。</p>
<p>当然，也可以在每次<span class="exturl" data-url="aHR0cHM6Ly9tYWlsLWFyY2hpdmVzLmFwYWNoZS5vcmcvbW9kX21ib3gvem9va2VlcGVyLXVzZXIvMjAxMzAzLm1ib3gvJTNDQ0FKd0ZDYTBIb2VrYzE0Wnk2aTBMeUxqPWVyYUY4SmltcU1aYWRvaG9LUUpOVE10WVNnQG1haWwuZ21haWwuY29tJTNF">读操作之前发一个sync命令<i class="fa fa-external-link-alt"></i></span>使得ZooKeeper支持线性化的读取。但这不是默认设置，因为这样牺牲了一部分性能。人们只在必要的时候才会去用 sync 命令，而不会所有读操作前都用。</p>
<p>那ZooKeeper的可用性呢？ZK 需要<span class="exturl" data-url="aHR0cDovL3d3dy50Y3MuaHV0LmZpL1N0dWRpZXMvVC03OS41MDAxL3JlcG9ydHMvMjAxMi1kZVNvdXphTWVkZWlyb3MucGRm">集群节点的多数票<i class="fa fa-external-link-alt"></i></span>来达到数据共识，比如，只有在多数节点同意时才能成功执行一个写操作。如果出现有网络分区，一边有大多数节点，另一边只有少部分节点。此时，拥有大多数节点的分区还可以继续提供服务；但对于少数节点分区来说，即使节点都活着，也不能正常处理读写请求。所以在出现网络分区时，ZK 的写操作不满足<em>CAP可用性</em>（即使拥有大多数节点的分区仍然可以处理写操作）。</p>
<p>更有意思的是，ZooKeeper 3.4.0 还加入了一个<span class="exturl" data-url="aHR0cDovL3pvb2tlZXBlci5hcGFjaGUub3JnL2RvYy9yMy40LjYvem9va2VlcGVyQWRtaW4uaHRtbCNFeHBlcmltZW50YWwrT3B0aW9ucyUyRkZlYXR1cmVz">只读模式<i class="fa fa-external-link-alt"></i></span>。在该模式下，少部分节点分区仍可以处理读操作 ，不需要quorum！ 这个只读模式是满足<em>CAP可用性</em>的。因此，ZooKeeper 默认设置既不不满足 <em>CAP一致性</em>（CP）也不满足 <em>CAP可用性</em>（AP），它真正满足的只有分区容错（P）。但你可以在需要的情况下调用 sync 命令让读请求满足 CP；或者在只读模式下，使其读操作（不包括写）满足 AP。</p>
<p>这就很烦人了。如果仅因为ZooKeeper 的默认配置不是可线性化的就称其为“不一致”，会严重歪曲 ZK 的功能。他其实可以提供非常强的一致性！他支持<span class="exturl" data-url="aHR0cDovL2RzLnFjcmkub3JnL3Blb3BsZS9tc2VyYWZpbmkvemFiLnBkZg==">原子广播<i class="fa fa-external-link-alt"></i></span>（<span class="exturl" data-url="aHR0cDovL2NvdXJzZXMuY3NhaWwubWl0LmVkdS82Ljg1Mi8wOC9wYXBlcnMvQ1Q5Ni1KQUNNLnBkZg==">可以简单理解为共识问题<i class="fa fa-external-link-alt"></i></span>）并且每个会话都提供<span class="exturl" data-url="aHR0cDovL3d3dy1pMi5pbmZvcm1hdGlrLnJ3dGgtYWFjaGVuLmRlL2kyL2ZpbGVhZG1pbi91c2VyX3VwbG9hZC9kb2N1bWVudHMvU2VtaW5hcl9NQ01NMTEvQ2F1c2FsX21lbW9yeV8xOTk2LnBkZg==">因果一致性<i class="fa fa-external-link-alt"></i></span><strong>[4]</strong> – 这比<span class="exturl" data-url="aHR0cHM6Ly93d3cucmVzZWFyY2hnYXRlLm5ldC9wcm9maWxlL0RvdWdsYXNfVGVycnkzL3B1YmxpY2F0aW9uLzM1NjEzMDBfU2Vzc2lvbl9ndWFyYW50ZWVzX2Zvcl93ZWFrbHlfY29uc2lzdGVudF9yZXBsaWNhdGVkX2RhdGEvbGlua3MvMDJlN2U1MmNkYmU2MGE2Y2I0MDAwMDAwLnBkZg==">read your writes, monotonic reads<i class="fa fa-external-link-alt"></i></span> 还有<span class="exturl" data-url="aHR0cDovL3Jlc2VhcmNoLm1pY3Jvc29mdC5jb20vcHVicy8xNTc0MTEvQ29uc2lzdGVuY3lBbmRCYXNlYmFsbFJlcG9ydC5wZGY=">consistent prefix reads<i class="fa fa-external-link-alt"></i></span><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLnRoZS1wYW5zLmNvbS9jYXAvYXJ4aXYub3JnL3BkZi8xMzAyLjAzMDkucGRm">在一起都要强<i class="fa fa-external-link-alt"></i></span>。ZK 文档上说提供<span class="exturl" data-url="aHR0cHM6Ly9sYW1wb3J0LmF6dXJld2Vic2l0ZXMubmV0L3B1YnMvbXVsdGkucGRm">可序列化的一致性<i class="fa fa-external-link-alt"></i></span>，但这其实过于谦虚了，因为它可以提供比这强的多的一致性保证。</p>
<p>从 ZooKeeper的例子可以看出，就算一个系统在有网络分区的时候既不满足 <em>CAP一致性</em>（CP），也不满足 <em>CAP可用性</em>；甚至就算没有网络分区时，其默认配置也不提供可线性化，但仍可以不失为一个好系统（我猜ZK在<span class="exturl" data-url="aHR0cDovL2RibXNtdXNpbmdzLmJsb2dzcG90LmNvbS8yMDEwLzA0L3Byb2JsZW1zLXdpdGgtY2FwLWFuZC15YWhvb3MtbGl0dGxlLmh0bWw=">Abadi的PACELC的框架<i class="fa fa-external-link-alt"></i></span>下是PC&#x2F;EL，但我不觉得这比CAP更有启发性）。</p>
<h2 id="CP-x2F-AP：失当的二分法"><a href="#CP-x2F-AP：失当的二分法" class="headerlink" title="CP&#x2F;AP：失当的二分法"></a>CP&#x2F;AP：失当的二分法</h2><p>一个数据库不能无歧义地分类为 CP&#x2F;AP 的事实，表明 CP&#x2F;AP 本就不适合作为描述系统的标签。</p>
<p>基于以下几点，我认为不要再把数据存储系统强行归为AP或CP了：</p>
<ul>
<li>在同一个软件内，你可能有<span class="exturl" data-url="aHR0cHM6Ly9ncm91cHMuY3NhaWwubWl0LmVkdS90ZHMvcGFwZXJzL0dpbGJlcnQvQnJld2VyMi5wZGY=">多个一致性属性的选择<i class="fa fa-external-link-alt"></i></span>。</li>
<li>在CAP定理的严格定义下，大部分系统既不满足一致性也不满足可用性。然而我从来没听到别人称这些系统为”P”，或许这样听上去不大好。但这样的系统其实没那么糟糕，反而可能是非常合理的设计，只是不在CP&#x2F;AP这两个分类中罢了。</li>
<li>虽然大部分软件都不能恰好的归到 CP&#x2F;AP 这两类中，但人们还是强行按其进行了划分。这就导致为了适应其应用的具体场景，不可避免地改变了对 CAP定理中“一致性”或者“可用性”的定义。不幸的是，当这个几个关键概念的定义改变后，CAP定理也就不生效了，此时 CP&#x2F;AP 的区分也就完全没有意义了。</li>
<li>将一个系统强行归到两类中，容易让人忽略大量细微的差别。在设计分布式系统时，有很多因素需要考虑：服务的延迟、模型的简约、运维的难易等等，显然不可能把这么多细节压缩到仅用一个比特的信息来表示。比如，ZooKeeper 有一个符合 AP 的只读模式，但该模式同时提供对所有写操作的全局有序性，这个特性比 Riak 或者 Cassandra 这些所谓的 AP 系统提供的承诺要强得多，粗暴的将其归为 AP 显然很可笑。</li>
<li>甚至 CAP 作者 Eric Brewer 也<span class="exturl" data-url="aHR0cDovL2NzNjA5LmNzLnVhLmVkdS9DQVAxMi5wZGY=">承认 <i class="fa fa-external-link-alt"></i></span>CAP定理是一个有误导性且过于简化的模型。在2000年，抛出 CAP定理的意义在于引导业界针对分布式数据系统的取舍的讨论，CAP 定理的确也达到了这个效果。但该定理的目的不在于提出一个突破性的正式结论，也不是要成为一个严谨的数据系统的分类方式。十五年之后的现在，我们已经有了多得多的一致性和容错的模型来进行参考，CAP已经完成了他的使命，现在是时候往前看了。</li>
</ul>
<h2 id="学着独立思考"><a href="#学着独立思考" class="headerlink" title="学着独立思考"></a>学着独立思考</h2><p>如果 CP&#x2F;AP 不适合用来描述和评判一个系统，那我们应当用什么？我觉得正确答案不唯一。很多前人花了不少精力思考过这些问题，也提出了很多术语和模型来帮助我们理解这些问题。想学习这些知识，你需要更深入地去阅读相关文献。</p>
<ul>
<li>Doug Terry 的论文是一个很好的开始，<span class="exturl" data-url="aHR0cDovL3Jlc2VhcmNoLm1pY3Jvc29mdC5jb20vcHVicy8xNTc0MTEvQ29uc2lzdGVuY3lBbmRCYXNlYmFsbFJlcG9ydC5wZGY=">他以棒球为例解释了各种各样的最终一致性<i class="fa fa-external-link-alt"></i></span>。纵然你不是美国人，也不了解棒球，也会感觉该论文思路很清晰、可读性很强。</li>
<li>如果你对事务的隔离性模型（isolation，不同于分布式系统的一致性，但比较相关）有兴趣，我的小项目<span class="exturl" data-url="aHR0cDovL21hcnRpbi5rbGVwcG1hbm4uY29tLzIwMTQvMTEvMjUvaGVybWl0YWdlLXRlc3RpbmctdGhlLWktaW4tYWNpZC5odG1s">Hermitage<i class="fa fa-external-link-alt"></i></span>可以一看。</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzEzMDIuMDMwOS5wZGY=">Peter Bails 的这篇论文<i class="fa fa-external-link-alt"></i></span>探讨了一致性、事务的隔离性、可用性之间的关系（这篇论文描述了各种不同的一致性之间的层次化结构，Kyle Kingsbury<span class="exturl" data-url="aHR0cHM6Ly9hcGh5ci5jb20vcG9zdHMvMzIyLWNhbGwtbWUtbWF5YmUtbW9uZ29kYi1zdGFsZS1yZWFkcw==">很喜欢给别人讲这个<i class="fa fa-external-link-alt"></i></span>）。<img src="https://blog.the-pans.com/content/images/2018/07/isolation-levels.png" alt="isolation-levels"></li>
<li>当你读到过这些以后，应该已经准备好深入阅读文献。我在行文过程中加入了很多论文引用，不妨去看一下，专家们已经帮你把很多问题都解决了。</li>
<li>作为最后的选择，如果你不想逐篇读这些原始论文，可以看一下<span class="exturl" data-url="aHR0cDovL2RhdGFpbnRlbnNpdmUubmV0Lw==">我的书<i class="fa fa-external-link-alt"></i></span>，该书将大部分的重要思想用很平易的方式梳理了一遍（你看，我已经尽可能的让这篇文章看上去不是用来推销我的书的）</li>
<li>如果你想学习更多关于 ZooKeeper 使用的正确打开方式 ，<span class="exturl" data-url="aHR0cDovL3Nob3Aub3JlaWxseS5jb20vcHJvZHVjdC8wNjM2OTIwMDI4OTAxLmRv">Flavio Junqueira 和 Benjamin Reed的书<i class="fa fa-external-link-alt"></i></span>是不错的选择。</li>
</ul>
<p>不管你选择哪种学习方式，我都希望你保持好奇和耐心——这不是容易的学科。但一切付出都是值得的，你将学会如何合理的进行取舍，进而找出最适合你应用的架构。最后，不管怎么样，请不要再说 CP 和 AP 了，因为他们根本没有意义。</p>
<h2 id="译注"><a href="#译注" class="headerlink" title="译注"></a>译注</h2><p>[1] <strong>CAP可用性</strong>。作者用术语 CAP-Available 来专指 CAP 定理中狭义、专用的可用性，因此文中 <em>CAP可用性</em> 整体是一个名词，用斜体来表示。同样的 CAP-Consistency 也是如此，作者为了避免歧义，干脆用可线性化（Linearizability）来代称。</p>
<p>[2] <strong>可线性化</strong>。可以从另一个侧面进行理解，即系统中一系列具有偏序关系的事件，可以进行全局拓扑排序，即没有环。</p>
<p>[3] <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUXVvcnVtXyhkaXN0cmlidXRlZF9jb21wdXRpbmcp">Quorum机制<i class="fa fa-external-link-alt"></i></span>。是一种分布式系统中常用的，用来进行数据备份和保证最终一致性的投票算法，其主要数学思想来源于鸽巢原理，该算法可以保证同一份数据对象的多个副本不会被超过两个访问对象读写。每个使用此算法的系统，都有两个关键参数：最小读票数 R 和最小写票数 W。其关系需满足：1.R + W &gt; N  2. W &gt; N&#x2F;2，其中 N 是集群备份数。理解时可以类比读写锁，即系统不能同时有多个写写、读写，但是 R 设置的小一些可以同时有多个读。</p>
<p>[4] 因果一致性。<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQ2F1c2FsX2NvbnNpc3RlbmN5">causal consistency<i class="fa fa-external-link-alt"></i></span>，是一种主要的内存一致性模型，它会保证存在因果关系的操作顺序发生，没有明显因果关系事件的执行顺序则不作保证。</p>
<p>[5] replicate。可以翻译为副本、冗余、备份等等。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>基础</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>分布式系统</tag>
        <tag>CAP</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式基础（一）：CAP 的理解</title>
    <url>/2020/02/08/CAP/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/02/09/1dBXt5lG7FVvNqa.png" alt="cap-consistency-example.png"></p>
<h2 id="小引"><a href="#小引" class="headerlink" title="小引"></a>小引</h2><p>曾经在一个面试中让谈谈对 CAP 的理解，当时凭着准备面试时谷歌到的N手资料，类似于小学生背书一样，生挤出只言片语。面试官无奈的笑笑，简练的概括出他想要听到的要点，听的我心下惭愧。面试自然是挂了，后来工作时偶尔接触到这个词汇，初不得要领，后通过不同资料的多侧面理解、印证，渐渐拼凑出了一个轮廓，在这里梳理下，将影子撵到纸上，以供日后索引。</p>
<p>面试官大约是这么概括的：<em>在分布式系统中，失败必然的，分区容错（P）是一定需要的，因此设计系统时需要在可用性（A）和一致性（C）间进行权衡</em>。当时被教育印象很深，现在看来，这句概括是点出了小荷才露尖尖角的那个角。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/">https://www.qtmuniao.com</a>, 转载请注明出处</em></p>
<h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU1JTlGJTgzJUU5JTg3JThDJUU1JTg1JThCJUMyJUI3JUU1JUI4JTgzJUU5JUIyJTgxJUU1JUIwJTk0">埃里克·布鲁尔<i class="fa fa-external-link-alt"></i></span>（因此 CAP 定理又被成为 <strong>Brewer’s theorem</strong> ）大约在 1998 年就有了相关想法，然后在 1999 年作为一个原则将其发表出来，并且最终在 1999 年的 PODC 上作为一个猜想将其正式提出。2002 年，MIT 的  <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3cvaW5kZXgucGhwP3RpdGxlPVNldGhfR2lsYmVydCZhY3Rpb249ZWRpdCZyZWRsaW5rPTE=">Seth Gilbert<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTmFuY3lfTHluY2g=">Nancy Lynch<i class="fa fa-external-link-alt"></i></span> 做了一个非常收束条件下的证明，使其成为一个定理。</p>
<p>这里想说明的一点是，说到 <strong>CAP 原则</strong>（类似的意思，这个是我随口起的），可以是定义模糊、涵盖广泛、启发分布式系统设计的原则。但是 <strong>CAP 定理</strong>，则属于每个性质都有严格数学定义、结论有完善推导的<strong>理论计算科学</strong>范畴的概念。大多数人想表达前者的意思，但用的却是后者的术语。DDIA 作者 <span class="exturl" data-url="aHR0cHM6Ly9tYXJ0aW4ua2xlcHBtYW5uLmNvbS8=">Martin Kleppmann<i class="fa fa-external-link-alt"></i></span> 老爷子，还专门就此<span class="exturl" data-url="aHR0cHM6Ly9tYXJ0aW4ua2xlcHBtYW5uLmNvbS8yMDE1LzA1LzExL3BsZWFzZS1zdG9wLWNhbGxpbmctZGF0YWJhc2VzLWNwLW9yLWFwLmh0bWw=">吐槽了一番<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>CAP 原则指出，一个分布式存储系统提供的服务，不可能同时满足以下三点：</p>
<ol>
<li><strong>一致性</strong>（<em>Consistency</em>）：对于不同节点的请求，要么给出包含最新的修改响应、要么给出一个出错响应。</li>
<li><strong>可用性</strong>（<em>Available</em>）：对于每个请求都会给出一个非错响应，但是不保证响应数据的时效性。</li>
<li><strong>分区容错性</strong>（<em>Partition tolerance</em>）：当系统中节点间出现<em>网络分区</em>时，系统仍然能够正常响应请求。</li>
</ol>
<h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>分布式系统通常会包含多个数据节点（<em>Data Server</em>），将一个数据集（<em>Dataset</em>）分散到多个节点的方法常用的有三种：</p>
<ol>
<li><strong>冗余（<em>Replication</em>）</strong>：在多个节点上各存一份相同的全量数据集，每份称为<strong>副本</strong>（<em>Replica</em>）。</li>
<li><strong>分片（<em>Partition</em></strong>）：将数据集切成大小合适的几个分片，分别存到不同的节点上。</li>
<li><strong>冗余和分片</strong>：将数据集切成多片，每片又冗余多份，将其存放到不同节点上。</li>
</ol>
<p>正是数据的多机冗余和分片引出了分布式系统中的一致性问题。举个例子简单说明：</p>
<p>拿只有数据冗余的策略来说，假设有 <em>S0</em>、<em>S1</em>、<em>S2</em> 三个节点组成的一个数据系统，分别存放了某数据集 D 的三个副本 <em>D0</em>、<em>D1</em>、<em>D2</em> ，该数据集是个简单的<strong>键值对</strong>（<em>Key-value</em>）集合。初始，集合中 <code>&quot;a&quot; = 0</code>；某时刻 t，客户端 C0 向 <em>S0</em> 发送写请求 <code>set(&quot;a&quot;, 1)</code> ，并得到成功响应；紧跟 t 之后，另一个客户端 <em>C1</em> 向 <em>S1</em> 发送了一个读请求 <code>get(&quot;a&quot;)</code>，</p>
<p><img src="https://i.loli.net/2020/02/09/1dBXt5lG7FVvNqa.png" alt="cap-consistency-example.png"></p>
<p>如果系统如下设计：</p>
<ol>
<li><em>S0</em> 改变了 “a” 的值，并且将其同步到了 <em>S1</em>，<em>C1</em> 得到带有<strong>全局最新</strong>数据 <code>&quot;a&quot; = 1</code> 的响应</li>
<li>系统检测到 <em>S1</em> 尚未同步最新数据，于是返回给 <em>C1</em> 一个<strong>出错响应</strong>，提示其进行重试</li>
</ol>
<p>则该系统满足一致性。</p>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p>这个性质比较好理解，即系统必须在<strong>有限的时间</strong>内给出<strong>非错响应</strong>。如果响应时间超过可以容忍时间的几个数量级，那么该服务基本不可用。系统反应很快，但是给出了一个出错响应，比如 bad file、data stale 等等，则服务仍然不可用。</p>
<h3 id="分区容错性"><a href="#分区容错性" class="headerlink" title="分区容错性"></a>分区容错性</h3><p>这个性质曾经比较困扰我（当然现在也是），尚给不出一个精确的描述，只能从几个侧面来刻画一下。</p>
<p>这里面的难点在于如何理解<strong>网络分区</strong>（<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTmV0d29ya19wYXJ0aXRpb24=">network partitioning<i class="fa fa-external-link-alt"></i></span>）。</p>
<p>首先，一个简单的理解是，系统中的一部分和其他部分发生了网络隔离，互相不能够通信，进而不能及时完成数据同步，则可认为发生了网络分区。如上述例子中 {<em>S0</em>} 和 {<em>S1</em>, <em>S2</em>} 出现了网络隔离，则 {<em>S0</em>} 中更新的数据不能够及时同步给 {<em>S1</em>, *S2}*，则 {<em>S0</em>} 和 {<em>S1</em>, <em>S2</em>} 间产生了分区。</p>
<p>然后，将限制进一步放宽，如果系统中存在两个部分，其间通信时延很大，不能够在时限内进达成一致，则仍然可认为发生了网络分区。如上述例子中  {<em>S0</em>} 更新了数据后，尚未同步给 {<em>S1</em>, <em>S2</em>} 时，<em>C1</em> 的请求来了，用户仍会访问到旧的数据，也可认为{<em>S0</em>} 和 {<em>S1</em>, <em>S2</em>} 间产生了分区。</p>
<p>如果发生了网络分区以后，系统仍然能够正常提供服务，则该系统具有<strong>分区容错性</strong>。</p>
<p>抽象来说，如果<strong>系统组件</strong>之间的<strong>通信时延</strong>大于<strong>系统事件</strong>（比如说系统请求）的间隔，则会发生网络分区，这也是分布式系统的常态。极端情况下，如果某个系统运行在单机上，但是该机器内内存和 CPU 等组件间的通信延迟很高，则该单机可以认为是分布式系统，并且发生了网络分区。</p>
<p>以上都是从实践角度的一些理解，理论上严格定义的发生网络分区的条件更为苛刻，后面会详细说明。</p>
<h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p>在一个分布式系统中，网络故障和节点宕机是常态，因此网络分区是一定会出现的。在网络分区发生时，根据业务需求，系统需要在可用性和一致性之间二选一：</p>
<ol>
<li><strong>优先保证可用性</strong>。网络分区使得有些节点不可达，导致系统不能够及时同步数据。尽管被请求节点试图返回其可见范围内的最新数据，但仍不能保证该数据是全局最新的，即牺牲一致性保证可用性。</li>
<li><strong>优先保证一致性</strong>。网络分区使得被请求节点不能够保证数据全局最新时，返回一个出错信息给用户；或者什么也不返回，直到客户端超时。</li>
</ol>
<p>但该原则并不是说，系统在任何时候都必须抛弃 CAP 中的一个。比如系统网络状况良好时，并不需要在三者间进行取舍，此时不需要分区容错，可兼顾一致性和可用性。</p>
<p>深入理解这个原则，需要把握分布式系统设计时的两个关键因素：<strong>网络环境</strong>和<strong>业务需求</strong>。尤其要注意，原则是理想情况下的断言，而实践是实际场景下的取舍，CAP 原则只是点出了系统设计的三个重要权衡方向。</p>
<p><strong>网络环境</strong>，不同系统所要面对网络环境变化范围极大。</p>
<p>如果网络状况很好，网络分区很少发生，则系统设计时不需要过分考虑分区容错，比如可以简单设计为出现分区就停止服务，稍好一点可以让客户端进行重试等等。看起来似乎牺牲了可用性，但要注意到这种情况很少发生，所以系统可能仍然能提供N个9的服务。</p>
<p>如果网络状况堪忧、集群规模很大，网络不通、节点宕机是常态，则系统设计时需认真考虑出现网络分区时可用性和一致性间的取舍。这里在此强调一下，<strong>CAP定理</strong>中的分区容错性是非常理想化的：</p>
<blockquote>
<p>网络将被允许任意丢失从一个节点发送到另一节点的许多消息 —— Gilbert，Lynch</p>
</blockquote>
<p>如果网络任意丢失节点间的消息，经典的分布式共识协议（如 Paxos 和 Raft）将不能稳定的选出主节点并正常提供服务；工业级别的分布式数据库系统（如 HBase 和 Dynamo）也将不能多机同步数据，正常的提供存储服务。但是一般系统所面对的网络环境都没有这么糟糕，我们因此可以通过共识算法、冗余备份等手段兼顾<strong>某种程度的</strong>可用性和一致性。</p>
<p>而这个某种程度，就是接下来要谈的业务需求。</p>
<p><strong>业务需求</strong>，针对不同业务场景偏好进行设计，就产生了市面上形形色色的分布式系统中间件。在这里，我们只考虑可用性和一致性两个需求。这里也要再次强调，在实际情况中，大部分系统都不会要求<strong>原子一致性</strong>（<em>atomic consistency</em> ）或者<strong>完全的可用性</strong>(<em>perfect availability</em>) 。</p>
<p>对一致性来说，根据需求可以有强一致性、弱一致性、最终一致性等选择。工业级别的系统，为了提供高可用性，在业务可以容忍的范围内，往往选择弱一致性或者最终一致性，如 Amazon 的键值对存储 <a href="https://www.qtmuniao.com/2020/06/13/dynamo/">Dynamo</a>。</p>
<p>对可用性来说，需要考虑系统用户请求的多少、并发的高低、数据的大小等等方面来定义系统的可用性。任何系统都不可能做到全场景覆盖，只要系统设计能够满足其面向的业务场景，就可以说系统满足可用性需求。比如一个私有云对象存储服务，所面对的流量可能只是每天几十 QPS、读远大于写、并发很低；在这个情况下，我们完全可以在把系统设计的不是很复杂的基础上兼顾一致性和可用性。但如果把该服务用作淘宝双十一等场景，那系统可用性基本上就没有了。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>CAP 在分布式系统未火热之时，归纳出了分布式系统设计中所需权衡重要的方向。在云计算、大数据如火如荼的今天，一大批优秀的分布式系统涌现出来，给了我们更多的系统设计的考虑方向和实践细节。如今做系统设计时，不用太过拘泥于 CAP 原则，根据所面对业务场景，大胆进行取舍即可。</p>
<h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><ol>
<li>维基百科， CAP theorem： <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQ0FQX3RoZW9yZW0=">https://en.wikipedia.org/wiki/CAP_theorem<i class="fa fa-external-link-alt"></i></span></li>
<li>分布式小册，Distributed Systems for Fun and Profit： <span class="exturl" data-url="aHR0cDovL2Jvb2subWl4dS5uZXQvZGlzdHN5cy9hYnN0cmFjdGlvbnMuaHRtbA==">http://book.mixu.net/distsys/abstractions.html<i class="fa fa-external-link-alt"></i></span> </li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuc29tZXRoaW5nc2ltaWxhci5jb20vYWJvdXQ=">Jeff Hodges<i class="fa fa-external-link-alt"></i></span>，写给分布式系统初学者的笔记：<span class="exturl" data-url="aHR0cHM6Ly93d3cuc29tZXRoaW5nc2ltaWxhci5jb20vMjAxMy8wMS8xNC9ub3Rlcy1vbi1kaXN0cmlidXRlZC1zeXN0ZW1zLWZvci15b3VuZy1ibG9vZHMvI2NhcA==">https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/#cap<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9jb2RhaGFsZS5jb20veW91LWNhbnQtc2FjcmlmaWNlLXBhcnRpdGlvbi10b2xlcmFuY2Uv">https://codahale.com/you-cant-sacrifice-partition-tolerance/<i class="fa fa-external-link-alt"></i></span></li>
<li>左耳朵耗子推荐，分布式系统架构经典资料： <span class="exturl" data-url="aHR0cHM6Ly93d3cuaW5mb3EuY24vYXJ0aWNsZS8yMDE4LzA1L2Rpc3RyaWJ1dGVkLXN5c3RlbS1hcmNoaXRlY3R1cmU=">https://www.infoq.cn/article/2018/05/distributed-system-architecture<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>基础</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>CAP</tag>
        <tag>CAP定理</tag>
        <tag>一致性</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 2020 视频笔记一：绪论</title>
    <url>/2020/02/29/6-824-video-notes-1/</url>
    <content><![CDATA[<blockquote>
<p><img src="https://i.loli.net/2020/03/06/IewXsYmP4T7UrzJ.png" alt="6.824-schedule.png"></p>
<p>MIT 今年终于主动在 Youtube 上放出了随堂视频资料，之前跟过一半这门课，今年打算刷一下视频，写写随堂笔记。该课程以分布式基础理论：容错、备份、一致性为脉络，以精选的工业级系统论文为主线，再填充上翔实的阅读材料和精到的课程实验，贯通学术理论和工业实践，实在是一门不可多得的分布式系统佳课。课程视频: <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vY2hhbm5lbC9VQ183V3JiWlRDT0R1MW9fa2ZVTXE4OGcvdmlkZW9z">Youtube<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL2F2OTA5MTU1MjY=">B站<i class="fa fa-external-link-alt"></i></span>。课程资料：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvc2NoZWR1bGUuaHRtbA==">6.824主页<i class="fa fa-external-link-alt"></i></span>。本篇是第一节课笔记，绪论。</p>
</blockquote>
<h2 id="课程背景"><a href="#课程背景" class="headerlink" title="课程背景"></a>课程背景</h2><p>构建分布式系统的原因：</p>
<ol>
<li>Parallelism，资源并行（提高效率）。</li>
<li>Fault tolerance，容错。</li>
<li>Physical，系统内在的物理分散。</li>
<li>Security，不可信对端（区块链）。</li>
</ol>
<p>分布式系统面临的挑战：</p>
<ol>
<li>Concurrency，系统构件很多，并行繁杂，交互复杂。</li>
<li>Partial failure，存在部分失败，而不是像单机一样要么正常运行，要么完全宕机。</li>
<li>Performance，精巧设计才能获取与机器数量线性相关的性能。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/02/29/6-824-video-notes-1/">https://www.qtmuniao.com/2020/02/29/6-824-video-notes-1/</a>, 转载请注明出处</em></p>
<h2 id="课程组成"><a href="#课程组成" class="headerlink" title="课程组成"></a>课程组成</h2><ol>
<li>Lectures，授课，一些案例学习。</li>
<li>Papers，论文。<ul>
<li>包括一些经典的和前沿的、学术的和工业界的。</li>
<li>看其观点，学其实现，断其性能。</li>
<li>抓重要部分，略次要部分。</li>
<li>课程主页有所有论文链接。</li>
</ul>
</li>
<li>Exams，期中期末两次考试。</li>
<li>Labs：四个实验<ul>
<li>lab1： MapReduce</li>
<li>lab2： Raft 容错</li>
<li>lab3： K&#x2F;V server use Raft</li>
<li>lab4： Shared K&#x2F;V based on lab3<br>分布式系统巨难调试，做好心理准备，早点开做。</li>
</ul>
</li>
<li>Project，可以自选相关题目，组队完成，用来替代 lab4。</li>
</ol>
<h2 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h2><p>本课程旨在学习支撑应用的基础设施<strong>抽象</strong>（abstraction），包括</p>
<ol>
<li>Storage，存储，一个很直接并常用的抽象；如何构建多副本、容错、高性能分布式存储系统。</li>
<li>Communication，通信，如何可靠的通信。</li>
<li>Computation，现代的大规模计算，如 MapReduce</li>
</ol>
<p>最终理想是提供能够屏蔽分布式细节的、类似于单机的通用接口，同时能兼具<strong>容错</strong>和<strong>性能</strong>。</p>
<p>对于上述抽象，我们有哪些实现呢？</p>
<ol>
<li>RPC：像在本机调用一样跨节点通信</li>
<li>Concurrency，Threads：并发载体</li>
<li>Concurrency，Lock：并发控制。</li>
</ol>
<h3 id="Performance-性能"><a href="#Performance-性能" class="headerlink" title="Performance 性能"></a>Performance 性能</h3><p>scalability，可扩展性</p>
<ul>
<li>可以线性的集结计算机资源：使用两倍的机器获取两倍的吞吐。</li>
<li>意味着遇到瓶颈你只需要花少量的钱买机器，而不用付很多的工资找程序员重构。</li>
<li>但这个特点很难实现。通常你将一个组件扩展后，瓶颈就转移到了另一个组件，全组件的无限扩展很难。</li>
</ul>
<h3 id="Fault-Tolerance-容错"><a href="#Fault-Tolerance-容错" class="headerlink" title="Fault Tolerance 容错"></a>Fault Tolerance 容错</h3><p>单机虽好，作为上千台机器组成的集群来说，故障却是常态。比如说：</p>
<ul>
<li>主机宕机</li>
<li>网络抖动</li>
<li>交换机故障</li>
</ul>
<p>Availability 可用性<br>Recoverbility 可恢复性，无干预 、不影响正确性的可恢复</p>
<p>手段：<br>NV storage：持久化<br>Replication：多副本</p>
<h3 id="Consistency-一致性"><a href="#Consistency-一致性" class="headerlink" title="Consistency 一致性"></a>Consistency 一致性</h3><p>分布式系统产生不一致的因素：</p>
<ol>
<li>缓存</li>
<li>多副本</li>
</ol>
<p>不同程度的一致性：</p>
<ol>
<li><p>强一致性：每个客户端每次都能读到（自己or他人）之前所写数据。在多副本系统实现强一致性代价十分高昂，需要进行大量的通信。简单说两种方法：</p>
<ul>
<li>每次更改同时写到所有副本</li>
<li>每次读取都去读所有副本，使用具有最新时间戳的数据。</li>
</ul>
</li>
<li><p>弱一致性，为了性能，工业级系统通常选择弱一致性。</p>
</li>
</ol>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>Google （2003年左右）面对巨量（数十T）的索引数据和全网结构的数据，需要找到最重要的网页。可以简化为一个排序问题，但如此数量级的排序，单机不是一个可选项。而又不是所有工程师都有手撸分布式系统的能力，因此产生了做一个分布式框架的需求，以对应用程序员屏蔽分布式环境细节：</p>
<ol>
<li>如何将工作高效分配到上千台机器上。</li>
<li>如何控制数据流动。</li>
<li>如何进行容错。</li>
</ol>
<p>等等。</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>以 WordCount 为例：</p>
<p><strong>Map</strong>: document -&gt; (word, 1)</p>
<p><strong>Shuffle</strong>：group by word in Map machine，send each key Range to the corresponding Reduce Machine。</p>
<p><strong>Reduce</strong>: List(word, 1) -&gt; (word, count)</p>
<h3 id="术语体系"><a href="#术语体系" class="headerlink" title="术语体系"></a>术语体系</h3><p><strong>任务</strong>：Job</p>
<p><strong>工作</strong>：Task，分为 Map Task 和 Reduce Task。</p>
<p><strong>工作节点</strong>：worker server</p>
<p><strong>工作进程</strong>：worker process</p>
<p><strong>主节点</strong>：master server</p>
<h3 id="存储配合"><a href="#存储配合" class="headerlink" title="存储配合"></a>存储配合</h3><p>为了更好的并行读写，需要一个网络文件系统来配合输入和输出，这就是 GFS（谷歌文件系统）。</p>
<p>GFS 可以简单理解为，一个将大文件拆为一个个小的 64M 的块分散到不同机器上网络文件系统。</p>
<h3 id="网络开销"><a href="#网络开销" class="headerlink" title="网络开销"></a>网络开销</h3><p>为了尽量绕开当时的主要瓶颈（网络传输），Google 做了一系列优化，包括 GFS 和 MR 跑在一个集群上，以减少读取和写入数据的网络传输。具体做法是让 Map 任务（Map Task）去找数据（Block）—— 将 Task 调度到其输入所在的机器上。但对于 Reduce 任务，无论如何都会存在大量网络开销：GFS 对数据都进行了冗余备份，意味着每个结果都要写多次。</p>
<p>不过，时下的数据中心可以通过很多手段使得网络传输的速度大大提高，比如使用多个根路由器进行分摊流量，意味着在设计时可以有更多灵活性，不用太为网络传输而优化。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>6.824</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 2020 视频笔记三：GFS</title>
    <url>/2020/03/14/6-824-vidoe-notes-3-gfs/</url>
    <content><![CDATA[<blockquote>
<p><img src="https://i.loli.net/2020/03/06/IewXsYmP4T7UrzJ.png" alt="6.824-schedule.png"></p>
<p>MIT 今年终于主动在 Youtube 上放出了随堂视频资料，之前跟过一半这门课，今年打算刷一下视频，写写随堂笔记。该课程以分布式基础理论：容错、备份、一致性为脉络，以精选的工业级系统论文为主线，再填充上翔实的阅读材料和精到的课程实验，贯通学术理论和工业实践，实在是一门不可多得的分布式系统佳课。课程视频: <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vY2hhbm5lbC9VQ183V3JiWlRDT0R1MW9fa2ZVTXE4OGcvdmlkZW9z">Youtube<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL2F2OTA5MTU1MjY=">B站<i class="fa fa-external-link-alt"></i></span>。课程资料：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvc2NoZWR1bGUuaHRtbA==">6.824主页<i class="fa fa-external-link-alt"></i></span>。本篇是第三节课笔记，GFS。</p>
</blockquote>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>存储（Storage）是一个非常关键的抽象，用途广泛。</p>
<p>GFS 论文还提到了很多关于容错、备份和一致性的问题。</p>
<p>GFS 本身是 Google 内部一个很成功的实用系统，其关键点被很好的组织到一块发表成为了学术论文，从硬件到软件，涵盖了很多问题，值得我们学习。</p>
<p>想详细了解 GFS，也可以看我之前的 <a href="https://www.qtmuniao.com/2019/05/26/gfs/">GFS 论文笔记</a>。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/03/14/6-824-vidoe-notes-3-gfs/">https://www.qtmuniao.com/2020/03/14/6-824-vidoe-notes-3-gfs/</a>, 转载请注明出处</em></p>
<h2 id="为什么难"><a href="#为什么难" class="headerlink" title="为什么难"></a>为什么难</h2><ol>
<li><p>性能（High Performance）–&gt; 分片（sharding）</p>
<p>分布式系统，自然想利用大量的机器提供成比例的性能，于是通常将数据分散到不同的机器上，以并行读取。我们称之为：分片（Sharding）。但分片一多，故障率就上来了。</p>
</li>
<li><p>故障（Faults）—&gt; 容错（tolerance）</p>
<p>故障多了，就需要进行自动容错。最简单直接、通常也最有效的容错方法就是：备份（Replication，或译为冗余、副本）。如果副本是可修改的，就需要定期同步，这就引出了一致性的问题。</p>
</li>
<li><p>副本（Replication）—&gt; 一致性（Consistency）</p>
<p>当然，通过精心的设计，可以维持系统的一致性，但这就意味着你需要损失性能。</p>
</li>
<li><p>一致性（Consistency）—&gt; 低性能（Low Performance）</p>
</li>
</ol>
<p>这有点类似于反证法，最后推出了矛盾，说明了构建分布式存储系统这件事的难点所在。在实践中，在<strong>给定场景性</strong>下，我们有更多的取舍余地，也就让设计一个合理的系统成为可能。</p>
<h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><h3 id="强一致性"><a href="#强一致性" class="headerlink" title="强一致性"></a>强一致性</h3><p>即，尽管存储系统中有很多副本、很多机器，但是对外表现的行为却像单机一样：所有客户端都能够读到其他客户端之前所写内容。这个行为，或者说保证，看起来很简单、自然，但在分布式环境中，这确非易事。这部分想详细了解的可以看我翻译的一篇关于 CAP 的<a href="https://www.qtmuniao.com/2020/02/16/not-cp-or-ap/">经典文章</a>。</p>
<h3 id="糟糕设计"><a href="#糟糕设计" class="headerlink" title="糟糕设计"></a>糟糕设计</h3><p>为了使得所有副本保持一致性，可以在在客户端做同步：每次写操作，都并行的写多个备份。每个备份服务器接收到的写操作顺序可能并不一致，从而造成备份的不一致性。</p>
<h2 id="GFS"><a href="#GFS" class="headerlink" title="GFS"></a>GFS</h2><p>在谷歌三篇著名论文（MapReduce，GFS，Bigtable）出来之前，一些分布式的理论大多停留在学术界中，谷歌由于面临海量数据（youtube 视频、网页索引等等）的处理、存储和访问需求，最早开发出了实用的大规模的分布式框架。</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ol>
<li>体量大，速度快（Big，Fast）：海量数据的快速存取</li>
<li>全球部署（Global）：不同 site 的数据访问和共享</li>
<li>分片（Sharding）：多客户端并发访问，增大吞吐</li>
<li>自动恢复（Auto recovery）：机器太多，自动化运维</li>
</ol>
<p>不过接下来，我们只讨论具有以下限定的 GFS：</p>
<ol>
<li>部署在单个数据中心（datacenter）</li>
<li>仅供内部使用，不用过多考虑安全性</li>
<li>大数据的顺序读写，而非随机访问</li>
</ol>
<p>GFS 可贵之处在于他是经过实践检验、部署过上千台机器的工业级系统，颠覆了之前学术界中很多的经典设计认知，比如：</p>
<ol>
<li>为了保证数据访问不出错，需要提供强一致性保证（GFS 仅提供某种弱一致性）</li>
<li>为了系统的可靠性，用多机来保证主节点的可靠性（GFS 使用了单点 Master）</li>
</ol>
<h3 id="系统角色"><a href="#系统角色" class="headerlink" title="系统角色"></a>系统角色</h3><p>Clients：客户端，通过接口访问系统。</p>
<p>Master：保存命名空间以及元信息</p>
<p>ChunkServer：存储节点。</p>
<h3 id="Master-数据结构"><a href="#Master-数据结构" class="headerlink" title="Master 数据结构"></a>Master 数据结构</h3><p>Master 数据：</p>
<p>主要有以下两张表（Map）：</p>
<ol>
<li><p>文件名到 chunk 句柄的映射：filename –&gt; array of chunk handles（nv）</p>
</li>
<li><p>chunk 句柄到 chunk元信息的映射（包括副本位置，chunk 版本号，主 chunk，租约过期时间）：chunk handle —&gt; list of chunk servers(v)&#x2F;version(nv)&#x2F; Primary(v) &#x2F; lease expire time(v)</p>
<p>这两个数据结构都存在内存（RAM）中。但为了宕机恢复，需要把一些信息（标记为 nv：non-volatile）写到硬盘上，即：</p>
</li>
<li><p>读取，从内存中读即可。</p>
</li>
<li><p>写入，修改内存同时在磁盘上记操作日志（ LOG）+ 快照（CheckPoint）。</p>
<p>对于另外一些信息（标记为v：volatile），根据从 chunkserver 来的心跳构建即可。</p>
</li>
</ol>
<p>使用日志（Log）而不是数据库（DB）来记录操作信息，是因为在磁盘上，前者更快。但如果操作特别多，恢复起来会很慢。能不能压缩？因此有了快照（snapshot）：将操作日志所对应的内存状态通过某种格式（比如说B-tree）做一个快照。两者结合：将历史息用快照存储、最近一段信息用操作日志存储。这样既提高了空间利用率，也降低了操作延迟。</p>
<h3 id="读写流程"><a href="#读写流程" class="headerlink" title="读写流程"></a>读写流程</h3><p><strong>读取 READS</strong>：</p>
<ol>
<li>文件名、偏移量 –请求-&gt; Master</li>
<li>Master –回应–&gt; Chunk 句柄，Chunk 副本地址列表（Client 会缓存该信息）</li>
<li>客户端向某个副本（比如物理最近）所在的 chunk sever 请求数据，chunk server 返回相应数据</li>
</ol>
<p>Q&amp;A：</p>
<ol>
<li>待访问数据跨 chunk 怎么办？GFS 会提供客户端 lib，自动将其拆成多次请求。客户端不需要关心这些细节。</li>
</ol>
<p><strong>写入 WRITES</strong>：<br>这里只讲一下 Record Appends，分两种情况，</p>
<ul>
<li>Master 上没有主副本信息（No Primary）</li>
</ul>
<ol>
<li>找到所有最新副本（即需要大于等于 Master 所知最新版本号）</li>
<li>Master 选择其中一个作为主副本（Primary），其他的即为从副本（Secondary）</li>
<li>Master 增加版本号</li>
<li>Master 将新版本号同步给所有主从副本；同时给主副本一个租约。</li>
<li>Master 将版本号持久化。</li>
</ol>
<ul>
<li>Master 有主副本信息</li>
</ul>
<ol>
<li>Primary 选定 offset（由于 append 存在并发，Primary 负责将并发的 append 安排一个写入顺序，即给每个 append 一个不同的 offset）。</li>
<li>所有副本被通知在该 offset 写入数据。</li>
<li>如果所有副本回复 Primary 写成功，Primary 回复 Client 写成功</li>
<li>任何一个副本写失败，则 Primary 回复 Client 写失败。Client lib 会自动重试整个 Append 过程。</li>
</ol>
<p>Q&amp;A：</p>
<ol>
<li>如果 Client 写失败，则最终不同副本可能会存在不一致的区域（有些写成功了，有些写失败了）。但只要最终写成功了，会保证在返回的 offset 处，所有的数据都一致。中间写失败形成的不一致会在读取的时候被跳过。</li>
<li>同步数据时，Client 只会同步给最近的一个 replica，然后该 replica 进一步同步给其他 replica。如此链式同步，以避免交换机带宽瓶颈。</li>
<li>只有在 Master 认为所请求 chunk 没有主副本时，才会更新版本号。如果能在其内存表中找到主副本地址，则直接返回给 Client。</li>
<li>当发生网络分区时，Primary 和 Client 可以正常连接，但是与 Master 失联。租约到期时，没有收到Primary 心跳（Primary 通过向 Master 心跳来续约），Master 就会认为 Primary 宕机，从而重新选择一个 Primary。此时就会形成 split brain。这种情况就比较难办了。一个解决办法是，Master 等旧 Primary 租约过期（旧 Primary 也知道自己的租约过期时间，没有正常续约时，会自动失去 Primary 身份）后再去选择一个新 Primary。</li>
<li>如果要 Append 的某个文件还不存在怎么办？Master 会初始化一个版本号，然后随机选定一个 Primary 和几个 secondaries，然后回复给 Client。</li>
</ol>
<h3 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h3><p>为了实现一致性，可能需要类似两阶段提交的协议，但无疑会降低性能。</p>
<p>随着数据量的增大，元信息变多，Master 的内存可能会装不下，也就是 GFS 的单点瓶颈问题。</p>
<p>Master 恢复需要人工接入，导致系统宕机恢复可能需要数十分钟。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>6.824</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 2020 视频笔记二：RPC和线程</title>
    <url>/2020/03/06/6-824-video-notes-2/</url>
    <content><![CDATA[<blockquote>
<p><img src="https://i.loli.net/2020/03/06/IewXsYmP4T7UrzJ.png" alt="6.824-schedule.png"></p>
<p>MIT 今年终于主动在 Youtube 上放出了随堂视频资料，之前跟过一半这门课，今年打算刷一下视频，写写随堂笔记。该课程以分布式基础理论：容错、备份、一致性为脉络，以精选的工业级系统论文为主线，再填充上翔实的阅读材料和精到的课程实验，贯通学术理论和工业实践，实在是一门不可多得的分布式系统佳课。课程视频: <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vY2hhbm5lbC9VQ183V3JiWlRDT0R1MW9fa2ZVTXE4OGcvdmlkZW9z">Youtube<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL2F2OTA5MTU1MjY=">B站<i class="fa fa-external-link-alt"></i></span>。课程资料：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvc2NoZWR1bGUuaHRtbA==">6.824主页<i class="fa fa-external-link-alt"></i></span>。本篇是第二节课笔记，RPC 和线程。</p>
</blockquote>
<h2 id="为什么用-Go"><a href="#为什么用-Go" class="headerlink" title="为什么用 Go"></a>为什么用 Go</h2><ol>
<li><strong>语法先进</strong>。在语言层面支持线程（goroutine）和管道（channel）。对线程间的加锁、同步支持良好。</li>
<li><strong>类型安全（type safe）</strong>。内存访问安全（memory safe），很难写出像 C++ 一样内存越界访问等 bug。</li>
<li><strong>支持垃圾回收（GC）</strong>。不需要用户手动管理内存，这一点在多线程编程中尤为重要，因为在多线程中你很容易引用某块内存，然后忘记了在哪引用过。</li>
<li><strong>简洁直观</strong>。没 C++ 那么多复杂的语言特性，并且在报错上很友好。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/02/29/6-824-video-notes-2/">https://www.qtmuniao.com/2020/02/29/6-824-video-notes-2/</a>, 转载请注明出处</em></p>
<h2 id="线程（Threads）"><a href="#线程（Threads）" class="headerlink" title="线程（Threads）"></a>线程（Threads）</h2><p>线程为什么这么重要？因为他是我们控制并发的主要手段，而并发是构成分布式系统的基础。在 Go 中，你可以将 goroutine 认为是线程，以下这两者混用。 每个线程可以有自己的内存栈、寄存器，但是他们可以共享一个地址空间。</p>
<h3 id="使用原因"><a href="#使用原因" class="headerlink" title="使用原因"></a>使用原因</h3><p><strong>IO concurrency（IO并发）</strong>：一个历史说法，以前单核时，IO 是主要瓶颈，为了充分利用 CPU，一个线程在进行IO 时，可以让出 CPU，让另一个线程进行计算、读取或发送网络消息等。在这里可以理解为：你可以通过多个线程并行的发送多个网络请求（比如 RPC、HTTP 等），然后分别等待其回复。</p>
<p><strong>Parallelism（并行）</strong>：充分利用多核 CPU。</p>
<p>关于并发（concurrency）和并行（parallelism）的区别和联系，可以看<span class="exturl" data-url="aHR0cHM6Ly9sYWlrZTltLmNvbS9ibG9nL2h1YW4temFpLXlpLWh1by1iaW5nLWZhLWhlLWJpbmcteGluZyw2MS8=">这篇文章<i class="fa fa-external-link-alt"></i></span>。记住两个关键词即可：逻辑并发设计 vs 物理并行执行。</p>
<p><strong>Convenience（方便）</strong>：比如可以在后台启动一个线程，定时执行某件事、周期性的检测什么东西（比如心跳）。</p>
<p><strong>Q&amp;A：</strong></p>
<ol>
<li><em>不使用线程还能如何处理并发</em>？基于事件驱动的异步编程。但是多线程模型更容易理解一些，毕竟每个线程内执行顺序和你的代码顺序是大体一致的。</li>
<li><em>进程和线程的区别</em>？进程是操作系统提供的一种包含有独立地址空间的一种抽象，一个 Go 程序启动时作为一个进程，可以启动很多线程（不过我记得 Goroutine 是用户态的执行流）。</li>
</ol>
<h3 id="使用难点（challenges）"><a href="#使用难点（challenges）" class="headerlink" title="使用难点（challenges）"></a>使用难点（challenges）</h3><p>共享内存易出错。一个经典的问题是，多个线程并行执行语句：<code>n = n + 1</code> 时，由于该操作不是原子操作，在不加锁时，很容易出现 n 为非期望值。</p>
<p>我们称这种情况为<strong>竞态</strong> （race）：即两个以上的线程同时试图改变某个共享变量。</p>
<p>解决的方法是加锁，但如何科学的加锁以<strong>兼顾性能</strong>并<strong>避免死锁</strong>又是一门学问。</p>
<p><strong>Q&amp;A：</strong></p>
<ol>
<li><em>Go 是否知道锁和资源（一些共享的变量）间的映射</em>？Go 并不知道，它仅仅就是等待锁、获取锁、释放锁。需要程序员在脑中、逻辑上来自己维护。</li>
<li><em>Go 会锁上一个 Object 的所有变量还是部分</em>？和上个问题一样，Go 不知道任何锁与变量之间的关系。Lock 本身的源语很简单，goroutine0 调用 mu.Lock 时，没有其他 goroutine 持有锁，则 goroutine0 获取锁；如果其他goroutine 持有锁，则一直等待直到其释放锁；当然，在某些语言，如 Java 里，会将对象或者实例等与锁绑定，以指明锁的作用域。</li>
<li><em>Lock 应该是某个对象的私有变量</em>？如果可以的话，最好这样做。但如果由跨对象的加锁需求，就需要拿出来了，但要注意避免死锁。</li>
</ol>
<h3 id="线程协调（Coordination）"><a href="#线程协调（Coordination）" class="headerlink" title="线程协调（Coordination）"></a>线程协调（Coordination）</h3><ol>
<li>channels：go 中比较推荐的方式，分阻塞和带缓冲。</li>
<li>sync.Cond：信号机制。</li>
<li>waitGroup：阻塞知道一组 goroutine 执行完毕，后面还会提到。</li>
</ol>
<h3 id="死锁（DeadLock）"><a href="#死锁（DeadLock）" class="headerlink" title="死锁（DeadLock）"></a>死锁（DeadLock）</h3><p>产生条件：多个锁，循环依赖，占有并等待。</p>
<p>如果你的程序不干活了，但是又没死，那你就需要看看是否死锁了。</p>
<h2 id="爬虫（Web-crawler）"><a href="#爬虫（Web-crawler）" class="headerlink" title="爬虫（Web crawler）"></a>爬虫（Web crawler）</h2><ol>
<li><p>从一个种子网页 URL 开始</p>
</li>
<li><p>通过 HTTP 请求，获取其内容文本</p>
</li>
<li><p>解析其内容包含的所有 URL，针对所有 URL 重复过程 2，3</p>
<p>为了避免重复抓取，需要记下所有抓取过的 URL。</p>
</li>
</ol>
<p>由于：</p>
<ol>
<li>网页数量巨大</li>
<li>网络请求较慢<br>一个接一个的抓取用时太长，因此需要并行抓取。这里面有个难点，就是如何判断已经抓取完所有网页，并需要结束抓取。</li>
</ol>
<h3 id="抓取代码"><a href="#抓取代码" class="headerlink" title="抓取代码"></a>抓取代码</h3><p>代码在<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbm90ZXMvY3Jhd2xlci5nbw==">阅读材料<i class="fa fa-external-link-alt"></i></span>中有。</p>
<p><strong>串行爬取</strong>。深度优先遍历（DFS ）全部网页构成的图结构，利用一个名为 fetched 的 set 来保存所有已经抓取过的 URL。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Serial</span><span class="params">(url <span class="type">string</span>, fetcher Fetcher, fetched <span class="keyword">map</span>[<span class="type">string</span>]<span class="type">bool</span>)</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> fetched[url] &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  fetched[url] = <span class="literal">true</span></span><br><span class="line">  urls, err := fetcher.Fetch(url)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> _, u := <span class="keyword">range</span> urls &#123;</span><br><span class="line">    Serial(u, fetcher, fetched)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>并行爬取</strong></p>
<ol>
<li>将抓取部分使用 go 关键字变为并行。但如果仅这么改造，不利用某些手段（sync.WaitGroup）等待子 goroutine，而直接返回，那么可能只会抓取到种子 URL，同时造成子 goroutine 的泄露。</li>
<li>如果访问已经抓取的 URL 集合 fetched 不加锁，很可能造成多次拉取同一个网页。</li>
</ol>
<h3 id="WaitGroup"><a href="#WaitGroup" class="headerlink" title="WaitGroup"></a>WaitGroup</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> done sync.WaitGroup</span><br><span class="line"><span class="keyword">for</span> _, u := <span class="keyword">range</span> urls &#123;</span><br><span class="line">  done.Add(<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(u <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">defer</span> done.Done()</span><br><span class="line">    ConcurrentMutex(u, fetcher, f)</span><br><span class="line">  &#125;(u) <span class="comment">// u 被拷贝</span></span><br><span class="line">&#125;</span><br><span class="line">done.Wait()</span><br></pre></td></tr></table></figure>

<p>WaitGroup 内部维护了一个计数器：调用 <code>wg.Add(n)</code> 时候会增加 n；调用 <code>wait.Done()</code> 时候会减少1。这时候调用 <code>wg.Wait()</code> 会一直阻塞直到当计数器变为 0 。所以 WaitGroup 很适合等待一组 goroutine 都结束的场景。</p>
<p><strong>Q&amp;A</strong></p>
<ol>
<li><p><em>如果 goroutine 异常退出没有调用 wg.Done() 怎么办</em>？可以使用 defer 将其写在 goroutine 开始：<code>defer wg.Done()</code></p>
</li>
<li><p><em>两个 goroutine 同时调用 wg.Done() 会有竞争（race），以至于内部计数器不能正确减少两次吗</em>？WaitGroup 应该有相应机制（锁什么的）来保证 Done() 的原子性。</p>
</li>
<li><p><em>定义匿名函数时，匿名函数中变量和外层函数同名变量间的关系</em>？这是个闭包（closure）问题。如果匿名函数中变量没有被参数覆盖（如上述代码中 <code>fetcher</code>），就会和外层同名变量<strong>引用</strong>同一个地址。如果通过传参传递（如上述代码中 <code>u</code>），哪怕参数和外层变量看起来一样，但匿名函数使用的也是传进来的参数，而非外层变量；尤其针对 for 循环变量，我们通常通过参数来将其在调用时拷贝一次，否则 for 循环启动的所有 goroutine 都会指向这个不断被 for 循环赋值改变的变量。</p>
<p><strong>对于闭包，go 中有个”变量逃逸“（Variable Escape）的说法，如果某个变量在函数声明周期结束时仍被引用，则将其分被到堆而非函数栈上。对闭包来说，某个变量同时被内层和外层函数引用，则其会被分配到堆上</strong>。</p>
</li>
<li><p><em>既然字符串 <code>u</code> 是不可变（immutable）的，为什么所有 goroutine 还会引用到不断变化的值</em>？string 的确是不可变的，但是 <code>u</code> 的值一直在变，而 goroutine 和外层 goroutine 共享 u 的引用。</p>
</li>
</ol>
<h3 id="去掉锁"><a href="#去掉锁" class="headerlink" title="去掉锁"></a>去掉锁</h3><p>如果在更新 map 的时候去掉锁，运行几次发现并没有什么异常，因为 race 其实很难检测。好在 go 提供了竞态分析工具帮你来找到潜在含有竞态的地方：<code>go run -race crawler.go</code></p>
<p>注意该工具没有做静态分析，而是在动态执行过程中观察、记录各个 goroutine 的执行轨迹，进行分析。</p>
<h3 id="线程数量"><a href="#线程数量" class="headerlink" title="线程数量"></a>线程数量</h3><p>Q&amp;A</p>
<p>1.该代码在整个运行中会同时多少线程在运行（goroutine）？<br>该代码并没有做明显的限制，但是其明显和 URL 数量、抓取时间正相关。例子中输入只有五个 URL，因此没有什么问题。但在现实中，这么做可能会同时启动上百万个 goroutine。因此一个改进是，实现启动一个固定数量的 worker 池子，每个 worker 干完后就去要&#x2F;被分配下一个任务。</p>
<h3 id="使用-channel-通信"><a href="#使用-channel-通信" class="headerlink" title="使用 channel 通信"></a>使用 channel 通信</h3><p>我们可以实现一个新的爬虫版本，不用锁+共享变量，而用 go 中内置的语法：channel 来通信。具体做法类似实现一个生产者消费者模型，使用 channel 做消息队列。</p>
<ol>
<li>初始将种子 url 塞进 channel。</li>
<li>消费者：master 不断从 channel 中取出 urls，判断是否抓取过，然后启动新的 worker goroutine 去抓取。</li>
<li>生产者：worker goroutine 抓取到给定的<em>任务</em> url，并将解析出的<em>结果</em> urls 塞回 channel。</li>
<li>master 使用一个变量 n 来追踪发出的<em>任务</em>数；往发出一份<em>任务</em>增加一；从 channel 中获取并处理完一份<em>结果</em>（即将其再安排给worker）减掉一；当所有任务都处理完时，退出程序。</li>
</ol>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">worker</span><span class="params">(url <span class="type">string</span>, ch <span class="keyword">chan</span> []<span class="type">string</span>, fetcher Fetcher)</span></span> &#123;</span><br><span class="line">  urls, err := fetcher.Fetch(url)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    ch &lt;- []<span class="type">string</span>&#123;&#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ch &lt;- urls</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">master</span><span class="params">(ch <span class="keyword">chan</span> []<span class="type">string</span>, fetcher Fetcher)</span></span> &#123;</span><br><span class="line">  n := <span class="number">1</span></span><br><span class="line">  fetched := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]<span class="type">bool</span>)</span><br><span class="line">  <span class="keyword">for</span> urls := <span class="keyword">range</span> ch &#123;</span><br><span class="line">    <span class="keyword">for</span> _, u := <span class="keyword">range</span> urls &#123;</span><br><span class="line">      <span class="keyword">if</span> fetched[u] == <span class="literal">false</span> &#123;</span><br><span class="line">        fetched[u] = <span class="literal">true</span></span><br><span class="line">        n += <span class="number">1</span></span><br><span class="line">        <span class="keyword">go</span> worker(u, ch, fetcher)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    n -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">0</span> &#123;</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ConcurrentChannel</span><span class="params">(url <span class="type">string</span>, fetcher Fetcher)</span></span> &#123;</span><br><span class="line">  ch := <span class="built_in">make</span>(<span class="keyword">chan</span> []<span class="type">string</span>)</span><br><span class="line">  <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    ch &lt;- []<span class="type">string</span>&#123;url&#125;</span><br><span class="line">  &#125;()</span><br><span class="line">  master(ch, fetcher)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Q&amp;A:</strong></p>
<ol>
<li><em>master 读 channel，多 worker 写 channel，不会有竞争问题吗</em>？channel 是线程安全的。</li>
<li><em>channel 不需要最后 close 吗</em>？我们用 n 追踪了所有执行中的任务数，因此当 n 为0退出时，channel 中不存在任何任务&#x2F;结果，因此 master&#x2F;worker 都不会对 channel 存在引用，稍后 gc collector 会将其回收。</li>
<li><em>为什么在 ConcurrentChannel 需要用 goroutine 往 channel 中写一个 url</em>？否则 master 在读取的时候会一直阻塞。并且 channel 是一个非缓冲 channel，如果不用 goroutine，将会永远阻塞在写的时候。</li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>6.824</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Vercel 托管 Hexo 静态博客</title>
    <url>/2020/03/15/hexo-to-zeit-co/</url>
    <content><![CDATA[<p>博客本来用的是 github pages，但貌似由于百度爬虫太疯狂，被 github 给 ban 掉了。根据 <span class="exturl" data-url="aHR0cHM6Ly93d3cubWFya2V0bWVjaGluYS5jb20vYmFpZHUtc2VhcmNoLWVuZ2luZS1tYXJrZXQtc2hhcmUtaW4tY2hpbmEtZGVjLTIwMTkv">marketmechian<i class="fa fa-external-link-alt"></i></span> 的数据，在中国大陆搜索引擎界，百度还是占了半壁江山：</p>
<ul>
<li>Baidu: 67.09%</li>
<li>Sogou: 18.75%</li>
<li>Shenma: 6.84%</li>
<li>Google: 2.64%</li>
<li>bing: 2.6%</li>
<li>Other: 2.08%</li>
</ul>
<p>而作为一个中文博客，还是希望能够被更多的国内用户看到，因此一直在寻求一个使得百度爬虫自动爬取博客的方法。偶然间在浏览博客时，看到了有人在推荐 zeit.co 这个托管平台，使用了下，发现真是个非常棒的静态代码托管+CI Serverless Function 平台，在这里推荐给大家。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/03/15/hexo-to-zeit-co/">https://www.qtmuniao.com/2020/03/15/hexo-to-zeit-co/</a>, 转载请注明出处</em></p>
<h2 id="几种方法"><a href="#几种方法" class="headerlink" title="几种方法"></a>几种方法</h2><p>网上有很多方法可以使百度爬虫爬取博客页面，总结起来主要有：</p>
<ol>
<li>CDN，利用云服务提供商将 blog 多做几个镜像。</li>
<li>换托管平台，比如说国内的代码托管平台。</li>
<li>自行使用 VPS 托管。</li>
</ol>
<p>CDN 比较贵，又不想换托管平台，VPS 大陆访问速度不快。因此这件事一直搁置。</p>
<h2 id="zeit-co-vercel"><a href="#zeit-co-vercel" class="headerlink" title="zeit.co(vercel)"></a>zeit.co(vercel)</h2><p>这天在搜索资料时，注意到有博主 [1] 提到 <span class="exturl" data-url="aHR0cHM6Ly96ZWl0LmNvL2RvY3M=">zeit.co<i class="fa fa-external-link-alt"></i></span>，一个静态网页和无状态函数托管的云平台。试用了之后，感觉非常强大，它能够以 Github App 的形式与 GitHub 集成，接管 repo 的 CI，进行深度定制，并且能够快速部署、自动伸缩。</p>
<p>关键是，现在基本功能是免费的，这对于我们托管博客来说，已经很够用了。更惊喜的是，它还提供智能 CDN 和智能 DNS。</p>
<p><img src="https://i.loli.net/2020/03/15/31UAIsDMlKfTLNi.png" alt="zeit-price.png"></p>
<h2 id="改造"><a href="#改造" class="headerlink" title="改造"></a>改造</h2><p>了解到 zeit 的优势后，就开始着手改造博客的托管方式。主要有以下几个步骤：</p>
<ol>
<li>静态代码生成修改</li>
<li>代码库导入 zeit</li>
<li>修改 dns 指向</li>
</ol>
<h3 id="静态代码生成"><a href="#静态代码生成" class="headerlink" title="静态代码生成"></a>静态代码生成</h3><p>并不是所有人都需要这一步，我需要只是因为之前不太懂 hexo 的工作机制，自己坑了自己。</p>
<p>之前我只使用了一个 repo 来管理所有博客代码：用 master 分支作为 hexo 开发分支，使用 gh-pages 分支作为静态代码分支，然后将 repo 的 github pages 指向 gh-pages 分支，以发布博客。</p>
<p>由于 zeit 只能给 repo 的默认分支（即 master）做 CI，因此使用 zeit 托管 hexo 博客至少有两种方式：</p>
<ol>
<li><strong>托管 Hexo 开发代码</strong>。使用 zeit 接管 hexo 仓库代码，并为其配置 CI：每次往 master push 代码时，触发 CI，编译生成静态网页代码到 public 文件夹，然后将 public 文件夹发布。</li>
<li><strong>托管静态网页代码</strong>。让 hexo 每次将静态网页代码生成到一个新的 repo 的 master 分支，然后将该 repo 导入到 zeit 进行托管。</li>
</ol>
<p>我使用第一种的时候，发现 <code>hexo build</code> 老是失败，后面发现是我由于深度定制 NexT，修改了 NexT 主题的一些代码，但是并没有将其提交到仓库中。因为我本地的 NexT 主题代码仍然通过 git 关联着官方 NexT repo，以便及时 pull 最新特性，所以没有将其纳入 hexo 的仓库中。这一块深究一下应该也有解决方案，但是我懒，就选择了更简单的第二种托管方式：</p>
<p>将 hexo 代码库中配置文件  <code>hexo/_config.yml</code> 中部署方式修改如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">78</span> <span class="comment"># Deployment</span></span><br><span class="line"><span class="number">79</span> <span class="comment">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line"><span class="attr">80 deploy:</span></span><br><span class="line"><span class="attr">81   type:</span> <span class="string">git</span></span><br><span class="line"><span class="attr">82   repo:</span> <span class="string">https://github.com/you-git-name/blog-publish.git</span></span><br><span class="line"><span class="attr">83   branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>

<p>每次执行命令 <code>hexo d -g</code> 时，就会将生成的静态网页代码 push 到 repo <code>blog-publish</code> 下：</p>
<p><img src="https://i.loli.net/2020/03/15/XUSAh2Ci5GwE4ab.png" alt="zeit-repo-publish.png"></p>
<p>这样还有额外的好处，就是以前我很蠢的将各种配置（包括我的一些网站的秘钥）暴露在了 git 的公共仓库中（因为 private 仓库不能用 github pages），使用第二种部署方式，我将我的开发 repo 和静态代码 repo 都设置为了 private。此外，zeit 会获取导入 repo 的所有读写权限，还是有点小颤抖，因此，搞一个额外的静态代码 repo 在这里很合适。</p>
<h3 id="代码-repo-导入-zeit"><a href="#代码-repo-导入-zeit" class="headerlink" title="代码 repo 导入 zeit"></a>代码 repo 导入 zeit</h3><p>Zeit 网页界面很简洁，还算比较好用。</p>
<p><strong>注册</strong>。打开登陆页面：<span class="exturl" data-url="aHR0cHM6Ly96ZWl0LmNvL2xvZ2luJUVGJUJDJThDJUU0JUJEJUJGJUU3JTk0JUE4">https://zeit.co/login，使用<i class="fa fa-external-link-alt"></i></span> GitHub 账号登陆即可。</p>
<p><strong>导入</strong>。在主页面点击 “Import Project”，然后 “Import Project From Git Repo”，选择 GitHub。进行一下授权，注意只需导入静态代码仓库 <code>blog-publish</code> 。</p>
<p><strong>部署</strong>。导入过程中，选择 other 模板即可，默认 ci 命令不用改，Root Directory 也不用改，导入完成后就会自动帮你 deploy。</p>
<p>最后在部署卡片中就可以看到 zeit 生成的 URL：</p>
<p><img src="https://i.loli.net/2020/03/15/WXr3IK6VtwE1ZDs.png" alt="zeit-deploy.png"></p>
<h3 id="修改-DNS-指向"><a href="#修改-DNS-指向" class="headerlink" title="修改 DNS 指向"></a>修改 DNS 指向</h3><p>如果你有自己的域名，需要在域名服务提供商（阿里云、GoDaddy等）的 DNS 解析中增加一条 CNAME 记录（将你的域名指向另一个域名）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">www  CNAME	默认	blog-publish.now.sh.	0	600</span><br></pre></td></tr></table></figure>



<h2 id="百度爬取"><a href="#百度爬取" class="headerlink" title="百度爬取"></a>百度爬取</h2><p>最后在百度<span class="exturl" data-url="aHR0cHM6Ly96aXl1YW4uYmFpZHUuY29tL2h0dHBzL2luZGV4">站长工具页面<i class="fa fa-external-link-alt"></i></span>，在 <em>数据监控</em> &gt; <em>抓取诊断</em>，进行测试。</p>
<p>坑爹的是，我之前在域名解析时为百度爬虫配置了专门的线路，让其去我的 vps 抓取（当然最后没有成功，不然也就不会有本文了）。现在将那条记录去除后，百度爬虫这边时时不更新我的域名所对应 IP，点击报错后，提示几分钟后更新，然而几个小时过去了，依然未更新，当然这就是后话了。</p>
<p><img src="https://i.loli.net/2020/03/15/B6IenXtNiWQpMAF.png" alt="zeit-baidu.png"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><strong>[1]</strong> 解决百度爬虫无法爬取 Github Pages 个人博客的问题：<span class="exturl" data-url="aHR0cHM6Ly96cGppYW5nLm1lLzIwMjAvMDEvMTUvbGV0LWJhaWR1LWluZGV4LWdpdGh1Yi1wYWdlLw==">https://zpjiang.me/2020/01/15/let-baidu-index-github-page/<i class="fa fa-external-link-alt"></i></span></p>
<p><strong>[2]</strong> zeit.co 帮助文档：<span class="exturl" data-url="aHR0cHM6Ly96ZWl0LmNvL2RvY3M=">https://zeit.co/docs<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>搭建博客</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>vercel</tag>
        <tag>百度爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>WiscKey —— SSD 介质下的 LSM-Tree 优化</title>
    <url>/2020/03/19/wisckey/</url>
    <content><![CDATA[<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>充分利用现代存储 SSD 的性能，在提供同样 API 的情况下，显著降低 LSMTree 的读写放大，以提高其性能。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在传统磁盘上，顺序 IO 的性能大概是随机 IO 的 100 多倍，LSMTree 基于此，将海量 KV 的随机读写实现为内存随机读写+顺序刷盘+定期归并（compact），以提高读写性能，尤其适用于<strong>写多于读</strong>且<strong>时效性比较强</strong>（最近数据最常访问）的场景。</p>
<p><img src="https://i.loli.net/2020/03/21/IetKyMmGNQVrBsS.png" alt="wisckey-lsm-tree.png"></p>
<span id="more"></span>

<p><em>作者：木鸟杂记<a href="https://www.qtmuniao.com/2020/03/19/wisckey/">https://www.qtmuniao.com/2020/03/19/wisckey/</a>, 转载请注明出处</em></p>
<p><strong>读写放大</strong>。对于写放大，由于 LSMTree 有很多层，为了加快读取速度，需要不断地进行归并排序以 compact，由此导致每一个 KV 都会被读写多次。对于读放大，在垂直方面需要多层查询以寻找指定key，在水平方向由于同一层有多个 key range，需要进行二分查询。当然，为了加速查找，可以为每一层配一个 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQmxvb21fZmlsdGVy">bloom filter<i class="fa fa-external-link-alt"></i></span>，以在该层不存在要查找的 key 时快速跳过。随着数据量的增大，读写放大会更甚。</p>
<p><img src="https://i.loli.net/2020/03/21/GeaXn8tA51T2LKp.png" alt="wisckey-rw-amplification.png"></p>
<p>如今，SSD 价格愈发降低，使用规模愈发变大，而 SSD 的并行随机读性能是很不错的，和顺序读已经差不了那么多。当然，随机写还是尽量要避免，因为它既没随机读那么均匀的快，且会降低 SSD 寿命。</p>
<p><img src="https://i.loli.net/2020/03/21/MbcStji3UQs1a4N.png" alt="wisckey-ssd.png"></p>
<h2 id="核心设计"><a href="#核心设计" class="headerlink" title="核心设计"></a>核心设计</h2><p>WiscKey 的核心设计主要有以下四条：</p>
<ol>
<li>键值分开存储，Key 仍然存在 LSM-tree 中，Value 存在额外的日志文件（vLog）中。</li>
<li>对于无序的值数据，利用 SSD 并行随机读以加速读取速度。</li>
<li>使用独特的崩溃一致性和垃圾回收策略以高效的管理 Value 日志文件。</li>
<li>去除 WAL 并且不影响一致性，提升小数据流量的写入性能。</li>
</ol>
<h2 id="设计细节"><a href="#设计细节" class="headerlink" title="设计细节"></a>设计细节</h2><h3 id="键值分开"><a href="#键值分开" class="headerlink" title="键值分开"></a>键值分开</h3><p>仍然将 Key 存储于 LSM-tree 结构中，由于 Key 所占空间通常远小于 Value 的空间，WiscKey 中 LSM-tree 的层数会很少，不会有太多读写放大。将 Value 存在额外的一个日志文件</p>
<p>中，称为 vLog。当然 Value 的一些元信息，比如 Value 在 vLog 中的位置信息，会随着 Key 一起存在 LSM-tree 中，但其占空间很小。</p>
<p><img src="https://i.loli.net/2020/03/21/Q6IjovGPFybNHOA.png" alt="wisckey-architecture.png"></p>
<p><strong>读取</strong>。尽管 Key 和 Value 需要分开读取（即一次读取需要分解成一次 LSM-tree 中的内存（大概率）查找，一次 SSD 上的随机查找），但由于两者速度相较原来逐层查找都要块，所耗费时间并不会比 LevelDB 更多。</p>
<p><strong>写入</strong>。首先将 Value 追加到 vLog，得到其在 vLog 中的偏移量 vLog-offset。然后将 Key 和 <code>&lt;vLog-offset, value-size&gt;</code> 一起写入 LSM-tree 中。一个追加操作，一个内存写操作，都很快。</p>
<p><strong>删除</strong>。采用异步删除策略，仅仅删除 LSM-tree 中的 key 即可，vLog 中的 Value 会被定期的垃圾回收进程回收掉。</p>
<p>虽然有以上优点，但 Key Value 分开也随之带来了很多挑战，比如 Range Query、垃圾回收和一致性问题。</p>
<h3 id="挑战1：范围查询"><a href="#挑战1：范围查询" class="headerlink" title="挑战1：范围查询"></a>挑战1：范围查询</h3><p>范围查询（Range Query，指定起止 Key 顺序遍历 KV-Pair）是当代 KV 存储很重要的一个特性。 LevelDB 中键值对是按照 Key 的顺序存储的，因此顺序遍历相关 Memtable 和 SSTable 即可进行范围查询。但 WiscKey 的 Value 是无序的，因此需要大量随机查询。但是如图三所示，我们可以利用多线程并行随机查询以打满 SSD 带宽，大大提升查询速度。</p>
<p>具体来说，进行范围查询时，首先去 LSM-tree 中顺序加载出所需 Key，然后使用 SDD 的多线程随机读进行预读取放到 Buffer 中，就可以顺序的组合读出的 Key 和 buffer 中的 Value 返回给用户，以此获取很高的性能。</p>
<h3 id="挑战2：垃圾回收"><a href="#挑战2：垃圾回收" class="headerlink" title="挑战2：垃圾回收"></a>挑战2：垃圾回收</h3><p>LevelDB 利用紧缩机制（compact）进行延迟的垃圾回收，WiscKey 中 Key 的回收也使用同样机制。但对于 Value，由于其存在 vLog 中，需要考虑额外的垃圾回收机制。</p>
<p>最简单粗暴的做法，可以先扫一遍 WiscKey 中 LSM-tree 结构，以获取正在使用的 Key 集合；然后扫描 vLog，回收所有不被 Key 集合引用的 Value 即可。但显然，这是一个很重（耗时很长）的操作，为了保持一致性，可能需要停止对外提供服务，类似于早期 JVM GC 时的 stop-the-world。</p>
<p>而我们显然需要更轻量级的做法。WiscKey 的做法很巧妙，其基本思想是将 vLog 中所有 Value 数据视为一个条带，将所有正在使用的数据<strong>维持</strong>在条带中间，使用两个指针标记中间有效数据区域头尾。头部（head）只能进行追加操作，尾部（tail）进行垃圾回收。那么我们如何维持这个有效的中间数据区域呢？</p>
<p><img src="https://i.loli.net/2020/03/21/y2OaUcY9bnRS6PD.png" alt="wisckey-gc.png"></p>
<p>当需要进行垃圾回收时，从尾部读取一块数据（Block，含有一批数据条目，每个数据条目包含<code>&lt;ksize, vsize, key, value&gt;</code> 四个字段，每次读取一块是为了减少 IO）到内存中；对于每个数据条目，如其正在使用，则将其追加到 vLog 条带头部；否则将其丢弃；然后移动尾指针（tail）跳过此数据。</p>
<p>尾指针是一个关键变量，需要进行持久化以应对宕机。WiscKey 做法是复用存储 Key 的 LSM-tree 结构，利用一个特殊的 Key （<code>&lt;‘‘tail’’, tail-vLog-offset&gt;</code>）将其和 Keys 存在一块。头指针就是 vLog 文件的结尾，不需要保存。此外，WiscKey 的垃圾回收时机可以根据情况进行灵活配置，比如定期回收、达到某个阈值进行回收、系统闲时回收等等。</p>
<h3 id="挑战3：崩溃一致性"><a href="#挑战3：崩溃一致性" class="headerlink" title="挑战3：崩溃一致性"></a>挑战3：崩溃一致性</h3><p>当系统宕机崩溃时，LSM-tree 通常提供 KV 插入的原子性以及恢复时的顺序性等保证。WiscKey 也可以提供同样的一致性，但由于键值分开存储，实现机制稍微复杂一些（起码原子性会难一些）。</p>
<p>对于数据插入的<strong>原子性</strong>，我们考虑如下情况。宕机恢复后，当用户查询某 Key 时，</p>
<ol>
<li>如果不能在 LSM-tree 中找到，则系统当其不存在。即使 Value 可能已经被追加到了 vLog 中，之后也会被回收掉。</li>
<li>如果可以在 LSM-tree 中找到，则去查看其对应的 vLog 中的数据条目<code>&lt;ksize, vsize, key, value&gt;</code>，并依次检查该条目是否存在、位置是否在于中间合法段中、 Key 是否能匹配的上。如果不能，则删除该 Key，然后告诉用户不存在。为了防止数据只写一半后挂了，导致存在残缺的数据条目，也可以在数据条目中加入校验和。</li>
</ol>
<p>通过上述流程，我们可以保证 KV 写入的原子性：对用户来说，KV 要么都存在，要么都不存在。</p>
<p>对于数据插入的<strong>顺序性</strong>，由于当代文件系统（如 ext4，btrfs，xfs）等都保证追加的顺序性，即如果在 vLog 中顺序追加了数据条目 D1, D2, D3 … Dx, Dx+1, … 如果 Dx 在系统宕机时没有追加到 vLog 中，则其之后的数据条目都不会追加到系统中。由此可以保证数据插入的顺序性。</p>
<p>下面会讲到，为了提高小尺寸 Value 的追加效率，WiscKey 使用了写 Buffer。因此宕机时可能会丢失部分数据条目，为此 WiscKey 提供了同步写开关，以让 WiscKey 放弃 Buffer，强制刷 Value 到 vLog 文件后，再写对应的 Key 入 LSM-tree。</p>
<h3 id="优化1：vLog-缓存"><a href="#优化1：vLog-缓存" class="headerlink" title="优化1：vLog  缓存"></a>优化1：vLog  缓存</h3><p>对于密集型、小尺寸写入流量，如果用户每次调用 <code>put(K, V)</code>，就调用 <code>write</code> 源语，往 vLog 中追加一条数据条目，如此频繁 IO 会导致性能会很差，不能充分利用 SSD 带宽，如下图所示：</p>
<p><img src="https://i.loli.net/2020/03/21/DxZYFRzunNrOpgB.png" alt="wisckey-buffer-write.png"></p>
<p>因此，WiscKey 使用一个 Buffer 来缓存写入的 Value，仅在用户要求或者达到设定尺寸阈值时才真正的追加到 vLog 中。在查询时也需要相应做一些修改，每次查询首先要到 buffer 中查找，然后再去 vLog 中查找。但这么做的代价是，如前所述，在系统崩溃时会丢失 buffer 中的这部分未刷盘的数据。</p>
<h3 id="优化2：省去-WAL"><a href="#优化2：省去-WAL" class="headerlink" title="优化2：省去 WAL"></a>优化2：省去 WAL</h3><p>WAL，Write Ahead Log，预写日志，是数据库系统中常用的数据恢复机制。在传统 LSM-tree 中，由于数据直接写入内存中，为了进行宕机恢复，会在每次操作前记一条日志；在宕机恢复时，逐条读取日志，恢复内存中数据结构。但这样一来，每次写请求都增加了磁盘 IO，从而降低了系统写入性能。</p>
<p>由于 vLog 中的数据条目按顺序记录了所有插入的 Key，因此可以复用 vLog 作为 WiscKey 中 LSM-tree 的 WAL。作为一个优化，可以将每次未持久化的 Key 的点  <code>&lt;‘‘head’’, head-vLog-offset&gt;</code> 也保存在 LSM-tree 中，每次宕机恢复时，先获取该点，然后从该点之后逐条读取 vLog 中的 Key，恢复 LSM-tree。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>存储</tag>
        <tag>WiscKey</tag>
        <tag>LSM-tree</tag>
        <tag>SSD</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 2020 视频笔记四：VM-FT</title>
    <url>/2020/04/01/6-824-video-notes-4-vm-ft/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/03/06/IewXsYmP4T7UrzJ.png" alt="6.824-schedule.png"></p>
<p>MIT 今年终于主动在 Youtube 上放出了随堂视频资料，之前跟过一半这门课，今年打算刷一下视频，写写随堂笔记。该课程以分布式基础理论：容错、备份、一致性为脉络，以精选的工业级系统论文为主线，再填充上翔实的阅读材料和精到的课程实验，贯通学术理论和工业实践，实在是一门不可多得的分布式系统佳课。课程视频: <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vY2hhbm5lbC9VQ183V3JiWlRDT0R1MW9fa2ZVTXE4OGcvdmlkZW9z">Youtube<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL2F2OTA5MTU1MjY=">B站<i class="fa fa-external-link-alt"></i></span>。课程资料：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvc2NoZWR1bGUuaHRtbA==">6.824主页<i class="fa fa-external-link-alt"></i></span>。本篇是第四节课笔记，VM-FT。</p>
<h2 id="备份——容错"><a href="#备份——容错" class="headerlink" title="备份——容错"></a>备份——容错</h2><h3 id="失败（Failue）"><a href="#失败（Failue）" class="headerlink" title="失败（Failue）"></a>失败（Failue）</h3><p>如何定义？在其他电脑看来，停止对外提供服务。<br>通过备份&#x2F;副本（Replication）<br>可以解决：宕机（fail-stop），比如 CPU 过热而关闭、主机或者网络断电、硬盘空间耗尽等问题。<br>不能解决：一些相关联（correlated，主副本机器会同时存在）的问题，比如软件 Bug、人为配置问题</p>
<h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><p>主从备份可以工作的一个假设是，主从机器的出错概率需要时独立的。<br>比如说：同一批次机器、同一个机架上的机器，出错概率就存在强正相关特性。</p>
<h3 id="是否值当"><a href="#是否值当" class="headerlink" title="是否值当"></a>是否值当</h3><p>需要对业务场景和所需费用考量，是否真的需要进行 Replica。比如银行数据就需要多备份，而课程网站可能并不需要。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/04/01/6-824-video-notes-4-vm-ft/">https://www.qtmuniao.com/2020/04/01/6-824-video-notes-4-vm-ft/</a>, 转载请注明出处</em></p>
<h2 id="Primary-Backup-Paper"><a href="#Primary-Backup-Paper" class="headerlink" title="Primary-Backup Paper"></a>Primary-Backup Paper</h2><p>两种进行状态备份的方式：</p>
<ul>
<li>状态转移（State transfer）<br>持续增量同步 Primary 的状态到 Backup，包括CPU、内存、IO设备等等；但是这些状态通常所占带宽很大，尤其是内存变化。</li>
<li>冗余状态机（Replicated State Machine）<br>将服务器看作是一个具有确定性状态的状态机，只要给定相同初始状态和同样顺序的确定输入，就能保持同样的状态。同步的是外部的<strong>事件&#x2F;操作&#x2F;输入</strong>；同步的内容通常较小，但是依赖主机的一些特性：比如指令执行的确定性（deterministic）。而在物理机上保证确定性很难，但是在 VM 上就简单的多，由于 hypervisor 有对 VM 有完全的控制权，因此可以通过某些手段来额外同步某些不确定性输入（比如类似随机数、系统时钟等）。</li>
</ul>
<p>一般来说操作会比状态小的多，因此 Replicated State Machine 被采纳。</p>
<p>Q&amp;A：</p>
<ol>
<li>如果主从备份由于某种原因不一致了会怎么样？<br>可以考虑 GFS 中，由于网络分区造成两个 chunkserver 都认为自己是 Primary 的例子。</li>
<li>如果指令中有一些类似于依赖于随机数的指令，Replicated State Machine 如何进行同步？<br>这正是之前强调的需要依赖指令的确定性的意义所在。当然，也可以在遇到这种命令时，让 Backup 去直接接受 Primary 的执行结果。</li>
</ol>
<p>此外，Replicated State Machine 需要机器为单核，因为在多核机器上，指令的执行顺序本身是不确定的。那对于多核机器如何做同步？State Transfer 。</p>
<p><img src="https://i.loli.net/2020/04/03/ANYB2XQPEKbzoOj.png" alt="pb-ft-configuration.png"></p>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><ol>
<li>需要同步什么状态？</li>
<li>Primary 需要等 Backup吗？</li>
<li>Primary 宕机时，如何进行切换？</li>
<li>在 Primary&#x2F;Backup 宕机时，如何进行快速恢复。</li>
</ol>
<p>同步状态的层级：</p>
<ol>
<li>应用层（Application state）。如 GFS，更为高效，只需要发送高维操作即可，缺点是需要在应用层进行容错。</li>
<li>机器层（Machine level）。可以让运行在服务器上的应用无需改动而获取容错能力。但需要细粒度的同步机器事件（中断、DMA）；并且需要修改机器底层实现以发送这些事件。</li>
</ol>
<p>而 VM-FT 选择了后者，能力更强大，但也做出了更多牺牲。</p>
<p>VM-FT 系统使用一个额外的虚拟层 VMMonitor（ hypervisor &#x3D;&#x3D; monitor &#x3D;&#x3D; VMM ），当 client 请求到达 Primary 时，VMMonitor 一方面向本机转发请求、一方面向 Backup 的 VMMonitor 同步请求。处理完请求得到结果时，Primary 的 VMMonitor 会回复 Client，而 Backup 的 VMMonitor 会丢弃 Backup 产生的回复。</p>
<p>使用两种方法来检测 Primary 和 Backup 的健康状况：</p>
<ol>
<li>和 Primary&#x2F;Backup 进行心跳。</li>
<li>监控 logging channel。</li>
</ol>
<h3 id="主从切换"><a href="#主从切换" class="headerlink" title="主从切换"></a>主从切换</h3><p>如何实现主从间的切换？在 Primary 宕机后，Backup 声称具有 Primary 的 MAC 地址，然后让 ARP 缓存表过期，就将打向某个IP的流量从 Primary 切换到了 Backup。</p>
<p>切换后，原先的 Backup 成为新的 Primary，对外进行回复。然后利用 VMotion 的技术在和新 Primary 共享外存的地方启动一个副本，并且建立日志通道。</p>
<h3 id="不确定性事件"><a href="#不确定性事件" class="headerlink" title="不确定性事件"></a>不确定性事件</h3><p>都有哪些不确定性（Non-deterministic）操作（operations）和事件（events）？</p>
<ul>
<li>输入的不确定性。系统中断事件。</li>
<li>奇怪指令。比如随机数、依赖时间戳的指令。</li>
<li>多核。不同机器可能以不同的方式在多核上交替运行指令。</li>
</ul>
<p>对于不确定性操作，需要保留充足的信息到日志通道中，以使 Backup 可以进行同样的状态改变，并且产生同样输出。对于不确定性事件，如时钟信号中断和 IO 完成中断，不仅需要记录事件本身，也要记录下事件发生的指令序列的位置，由此才能在 Backup 上确定性复现。</p>
<h3 id="Logging-Channel"><a href="#Logging-Channel" class="headerlink" title="Logging Channel"></a>Logging Channel</h3><p>为了进行容错（FT），我们使用<em>日志条目</em>（log entry ）来记录 Primary 上发生的事件；但我们并没有将这些日志写到硬盘中，而是将其通过<em>日志通道</em>（logging channel）传送到 Backup 上进行实时<em>确定性的重建</em>（deterministic replay）。每个 LogEntry 可能包含以下数据：</p>
<ol>
<li>指令编号</li>
<li>指令类型</li>
<li>数据</li>
</ol>
<h3 id="DMA"><a href="#DMA" class="headerlink" title="DMA"></a>DMA</h3><p>DMA能够直接将数据从网口拷贝到内存，而不经过CPU。这时需要 VMM 强行中断，拷贝来到的数据，模拟一个指令，并发送给 Backup。</p>
<h3 id="OutPut-rule"><a href="#OutPut-rule" class="headerlink" title="OutPut rule"></a>OutPut rule</h3><p>当 Primary 宕机时，其发送给 Backup 的最后一条指令也由于网络问题丢失了。当 Backup 接手时，如何处理该条指令丢失造成的不一致？<br>使用 Output Rule 保证。即 Primary 仅当在收到 Backup 该条指令的 ACK 时，才会将该指令结果发送给用户。当然，为缩短响应延迟，在 Backup 上，VMM 只需要将收到的指令缓存到 Buffer 中就可以回 ACK。而且，Primary 只是会延迟将回复发送给用户，以等待 Backup 的 ACK，但在这段等待时间内并不用真停止执行，毕竟网络请求回复是异步的，Primary 可以并行的做其他事情。</p>
<p><img src="https://i.loli.net/2020/04/03/wHOcrpf9s1LZQqM.png" alt="pb-ft-protocol.png"></p>
<p>在 Primary 宕机后，Backup 接管时，可能会产生重复的结果。但是由于P&#x2F;B 共用 TCP channel，SEQ 也会被重用，会在 Client 端作为重复TCP 帧被忽略，从而不会暴露到用户层面。</p>
<h3 id="吞吐"><a href="#吞吐" class="headerlink" title="吞吐"></a>吞吐</h3><p>如果 Primary 和 Backup 不在一个城市，每次通信都需要几ms，那么久很难构建高吞吐系统。</p>
<h3 id="网络分区"><a href="#网络分区" class="headerlink" title="网络分区"></a>网络分区</h3><p>如果 P&#x2F;B 之前的网络断了，但是同时都可以和 client 通信，就发生了 split-brain。解决办法是引入一个第三方仲裁，来保存谁可以进行应答：比如使用一个 TAS（Test-and-Set Server） 或者一个共享外存。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>6.824</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 2020 视频笔记五：Go Concurrency</title>
    <url>/2020/04/27/6-824-video-notes-5-go-concurrency/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/03/06/IewXsYmP4T7UrzJ.png" alt="6.824-schedule.png"></p>
<p>MIT 今年终于主动在 Youtube 上放出了随堂视频资料，之前跟过一半这门课，今年打算刷一下视频，写写随堂笔记。该课程以分布式基础理论：容错、备份、一致性为脉络，以精选的工业级系统论文为主线，再填充上翔实的阅读材料和精到的课程实验，贯通学术理论和工业实践，实在是一门不可多得的分布式系统佳课。课程视频: <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vY2hhbm5lbC9VQ183V3JiWlRDT0R1MW9fa2ZVTXE4OGcvdmlkZW9z">Youtube<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL2F2OTA5MTU1MjY=">B站<i class="fa fa-external-link-alt"></i></span>。课程资料：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvc2NoZWR1bGUuaHRtbA==">6.824主页<i class="fa fa-external-link-alt"></i></span>。本篇是第五节课笔记，包括两部分：第一部分由一个助教讲了 lab2 中将会用到的一些 go 的源语、设计模式和实践技巧，包括内存模型、goroutine和闭包、时间库、锁、条件变量、channel、信号、并行和一些常用工具等等。第二部分是由另两个助教梳理了下  raft 中常遇到的一些 bug 和调试方法。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/04/27/6-824-video-notes-5-go-concurrency/">https://www.qtmuniao.com/2020/04/27/6-824-video-notes-5-go-concurrency/</a>, 转载请注明出处</em></p>
<p><strong>注</strong>： goroutine 是一种轻量级的线程，下面 goroutine 和线程两个名词混用，都表示 go 中的线程，虽然他们并不完全等价。</p>
<h2 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h2><p>用线程有两个作用：</p>
<ol>
<li>提高性能，利用多核。</li>
<li>更优雅的构造代码。</li>
</ol>
<p>在本课程实验中，我们并不要求使用线程以极尽性能，只要求程序的正确性。</p>
<p>对锁的使用也一样，不要求细粒度的加锁以提升性能，可以大范围加锁以简化代码。</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9nb2xhbmcub3JnL3JlZi9tZW0=">内存模型<i class="fa fa-external-link-alt"></i></span>中主要提到了多线程执行时，代码运行的顺序性。主要结论是，单个线程内的可以保证执行效果和代码语句顺序一致，但是跨线程间，如果没有做显式同步（通过锁或者 channel），那么语句执行的先后是没有办法保证的。内存模型大致就讲这么多，本节课的重点在于探讨实验中可能会用到的一些典型<em>代码模式</em>。</p>
<h2 id="线程和闭包（goroutine-amp-amp-closure）"><a href="#线程和闭包（goroutine-amp-amp-closure）" class="headerlink" title="线程和闭包（goroutine &amp;&amp; closure）"></a>线程和闭包（goroutine &amp;&amp; closure）</h2><p>使用 for 循环 + goroutine 可以很自然的表达 Leader 并行地给 Follower 发送消息的过程。但需要注意循环变量（下例中的 <code>i</code>）在子 goroutine 中被引用时，最好事先拷贝一份（一般是通过<em>函数传参</em>或者<em>在循环体内复制</em>来拷贝）。此外，经常利用 WaitGroup 来在父 goroutine 中阻塞地等待一组子 goroutine 的完结。样例如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">    wg.Add(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(x <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">      sendRPC(x)</span><br><span class="line">      wg.Done()</span><br><span class="line">    &#125;(i)</span><br><span class="line">  &#125;</span><br><span class="line">  wg.Wait()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sendRPC</span><span class="params">(i <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">  <span class="built_in">println</span>(i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="时间库（time）"><a href="#时间库（time）" class="headerlink" title="时间库（time）"></a>时间库（time）</h2><p>使用 go 标准库 time ，可以很方便的实现周期性的做某些事情，比如 raft 中的心跳逻辑。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">periodic</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    <span class="built_in">println</span>(<span class="string">&quot;heartbeat&quot;</span>)</span><br><span class="line">    time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在 raft 被杀死时，你可能想要结束所有后台线程，可以使用一个共享变量作为循环跳出条件来达到目的。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> done <span class="type">bool</span></span><br><span class="line"><span class="keyword">var</span> mu sync.Mutex</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="built_in">println</span>(<span class="string">&quot;started&quot;</span>)</span><br><span class="line">  <span class="keyword">go</span> periodic()</span><br><span class="line">  time.Sleep(<span class="number">5</span> * time.Second) <span class="comment">// wait for a while so we can observe what ticker does</span></span><br><span class="line">  mu.Lock()</span><br><span class="line">  done = <span class="literal">true</span></span><br><span class="line">  mu.Unlock()</span><br><span class="line">  <span class="built_in">println</span>(<span class="string">&quot;cancelled&quot;</span>)</span><br><span class="line">  time.Sleep(<span class="number">3</span> * time.Second) <span class="comment">// observe no output</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">periodic</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">for</span> done&#123;</span><br><span class="line">    <span class="built_in">println</span>(<span class="string">&quot;tick&quot;</span>)</span><br><span class="line">    time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">    mu.Lock()</span><br><span class="line">    <span class="keyword">if</span> done &#123;</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    mu.Unlock()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>需要注意的是，共享变量 <code>done</code> 修改和读取时，都需要使用锁 <code>sync.Mutex</code> 包裹起来，这是通过锁 <code>sync.Mutex</code> 强制多线程间同步（一个 goroutine <code>mu.Unlock</code> 会唤醒另外的 goroutine 正在阻塞 <code>mu.Lock</code>）来保证主线程对 <code>done</code> 的修改一定能够被子线程看到。否则，如果不做任何同步措施，由于多线程内部的变量缓存问题，go 的内存模型并不严格对共享变量的可见性做保证。</p>
<h2 id="锁（mutex）"><a href="#锁（mutex）" class="headerlink" title="锁（mutex）"></a>锁（mutex）</h2><p>主要有以下两种情况需要使用锁：</p>
<ol>
<li>保证多线程间共享变量的可见性。</li>
<li>保证一个代码块的原子性（不会与其他 goroutine 中的语句交替执行）。</li>
</ol>
<p>当然这两种情况往往是一种情况。</p>
<p>由于 go 内存模型的不可捉摸性（fancy），最好通过加锁来保护所有对共享变量的访问，否则写出的多线程代码很可能会出现一些难以发现和调试的问题。下面是一个使用多线程对未加锁的共享变量进行自增的例子：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  counter := <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++ &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">      counter = counter + <span class="number">1</span></span><br><span class="line">    &#125;()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">  <span class="built_in">println</span>(counter) <span class="comment">// 大概率不输出 1000</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最后 <code>counter</code> 值不为 1000 的原因有两个：</p>
<ol>
<li><code>counter = counter + 1</code> 编译成 CPU 指令后不是原子的，并行运行时可能会产生交错执行。</li>
<li><code>counter</code> 修改后可能不能及时被其他线程所看到，从而对旧值加一。</li>
</ol>
<p>修改后如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  counter := <span class="number">0</span></span><br><span class="line">  <span class="keyword">var</span> mu sync.Mutex</span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++ &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">      mu.Lock()</span><br><span class="line">      <span class="keyword">defer</span> mu.Unlock()</span><br><span class="line">      counter = counter + <span class="number">1</span></span><br><span class="line">    &#125;()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  time.Sleep(<span class="number">1</span> * time.Second) <span class="comment">// 这里用 WaitGroup 更为稳妥，等待1s只能保证大概率正确。</span></span><br><span class="line">  mu.Lock()</span><br><span class="line">  <span class="built_in">println</span>(counter)</span><br><span class="line">  mu.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面看一个 Alice 和 Bob 相互借钱，并试图维持总钱数不变的例子。我们各用一个线程来分别表示 Alice 借给 Bob 钱和 Bob 借给 Alice 钱的过程。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  alice, bob := <span class="number">10000</span>, <span class="number">10000</span></span><br><span class="line">  <span class="keyword">var</span> mu sync.Mutex</span><br><span class="line"></span><br><span class="line">  total := alice + bob</span><br><span class="line"></span><br><span class="line">  <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++ &#123;</span><br><span class="line">      mu.Lock()</span><br><span class="line">      alice -= <span class="number">1</span></span><br><span class="line">      mu.Unlock()</span><br><span class="line">      mu.Lock()</span><br><span class="line">      bob += <span class="number">1</span></span><br><span class="line">      mu.Unlock()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;()</span><br><span class="line">  <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++ &#123;</span><br><span class="line">      mu.Lock()</span><br><span class="line">      bob -= <span class="number">1</span></span><br><span class="line">      mu.Unlock()</span><br><span class="line">      mu.Lock()</span><br><span class="line">      alice += <span class="number">1</span></span><br><span class="line">      mu.Unlock()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;()</span><br><span class="line"></span><br><span class="line">  start := time.Now()</span><br><span class="line">  <span class="keyword">for</span> time.Since(start) &lt; <span class="number">1</span>*time.Second &#123;</span><br><span class="line">    mu.Lock()</span><br><span class="line">    <span class="keyword">if</span> alice+bob != total &#123;</span><br><span class="line">      fmt.Printf(<span class="string">&quot;observed violation, alice = %v, bob = %v, sum = %v\n&quot;</span>, alice, bob, alice+bob) <span class="comment">// # violation</span></span><br><span class="line">    &#125;</span><br><span class="line">    mu.Unlock()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述代码会打印出 violation 么？答案是会的。因为观察线程可能在某人借出钱，但是另外一个人没有收到钱的时候打印出 violation。可以从以下两个角度来理解这个问题：</p>
<ol>
<li><strong>原子性</strong>。出借和借钱应该是一个原子性操作，因此需要使用锁整个包裹起来。否则在中间某个时刻观察，就会产生不一致：钱被借出了，但是还没有收到，即在“控制”。</li>
<li><strong>不变性</strong>（invariant）。锁可以守护不变性，即当获取锁进入临界区后，可能会破坏不变性（借钱，此时钱在“空中”，此时观察会凭空少了一块钱），但是释放锁前恢复（收钱，从“空中”放到另一个人的账户里，两人账户和维持不变）即可。</li>
</ol>
<p>因此需要将交易过程改为如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++ &#123;</span><br><span class="line">      mu.Lock()</span><br><span class="line">      alice -= <span class="number">1</span></span><br><span class="line">      bob += <span class="number">1</span></span><br><span class="line">      mu.Unlock()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;()</span><br><span class="line"><span class="comment">// 另一个线程也对应修改</span></span><br></pre></td></tr></table></figure>



<h2 id="条件（Condition）"><a href="#条件（Condition）" class="headerlink" title="条件（Condition）"></a>条件（Condition）</h2><p>在 raft 里，会有一个场景，<em>Candidate</em> 向所有 <em>Followers</em> 要票，然后根据收集到的票数决定是否成为 <em>Leader</em>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  rand.Seed(time.Now().UnixNano())</span><br><span class="line"></span><br><span class="line">  count := <span class="number">0</span></span><br><span class="line">  finished := <span class="number">0</span></span><br><span class="line">  <span class="keyword">var</span> mu sync.Mutex</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">      vote := requestVote()</span><br><span class="line">      mu.Lock()</span><br><span class="line">      <span class="keyword">defer</span> mu.Unlock()</span><br><span class="line">      <span class="keyword">if</span> vote &#123;</span><br><span class="line">        count++</span><br><span class="line">      &#125;</span><br><span class="line">      finished++</span><br><span class="line">    &#125;()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> &#123; <span class="comment">// busy wait</span></span><br><span class="line">    mu.Lock()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> count &gt;= <span class="number">5</span> || finished == <span class="number">10</span> &#123; </span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">    &#125;</span><br><span class="line">    mu.Unlock()</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  mu.Lock()</span><br><span class="line">  <span class="keyword">if</span> count &gt;= <span class="number">5</span> &#123;</span><br><span class="line">    <span class="built_in">println</span>(<span class="string">&quot;received 5+ votes!&quot;</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">println</span>(<span class="string">&quot;lost&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  mu.Unlock()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">requestVote</span><span class="params">()</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">  time.Sleep(time.Duration(rand.Intn(<span class="number">100</span>)) * time.Millisecond)</span><br><span class="line">  <span class="keyword">return</span> rand.Int() % <span class="number">2</span> == <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这种写法有个忙等待，再加上循环过程中不断加锁、释放锁会造成极大的 CPU 占用。</p>
<p>一种很简单的性能提升方法，在忙等待循环中加一个 <code>time.Sleep(50 * time.Millisecond)</code>，就能极大的减少 CPU 的占用。</p>
<p>另一种更高效的方式，是使用 <code>condition</code>，<code>condition</code> 与一个锁绑定，在获取锁之后，通过 <code>Wait</code> 来暂时挂起线程，并且释放锁；于是另一个线程就可以通过 <code>Lock</code> 获取锁，并且在出临界区前，通过调用 <code>Broadcast</code> 来唤醒所有 <code>Wait</code> 在此锁上挂起的线程。类似使用一种信号机制，来在多个线程间进行通知锁的释放和获取。</p>
<p>使用 <code>Condition</code> 修改上述代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  rand.Seed(time.Now().UnixNano())</span><br><span class="line"></span><br><span class="line">  count := <span class="number">0</span></span><br><span class="line">  finished := <span class="number">0</span></span><br><span class="line">  <span class="keyword">var</span> mu sync.Mutex</span><br><span class="line">  cond := sync.NewCond(&amp;mu)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">      vote := requestVote()</span><br><span class="line">      mu.Lock()</span><br><span class="line">      <span class="keyword">defer</span> mu.Unlock()</span><br><span class="line">      <span class="keyword">if</span> vote &#123;</span><br><span class="line">        count++</span><br><span class="line">      &#125;</span><br><span class="line">      finished++</span><br><span class="line">      cond.Broadcast()</span><br><span class="line">    &#125;()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  mu.Lock()</span><br><span class="line">  <span class="keyword">for</span> count &lt; <span class="number">5</span> &amp;&amp; finished != <span class="number">10</span> &#123;</span><br><span class="line">    cond.Wait() <span class="comment">// 1. release the mu 2. wait Broadcast() 3. try to acquire the mu again</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> count &gt;= <span class="number">5</span> &#123;</span><br><span class="line">    <span class="built_in">println</span>(<span class="string">&quot;received 5+ votes!&quot;</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">println</span>(<span class="string">&quot;lost&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  mu.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>需要注意的是，<code>Condition</code> 的使用模式要求 <code>cond.Broadcast</code> 和 <code>cond.Wait</code> 都必须在对应的锁所守护的临界区间内，并且调用 <code>cond.Broadcast</code> 后要及时释放锁，否则会引起其他线程的对一个未释放的锁的争抢。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">mu.Lock()</span><br><span class="line"><span class="comment">// do something that might affect the condition</span></span><br><span class="line">cond.Broadcast()</span><br><span class="line">mu.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="comment">//----</span></span><br><span class="line"></span><br><span class="line">mu.Lock()</span><br><span class="line">while condition == <span class="literal">false</span> &#123;</span><br><span class="line">  cond.Wait()</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// now condition is true, and we have the lock</span></span><br><span class="line">mu.Unlock()</span><br></pre></td></tr></table></figure>

<p>此外，<code>cond.Signal</code> 每次仅唤起一个调用 <code>cond.Wait</code> 进入等待的线程，而 <code>cond.Broadcast</code> 会唤起所有等待在相应锁上的线程。当然，前者更高效。 </p>
<h2 id="通道（channel）"><a href="#通道（channel）" class="headerlink" title="通道（channel）"></a>通道（channel）</h2><p>不带缓冲（unbuffered channel）的 channel 通常被用作多线程间进行同步的一种控制手段。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">bool</span>)</span><br><span class="line">  <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    time.Sleep(<span class="number">1</span> * time.Second)</span><br><span class="line">    &lt;-c</span><br><span class="line">  &#125;()</span><br><span class="line">  start := time.Now()</span><br><span class="line">  c &lt;- <span class="literal">true</span> <span class="comment">// blocks until other goroutine receives</span></span><br><span class="line">  fmt.Printf(<span class="string">&quot;send took %v\n&quot;</span>, time.Since(start))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>channel 用在同一个线程内部没有意义，一般都是用作多线程间的通信手段（进行同步或者传递消息）。</p>
<p>而带缓冲的 channel 类似一个同步队列，不过在此次 raft 实验中基本用不到，建议在实验中通过共享变量+锁来进行多线程间消息的同步和互斥。</p>
<p>使用 channel 进行同步，可以发挥类似 <code>WaitGroup</code> 的作用：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  done := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">bool</span>)</span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(x <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">      sendRPC(x)</span><br><span class="line">      done &lt;- <span class="literal">true</span></span><br><span class="line">    &#125;(i)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">    &lt;-done</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sendRPC</span><span class="params">(i <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">  <span class="built_in">println</span>(i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Raft-死锁"><a href="#Raft-死锁" class="headerlink" title="Raft 死锁"></a>Raft 死锁</h2><p>死锁的一个很重要的条件，通俗来说是，占有并等待。即都是<em>占着自己碗里的不放，还想要对方碗里</em>，自然就会形成死锁。</p>
<p>一个简单原则是在进行耗时任务时（比如 rpc，IO），要及时释放锁。</p>
<h2 id="RPC-回应过期"><a href="#RPC-回应过期" class="headerlink" title="RPC 回应过期"></a>RPC 回应过期</h2><p>在 Candidate 收回选票结果时，需要判断自己是否仍然在原来的 term 内，以及是否仍然是 Candidate。否则可能选出两个 leader。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> rf.state != Candidate || rf.currentTerm != term &#123;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>不过，其实只检查 currentTerm 就足够了，但是只检查 state 是不够的。 </p>
<h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><p>DPrintf ：server 编号是一个很重要的字段，建议输出在开头；然后在关注的地方前后加输出语句。</p>
<p>死锁：可以通过 ‘control+\‘ 发送一个 SIGQUIT 信号给正在运行中的 go 程序，然后程序就会退出，并且打印出当前各个线程的运行栈。</p>
<p>竞态条件：<code>go test -race -run 2A</code> ，使用 <code>-race</code> 当 go 检测到竞态发生时打印运行栈。一般多是共享变量被多个线程访问，并且至少有一个访问的地方没有加锁。</p>
<h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><p>临界区（strict area）：多个线程需要互斥访问的代码段。</p>
<p>忙等待（busy wait）：一直循环，直到条件满足。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>相关英文<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbm90ZXMvbC1nby1jb25jdXJyZW5jeS50eHQ=">板书<i class="fa fa-external-link-alt"></i></span>。</li>
<li>提到的相关<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbm90ZXMvZ28tY29uY3VycmVuY3kudGFyLmd6">代码<i class="fa fa-external-link-alt"></i></span>。</li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>6.824</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 2020 视频笔记六：Fault Tolerate Raft 1</title>
    <url>/2020/05/09/6-824-video-notes-6-fault-tolerate-raft-1/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/03/06/IewXsYmP4T7UrzJ.png" alt="6.824-schedule.png"></p>
<p>MIT 今年终于主动在 Youtube 上放出了随堂视频资料，之前跟过一半这门课，今年打算刷一下视频，写写随堂笔记。该课程以分布式基础理论：容错、备份、一致性为脉络，以精选的工业级系统论文为主线，再填充上翔实的阅读材料和精到的课程实验，贯通学术理论和工业实践，实在是一门不可多得的分布式系统佳课。课程视频: <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vY2hhbm5lbC9VQ183V3JiWlRDT0R1MW9fa2ZVTXE4OGcvdmlkZW9z">Youtube<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL2F2OTA5MTU1MjY=">B站<i class="fa fa-external-link-alt"></i></span>。课程资料：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvc2NoZWR1bGUuaHRtbA==">6.824主页<i class="fa fa-external-link-alt"></i></span>。本篇是第六节课笔记，是 Raft 论文讲解的第一部分，主要总结了容错的几种类型以及 Raft 中的 Leader 选举相关内容。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/05/09/6-824-video-notes-6-fault-tolerate-raft-1/">https://www.qtmuniao.com/2020/05/09/6-824-video-notes-6-fault-tolerate-raft-1/</a>, 转载请注明出处</em></p>
<h2 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h2><p>状态机备份：State machine replication</p>
<h3 id="容错模式"><a href="#容错模式" class="headerlink" title="容错模式"></a>容错模式</h3><p>我们已经学习了以下几种容错模式（fault-tolerance pattern）：</p>
<ul>
<li>计算冗余：MapReduce，但是所有计算由单点 Master 进行调度。</li>
<li>数据冗余：GFS，也是依赖单点 Master 来对多个副本进行选主。</li>
<li>服务冗余：VMware-FT 依赖单个 TestAndSet 操作</li>
</ul>
<p>可以看出他们都依赖单个组件来做一些关键决策。这样做的好处在于，单个组件不需要共识算法，不会产生不一致；不好的地方在于，该组件成为系统中的一个单点。当然，上述系统已经将单点问题压缩到了一个很小的部分，那么接下来，我们将进一步用一种共识算法——Raft，来将最后这个硬骨头啃下来。</p>
<h3 id="Split-Brain"><a href="#Split-Brain" class="headerlink" title="Split Brain"></a>Split Brain</h3><p>共识算法中最大的问题在于——如何避免 <strong>Split Brain</strong>。</p>
<p>那么 Split Brain 是如何产生的，其危害性为什么很大？</p>
<p>假设我们要对 test-and-set 服务进行备份。test-and-set，简而言之，就是一个锁服务。当多个 Client 同时请求服务时，只有其中一个能通过 Test（测试是否为0），获取锁，并设置 Server 状态为 1，则其他 Client 测试不能通过，从而不能获取锁。</p>
<p>考虑有以下四个系统角色：[C1, C2, S1, S2]，S1 和 S2 组成一个双备份的、可容错的系统，C1 和 C2 是使用此系统的客户端。假设 C1 可以和 S1 通信，但是与 S2 失联。那在只有 S1 的情况下，系统能够给 C1 正常提供服务么？</p>
<ol>
<li>如果 S2 真的宕机了，系统应当在 S2 缺席的情况下正常工作，否则系统就不能称之为是容错的（fault-tolerance）。</li>
<li>如果 S2 没有宕机，但是和 C1 失联了。则系统不能够给 C1 提供服务，因为 S2 可能正在给 C2 提供服务，如果让 S1 同时给 C1 服务，则会造成系统状态不一致，从而使服务出错：C1 和 C2 同时获取到锁。</li>
</ol>
<p><img src="https://i.loli.net/2020/05/15/2HrYAaSULhckRDT.png" alt="split-brain"></p>
<p>在此种情况下，我们面临一种选择的困境：</p>
<ol>
<li>要么不提供容错保证，尽管我们使用了双备份服务器。</li>
<li>要么仍然回复客户端请求，但由于 Split Brain 可能会发生，不保证一致性。</li>
</ol>
<p>但问题在于，服务器 S1 无法区分 S2 是失联了（”server crashed”）还是网络故障了（network broken）。因为在这两种情况下，S1 看到的现象是一样的：向 S2 的请求得不到回复。S1 能够和 C1 通信，S2 能够和 C2 通信；但是 S1+C1 收不到 S2+C2 的回复，我们称这种情况为出现了<strong>网络分区</strong>（network partitionn）。</p>
<p>网络分区可能会持续很久，可能需要引入一个外力（比如说运维人员），来判断何时网络可信、何时服务器可信，才能打破僵局。那我们如何可以将容错做到自动化？答曰：<strong>多数票原则</strong>（majority vote）。</p>
<h3 id="多数票原则"><a href="#多数票原则" class="headerlink" title="多数票原则"></a>多数票原则</h3><p>多数票原则，要求系统集群包含奇数个服务器，以此来避免出现<strong>同票困境</strong>（symmetry）。如上面只有两个服务的情况，两方各执一词，就很难决定以谁为准。</p>
<p>在有奇数个服务器的系统中，我们只要获取多数票就可以保持系统正常运转，而不会陷入同票僵局（如 Raft 中的主选举、提交日志条目等）。多数票原则能够打破僵局，其原理也很简单：<em>不可能出现一个以上同时包含多数服务器的分区</em>。需要注意的是，这里的多数指的是构成系统所有的服务器的多数，而非存活服务器的多数。</p>
<p>如果集群由 2f + 1 个服务器构成，最多能够承受 f 个服务器宕机，而仍能对外提供服务。</p>
<p>多数票原则还有一个重要的性质就是，<em>任何两个投出多数票的集群必定相交</em>。如在 raft 中，前后相继的两次 Leader 选举所涉及到的投票集群肯定有交集，因此下一轮能够通过相交部分获取上一个 term 的决策信息（包括上一轮的 term 和上一轮的 commit 信息）。</p>
<p>上世纪九十年代左右，出现了两个算法 Paxos 和 View-Stamped Replication （VSR，MIT提出的），使用多数票原则来解决 Split-brain 问题。虽然现在前者更广为人知，但是后者在思想上与 Raft 更为接近。</p>
<h2 id="Raft-概览"><a href="#Raft-概览" class="headerlink" title="Raft 概览"></a>Raft 概览</h2><p>Raft 一般表现为库的形式，运行在在每个副本（replica）服务器上，对<strong>多副本状态机</strong> （replicated state machine） 进行管理，主要负责对操作日志的同步。基于此，我们可以进一步构建可靠的 KV 存储层，主要负责状态的存储。</p>
<p><img src="https://i.loli.net/2020/05/14/WQUBHvNSe6O72zF.png" alt="raft-replicated-kv-service"></p>
<p>上图表现了一个典型的客户端与键值对服务的交互流程：</p>
<ol>
<li>客户端发送 “Put&#x2F;Get” 请求到 Leader 的 k&#x2F;v 层</li>
<li>Leader 将该请求转换为 Command（包括动作和参数），追加到本机日志文件中</li>
<li>Leader 通过 AppendEntries RPC 将该 Command 同步给 Followers</li>
<li>Followers 将该 Command 追加到本机日志文件中</li>
<li>Leader 等待包含自己内的多数 Server 回复</li>
<li>获取多数Server 回复后，Leader 就会提交 Command 对应日志条目。提交意味着该 Command 条目不会被删除，即使部分服务器宕机后，仍然能够被下一轮次 Leader 所继承</li>
<li>Leader 执行该 Command，将其应用到状态机，然后回复给客户端</li>
<li>在下一次执行 AppendEntries RPC 时，Leader 将捎带 commit 信息（即 commit 到的操作日志中的 offset）同步给各个 Followers</li>
<li>Followers 在收到 commit 信息后，将对应 Command 应用到状态机</li>
</ol>
<h3 id="操作日志"><a href="#操作日志" class="headerlink" title="操作日志"></a>操作日志</h3><p>那么为什么要使用操作日志这种形式对用户的请求操作（Command）进行记录呢？</p>
<ol>
<li>Leader 使用日志来决定 Command 的顺序。使得所有副本就请求（尤其是大量几乎同时到达的请求）顺序达成一致、并且保有同样顺序的日志条目。在这种情况下，日志充当一个带锁的队列</li>
<li>暂存 Command 以备稍后 commit 之后进行提交</li>
<li>保存 Command 以备由于网络&#x2F;服务器异常导致 Leader 需要再次发送给 Follower</li>
<li>服务器重启后进行状态重建</li>
</ol>
<p>Q&amp;A：</p>
<ol>
<li><p>如果请求过快，但是日志 append 速度不够怎么办？</p>
<p>因此一般不用 raft 做高并发中间件。基于这种假设，如果真遇到这种情况，可以限制 Leader 的请求处理速度。</p>
</li>
<li><p>每个服务器在重启时，并不<em>立即</em>执行日志中的 Command，因为他并不知道哪些已经被提交了（提交点没有被持久化），需要后面 Leader 告诉他。</p>
</li>
</ol>
<h3 id="Raft-接口"><a href="#Raft-接口" class="headerlink" title="Raft 接口"></a>Raft 接口</h3><p>Raft 对 KV 层提供的接口主要有两个：<code>Start(command)</code>，<code>ApplyMsg-&gt;ApplyCh</code>。</p>
<p><code>Start(command) (index, term, isleader)</code></p>
<p>Start 只在 Leader 上调用才有效，其含义在于让多数服务器在一个新的日志条目（Log Entry，其中包含 Command ）上达成一致。主要有以下几步：</p>
<ol>
<li>Leader 将 Command 追加到本地日志中</li>
<li>向各 Follower 发送 AppendEntries RPC</li>
<li>Start() 立即返回（给 k&#x2F;v 层）而不等待各个 Follower 的回复（<strong>异步</strong>）</li>
<li>k&#x2F;v 层需要监听 applyCh 以确定该 Command 是否被提交 （commit）</li>
</ol>
<p>返回值有三个：</p>
<ol>
<li>index：Command 将会被提交到的日志位置</li>
<li>term：Leader 的当前任期</li>
<li>isleader：如果其值为 false，则客户端需要尝试其他服务器直到试到 Leader。</li>
</ol>
<p><code>ApplyMsg-&gt;ApplyCh</code></p>
<p><strong>ApplyMsg</strong>，包含 Command 和 Index 两个字段；<strong>applyCh</strong>，k&#x2F;v 监听 raft commit 后发来的 ApplyMsg 的 channel</p>
<ol>
<li>系统中每个服务器对于每个<em>提交了的</em>日志条目都要发送一个 ApplyMsg 给 applyCh</li>
<li>系统中每个服务器，获取到 ApplyMsg 后，将其中的 Command 更新到本地状态机</li>
<li>Leader 负责回复请求给客户端（在对应日志条目 commit 之后）</li>
</ol>
<p>在某个时刻，系统中的每个服务器的日志条目并不一定完全一致，比如说在 Leader 同步日志条目的过程中宕机了，那么 Leader 包括部分 Followers 已经追加了该日志条目，而另外的 Followers 没有收到该日志条目，此时系统中的每个服务器的的日志条目产生了分叉。</p>
<p>但好消息是，所有服务器的日志条目最终会被新的 Leader 统一。</p>
<h2 id="Leader-选举"><a href="#Leader-选举" class="headerlink" title="Leader 选举"></a>Leader 选举</h2><p>说到 Leader 选举，首先需要思考的一个问题是：Leader 是必须的吗？我们必须得有一个 Leader 才能够完成所有服务器上的日志同步么？答案是否定的，比如 Paxos。</p>
<p>那为什么 Raft 会采取 Leader 做法呢？原因有很多，其中一个是，在系统和网络正常工作的情况下，有 Leader 做决策能够使得系统更为高效；客户端每次请求至多两次（第一次得到 Leader 位置，第二次向 Leader 发送请求）。</p>
<h3 id="任期（term）"><a href="#任期（term）" class="headerlink" title="任期（term）"></a>任期（term）</h3><p>Raft 对 Leader 的序列进行了标号，即<strong>任期</strong>（term）：</p>
<ol>
<li>新 Leader 意味着新任期</li>
<li>一个任期最多有一个 Leader，也可能没有 Leader</li>
<li>任期帮助 Followers 追随最新的 Leader，而不是已经下台的 Leader</li>
</ol>
<h3 id="选举（election-）"><a href="#选举（election-）" class="headerlink" title="选举（election ）"></a>选举（election ）</h3><p>当 Follower 在一定时间间隔（Raft 称之为选举<strong>选举超时</strong>，election timeout，具体实现时，我们会使用一个 election timer）内没有收到当前 Leader 的心跳信息，就会将将自己的 term 加一（因为一个 term 内不允许出现两个 Leader，因此只有先增加任期计数，才有可能在新的任期当选为新的 Leader），并且自封候选人，向自己投一票，然后向其他服务器进行要票。</p>
<p>需要注意的是：</p>
<ol>
<li>这个过程可能会引起不必要的选举，比如说某个服务器暂时与 Leader 失联，超过 election timeout 之后，发起选举，此时又连上了 Leader，则其会将整个集群带入新的任期，使得原来 Leader 失效。这种做法虽然有时候效率不高，但是很安全</li>
<li>老的 Leader 可能还活着，并且认为自己是 Leader。比如发生了网络分区，Leader 被分到了少数服务器分区中，而多数服务器分区选出了新的 Leader。则老的 Leader 仍然会认为自己是 Leader，并且尝试行使 Leader 职能，比如接收客户端请求，并且尝试同步日志条目，但由于不可能获取多数回应，因此不可能 commit 进而回复客户端</li>
</ol>
<p>Q&amp;A：</p>
<p>如果网络发生了某种神奇的故障，只能单向通信，即 Leader 能够发送心跳给 Followers，抑制他们发起选举；但是却不能收到 Client 的请求。这种情况下 Raft 还能正常工作吗？</p>
<p>的确不能了，但是可以通过一些小手段来解决这个问题。比如说双向心跳，来及时排除这种”半连接”的服务器。</p>
<h3 id="Leader-和任期"><a href="#Leader-和任期" class="headerlink" title="Leader 和任期"></a>Leader 和任期</h3><p>那么如何保证在某个任期最多选出一个 Leader 呢？</p>
<ol>
<li>必须得到集群服务器的半数票以上才能成为 Leader</li>
<li>每个服务器在每个 term 内，最多投出一票<ul>
<li>如果是 Candidate，无脑投自己</li>
<li>如果不是 Candidate，投给第一个要票（且符合一定条件，下一节会提到）的 Candidate</li>
</ul>
</li>
</ol>
<p>并且，当发生网络分区时，仍然能保证最多有一个 Leader；即使有少量的服务器宕机，仍然能够正常选出 Leader。</p>
<h3 id="Leader-心跳"><a href="#Leader-心跳" class="headerlink" title="Leader 心跳"></a>Leader 心跳</h3><p>Candidate 通过获取多数票后当选为 Leader，但此时只有 Leader 自己知道自己是 Leader，而其他服务器无从得知。因此需要通过心跳，将此选举结果广播给其他服务器。收到心跳的服务器如果发现心跳 term 比自己的大，从而就认可该 Leader 为此 term 的 Leader，并且将自己所处 term 更新为 Leader term，然后变为 Follower。</p>
<p>此后，Leader 通过不断的心跳来抑制 Followers 转变为 Candidate，即抑制其他服务器发起选举。这也就要求 Leader 的心跳周期要比 election timeout 要小。</p>
<h3 id="平票"><a href="#平票" class="headerlink" title="平票"></a>平票</h3><p>在某个 term 内，有两种情况会导致选不出 Leader：</p>
<ol>
<li>没有任何多于半数的服务器互相可达</li>
<li>多个 Candidate 同时发起选举，并且都没有获得多数票</li>
</ol>
<p>为了避免多个 Candidate 不断的同时发起选举，同时超时而进入下一个 term，然后再次同时选举的死循环，Raft 引入随机值，即每个服务器的每次 election timeout 不是一个固定值，而是某个范围内的一个随机值。这样在某次选举撞车后，由于 election timeout 选择的不同，下一次发起选举就必然会错开。当然光错开还不行，必须错开的足够多，保证某个 Candidate 在其他服务器超时前，就开始对其发起投票，从而避免再次选举撞车。</p>
<h3 id="选举超时"><a href="#选举超时" class="headerlink" title="选举超时"></a>选举超时</h3><p>那么如何挑选 election timeout 呢？</p>
<ol>
<li>其最小值最好要大于几倍的（两个以上）心跳间隔；因为网络偶尔会丢包，从而导致丢掉某些心跳，进而引起不必要的选举</li>
<li>随机区间尽可能的大，以使最快超时变成 Candidate 的服务器能及时向其他服务器发起选举，并成为 Leader</li>
<li>但又不能过长，以防止系统失去 Leader 时，长时间陷入停顿</li>
<li>在我们的实验中，过长会使得测试过不了（测试程序对选出 Leader 的过程是与时限要求的）</li>
</ol>
<h3 id="老的-Leader"><a href="#老的-Leader" class="headerlink" title="老的 Leader"></a>老的 Leader</h3><p>当发生了网络隔离，Leader 和少数服务器被隔离到了一个分区，那么剩下的多数节点就会选出新的 Leader。如果老的 Leader 不能感受到新的 Leader 的产生，会出现什么问题吗？</p>
<ol>
<li>老的 Leader 不会提交任何日志条目，因为他不能让多数 Follower 同步日志条目</li>
<li>虽然不会提交，但是部分服务器会接收老的 Leader 的日志条目，由此造成集群中服务器间的日志分歧</li>
</ol>
<h3 id="日志分歧"><a href="#日志分歧" class="headerlink" title="日志分歧"></a>日志分歧</h3><p>当系统一切运作正常时，情况很简单，Followers 只需要单方面的接受 Leader 同步给他的日志条目即可。但是当出现了异常，比如 Leader 只给集群中的部分机器同步了日志，然后宕机了，此时系统该如何往下进行？</p>
<p><img src="https://i.loli.net/2020/05/14/krIQ9gYb5So8fD6.png" alt="log-and-crash"></p>
<p>当然，在上图 a 中，第 11 条日志可能被老 Leader 提交了，也可能没有。但是新的 Leader 如果无从得知，就只等根据多数票原则（有半数以上的服务器有该日志条目）当做其提交了。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvbm90ZXMvbC1yYWZ0LnR4dA==">英文板书<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWI3NDExYzdmMz9wPTY=">视频<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>6.824</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>让我们荡起双桨</title>
    <url>/2020/06/07/an-old-song/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/06/11/egfPnaXUzvFQ5Nt.jpg" alt="1591539058644.jpg"></p>
<p>儿时初学“让我们荡起双桨”，只感觉旋律朗朗；年岁稍长，偶尔哼起，三言两语，味出千万意境；后来，求学帝都，游北海，正是“湖面倒映着美丽的白塔，四周环绕着绿树红墙”，光阴荏苒，不变的是文字的生命力。</p>
<p>歌词为乔羽先生所做，很多脍炙人口的名作皆出自其手：《我的祖国》、《难忘今宵》、《爱我中华》。词分三段，层层递进。第一段写划船之景，寥寥几句，首尾勾连、推近及远、勾勒出四合景象。第二段写欢快之情，童真昂扬，心情轻快，描绘出饱满的童趣。第三段继而升华，设问如此美景、如此生活、如此时代，如何得来？尔后戛然而止，语已尽而意无穷。</p>
<span id="more"></span>

<p>所以那是一个怎样的时代？</p>
<p>搜寻一番得知，“让我们荡起双桨” 是电影《祖国的花朵》的主题曲，摄于 1955 年。那是一个怎样的时代？经历了漫长的帝国入侵、军阀混战、艰难抗日，新中国诞生。灭土匪、分田地、稳经济，一五计划热烈开展，抗美援朝逼停美国，新时代大幕徐徐拉开。彼时，各种运动尚未开展，人民安定有盼头，到处弥漫的昂扬的空气，敢叫日月换新天。</p>
<p>影片就是在这样的大环境下制作的，剧情简洁明快，讲述了五年甲班游离集体之外的杨永丽和江林一番经历后转变而入少先队的小小历程。 故事用了经典的起承转合的叙事手法，起在北海公园，合在北海公园，情景、冲突安排的明明白白。杨永丽聪明伶俐，用妈妈的话说是不用怎么学也能考的很好，但是有诸多任性以及小小自私；江林活泼冲动，上屋檐掏鸟，去城外钓鱼，就是不爱学习。另有中队长梁惠明，虽也会哭鼻子，但已初显组织才能。影片开始通过各种小事铺陈出杨永丽和江林的家庭环境、鲜明个性，进而不被群体所接受，被排斥在各种活动之外。梁惠明虽出于队长责任，觉得需要做些什么，然并不走心，不得其法。但每每关键节点，总有班主任冯老师号召提点，推进事情前进。通过补习功课、分担家务，增进了集体和杨江的互动，将其融入集体，也锻炼出了梁的协调才能。</p>
<p>漂亮的公园、低矮的胡同、蜿蜒的护城河、高耸的城门，林立的烟囱、带着颤音的歌声、略带北方方言的普通话，将我们带回五十年代的北京。剧中似乎成年男性出场较少，似也凸显新中国女性地位。说到剧情本身，让人很容易想到各行各业被团结在一块建设社会主义，而党就是那个班主任，于关键处进行引导和仲裁。剧中的集体主义和意识形态引导，现在看来似乎稍微有些尴尬，但何尝不是那个年代的主旋律，以及初生中国所以快速发展的原动力。</p>
<p>集体主义所压抑的人性，久了，也必定会反噬体制。个人主义肆意喷薄，末了，也逃不过贫富分化和极度内卷。理想的鸡汤要喝，务实的刺激亦需并重，但对于人性来说，走钢丝以维持平衡太累了，在两极间不断震荡才是常态。</p>
<p><img src="https://i.loli.net/2020/06/11/dLJgFvCaDNUScXV.jpg" alt="DSCF0094.jpg"></p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>老歌</tag>
        <tag>体制</tag>
      </tags>
  </entry>
  <entry>
    <title>Amazon 针对小对象的分布式键值存储——Dynamo</title>
    <url>/2020/06/13/dynamo/</url>
    <content><![CDATA[<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>Dynamo 是一个高可用的 KV 存储系统。为了保证高可用和高性能，Dynamo 采用了最终一致性模型，它对开发人员提供一种新型 API，使用了版本机制，并通过用户侧辅助解决冲突。Dynamo 目标是提供不间断的服务，同时保证性能和可扩展性。由于亚马逊大量采用了去中心化、高度解耦微服务架构，因此对微服务状态的存储系统的可用性要求尤其高。</p>
<p>S3 （Simple Storage Service）是 Amazon 另一款有名的存储服务，虽然也可以理解为 KV 存储，但它和 Dynamo 的目标场景并不一致。S3 是面向大文件的对象存储服务，主要存储二进制文件，不提供跨对象的事务。而 Dynamo 是一款面向小文件的文档存储服务，主要存储结构化数据（如 json），并且可以对数据设置索引，且支持跨数据条目的事务。</p>
<p>相对于传统的关系型数据库，Dynamo 可以认为是只提供主键索引，从而获取更高的性能和更好的扩展性。</p>
<p>为了实现可扩展性和高可用性，并保证最终一致性，Dynamo 综合使用了以下技术：</p>
<ol>
<li>使用一致性哈希对数据进行分片（partition）和备份（replicate）。</li>
<li>使用版本号机制（Vector Clock）处理数据一致性问题。</li>
<li>使用多数票（Quorum）和去中心化同步协议来维持副本间的一致性（Merkle Tree）。</li>
<li>基于 Gossip Protocol 进行失败检测和副本维持。</li>
</ol>
<p>实现上来说，Dynamo 有以下特点：</p>
<ol>
<li>完全去中心化，没有中心节点，所有节点关系对等。</li>
<li>采用最终一致性，使用版本号解决冲突，甚至要求用户参与解决冲突。</li>
<li>使用哈希值进行数据分片，组织数据分布，均衡数据负载。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/06/13/dynamo/">https://www.qtmuniao.com/2020/06/13/dynamo/</a>, 转载请注明出处</em></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="目标和假设"><a href="#目标和假设" class="headerlink" title="目标和假设"></a>目标和假设</h3><p>不同的设计假设和要求会导致完全不同的设计，Dynamo 的设计目标有以下几个：</p>
<p><strong>查询模型</strong>。使用 Dynamo 只会使用主键进行查询，一般没有跨数据条目，因此不需要关系模型。此外，Dynamo 假设其存储的数据都相对较小，通常小于 1M。</p>
<p><strong>ACID 特性</strong>。传统关系型数据库（<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvREJNUw==">DBMS<i class="fa fa-external-link-alt"></i></span>）为了保证事务的正确性和可靠性，通常需要具备 ACID 特性。但对 ACID 的支持会极大降低数据的性能，为了高可用性，Dynamo 只提供弱一致性（C），不提供隔离性（I），不允许单个 key 的并发更新。</p>
<p><strong>效率</strong>。Amazon 中大部分服务对延迟有着严格的要求，为了能够满足此类服务的 SLA，Dynamo 须可配置，让用户自己在性能、效率、可用性和持久化间进行选择。</p>
<p><strong>其他</strong>。Dynamo 只用在 Amazon 内部服务中，因此可以不考虑安全性。此外，很多服务会使用独立的 Dynamo 实例，因此最初针对可扩展性的目标在百台机器级别。</p>
<h3 id="SLA"><a href="#SLA" class="headerlink" title="SLA"></a>SLA</h3><p>由于采用微服务架构，Amazon 购物网站的每个页面的渲染通常会涉及到上百个服务。为了保证用户体验，必须对每个服务的延迟做严格限制。Amazon 采用三个九（99.9% 的请求需要小于 300ms）的 SLA。而服务的状态存储环节则是提供该 SLA 的关键节点，为此 Dynamo 的一个关键设计是让服务可按需定制持久化和一致性等参数，以在性能、成本和正确性间进行抉择。</p>
<h3 id="设计考量"><a href="#设计考量" class="headerlink" title="设计考量"></a>设计考量</h3><p>对于多副本系统，高可用性和强一致性是一对矛盾。传统商用系统多为了保证强一致性而牺牲部分可用性，但Dynamo 为高可用而生，因此选择了异步同步策略。但是由于网络和服务器故障的频发特性，系统必须处理这些故障所导致的不一致，或者说是冲突。这些冲突如何解决，主要包括两方面：在什么时候解决，以及，谁来解决。</p>
<p><strong>何时解决</strong>。传统存储系统为了简化读取，通常在写入侧解决冲突，即当存在冲突的时候，拒绝写入。但 Dynamo 为了保证商城业务对用户任意时刻可用（比如随时能将商品加购物车，毕竟类似过程的体验稍微一下降，就会影响大把的收入），需要提供”永远可写”（always writable）的保证，因此需要将解决冲突的复杂度推迟到<strong>读取</strong>时刻。</p>
<p><strong>谁来解决</strong>。是由 Dynamo 来解决，还是应用侧来解决。如果是 Dynamo 系统来解决，通常会无脑选择”后者胜(last write win)”，即使用较新的更改覆盖偏旧的更改。如果交由应用来解决，则可以依据应用需求便宜行事，比如可以合并多次多次加购物车操作返回给用户。当然，这个是可选的，毕竟很多应用使用通用策略（”last write win”）就足够了。</p>
<p>其他关键设计原则还有：</p>
<p><strong>增量扩展</strong>（incremental scalability）。支持节点的动态增删，而最小化对系统和运维的影响。</p>
<p><strong>对称性</strong>（Symmetry）。系统中的每个节点职责相同，没有特殊节点，以简化构建和维护成本。</p>
<p><strong>去中心化</strong>（Decentralization）。没有中心控制节点，使用点对点的技术以使系统高可用、易扩展。</p>
<p><strong>异构性</strong>（Heterogeneity）。系统需要能够充分利用资源异构的节点，来按节点容量进行负载分配。</p>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p>围绕分区算法、备份策略、版本机制、成员组织，错误处理和可扩展性等分布式技术进行展开。</p>
<p><img src="https://i.loli.net/2020/06/21/HdFhQBOPjX52vl3.png" alt="tech summary"></p>
<h3 id="系统接口"><a href="#系统接口" class="headerlink" title="系统接口"></a>系统接口</h3><p>Dynamo 暴露两个接口：<code>put()</code> 和 <code>get()</code>:</p>
<p><code>get(key)  </code>：返回 key 对应的单个 object，或者有有版本冲突的 object 列表。</p>
<p><code>put(key, context, object)</code>：根据 key 选出 object 要放的副本机器，并将数据落盘。context 会包含一些对调用者透明的系统元信息，比如 object 的版本号信息。context 会和 object 一块存储以验证 put 请求的合法性。</p>
<p>Dynamo 将 key 和 value 都视为字节数组，并且对 key 进行 MD5 算法以生成一个 128 位的标识符，以进行存储节点的选择。</p>
<h3 id="分区算法-Partitioning-algorithm"><a href="#分区算法-Partitioning-algorithm" class="headerlink" title="分区算法(Partitioning algorithm)"></a>分区算法(Partitioning algorithm)</h3><p>为了支持增量式扩容，Dynamo 使用一致性哈希算法进行负载分配。但基本版的一致性哈希算法有两个缺点：</p>
<ol>
<li>不能够均匀的分摊负载。</li>
<li>照顾不到不同节点的资源差异。</li>
</ol>
<p>为了解决些问题，Dynamo 使用了一致性哈希的变种：引入虚拟节点。具体算法为：</p>
<ol>
<li>节点在接入系统时，根据其容量大小生成相应数量的虚拟节点，每个虚拟节点随机分配一个节点编号。</li>
<li>所有虚拟节点按编号的大小组织成一个首尾相接环状结构。</li>
<li>当有请求到来时，在与节点同样的编号空间内使用 key 加某种哈希算法生成一个数据编号。</li>
<li>根据此编号绕着虚拟节点环顺时针查找，找到第一个虚拟节点所对应的物理节点，将请求路由过去。</li>
<li>当有节点离开时，只需要移除其对应的虚拟节点即可，负载便会自动重新绕着环迁移。</li>
</ol>
<p><img src="https://i.loli.net/2020/06/21/kOE3iGgo5dWLpvI.png" alt="Dynamo 环中的键的分区和备份"></p>
<p>其中，通过分配虚拟节点的数量来照顾到不同节点的容量差异，通过生成虚拟节点编号的随机算法保证节点增删时的流量均摊。</p>
<p>为了照顾节点的增删、备份的方便，Dynamo 先后使用了三种 Partition 策略：</p>
<p><img src="https://i.loli.net/2020/06/21/9lNkWXtychiO7wH.png" alt="dynamo partition schema"></p>
<ol>
<li><p><em>每个节点分配 T 个随机的数值编号（token），每个虚拟节点一个 token，哈希环中相邻两个虚拟节点的 token 所卡出的区间即为一个 partition。</em></p>
<p>这种最初的策略有以下几个缺点：</p>
<ul>
<li><p><strong>迁移扫描</strong>。当有新节点加入系统时，需要从其他节点偷过来一些数据。这需要扫描新增虚拟节点后继几个节点中所有数据条目以得到需要迁移的数据（猜测为了 serve  get 请求，节点上的数据一般是按用户 key 进行索引组织的，而不是 key 的 hash 值，因此要获取某个 hash 值段的数据，需要全盘扫描）。这个操作挺重的，为了保证可用性需要降低迁移进程的运行权重，但这会使得迁移过程持续很久。</p>
</li>
<li><p><strong>Merkle Tree 重新计算</strong>。Merkle Tree 下面会讲到，可粗理解为以分区为单位对数据进行层次化签名。当有节点加入&#x2F;离开集群时，会导致 key range 的拆分&#x2F;合并，进而引起对应 Merkle Tree 的重新计算，这也是一个计算密集型操作，会导致很重的额外负载，在线上系统中不能忍受。</p>
</li>
<li><p><strong>难以全局快照</strong>。由于数据在物理节点中的分布是按 key 的哈希值进行切分的，因此在 key 空间中是散乱的，很难在 key 空间中做全局快照，因为这要求所有节点上的数据进行全局归并排序，效率低下。</p>
</li>
</ul>
<p>可以看出，这种策略的根本问题在于，数据分区（partition）和数据归置（placement）是耦合在一块的。这样我们就无法单独的对节点进行增删而不影响数据分区。因此，一个很自然的改进想法是，将数据分区与数据归置独立开来。</p>
</li>
<li><p><em>每个节点仍随机分配 T 个编号，但是将<strong>哈希空间</strong>等分作为分区</em>。</p>
<p>在此策略下，节点的编号（token）只是用来构建虚拟节点的哈希环，而不再用来切分分区。我们将哈希空间等分为 Q 份，Q &gt;&gt; S*T，其中 S 是物理节点数。也就是说每个虚拟节点可以放很多分区。这种策略可以从另一种角度来理解，即节点 host 的最小单位不再是 key，而是一个分区，每次节点增删时，分区会整体进行移动。这样就解决了在节点增删时，迁移扫描和 Merkle Tree 重新计算的问题。</p>
<p>对于 key 的放置策略为，每次 key 进行路由时，首先算出其哈希值，依据哈希值所在分区（key range）的最后一个哈希值，在哈希环中查找。顺时针遇到的前 N 个物理节点作为偏好列表。</p>
</li>
<li><p><em>每个节点 Q&#x2F;S 个随机编号，哈希空间等分作为分区。</em></p>
<p>这种策略在上一种的基础上，强制每个物理节点拥有等量的分区。由于 Q 数量，甚至每个节点承载的分区数 （Q&#x2F;S） 的数量远大于节点数（S），因此在节点离开时，很容易将其承载的节点数分配给其他节点，而仍然能维持该性质；当有节点加入时，每个节点给他匀点也容易。</p>
</li>
</ol>
<h3 id="备份策略-Replication"><a href="#备份策略-Replication" class="headerlink" title="备份策略(Replication)"></a>备份策略(Replication)</h3><p>Dynamo 会将每条数据在 N 个节点上进行备份，其中 N 是可以配置的。对于每个 key，会有一个协调节点（coordinator）来负责其在多个节点的备份。具体来说，协调节点会负责一个键区段 （key range）。</p>
<p>在进行备份时，协调节点会选择一致性哈希环上，顺时针方向的后继 N - 1 节点，连同其本身，对数据条目进行 N副本存储，如图二所示。这 N 个节点被称为<em>偏好列表</em>（preference list）。其中：</p>
<ol>
<li>key 到节点的映射根据上述三种不同的分区策略而不同。</li>
<li>节点可能会宕机重启，偏好列表有时候可能会多于 N 个节点。</li>
<li>由于使用的是虚拟节点，如果不加干涉，这 N 个节点可能会对应小于 N 个物理机。为此，我们在选择节点的时候需要进行跳选，以保证 N 个节点处于 N 台物理机上。</li>
</ol>
<h3 id="版本机制-Data-Versioning"><a href="#版本机制-Data-Versioning" class="headerlink" title="版本机制(Data Versioning)"></a>版本机制(Data Versioning)</h3><p>Dynamo 提供最终一致性保证，从而允许多副本进行异步同步，提高可用性。如果没有机器和网络故障，多副本将会在有限时间内同步完毕；如果出现故障，可能有些副本（replica）将永远无法正常完成同步。</p>
<p>Dynamo 提供任意时刻的可用性，如果最新的数据不能用，需要提供次新的。为了提供这种保证，Dynamo 将每个修改视为一个新版本、不可变数据。它允许多个版本的数据并存，大多数情况下，新版本数据能够对旧版本的进行覆盖，从而让系统可以自动的挑选出权威版本（syntactic reconciliation，语法和解）。但当发生故障或者存在并行操作时，可能会出现互相冲突的版本分支，此时系统无法自动进行合并，就须交由客户端来进行合并（collapse）多个版本数据（语义和解，semantic reconciliation）。</p>
<p>Dynamo 使用一种叫做<em>矢量时钟</em>（<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvVmVjdG9yX2Nsb2Nr">vector clock<i class="fa fa-external-link-alt"></i></span>）的逻辑时钟来表达同一数据多个版本间的因果关系（causality）。矢量时钟由一组 <em>&lt;节点， 计数&gt;</em> 序列组成，分别对应同一数据的同步版本。可以通多个数据版本的矢量时钟来确定这些数据版本间的关系：是并行发生（parallel branches）还是存在因果（casual ordering）：</p>
<ol>
<li>如果矢量时钟 A 中的计数小于矢量时钟 B 中所有节点的计数，则 A 是 B 的前驱，可以被丢弃。比如，A 为[&lt;node1, 1&gt;]，B 为 [&lt;node1, 1&gt;, &lt;node2, 2&gt;, &lt;node3, 1&gt;]</li>
<li>如果 A 不是 B 的前驱，B 也不是 A 的前驱，则 A 和 B 存在版本冲突，需要被和解。</li>
</ol>
<p>在 Dynamo 中，客户端更新数据对象时，必须指明所要更新的数据对象的版本。具体方式为将之前从 Get 中获得的同一数据对象的版本信息（vector clock）传入更新操作中的 context。同样的，客户端在读取数据时，如果系统不能够进行自动合并（语法和解），则会将多个版本信息通过 context 返回给客户端，一旦客户端用此信息进行后续更新，系统就认为客户端对这多个版本进行了合并（语义和解）。下图是一个详细例子。</p>
<p><img src="https://i.loli.net/2020/06/21/jLFs2o6Xh8ZOuxT.png" alt="某个数据对象的版本演化"></p>
<p>其中有几点需要注意：</p>
<ol>
<li>每个服务器节点维护一个自增的计数器，当其处理更改请求前，更新计数器的值。</li>
<li>为了防止矢量时钟的尺寸无限增长，尤其是出现网络分区或者服务器失败时，Dynamo 的策略是，矢量时钟序列超过一定阈值时（比如说 10），将序列中最早的一个时钟对丢弃。</li>
</ol>
<h3 id="get-和-put"><a href="#get-和-put" class="headerlink" title="get() 和 put()"></a>get() 和 put()</h3><p>本小节描述系统不产生故障时的交互。主要分为两个过程：</p>
<ol>
<li>用某种方式选择一个 coordinator。</li>
<li>coordinator 使用 quorum 机制进行数据多副本同步。</li>
</ol>
<h4 id="选择-coordinator"><a href="#选择-coordinator" class="headerlink" title="选择 coordinator"></a>选择 coordinator</h4><p>Dynamo 通过 HTTP 方式对外暴露服务，主要有两种策略来进行 coordinator 的选择：</p>
<ol>
<li>使用一个负载均衡器来选出一个负载较轻的节点。</li>
<li>使用可以进行分区感知的客户端，直接路由到负责该 key 的相应 coordinator （即偏好列表中的第一个）。</li>
</ol>
<p>第一种方式客户端不用保存服务器节点信息，第二种方式不需要转发，延迟更低。</p>
<p>对于第一种方式，如果是 <code>put()</code> 请求，选出的节点 S 不在首选列表 N 个节点中，S 会将请求转发到偏好列表中一个机器作为 coordinator。如果是 <code>get()</code> 请求，不管 S 在不在偏好列表中，都可以直接作为 coordinator。</p>
<h4 id="Quorum-机制"><a href="#Quorum-机制" class="headerlink" title="Quorum 机制"></a>Quorum 机制</h4><p>Quorum 读写机制是一种有意思的读写方式，有两个关键配置参数 R 和 W，通常 R 和 W 需要满足1.R + W &gt; N 2. W &gt; N&#x2F;2，其中 N 是集群备份数。理解时可以从两个角度理解，一个是类比读写锁，即系统不能同时有多个写写、读写，但是 R 设置的小一些可以同时有多个读；另一个是需要半数以上写成功，以满足数据的持久化特性。但是在 Dynamo 这些都没有硬性要求，用户可以根据需求灵活配置。</p>
<p>当一个 <code>put()</code> 请求到达时，coordinator 为新数据生成一个新的 vector clock 版本信息，并将其写入本地，然后将数据发给 N 个偏好的 replica 节点，等到 W-1 节点回复，即可认为请求成功。</p>
<p>当一个 <code>get()</code> 请求到达时，coodinator 向保有该 key  N 个首选节点（包括&#x2F;不包括它自己）发送请求，等到其中 R 个节点返回时，将多版本结果列表返回给用户。然后通过 vector clock 规则进行语法和解，并将和解后的版本写回。</p>
<h3 id="故障处理：Hinted-Handoff"><a href="#故障处理：Hinted-Handoff" class="headerlink" title="故障处理：Hinted Handoff"></a>故障处理：Hinted Handoff</h3><p>如果使用严格的 Quorum 机制处理读写，那么即使只有少量节点宕机或者网络分区也会使得系统不可用，因此 Dynamo 使用一种”粗略仲裁”（sloppy quorum）算法，可以选择一致性哈希环中首选列表的前 N 个健康节点。</p>
<p>并且当首选 coordinator （比如说 A）故障时，请求在路由到其他节点（D）时，会在元信息中带上第一选择（A 的信息），D 后台会有个常驻线程，检测到 A 重新上线时，会将这些有标记的数据移到对应机器上，并且删除本机相应副本。Dynamo 通过这种 hinted handoff 的方式，保证有节点或网络故障时，也能正常完成请求。</p>
<p>当然，服务为了高可用，可以将 W 设置 1，这样首选列表中任何节点可用，都可以写成功。但在实践中为了保证持久化，一般都不会设这么低。后面章节将会详述 N，R 和 W 的配置问题。</p>
<p>此外，为了处理数据中心级别的故障，Dynamo 通过配置使得首选节点列表跨越不同中心，以进行容灾。</p>
<h3 id="永久故障处理：副本同步"><a href="#永久故障处理：副本同步" class="headerlink" title="永久故障处理：副本同步"></a>永久故障处理：副本同步</h3><p>Hinted Handoff 只能处理偶然的、临时的节点宕机问题。为了处理其他更严重的故障带来的一致性问题，Dynamo 使用了去中心化的反熵算法（anti-entropy）来进行分片副本间的数据同步。</p>
<p>为了快速检测副本间数据是否一致、并且能够精确定位到不一样的区域，Dynamo 使用 Merkle Tree （也叫哈希树，区块链中也用）来以分片为单位对分片中所有数据进行层层签名。所有叶子节点是真实数据的 hash 值，而所有中间节点是其孩子节点的哈希值。这样的树有两个好处：</p>
<ol>
<li>只要比对根节点，就可以知道分片的两个副本数据是否一致。</li>
<li>每个中间节点都代表某个范围的所有数据的签名，只要其相等，则对应数据一致。</li>
<li>如果只有少量不一致，可以从根节点出发，迅速定位到不一致的数据位置。</li>
</ol>
<p><img src="https://i.loli.net/2020/06/21/hWz3jksmct9ZwRu.png" alt="merkle tree"></p>
<p>Dynamo 对每个数据分片（key range or shard，shard 是最小的逻辑存储单位）维护一个 Merkle Tree，借助Merkle Tree 的性质，Dynamo 可以很快比较两个数据分片的副本数据是否一致。如果不一致，可以通过定位不一致位置，最少化数据传输。</p>
<p>这样做的缺点是，如果有节点加入或者离开集群，会引起大量的 key range 的变动，从而需要对变化的 key range 重新计算 Merkle Tree。当然，前面也讨论了，改进后的分区策略改进了这个问题。</p>
<h3 id="成员关系和故障检测"><a href="#成员关系和故障检测" class="headerlink" title="成员关系和故障检测"></a>成员关系和故障检测</h3><p><strong>显式管理成员关系</strong>。在 Amazon 的环境中，由于故障或人为失误造成的节点离开集群通常很少，或者不会持续太长时间。如果每次有节点下线都立即自动调整数据分片的放置位置，会引起不必要的数据震荡迁移。因此 Dynamo 采用显式管理成员的方式，提供相应接口给管理员对物理节点进行上下线。即，由于故障导致节点下线不会引起数据分片的移动。</p>
<p><strong>类 Gossip 算法广播元信息</strong>。成员关系变动首先由处理成员增删请求的节点感知到，持久化到本地，然后利用类 Gossip 算法进行广播，每次随机选择一个节点进行传播，最终使得所有成员对此达成共识。此外，该算法也用于节点在刚启动时交换数据分片信息和数据分布信息。</p>
<p>每个节点刚启动时，只知道自己的节点信息和 token 信息，随着各个节点渐次启动，并通过算法互相交换信息，增量的在每个节点分别构建出整个哈希环的拓扑（key range 到虚拟节点，虚拟节点到物理节点的映射）。从而，当某个请求到来的时候，可以直接转发到对应的处理节点。</p>
<p><strong>种子节点避免逻辑分区</strong>。引入功能性的种子节点做服务发现，每个节点都会直连种子节点，以使得每个加入的节点快速为其他节点所知，避免由于同时加入集群，互不知晓，出现逻辑分区。</p>
<p><strong>故障检测</strong>。为了避免将 put&#x2F;get 请求和同步元信息请求持续转发到不可达节点，仅使用局部的故障检测就足够了。即如果 A 发向 B 的请求得到不到回应，A 就将 B 标记为故障，然后开启心跳，以感知其恢复。如果 A 收到应该转向 B 的请求，并且发现 B 故障，就会在该 key 对应的首选节点列表中选择一个替代节点。</p>
<p>可以看出，Dynamo 将节点的<em>永久离开</em>和<em>暂时离开</em>分开处理。使用显示接口来增删永久成员，并将成员拓扑通过 gossip 算法进行广播；使用简单标记和心跳来处理偶发故障，合理进行流量转发。在故障较少的环境里，如此分而治之，能大大提高达成一致的效率，最大限度避免节点偶发故障和网络阵法抖动引起的不必要的数据搬迁。</p>
<h3 id="增删节点"><a href="#增删节点" class="headerlink" title="增删节点"></a>增删节点</h3><p>如下图，考虑三副本（N&#x3D;3）并且采用最简单的分区策略的情况下，当在在节点 A 和 B 间加入一个节点 X 时，X 将会负责 Key Range： (F,G]，(G, A]，(A, X] ，同时 B 将不再负责 (F,G]，C 将不再负责(G, A]，D 将不再负责 (A, X] ，Dynamo 通过 B，C，D 主动向 X 推送相关 Key Range 的方式来适应 X 的加入。在推送前有个等待 X 确认阶段，以避免重复推送。</p>
<p><img src="https://i.loli.net/2020/06/21/e9nJWTS6BtoEXhy.png" alt="add member"></p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p> Dynamo 中每个节点主要包括四个组件：请求协调（request coordination），成员管理（membership），故障检测（failure detection）和一个本地的持久化引擎（local persistence engine）。所有组件都是用 Java 实现的。</p>
<p>Dynamo 的本地持久化组件，允许选择多种引擎，包括 Berkeley Database（BDB），MySQL 和一个基于内存+持久化的存储。用户可以根据业务场景进行选择，大部分的生产环境使用 BDB 。</p>
<p>请求协调组件使用 Java NIO 通道实现，采用事件驱动模型，将一个消息的处理过程被分为多个阶段。对于每个到来的读写请求都会初始化一个状态机来处理。比如对于读请求来说，实现了以下状态机：</p>
<ol>
<li>发送请求到包含 key 所在分片的副本的所有节点。</li>
<li>等待读请求最小要求的节点数（R）个节点返回。</li>
<li>在设定时限内，没有收集到 R 个请求，返回客户端失败消息。</li>
<li>否则收集所有版本数据，并决定需要返回的版本数据。</li>
<li>如果启用了版本控制，就会进行语法和解，并将和解后版本写入上下文。</li>
</ol>
<p>在读的过程中，如果发现某些副本数据过期了，会顺带将其更新，这叫做<em>读修复</em>（read repair）。</p>
<p>对于写请求，将会由首选 N 个节点中的一个作为协调者进行协调，通常是第一个。但为了提高吞吐，均衡负载，通常这 N 个节点都可以作为协调者。尤其是，大部分数据在读取之后，通常会紧跟着写入（读取获取版本，然后使用对应版本进行写入），因此常将写入调度到上次读取中回复最快的节点，该节点保存了读取时的上下文信息，从而能更快响应，提高吞吐。</p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>s3和 Dynamo 对比：<span class="exturl" data-url="aHR0cHM6Ly9zZXJ2ZXJsZXNzLnB1Yi9zMy1vci1keW5hbW9kYi8=">https://serverless.pub/s3-or-dynamodb/<i class="fa fa-external-link-alt"></i></span></p>
<p>乐观复制：<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvT3B0aW1pc3RpY19yZXBsaWNhdGlvbg==">https://en.wikipedia.org/wiki/Optimistic_replication<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>存储</tag>
        <tag>Dynamo</tag>
        <tag>分布式</tag>
        <tag>键值存储</tag>
        <tag>Amazon</tag>
      </tags>
  </entry>
  <entry>
    <title>漫谈 LevelDB 数据结构（一）：跳表（Skip List）</title>
    <url>/2020/07/03/leveldb-data-structures-skip-list/</url>
    <content><![CDATA[<blockquote>
<p>早对 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS9sZXZlbGRi">LevelDB<i class="fa fa-external-link-alt"></i></span> 有所耳闻，这次心血来潮结合一些资料粗略过了遍代码，果然名不虚传。如果你对存储感兴趣、如果你想优雅使用C++、如果你想学习如何架构项目，都推荐来观摩一下。更何况作者是 Sanjay Ghemawat 和  Jeff Dean 呢。</p>
<p>看过一遍如果不输出点什么，以我的记性，定会很快抛诸脑后。便想写点东西说说 LevelDB 之妙，但又不想走寻常路，从架构概览说起，以模块分析做合。读代码的这些天，一直在盘算从哪下笔比较好。在将将读完之时，印象最深的反而是 LevelDB 的各种精妙的数据结构：贴合场景、从头构建、剪裁得当、代码精到。不妨， LevelDB 系列就从这些边边角角的小构件开始吧。</p>
<p>本系列主要想分享 LevelDB 中用到的三个工程中常用的经典数据结构，分别是用以快速读写 memtable 的 <strong>Skip List</strong>、用以快速筛选 sstable 的 <a href="https://www.qtmuniao.com/2020/11/18/leveldb-data-structures-bloom-filter"><strong>Bloom Filter</strong></a> 和用以部分缓存 sstable 的 <strong>LRUCache</strong> 。这是第一篇，Skip List。</p>
</blockquote>
<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>LevelDB 是一个单机的 KV 存储引擎。KV 引擎在本质上可认为只提供对数据条目（key，val） <code>Put(key, val), Get(key) val, Delete(key)</code> 操作的三个接口。而在实现上，LevelDB 在收到删除请求时不会真正删除数据，而是为该 Key 写一个特殊标记，以备读取时发现该 Key 不存在，从而将  <code>Delete</code> 转为 <code>Put</code> ，进而将三个接口简化为两个。砍完这一刀后，剩下的就是在 <code>Put</code> 和 <code>Get</code> 间进行性能取舍，LevelDB 的选择是：**牺牲部分 <code>Get</code> 性能，换取强悍 <code>Put</code> 性能，再极力优化 <code>Get</code>**。</p>
<p>我们知道，在存储层次体系（<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTWVtb3J5X2hpZXJhcmNoeQ==">Memory hierarchy<i class="fa fa-external-link-alt"></i></span>）中，内存访问远快于磁盘，因此 LevelDB 为了达到目标做了以下设计：</p>
<ol>
<li><em>写入（Put）</em>：让所有写入都发生在<strong>内存</strong>中，然后达到一定尺寸后将其批量刷<strong>磁盘</strong>。</li>
<li><em>读取（Get）</em>：随着时间推移，数据不断写入，内存中会有一小部分数据，磁盘中有剩余大部分数据。读取时，如果在内存中没命中，就需要去磁盘查找。</li>
</ol>
<p>为了保证写入性能，同时优化读取性能，需要内存中的存储结构能够同时支持高效的<strong>插入</strong>和<strong>查找</strong>。</p>
<p>之前听说 LevelDB 时，最自然的想法，以为该内存结构（memtable）为是<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvU2VsZi1iYWxhbmNpbmdfYmluYXJ5X3NlYXJjaF90cmVl">平衡树<i class="fa fa-external-link-alt"></i></span>，比如<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUmVkJUUyJTgwJTkzYmxhY2tfdHJlZQ==">红黑树<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQVZMX3RyZWU=">AVL 树<i class="fa fa-external-link-alt"></i></span>等，可以保证插入和查找的时间复杂度都是 lg(n)，看源码才知道用了跳表。相比平衡树，跳表优势在于，在保证读写性能的同时，大大简化了实现。</p>
<p>此外，为了将数据定期 dump 到磁盘，还需要该数据结构支持高效的顺序遍历。总结一下 LevelDB  内存数据结构（memtable）需求点：</p>
<ol>
<li>高效查找</li>
<li>高效插入</li>
<li>高效顺序遍历</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/07/03/leveldb-data-structures-skip-list/">https://www.qtmuniao.com/2020/07/03/leveldb-data-structures-skip-list/</a>, 转载请注明出处</em></p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>跳表由 William Pugh 在 1990 年提出，相关论文为：<span class="exturl" data-url="aHR0cHM6Ly8xNTcyMS5jb3Vyc2VzLmNzLmNtdS5lZHUvc3ByaW5nMjAxOC9wYXBlcnMvMDgtb2x0cGluZGV4ZXMxL3B1Z2gtc2tpcGxpc3RzLWNhY20xOTkwLnBkZg==">Skip Lists: A Probabilistic Alternative to Balanced Trees<i class="fa fa-external-link-alt"></i></span>。从题目可以看出，作者旨在设计一种能够替换平衡树的数据结构，正如他在开篇提到：</p>
<blockquote>
<p>Skip lists are a data structure that can be used in place of balanced trees. </p>
<p>Skip lists use probabilistic balancing rather than strictly enforced balancing and as a result the algorithms for insertion and deletion in skip lists are much simpler and significantly faster than equivalent algorithms for balanced trees.</p>
</blockquote>
<blockquote>
<p>跳表是一种可以取代平衡树的数据结构。</p>
<p>跳表使用概率均衡而非严格均衡策略，从而相对于平衡树，大大简化和加速了元素的插入和删除。</p>
</blockquote>
<p>这段话中有个关键词：<strong>概率均衡</strong>（probabilistic balancing），先卖个关子，按下不表。</p>
<p>接下来我们从两个角度来解读跳表：链表和跳表，跳表和平衡树。</p>
<h3 id="链表到跳表"><a href="#链表到跳表" class="headerlink" title="链表到跳表"></a>链表到跳表</h3><p>简言之，<strong>跳表就是带有额外指针的链表</strong>。为了理解这个关系，我们来思考一下优化有序链表查找性能的过程。</p>
<p>假设我们有个有序链表，可知其查询和插入复杂度都为 O(n)。相比数组，链表不能进行二分查找的原因在于，不能用下标索引进行常数复杂度数据访问，从而不能每次每次快速的筛掉现有规模的一半。那么如何改造一下链表使之可以进行二分？</p>
<p>利用 map 构造一个下标到节点的映射？这样虽然可以进行二分查询了，但是每次插入都会引起后面所有元素的下标变动，从而需要在 map 中进行 O(n) 的更新。</p>
<p>增加指针使得从任何一个节点都能直接跳到其他节点？那得构造一个全连接图，指针耗费太多空间不说，每次插入指针的更新仍是 O(n) 的。</p>
<p>跳表给出了一种思路，<strong>跳步采样，构建索引，逐层递减</strong>。下面利用论文中的一张图来详细解释下。</p>
<p><img src="https://i.loli.net/2020/07/07/OeJRfVhHMEpxiNz.png" alt="skiplist-linked-lists-with-additional-pointers.png"></p>
<p>如上图，初始我们有个带头结点的有序链表 a，其查找复杂度为 O(n)。然后，我们进行跳步采样，将采样出的节点按用指针依次串联上，得到表 b，此时的查找复杂度为 O(<em>n</em>&#x2F;2 + 1)  <em>[注1]<em>。其后，我们在上次采样出的节点，再次进行跳步采样，并利用指针依次串联上，得到表 c，此时的查找复杂为 O(</em>n</em>&#x2F;4 + 2)。此后，我们重复这个跳步采样、依次串联的过程，直到采样出的节点只剩一个，如图 e，此时的查找复杂度，可以看出为 O(log2n) *[注2]*。</p>
<p>代价是我们增加了一堆指针，增加了多少呢？我们来逐次考虑这个问题。从图中可以看出，每次采样出多少节点，便会增加多少个指针；我们的采样策略是，每次在上一次的节点集中间隔采样，初始节点数为 n，最后采到只剩一个节点为止。将其加和则为：(n&#x2F;2 + n&#x2F;4 + … + 1) &#x3D; n。这和一个节点为 n 的二叉树的指针数是相同的。</p>
<p>这里我们回避了一个问题：该结构的插入时间复杂度是多少？这其实进一步了引出本质问题，我们该如何进行插入。</p>
<h3 id="跳表和平衡树"><a href="#跳表和平衡树" class="headerlink" title="跳表和平衡树"></a>跳表和平衡树</h3><p>在实践中，我们常用搜索二叉树作为字典表或者顺序表。在插入过程中，如果数据在 key 空间具有很好地随机性，那么二叉搜索树每次顺序插入就可以维持很好的查询性能。但如果我们顺序的插入数据，则会使得二叉搜索树严重失衡，从而使读写性能都大幅度退化。</p>
<p>为了保证性能，需要在发现不平衡时进行调整，于是有了 AVL 树和红黑树。众所周知，AVL 的旋转策略和红黑树的标色策略都稍显复杂，反正我粗看了两次都没记住，面试手撸更是不可能。</p>
<p>而跳表在保证同样查询效率的情况下，使用了一种很巧妙的转化，大大简化了插入的实现。我们不能保证所有的插入请求在 key 空间具有很好地随机性，或者说均衡性；但我们可以控制每个节点其他维度的均衡性。比如，跳表中每个节点的指针数分布的概率均衡。</p>
<h3 id="概率均衡"><a href="#概率均衡" class="headerlink" title="概率均衡"></a>概率均衡</h3><p>为了更好地讲清楚这个问题，我们梳理一下跳表的结构和所涉及到概念。跳表每个节点都会有1 ~ MaxLevel 个指针，有 k 个指针的节点称为 <em>k 层节点</em>（level k node）；所有节点的层次数的最大值为跳表的<em>最大层数</em>（MaxLevel）。跳表带有一个空的头结点，头结点有 MaxLevel 个指针。</p>
<p>按前面从有序链表构建跳表的思路，每次插入新节点就变成了难题，比如插入的节点需要有多少个指针？插入后如何才能保证查找性能不下降（即维持采样的均衡）？</p>
<p>为了解决这个问题， Pugh 进行了一个巧妙的转化：将<em>全局、静态</em>的构建索引拆解为<em>独立、动态</em>的构建索引。其中的关键在于<strong>通过对跳表全局节点指针数概率分布的维持，达到对查询效率的保持</strong>。分析上面见索引逐层采样的过程我们可以发现，建成的跳表中有 50% 的节点为 1 层节点，25% 的节点为 2 层节点，12.5% 的节点为三层节点，依次类推。若能维持我们构造的跳表中的节点具有同样的概率分布，就能保证差不多查询性能。这在直觉上似乎没问题，这里不去深入探讨背后的数学原理，感兴趣的同学可以去读一读论文。</p>
<p>经过这样的转化，就解决了上面提出的两个问题：</p>
<ol>
<li>插入新节点的指针数通过独立的计算一个概率值决定，使全局节点的指针数满足几何分布即可。</li>
<li>插入时不需要做额外的节点调整，只需要先找到其需要放的位置，然后修改他和前驱的指向即可。</li>
</ol>
<p>这样插入节点的时间复杂度为查找的时间复杂度 <code>O(log2n)</code>，与修改指针的复杂度 <code>O(1)</code>  <em>[注3]</em> 之和，即也为 <code>O(log2n)</code>，删除过程和插入类似，也可以转化为查找和修改指针值，因此复杂度也为 <code>O(log2n)</code>。</p>
<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>千呼万唤始出来，让我们进入正题。LevelDB 中对 SkipList 的实现增加了多线程并发访问方面的优化的代码，提供以下保证：</p>
<ol>
<li>Write：在修改跳表时，需要在用户代码侧加锁。</li>
<li>Read：在访问跳表（查找、遍历）时，只需保证跳表不被其他线程销毁即可，不必额外加锁。</li>
</ol>
<p>也就是说，用户侧只需要处理写写冲突，LevelDB 跳表保证没有读写冲突。</p>
<p>这是因为在实现时，LevelDB 做了以下假设（Invariants）：</p>
<ol>
<li>除非跳表被销毁，跳表节点只会增加而不会被删除，因为跳表对外根本不提供删除接口。</li>
<li>被插入到跳表中的节点，除了 next 指针其他域都是不可变的，并且只有插入操作会改变跳表。</li>
</ol>
<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>LevelDB 的 Skip List 对外提供的接口主要有三个，分别是插入、查询和遍历。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 插入 key 到跳表中.</span></span><br><span class="line"><span class="comment">// 要求: 不能够插入和跳表中的节点判等的 key.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="type">void</span> SkipList&lt;Key, Comparator&gt;::<span class="built_in">Insert</span>(<span class="type">const</span> Key&amp; key)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当且仅当跳表中有和给定 key 判等的节点才返回真.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="type">bool</span> SkipList&lt;Key, Comparator&gt;::<span class="built_in">Contains</span>(<span class="type">const</span> Key&amp; key) <span class="type">const</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回给定跳表的迭代器</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">Iterator</span>(<span class="type">const</span> SkipList* list)</span><br></pre></td></tr></table></figure>

<p>为了灵活适配，LevelDB 的 SkipList 使用了类模板（<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvVGVtcGxhdGVfKEMlMkIlMkIp">template class<i class="fa fa-external-link-alt"></i></span>），使得调用方可以自定义 Key 的类型，并且基于该 Key 定制比较类 Comparator。</p>
<p>在详细分析这几个接口之前，首先看下跳表的基本构成元素 <code>SkipList::Node</code> 的数据结构，代码里有一些多线程读写共享变量时进行同步的代码。这里主要涉及到指令重排的一些内容，下面稍微展开说一下。</p>
<p>我们知道，编译器&#x2F;CPU 在保在达到相同效果的情况下会按需（加快速度、内存优化等）对指令进行重排，这对单线程来说的确没什么。但是对于多线程，指令重排会使得多线程间代码执行顺序变的各种反直觉。用 go 代码<span class="exturl" data-url="aHR0cHM6Ly9nb2xhbmcub3JnL3JlZi9tZW0=">举个例子<i class="fa fa-external-link-alt"></i></span>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a, b <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line">  a = <span class="number">1</span></span><br><span class="line">  b = <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">g</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="built_in">print</span>(b)</span><br><span class="line">  <span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">go</span> f()</span><br><span class="line">  g()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该代码片段可能会打印出 <code>2 0</code>！</p>
<p>原因在于编译器&#x2F;CPU 将 <code>f()</code>  赋值顺序重排了或者将 <code>g()</code> 中打印顺序重排了。这就意味着你跟随直觉写出的多线程代码，可能会出问题。因为你无形中默认了单个线程中执行顺序是代码序，多线程中虽然代码执行会产生交错，但仍然保持各自线程内的代码序。实则不然，由于编译器&#x2F;CPU 的指令重排，如果不做显式同步，你不能对多线程间代码执行顺序有任何假设。</p>
<p>回到 LevelDB 跳表代码上，主要涉及 C++11 中 atomic 标准库中新支持的几种 memory order，规定了一些指令重排方面的限制，仅说明下用到的三种：</p>
<ol>
<li><code>std::memory_order_relaxed</code>：不对重排做限制，只保证相关共享内存访问的原子性。</li>
<li><code>std::memory_order_acquire</code>:  用在 load 时，保证同线程中该 load 之后的对相关内存读写语句不会被重排到 load 之前，并且其他线程中对同样内存用了 store release 都对其可见。</li>
<li><code>std::memory_order_release</code>：用在 store 时，保证同线程中该 store 之后的对相关内存的读写语句不会被重排到 store 之前，并且该线程的所有修改对用了 load acquire 的其他线程都可见。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SkipList</span>&lt;Key, Comparator&gt;::Node &#123;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">Node</span><span class="params">(<span class="type">const</span> Key&amp; k)</span> : key(k) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  Key <span class="type">const</span> key;</span><br><span class="line"></span><br><span class="line">  <span class="function">Node* <span class="title">Next</span><span class="params">(<span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(n &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> next_[n].<span class="built_in">load</span>(std::memory_order_acquire);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetNext</span><span class="params">(<span class="type">int</span> n, Node* x)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(n &gt;= <span class="number">0</span>);</span><br><span class="line">    next_[n].<span class="built_in">store</span>(x, std::memory_order_release);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 不带内存屏障版本的访问器。内存屏障（Barrier）是个形象的说法，也即加一块挡板，阻止重排/进行同步</span></span><br><span class="line">  <span class="function">Node* <span class="title">NoBarrier_Next</span><span class="params">(<span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(n &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> next_[n].<span class="built_in">load</span>(std::memory_order_relaxed);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">NoBarrier_SetNext</span><span class="params">(<span class="type">int</span> n, Node* x)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(n &gt;= <span class="number">0</span>);</span><br><span class="line">    next_[n].<span class="built_in">store</span>(x, std::memory_order_relaxed);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 指针数组的长度即为该节点的 level，next_[0] 是最低层指针.</span></span><br><span class="line">  std::atomic&lt;Node*&gt; next_[<span class="number">1</span>]; <span class="comment">// 指向指针数组的指针</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p>查找是插入的基础，每个节点要先找到合适位置，才能进行插入。因此 LevelDB 抽象出了一个公用函数： <code>FindGreaterOrEqual</code> ：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="type">bool</span> SkipList&lt;Key, Comparator&gt;::<span class="built_in">Contains</span>(<span class="type">const</span> Key&amp; key) <span class="type">const</span> &#123;</span><br><span class="line">  Node* x = <span class="built_in">FindGreaterOrEqual</span>(key, <span class="literal">nullptr</span>);</span><br><span class="line">  <span class="keyword">if</span> (x != <span class="literal">nullptr</span> &amp;&amp; <span class="built_in">Equal</span>(key, x-&gt;key)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该函数的含义为：在跳表中查找不小于给 Key 的第一个值，如果没有找到，则返回 nullptr。如果参数 <code>prev</code> 不为空，在查找过程中，记下待查找节点在各层中的前驱节点。显然，如果查找操作，则指定 <code>prev = nullptr</code> 即可；若要插入数据，则需传入一个合适尺寸的 <code>prev</code> 参数。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">typename</span> SkipList&lt;Key, Comparator&gt;::Node*</span><br><span class="line">SkipList&lt;Key, Comparator&gt;::<span class="built_in">FindGreaterOrEqual</span>(<span class="type">const</span> Key&amp; key, Node** prev) <span class="type">const</span> &#123;</span><br><span class="line">  Node* x = head_;                <span class="comment">// 从头结点开始查找</span></span><br><span class="line">  <span class="type">int</span> level = <span class="built_in">GetMaxHeight</span>() - <span class="number">1</span>; <span class="comment">// 从最高层开始查找</span></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    Node* next = x-&gt;<span class="built_in">Next</span>(level);  <span class="comment">// 该层中下一个节点</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">KeyIsAfterNode</span>(key, next)) &#123;</span><br><span class="line">      x = next;                   <span class="comment">// 待查找 key 比 next 大，则在该层继续查找</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (prev != <span class="literal">nullptr</span>) prev[level] = x;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">if</span> (level == <span class="number">0</span>) &#123;           <span class="comment">// 待查找 key 不大于 next，则到底返回</span></span><br><span class="line">        <span class="keyword">return</span> next;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;                    <span class="comment">// 待查找 key 不大于 next，且没到底，则往下查找</span></span><br><span class="line">        level--;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该过程借用论文中图示如下：</p>
<p><img src="https://i.loli.net/2020/07/07/N3iSsOqDBvdRCfg.png" alt="skiplist-search-insert.png"></p>
<h3 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h3><p>在 <code>FindGreaterOrEqual</code> 基础上，记下待插入节点的各层次前驱节点，比如上图中，调用 <code>FindGreaterOrEqual(17, prev)</code> 后 <code>prev = [12, 9, 6, 6]</code>。插入代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="type">void</span> SkipList&lt;Key, Comparator&gt;::<span class="built_in">Insert</span>(<span class="type">const</span> Key&amp; key) &#123;</span><br><span class="line">  <span class="comment">// 待做(opt): 由于插入要求外部加锁，因此可以使用 NoBarrier_Next 的 FindGreaterOrEqual 以提高性能</span></span><br><span class="line">  Node* prev[kMaxHeight]; <span class="comment">// 长度设定简单粗暴，直接取最大值（kMaxHeight = 12）肯定没错。</span></span><br><span class="line">  Node* x = <span class="built_in">FindGreaterOrEqual</span>(key, prev);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// LevelDB 跳表要求不能插入重复数据</span></span><br><span class="line">  <span class="built_in">assert</span>(x == <span class="literal">nullptr</span> || !<span class="built_in">Equal</span>(key, x-&gt;key));</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> height = <span class="built_in">RandomHeight</span>(); <span class="comment">// 随机获取一个 level 值</span></span><br><span class="line">  <span class="keyword">if</span> (height &gt; <span class="built_in">GetMaxHeight</span>()) &#123; <span class="comment">// GetMaxHeight() 为获取跳表当前层数</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="built_in">GetMaxHeight</span>(); i &lt; height; i++) &#123;</span><br><span class="line">      prev[i] = head_;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 此处不用为并发读加锁。因为并发读在（在另外线程中通过 FindGreaterOrEqual 中的 GetMaxHeight）</span></span><br><span class="line">    <span class="comment">// 读取到更新后跳表层数，但该节点尚未插入时也无妨。因为这意味着它会读到 nullptr，而在 LevelDB</span></span><br><span class="line">    <span class="comment">// 的 Comparator 设定中，nullptr 比所有 key 都大。因此，FindGreaterOrEqual 会继续往下找，</span></span><br><span class="line">    <span class="comment">// 符合预期。</span></span><br><span class="line">    max_height_.<span class="built_in">store</span>(height, std::memory_order_relaxed);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  x = <span class="built_in">NewNode</span>(key, height);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; height; i++) &#123;</span><br><span class="line">    <span class="comment">// 此句 NoBarrier_SetNext() 版本就够用了，因为后续 prev[i]-&gt;SetNext(i, x) 语句会进行强制同步。</span></span><br><span class="line">    <span class="comment">// 并且为了保证并发读的正确性，一定要先设置本节点指针，再设置原条表中节点（prev）指针</span></span><br><span class="line">    x-&gt;<span class="built_in">NoBarrier_SetNext</span>(i, prev[i]-&gt;<span class="built_in">NoBarrier_Next</span>(i));</span><br><span class="line">    prev[i]-&gt;<span class="built_in">SetNext</span>(i, x);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>LevelDB 跳表实现的<strong>复杂点</strong>在于提供不加锁的并发读的正确性保证。但算法的<strong>关键点</strong>在于每个节点插入时，如何确定新插入节点的层数，以使跳表满足概率均衡，进而提供高效的查询性能。即 <code>RandomHeight</code> 的实现：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="type">int</span> SkipList&lt;Key, Comparator&gt;::<span class="built_in">RandomHeight</span>() &#123;</span><br><span class="line">  <span class="comment">// 每次以 1/4 的概率增加层数</span></span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">unsigned</span> <span class="type">int</span> kBranching = <span class="number">4</span>;</span><br><span class="line">  <span class="type">int</span> height = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (height &lt; kMaxHeight &amp;&amp; ((rnd_.<span class="built_in">Next</span>() % kBranching) == <span class="number">0</span>)) &#123;</span><br><span class="line">    height++;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">assert</span>(height &gt; <span class="number">0</span>);</span><br><span class="line">  <span class="built_in">assert</span>(height &lt;= kMaxHeight);</span><br><span class="line">  <span class="keyword">return</span> height;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>LevelDB 的采样较为稀疏，每四个采一个，且层数上限为 kMaxHeight &#x3D; 12。具体实现过程即为构造 P &#x3D; 3&#x2F;4 的几何分布的过程。结果为所有节点中：3&#x2F;4 的节点为 1 层节点，3&#x2F;16 的节点为 2 层节点，3&#x2F;64 的节点为 3 层节点，依次类推。这样平均每个节点含指针数 1&#x2F;P &#x3D; 4&#x2F;3 &#x3D; 1.33 个。当然，在论文中的 p 的含义为相邻两层间采样的比例，和我提到的 P 的关系为：p &#x3D; 1-P。</p>
<p>选 p &#x3D; 1&#x2F;4 相比 p &#x3D; 1&#x2F;2 是用时间换空间，即只牺牲了一些常数的查询效率，换取平均指针数的减少，从而减小内存使用。论文中也推荐 p &#x3D; 1&#x2F;4 ，除非读速度要求特别严格。在此情况下，可以最多支持 n &#x3D; (1&#x2F;p)^kMaxHeight 个节点的情况，查询时间复杂度不退化。如果选 kMaxHeight &#x3D; 12，则跳表最多可以支持 n &#x3D; 4 ^ 12 &#x3D; 16M 个值。</p>
<h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><p>LevelDB 为跳表构造了一个内部类 Iterator，以 SkipList 作为构造函数参数，实现了 LevelDB 导出的 Iterator 接口的大部分函数，如 Next，Prev，Seek，SeekToFirst，SeekToLast 等等。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">Iterator</span>(<span class="type">const</span> SkipList* list) &#123;</span><br><span class="line">  list_ = list;</span><br><span class="line">  node_ = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">Valid</span>() <span class="type">const</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> node_ != <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> <span class="type">const</span> Key&amp; SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">key</span>() <span class="type">const</span> &#123;</span><br><span class="line">  <span class="built_in">assert</span>(<span class="built_in">Valid</span>());</span><br><span class="line">  <span class="keyword">return</span> node_-&gt;key;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">Next</span>() &#123;</span><br><span class="line">  <span class="built_in">assert</span>(<span class="built_in">Valid</span>());</span><br><span class="line">  node_ = node_-&gt;<span class="built_in">Next</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">Prev</span>() &#123;</span><br><span class="line">  <span class="comment">// 相比在节点中额外增加一个 prev 指针，我们使用从头开始的查找定位其 prev 节点</span></span><br><span class="line">  <span class="built_in">assert</span>(<span class="built_in">Valid</span>());</span><br><span class="line">  node_ = list_-&gt;<span class="built_in">FindLessThan</span>(node_-&gt;key);</span><br><span class="line">  <span class="keyword">if</span> (node_ == list_-&gt;head_) &#123;</span><br><span class="line">    node_ = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">Seek</span>(<span class="type">const</span> Key&amp; target) &#123;</span><br><span class="line">  node_ = list_-&gt;<span class="built_in">FindGreaterOrEqual</span>(target, <span class="literal">nullptr</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">SeekToFirst</span>() &#123;</span><br><span class="line">  node_ = list_-&gt;head_-&gt;<span class="built_in">Next</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> SkipList&lt;Key, Comparator&gt;::Iterator::<span class="built_in">SeekToLast</span>() &#123;</span><br><span class="line">  node_ = list_-&gt;<span class="built_in">FindLast</span>();</span><br><span class="line">  <span class="keyword">if</span> (node_ == list_-&gt;head_) &#123;</span><br><span class="line">    node_ = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看出该迭代器没有为每个节点增加一个额外的 prev 指针以进行反向迭代，而是用了选择从 head 开始查找。这也是一种用时间换空间的取舍。当然，其假设是前向遍历情况相对较少。</p>
<p>其中 <code>FindLessThan</code> 和 <code>FindLast</code> 的实现与 <code>FindGreaterOrEqual</code> 思路较为相似，不再赘述。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Return the latest node with a key &lt; key.</span></span><br><span class="line"><span class="comment">// Return head_ if there is no such node.</span></span><br><span class="line"><span class="function">Node* <span class="title">FindLessThan</span><span class="params">(<span class="type">const</span> Key&amp; key)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Return the last node in the list.</span></span><br><span class="line"><span class="comment">// Return head_ if list is empty.</span></span><br><span class="line"><span class="function">Node* <span class="title">FindLast</span><span class="params">()</span> <span class="type">const</span></span>;</span><br></pre></td></tr></table></figure>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>跳表本质上是对链表的一种优化，通过逐层跳步采样的方式构建索引，以加快查找速度。使用概率均衡的思路，确定新插入节点的层数，使其满足集合分布，在保证相似的查找效率简化了插入实现。</p>
<p>LevelDB 的跳表实现还专门对多线程读做了优化，但写仍需外部加锁。在实现思路上，整体采用时间换空间的策略，优化内存使用。</p>
<p>下一篇中，将继续剖析 LevelDB 中用到的另一个经典的数据结构：<a href="https://www.qtmuniao.com/2020/11/18/leveldb-data-structures-bloom-filter">布隆过滤器</a>（Bloom Filter）。</p>
<h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><p>[1] 先在上层查找，然后缩小到某个范围后去下层查找。</p>
<p>[2] 可以证明，也可以简单的找规律： O(<em>n</em>&#x2F;2 + 1) -&gt; O(<em>n</em>&#x2F;4 + 2) -&gt; … -&gt; O(1 + log2n)，即 O(log2n) 。</p>
<p>[3] 通过采样过程可知所有节点的概率满足 p &#x3D; 0.5 的<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvR2VvbWV0cmljX2Rpc3RyaWJ1dGlvbg==">几何分布<i class="fa fa-external-link-alt"></i></span>，则每个节点的期望指针个数为 1&#x2F;p &#x3D; 2，则每次插入平均需要修改 2 * 2 个指针，即为常数级别。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>LevelDB handbook：<span class="exturl" data-url="aHR0cHM6Ly9sZXZlbGRiLWhhbmRib29rLnJlYWR0aGVkb2NzLmlvL3poL2xhdGVzdC9pbmRleC5odG1s">https://leveldb-handbook.readthedocs.io/zh/latest/index.html<i class="fa fa-external-link-alt"></i></span></li>
<li>庖丁解 LevelDB 之数据存储：<span class="exturl" data-url="aHR0cHM6Ly9jYXRrYW5nLmdpdGh1Yi5pby8yMDE3LzAxLzE3L2xldmVsZGItZGF0YS5odG1s">https://catkang.github.io/2017/01/17/leveldb-data.html<i class="fa fa-external-link-alt"></i></span></li>
<li>C++ atomic memory order：<span class="exturl" data-url="aHR0cHM6Ly9lbi5jcHByZWZlcmVuY2UuY29tL3cvY3BwL2F0b21pYy9tZW1vcnlfb3JkZXI=">https://en.cppreference.com/w/cpp/atomic/memory_order<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<h2 id="The-last-thing"><a href="#The-last-thing" class="headerlink" title="The last thing"></a>The last thing</h2><p>Leetcode 上有跳表简化版的题目，看完了本文可以趁热打铁去实现一下：<span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS5jb20vcHJvYmxlbXMvZGVzaWduLXNraXBsaXN0Lw==">https://leetcode.com/problems/design-skiplist/<i class="fa fa-external-link-alt"></i></span></p>
<p>这是我的实现版本：<span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS5jb20vcHJvYmxlbXMvZGVzaWduLXNraXBsaXN0L2Rpc2N1c3MvNzQwODgxL0MlMkIlMkItY2xlYW4tYW5kLXNpbXBsZS1zb2x1dGlvbi1mcm9tLWxldmVsZGI=">https://leetcode.com/problems/design-skiplist/discuss/740881/C%2B%2B-clean-and-simple-solution-from-leveldb<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>leveldb</tag>
        <tag>skiplist</tag>
        <tag>跳表</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang 笔记（二）：Context 源码剖析</title>
    <url>/2020/07/12/go-context/</url>
    <content><![CDATA[<p><img src="https://i.loli.net/2020/07/25/Yjbq6ZSkEHQ3X1u.png" alt="go-context-tree-construction.png"></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Context 是 Go 中一个比较独特而常用的概念，用好了往往能事半功倍。但如果不知其然而滥用，则往往变成 “为赋新词强说愁”，轻则影响代码结构，重则埋下许多bug。</p>
<p>Golang  使用树形派生的方式构造 Context，通过在不同过程 <em>[1]</em> 中传递 deadline 和 cancel 信号，来管理处理某个任务所涉及到的一组 goroutine 的生命周期，防止 goroutine 泄露。并且可以通过附加在 Context 上的 Value 来传递&#x2F;共享一些跨越整个请求间的数据。</p>
<p>Context 最常用来追踪 RPC&#x2F;HTTP 等耗时的、跨进程的 IO 请求的生命周期，从而让外层调用者可以主动地或者自动地取消该请求，进而告诉子过程回收用到的所有 goroutine 和相关资源。</p>
<p>Context 本质上是一种在 API 间树形嵌套调用时传递信号的机制。本文将从接口、派生、源码分析、使用等几个方面来逐一解析 Context。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/07/12/go-context/">https://www.qtmuniao.com/2020/07/12/go-context/</a>, 转载请注明出处</em></p>
<h2 id="Context-接口"><a href="#Context-接口" class="headerlink" title="Context 接口"></a>Context 接口</h2><p>Context 接口如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Context 用以在多 API 间传递 deadline、cancelation 信号和请求的键值对。</span></span><br><span class="line"><span class="comment">// Context 中的方法能够安全的被多个 goroutine 并发调用。</span></span><br><span class="line"><span class="keyword">type</span> Context <span class="keyword">interface</span> &#123;</span><br><span class="line">    <span class="comment">// Done 返回一个只读 channel，该 channel 在 Context 被取消或者超时时关闭</span></span><br><span class="line">    Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Err 返回 Context 结束时的出错信息</span></span><br><span class="line">    Err() <span class="type">error</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果 Context 被设置了超时，Deadline 将会返回超时时限。</span></span><br><span class="line">    Deadline() (deadline time.Time, ok <span class="type">bool</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Value 返回关联到相关 Key 上的值，或者 nil.</span></span><br><span class="line">    Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面是简略注释，接口详细信息可以访问 Context 的 <span class="exturl" data-url="aHR0cHM6Ly9nb2xhbmcub3JnL3BrZy9jb250ZXh0Lw==">godoc<i class="fa fa-external-link-alt"></i></span>。</p>
<ul>
<li><p><code>Done()</code> 方法返回一个只读的 channel，当 Context 被主动取消或者超时自动取消时，该 Context 所有派生 Context 的 done channel 都被 close 。所有子过程通过该字段收到 close 信号后，应该立即中断执行、释放资源然后返回。</p>
</li>
<li><p><code>Err()</code> 在上述 channel 被 close 前会返回 nil，在被 close 后会返回该 Context 被关闭的信息，error 类型，只有两种，<em>被取消</em>或者<em>超时</em>：</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> Canceled = errors.New(<span class="string">&quot;context canceled&quot;</span>)</span><br><span class="line"><span class="keyword">var</span> DeadlineExceeded <span class="type">error</span> = deadlineExceededError&#123;&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>Deadline()</code> 如果本 Context 被设置了时限，则该函数返回 <code>ok=true</code> 和对应的到期时间点。否则，返回 <code>ok=false</code>和 nil。</p>
</li>
<li><p><code>Value()</code> 返回绑定在该 Context 链（我称为回溯链，下文会展开说明）上的给定的 Key 的值，如果没有，则返回 nil。注意，不要用于在函数中传参，其本意在于共享一些横跨整个 Context 生命周期范围的值。Key 可以是任何可比较的类型。为了防止 Key 冲突，最好将 Key 的类型定义为非导出类型，然后为其定义访问器。看一个通过 Context 共享用户信息的例子：</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> user</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;context&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// User 是要存于 Context 中的 Value 类型.</span></span><br><span class="line"><span class="keyword">type</span> User <span class="keyword">struct</span> &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// key 定义为了非导出类型，以避免和其他 package 中的 key 冲突</span></span><br><span class="line"><span class="keyword">type</span> key <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// userKey 是 Context 中用来关联 user.User 的 key，是非导出变量</span></span><br><span class="line"><span class="comment">// 客户端需要用 user.NewContext 和 user.FromContext 构建包含</span></span><br><span class="line"><span class="comment">// user 的 Context 和从 Context 中提取相应 user </span></span><br><span class="line"><span class="keyword">var</span> userKey key</span><br><span class="line"></span><br><span class="line"><span class="comment">// NewContext 返回一个带有用户值 u 的 Context.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewContext</span><span class="params">(ctx context.Context, u *User)</span></span> context.Context &#123;</span><br><span class="line">  <span class="keyword">return</span> context.WithValue(ctx, userKey, u)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// FromContext 从 Context 中提取 user，如果有的话.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FromContext</span><span class="params">(ctx context.Context)</span></span> (*User, <span class="type">bool</span>) &#123;</span><br><span class="line">  u, ok := ctx.Value(userKey).(*User)</span><br><span class="line">  <span class="keyword">return</span> u, ok</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Context-派生"><a href="#Context-派生" class="headerlink" title="Context 派生"></a>Context 派生</h2><p>Context 设计之妙在于可以从已有 Context 进行树形派生，以管理一组过程的生命周期。我们上面说了单个 Context 实例是不可变的，但可以通过 context 包提供的三种方法：<code>WithCancel</code> 、 <code>WithTimeout</code> 和 <code>WithValue</code> 来进行派生并附加一些属性（可取消、时限、键值），以构造一组树形组织的 Context。</p>
<p><img src="https://i.loli.net/2020/07/25/d5Slcasj1FAzItu.png" alt="go-context-tree.png"></p>
<p>当根 Context 结束时，所有由其派生出的 Context 也会被一并取消。也就是说，父 Context 的生命周期涵盖所有子 Context 的生命周期。</p>
<p><code>context.Background()</code> 通常用作根节点，它不会超时，不能被取消。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Background 返回一个空 Context。它不能被取消，没有时限，没有附加键值。Background 通常用在</span></span><br><span class="line"><span class="comment">// main函数、init 函数、test 入口，作为某个耗时过程的根 Context。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Background</span><span class="params">()</span></span> Context</span><br></pre></td></tr></table></figure>

<p><code>WithCancel</code> 和  <code>WithTimeout</code>  可以从父 Context 进行派生，返回受限于父 Context 生命周期的新 Context。</p>
<p>通过 <code>WithCancel</code> 从 <code>context.Background() </code>派生出的 Context 要注意在对应过程完结后及时 cancel，否则会造成 Context 泄露。</p>
<p>使用 <code>WithTimeout</code> 可以控制某个过程的处理时限。具体过程为，到点后， Context 发送信号到 Done Channel，子过程检测到 Context Done Channel <em>[2]</em> 中的信号，会立即退出。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// WithCancel 返回一份父 Context 的拷贝，和一个 cancel 函数。当父 Context 被关闭或者 </span></span><br><span class="line"><span class="comment">// 此 cancel 函数被调用时，该 Context 的 Done Channel 会立即被关闭.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCancel</span><span class="params">(parent Context)</span></span> (ctx Context, cancel CancelFunc)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用 CancelFunc 取消对应 Context.</span></span><br><span class="line"><span class="keyword">type</span> CancelFunc <span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// WithTimeout 返回一份父 Context 的拷贝，和一个 cancel 函数。当父 Context 被关闭、</span></span><br><span class="line"><span class="comment">// cancel 函数被调用或者设定时限到达时，该 Context 的 Done Channel 会立即关闭。在 cancel 函数</span></span><br><span class="line"><span class="comment">// 被调用时，如果其内部 timer 仍在运行，将会被停掉。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(parent Context, timeout time.Duration)</span></span> (Context, CancelFunc)</span><br></pre></td></tr></table></figure>

<p><code>WithValue</code> 可以给 Context 附加上整个处理过程中的键值。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// WithValue 返回一个父 Context 的副本，并且附加上给定的键值对.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithValue</span><span class="params">(parent Context, key <span class="keyword">interface</span>&#123;&#125;, val <span class="keyword">interface</span>&#123;&#125;)</span></span> Context</span><br></pre></td></tr></table></figure>

<h2 id="Context-源码解析"><a href="#Context-源码解析" class="headerlink" title="Context 源码解析"></a>Context 源码解析</h2><p>Go context 使用嵌入类，以类似继承的方式组织几个 Context 类：<code>emptyCtx</code>、<code>valueCtx</code>、 <code>cancelCtx</code>、<code>timerCtx</code>。</p>
<p><img src="https://i.loli.net/2020/07/25/9s6qG8RUkCQWLlc.png" alt="go-context-implementation.png"></p>
<p>形象的来说，通过嵌入的方式，Go 对树形组织的 Context 体系中的每个 Context 节点都构造了一个指向父亲实例”指针”。从另一个角度来说，这是一种经典代码组织模式——<span class="exturl" data-url="aHR0cHM6Ly9zb3VyY2VtYWtpbmcuY29tL2Rlc2lnbl9wYXR0ZXJucy9jb21wb3NpdGU=">组合模式<i class="fa fa-external-link-alt"></i></span>，每一层只增量 or 覆盖实现自己所关注的功能，然后通过路由调用来复用已有的实现。</p>
<h3 id="空实现-emptyCtx"><a href="#空实现-emptyCtx" class="headerlink" title="空实现 emptyCtx"></a>空实现 emptyCtx</h3><p><code>emptyCtx</code> 实现了一个空的 <code>Context</code>，所有接口函数都是空实现。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> emptyCtx <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span></span> Deadline() (deadline time.Time, ok <span class="type">bool</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span></span> Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125; &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span> <span class="comment">// 返回 nil，从语法上说是空实现，从语义上说是该 Context 永远不会被关闭。</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//... 其他的省略，类似都是满足语法要求的空函数体</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *emptyCtx)</span></span> String() <span class="type">string</span> &#123;</span><br><span class="line">  <span class="keyword">switch</span> e &#123;</span><br><span class="line">  <span class="keyword">case</span> background:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;context.Background&quot;</span></span><br><span class="line">  <span class="keyword">case</span> todo:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;context.TODO&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="string">&quot;unknown empty Context&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>context.Background()</code> 和 <code>context.TODO()</code> 返回的都是 <code>emptyCtx</code> 的实例。但其语义略有不同。前者做为 Context 树的根节点，后者通常在不知道用啥时用。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">  background = <span class="built_in">new</span>(emptyCtx)</span><br><span class="line">  todo       = <span class="built_in">new</span>(emptyCtx)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Background</span><span class="params">()</span></span> Context &#123;</span><br><span class="line">  <span class="keyword">return</span> background</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TODO</span><span class="params">()</span></span> Context &#123;</span><br><span class="line">  <span class="keyword">return</span> todo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="附加单键值-valueCtx"><a href="#附加单键值-valueCtx" class="headerlink" title="附加单键值 valueCtx"></a>附加单键值 valueCtx</h3><p><code>valueCtx</code> 嵌入了一个 <code>Context</code> 接口以进行 Context 派生，并且附加了一个 KV 对。从 <code>context.WithValue</code> 函数可以看出，每附加一个键值对，都得套上一层新的 <code>valueCtx</code>。在使用 <code>Value(key interface)</code> 接口访问某 Key 时，会沿着 Context 树回溯链不断向上遍历所有 Context 直到 <code>emptyCtx</code>：</p>
<ol>
<li>如果遇到 <code>valueCtx</code> 实例，则比较其 key 和给定 key 是否相等</li>
<li>如果遇到其他 Context 实例，就直接向上转发。但这里有个特例，为了获取给定 Context 所有祖先节点中最近的<code>cancelCtx</code>，go 用了一个特殊的 key：<code>cancelCtxKey</code>，遇到该 key 时，cancelCtx 会返回自身。这个在 <code>cancelCtx</code> 实现中会提到。</li>
</ol>
<p>对于其他的接口调用（<code>Done</code>, <code>Err</code>, <code>Deadline</code>），会路由到嵌入的 <code>Context</code> 上去。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> valueCtx <span class="keyword">struct</span> &#123;</span><br><span class="line">  Context <span class="comment">// 嵌入，指向父 Context</span></span><br><span class="line">  key, val <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *valueCtx)</span></span> Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line">  <span class="keyword">if</span> c.key == key &#123;</span><br><span class="line">    <span class="keyword">return</span> c.val</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> c.Context.Value(key)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithValue</span><span class="params">(parent Context, key, val <span class="keyword">interface</span>&#123;&#125;)</span></span> Context &#123;</span><br><span class="line">  <span class="keyword">if</span> key == <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">&quot;nil key&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> !reflectlite.TypeOf(key).Comparable() &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">&quot;key is not comparable&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> &amp;valueCtx&#123;parent, key, val&#125; <span class="comment">// 附加上 kv，并引用父 Context</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="可取消的-cancelCtx"><a href="#可取消的-cancelCtx" class="headerlink" title="可取消的 cancelCtx"></a>可取消的 cancelCtx</h3><p>context 包中核心实现在 <code>cancelCtx</code> 中，包括构造树形结构、进行级联取消。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> cancelCtx <span class="keyword">struct</span> &#123;</span><br><span class="line">  Context</span><br><span class="line"></span><br><span class="line">  mu       sync.Mutex            <span class="comment">// 保证下面三个字段的互斥访问</span></span><br><span class="line">  done     <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;         <span class="comment">// 惰式初始化，被第一个 cancel() 调用所关闭</span></span><br><span class="line">  children <span class="keyword">map</span>[canceler]<span class="keyword">struct</span>&#123;&#125; <span class="comment">// 被第一个 cancel() 调用置 nil</span></span><br><span class="line">  err      <span class="type">error</span>                 <span class="comment">// 被第一个 cancel() 调用置非 nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *cancelCtx)</span></span> Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line">  <span class="keyword">if</span> key == &amp;cancelCtxKey &#123; </span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> c.Context.Value(key)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *cancelCtx)</span></span> Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125; &#123;</span><br><span class="line">  c.mu.Lock()</span><br><span class="line">  <span class="keyword">if</span> c.done == <span class="literal">nil</span> &#123;</span><br><span class="line">    c.done = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">  &#125;</span><br><span class="line">  d := c.done</span><br><span class="line">  c.mu.Unlock()</span><br><span class="line">  <span class="keyword">return</span> d</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> <code>Value()</code> 函数的实现有点意思，遇到特殊 key：<code>cancelCtxKey</code> 时，会返回自身。这个其实是复用了 Value 函数的回溯逻辑，从而在 Context 树回溯链中遍历时，可以找到给定 Context 的第一个祖先 <code>cancelCtx</code> 实例。</p>
<p><code>children</code> 保存的是子树中所有路径向下走的第一个可以 cancel 的 Context (实现了 <code>canceler</code> 接口，比如 <code>cancelCtx</code> 或 <code>timerCtx</code> 节点)，可以参考后面的图来形象理解。</p>
<p>下面将逐一详细说明。</p>
<h4 id="回溯链"><a href="#回溯链" class="headerlink" title="回溯链"></a>回溯链</h4><p>回溯链是各个 context 包在实现时利用 go 语言嵌入（<em>embedding</em>）的特性来构造的，主要用于：</p>
<ol>
<li><code>Value()</code> 函数被调用时沿着回溯链向上查找匹配的键值对。</li>
<li>复用 <code>Value()</code> 的逻辑查找最近 <code>cancelCtx</code> 祖先，以构造 Context 树。</li>
</ol>
<p>在 <code>valueCtx</code>、<code>cancelCtx</code>、<code>timerCtx</code> 中只有 <code>cancelCtx</code> <strong>直接</strong>（<code>valueCtx</code> 和 <code>timerCtx</code> 都是通过嵌入实现，调用该方法会直接转发到 <code>cancelCtx</code> 或者 <code>emptyCtx</code> ）实现了非空  <code>Done()</code> 方法，因此 <code>done := parent.Done()</code> 会返回第一个祖先 <code>cancelCtx</code> 中的 done channel。但如果 Context 树中有第三方实现的 Context 接口的实例时，<code>parent.Done()</code> 就有可能返回其他 channel。</p>
<p>因此，如果 <code>p.done != done</code> ，说明在回溯链中遇到的第一个实现非空 <code>Done()</code> Context 是第三方 Context ，而非 <code>cancelCtx</code>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// parentCancelCtx 返回 parent 的第一个祖先 cancelCtx 节点</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">parentCancelCtx</span><span class="params">(parent Context)</span></span> (*cancelCtx, <span class="type">bool</span>) &#123;</span><br><span class="line">  done := parent.Done() <span class="comment">// 调用回溯链中第一个实现了 Done() 的实例(第三方Context类/cancelCtx)</span></span><br><span class="line">  <span class="keyword">if</span> done == closedchan || done == <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">  p, ok := parent.Value(&amp;cancelCtxKey).(*cancelCtx) <span class="comment">// 回溯链中第一个 cancelCtx 实例</span></span><br><span class="line">  <span class="keyword">if</span> !ok &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">  p.mu.Lock()</span><br><span class="line">  ok = p.done == done</span><br><span class="line">  p.mu.Unlock()</span><br><span class="line">  <span class="keyword">if</span> !ok &#123; <span class="comment">// 说明回溯链中第一个实现 Done() 的实例不是 cancelCtx 的实例</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> p, <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="树构建"><a href="#树构建" class="headerlink" title="树构建"></a>树构建</h4><p>Context 树的构建是在调用 <code>context.WithCancel()</code> 调用时通过 <code>propagateCancel</code> 进行的。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCancel</span><span class="params">(parent Context)</span></span> (ctx Context, cancel CancelFunc) &#123;</span><br><span class="line">  c := newCancelCtx(parent)</span><br><span class="line">  propagateCancel(parent, &amp;c)</span><br><span class="line">  <span class="keyword">return</span> &amp;c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">true</span>, Canceled) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Context 树，本质上可以细化为 <code>canceler</code> （<code>*cancelCtx</code> 和 <code>*timerCtx</code>）树，因为在级联取消时只需找到子树中所有的 <code>canceler</code> ，因此在实现时只需在树中保存所有 <code>canceler</code> 的关系即可（跳过 <code>valueCtx</code>），简单且高效。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// A canceler is a context type that can be canceled directly. The</span></span><br><span class="line"><span class="comment">// implementations are *cancelCtx and *timerCtx.</span></span><br><span class="line"><span class="keyword">type</span> canceler <span class="keyword">interface</span> &#123;</span><br><span class="line">  cancel(removeFromParent <span class="type">bool</span>, err <span class="type">error</span>)</span><br><span class="line">  Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>具体实现为，沿着回溯链找到第一个实现了 <code>Done()</code> 方法的实例，</p>
<ol>
<li>如果为 <code>canceler</code> 的实例，则其必有 children 字段，并且实现了 cancel 方法（canceler），将该 context 放进 children 数组即可。此后，父 cancelCtx 在 cancel 时会递归遍历所有 children，逐一 cancel。</li>
<li>如果为非 <code>canceler</code> 的第三方 Context 实例，则我们不知其内部实现，因此只能为每个新加的子 Context 启动一个守护 goroutine，当 父 Context 取消时，取消该 Context。</li>
</ol>
<p>需要注意的是，由于 Context 可能会被多个 goroutine 并行访问，因此在更改类字段时，需要再一次检查父节点是否已经被取消，若父 Context 被取消，则立即取消子 Context 并退出。 </p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">propagateCancel</span><span class="params">(parent Context, child canceler)</span></span> &#123;</span><br><span class="line">  done := parent.Done()</span><br><span class="line">  <span class="keyword">if</span> done == <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="comment">// 父节点不可取消</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">select</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> &lt;-done:</span><br><span class="line">    <span class="comment">// 父节点已经取消</span></span><br><span class="line">    child.cancel(<span class="literal">false</span>, parent.Err())</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> p, ok := parentCancelCtx(parent); ok &#123; <span class="comment">// 找到一个 cancelCtx 实例</span></span><br><span class="line">    p.mu.Lock()</span><br><span class="line">    <span class="keyword">if</span> p.err != <span class="literal">nil</span> &#123;</span><br><span class="line">      <span class="comment">// 父节点已经被取消</span></span><br><span class="line">      child.cancel(<span class="literal">false</span>, p.err)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> p.children == <span class="literal">nil</span> &#123;</span><br><span class="line">        p.children = <span class="built_in">make</span>(<span class="keyword">map</span>[canceler]<span class="keyword">struct</span>&#123;&#125;) <span class="comment">// 惰式创建</span></span><br><span class="line">      &#125;</span><br><span class="line">      p.children[child] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    p.mu.Unlock()</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;                                <span class="comment">// 找到一个非 cancelCtx 实例</span></span><br><span class="line">    atomic.AddInt32(&amp;goroutines, +<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">      <span class="keyword">select</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> &lt;-parent.Done():</span><br><span class="line">        child.cancel(<span class="literal">false</span>, parent.Err())</span><br><span class="line">      <span class="keyword">case</span> &lt;-child.Done(): </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面用一张图来解释下回溯链和树组织， <em>C0</em>  是 <code>emptyCtx</code>，通常由 <code>context.Background()</code> 得来，作为 Context 树的根节点。<em>C1</em>~<em>C4</em> 依次通过嵌入的方式从各自父节点派生而来。图中的虚线是由嵌入（<em>embedded</em>）而构成的回溯链，实线是由 <code>cancelCtx</code> children 数组而保存的父子关系。</p>
<p><code>parentCancelCtx(C2)</code> 和 <code>parentCancelCtx(C4)</code> 都为 <em>C1</em>，则 <em>C1</em> 的 children 数组中保存的为 <em>C2</em> 和 <em>C4</em>。构建了这两层关系后，就可以沿着回溯链向上查询 Value 值，包括找到第一个祖先 <code>cancelCtx</code>；也可以沿着 children 关系往下进行级联取消。</p>
<p><img src="https://i.loli.net/2020/07/25/Yjbq6ZSkEHQ3X1u.png" alt="go-context-tree-construction.png"></p>
<p>当然，图中所有 Context 都是针对 go 包中的系统 Context，没有画出有第三方 Context 的情况。而实际代码由于增加了对第三方 Context 的处理逻辑，稍微难懂一些。区分系统 Context 实现和用户自定义 Context 的关键点在于是否实现了 <code>canceler</code> 接口。</p>
<p>第三方 Context 实现了此接口就可以进行树形组织，并且在上游 <code>cancelCtx</code> 取消时，递归调用 children 的 cancel 进行级联取消。否则只能通过为每个第三方 Context 启动一个 goroutine 来监听上游取消事件，以对第三方 Context 进行取消了。</p>
<h4 id="级联取消"><a href="#级联取消" class="headerlink" title="级联取消"></a>级联取消</h4><p>下面是级联取消中的关键函数 <code>cancelCtx.cancel</code> 的实现。在本 <code>cancelCtx</code> 取消时，需要级联取消以该 <code>cancelCtx</code> 为根节点的 Context 树中的所有 Context，并将根 <code>cancelCtx</code> 从其从父节点中摘除，以让 GC 回收该 <code>cancelCtx</code> 子树所有节点的资源。</p>
<p> <code>cancelCtx.cancel</code> 是非导出函数，不能在 context 包外调用，因此持有 Context 的内层过程不能自己取消自己，须由返回的 <code>CancelFunc</code> （简单的包裹了<code>cancelCtx.cancel</code> ）来取消，其句柄一般为外层过程所持有。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *cancelCtx)</span></span> cancel(removeFromParent <span class="type">bool</span>, err <span class="type">error</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> err == <span class="literal">nil</span> &#123; <span class="comment">// 需要给定取消的理由，Canceled or DeadlineExceeded</span></span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">&quot;context: internal error: missing cancel error&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  c.mu.Lock()</span><br><span class="line">  <span class="keyword">if</span> c.err != <span class="literal">nil</span> &#123;</span><br><span class="line">    c.mu.Unlock()</span><br><span class="line">    <span class="keyword">return</span> <span class="comment">// 已经被其他 goroutine 取消</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 记下错误，并关闭 done</span></span><br><span class="line">  c.err = err</span><br><span class="line">  <span class="keyword">if</span> c.done == <span class="literal">nil</span> &#123;</span><br><span class="line">    c.done = closedchan</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">close</span>(c.done)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 级联取消</span></span><br><span class="line">  <span class="keyword">for</span> child := <span class="keyword">range</span> c.children &#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> 持有父 Context 的同时获取了子 Context 的锁</span></span><br><span class="line">    child.cancel(<span class="literal">false</span>, err)</span><br><span class="line">  &#125;</span><br><span class="line">  c.children = <span class="literal">nil</span></span><br><span class="line">  c.mu.Unlock()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 子树根需要摘除，子树中其他节点则不再需要</span></span><br><span class="line">  <span class="keyword">if</span> removeFromParent &#123;</span><br><span class="line">    removeChild(c.Context, c)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="timerCtx"><a href="#timerCtx" class="headerlink" title="timerCtx"></a>timerCtx</h3><p><code>timerCtx</code> 在嵌入 <code>cancelCtx</code> 的基础上增加了一个计时器 timer，根据用户设置的时限，到点取消。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> timerCtx <span class="keyword">struct</span> &#123;</span><br><span class="line">  cancelCtx</span><br><span class="line">  timer *time.Timer <span class="comment">// Under cancelCtx.mu</span></span><br><span class="line"></span><br><span class="line">  deadline time.Time</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *timerCtx)</span></span> Deadline() (deadline time.Time, ok <span class="type">bool</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> c.deadline, <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *timerCtx)</span></span> cancel(removeFromParent <span class="type">bool</span>, err <span class="type">error</span>) &#123;</span><br><span class="line">  <span class="comment">// 级联取消子树中所有 Context</span></span><br><span class="line">  c.cancelCtx.cancel(<span class="literal">false</span>, err)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> removeFromParent &#123;</span><br><span class="line">    <span class="comment">// 单独调用以摘除此节点，因为是摘除 c，而非 c.cancelCtx</span></span><br><span class="line">    removeChild(c.cancelCtx.Context, c)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 关闭计时器</span></span><br><span class="line">  c.mu.Lock()</span><br><span class="line">  <span class="keyword">if</span> c.timer != <span class="literal">nil</span> &#123;</span><br><span class="line">    c.timer.Stop()</span><br><span class="line">    c.timer = <span class="literal">nil</span></span><br><span class="line">  &#125;</span><br><span class="line">  c.mu.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>设置超时取消是在 <code>context.WithDeadline()</code> 中完成的。如果祖先节点时限早于本节点，只需返回一个 <code>cancelCtx</code> 即可，因为祖先节点到点后在级联取消时会将其取消。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithDeadline</span><span class="params">(parent Context, d time.Time)</span></span> (Context, CancelFunc) &#123;</span><br><span class="line">  <span class="keyword">if</span> cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123;</span><br><span class="line">    <span class="comment">// 祖先节点的时限更早</span></span><br><span class="line">    <span class="keyword">return</span> WithCancel(parent)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  c := &amp;timerCtx&#123;             </span><br><span class="line">    cancelCtx: newCancelCtx(parent), <span class="comment">// 使用一个新的 cancelCtx 实现部分 cancel 功能</span></span><br><span class="line">    deadline:  d,</span><br><span class="line">  &#125;</span><br><span class="line">  propagateCancel(parent, c) <span class="comment">// 构建 Context 取消树，注意传入的是 c 而非 c.cancelCtx</span></span><br><span class="line">  dur := time.Until(d)       <span class="comment">// 测试时限是否设的太近以至于已经结束了</span></span><br><span class="line">  <span class="keyword">if</span> dur &lt;= <span class="number">0</span> &#123;</span><br><span class="line">    c.cancel(<span class="literal">true</span>, DeadlineExceeded)</span><br><span class="line">    <span class="keyword">return</span> c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">false</span>, Canceled) &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 设置超时取消</span></span><br><span class="line">  c.mu.Lock()</span><br><span class="line">  <span class="keyword">defer</span> c.mu.Unlock()</span><br><span class="line">  <span class="keyword">if</span> c.err == <span class="literal">nil</span> &#123;</span><br><span class="line">    c.timer = time.AfterFunc(dur, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">      c.cancel(<span class="literal">true</span>, DeadlineExceeded)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">true</span>, Canceled) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Context-使用"><a href="#Context-使用" class="headerlink" title="Context 使用"></a>Context 使用</h2><p>使用了 Context 的子过程<strong>须保证</strong>在 Context 被关闭时及时退出并释放资源。也就是说，使用 Context 需要遵循上述原则才能保证级联取消时释放资源的效果。因此，Context 本质上是一种树形分发信号的机制，可以用 Context 树追踪过程调用树，当外层过程取消时，使用 Context 级联通知所有被调用过程。</p>
<p>以下是一个典型子过程的检查 Context 以确定是否需要退出的代码片段：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> ; ; time.Sleep(time.Second) &#123;</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;-context.Done():</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 一些耗时操作</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看出，Context 接口本身并没有 Cancel 方法，这和 <code>Done()</code> 返回的 channel 是只读的是一个道理：Context 关闭信号的发送方和接收方通常不在一个函数中。比如，当父 goroutine 启动了一些子 goroutine 来干活时，只能是父 goroutine 来关闭 done channel，子 goroutine 来检测 channel 的关闭信号。即不能在子 goroutine 中 取消父 goroutine 中传递过来的 Context。</p>
<h2 id="Context-注意"><a href="#Context-注意" class="headerlink" title="Context 注意"></a>Context 注意</h2><p>Context 有一些使用实践需要遵循：</p>
<ol>
<li>Context 通常作为函数中第一个参数</li>
<li>不要在 struct 中存储 Context，每个函数都要显式的传递 Context。不过实践中可以根据 struct 的生命周期来灵活组合。</li>
<li>不要使用 nil Context，尽管语法上允许。不知道使用什么值合适时，可以使用 <code>context.TODO()</code> 。</li>
<li>Context value 是为了在请求生命周期中共享数据，而非作为函数中传递额外参数的方法。因为这是一种隐式的语义，极易造成 bug；要想传额外参数，还是要在函数中显式声明。</li>
<li>Context 是 immutable 的，因此是线程安全的，可以在多个 goroutine 中传递并使用同一个 Context。</li>
</ol>
<h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>[1] 文中的过程，指的是计算密集型或者 IO 密集型的耗时函数，或者 goroutine。</p>
<p>[2] Context 的 Done Channel，指的是 <code>context.Done()</code> 返回的 channel。它是 Context 内的关键数据结构，作为沟通不同过程的的渠道。需要结束时，父过程向该 channel 发送信号，子过程读取该 channel 信号后做扫尾工作并且退出。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>go doc context：<span class="exturl" data-url="aHR0cHM6Ly9nb2xhbmcub3JnL3BrZy9jb250ZXh0Lw==">https://golang.org/pkg/context/<i class="fa fa-external-link-alt"></i></span></li>
<li>code review conmments: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvbGFuZy9nby93aWtpL0NvZGVSZXZpZXdDb21tZW50cyNjb250ZXh0cw==">https://github.com/golang/go/wiki/CodeReviewComments#contexts<i class="fa fa-external-link-alt"></i></span></li>
<li>go blog context：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmdvbGFuZy5vcmcvY29udGV4dA==">https://blog.golang.org/context<i class="fa fa-external-link-alt"></i></span></li>
<li>go context 源码：<span class="exturl" data-url="aHR0cHM6Ly9nb2xhbmcub3JnL3NyYy9jb250ZXh0L2NvbnRleHQuZ28/cz04NDE5Ojg0ODMjTDIyMg==">https://golang.org/src/context/context.go?s=8419:8483#L222<i class="fa fa-external-link-alt"></i></span></li>
<li>go 语言设计与实现： <span class="exturl" data-url="aHR0cHM6Ly9kcmF2ZW5lc3MubWUvZ29sYW5nL2RvY3MvcGFydDMtcnVudGltZS9jaDA2LWNvbmN1cnJlbmN5L2dvbGFuZy1jb250ZXh0Lw==">https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>context</tag>
      </tags>
  </entry>
  <entry>
    <title>漫谈 LevelDB 数据结构（二）：布隆过滤器（Bloom Filter）</title>
    <url>/2020/11/18/leveldb-data-structures-bloom-filter/</url>
    <content><![CDATA[<blockquote>
<p>早对 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS9sZXZlbGRi">LevelDB<i class="fa fa-external-link-alt"></i></span> 有所耳闻，这次心血来潮结合一些资料粗略过了遍代码，果然名不虚传。如果你对存储感兴趣、如果你想优雅使用C++、如果你想学习如何架构项目，都推荐来观摩一下。更何况作者是 Sanjay Ghemawat 和  Jeff Dean 呢。</p>
<p>看过一遍如果不输出点什么，以我的记性，定会很快抛诸脑后。便想写点东西说说 LevelDB 之妙，但又不想走寻常路：从架构概览说起，以模块分析做合。读代码的这些天，一直在盘算从哪下笔比较好。在将将读完之时，印象最深的反而是 LevelDB 的各种精妙的数据结构：贴合场景、从头构建、剪裁得当、代码精到。不妨， LevelDB 系列就从这些边边角角的小构件开始吧。</p>
<p>本系列主要想分享 LevelDB 中用到的三个工程中常用的经典数据结构，分别是用以快速读写 memtable 的 <a href="https://www.qtmuniao.com/2020/07/03/leveldb-data-structures-skip-list/"><strong>Skip List</strong></a>、用以快速筛选 sstable 的 <strong>Bloom Filter</strong> 和用以部分缓存 sstable 的 <strong>LRUCache</strong> 。这是第二篇，Bloom Filter。</p>
</blockquote>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>LevelDB 是一个单机的 KV 存储引擎，但没有使用传统的平衡查找树以平衡读写性能，而是使用了 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTG9nLXN0cnVjdHVyZWRfbWVyZ2UtdHJlZQ==">LSM-tree<i class="fa fa-external-link-alt"></i></span> 结构来组织数据，牺牲部分读性能来换取较高的写吞吐。下面来对照一张图来介绍 LSM-tree 在不同存储介质上的组织方式。</p>
<p><img src="https://i.loli.net/2020/11/22/pgCWKL8ni7sAF2G.png" alt="leveldb.png"></p>
<p>LevelDB 将数据分为两大部分，分别存放在内存和文件系统中。主要数据模块包括 WAL log，memtable，immutable memtable，sstable。按照数据流向依次如下：</p>
<ol>
<li>当 LevelDB 收到一个写入请求 <code>put(k, v)</code> ，会首先将其操作日志追加到日志文件（WAL）中，以备节点意外宕机恢复。</li>
<li>写完 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvV3JpdGUtYWhlYWRfbG9nZ2luZw==">WAL<i class="fa fa-external-link-alt"></i></span> 后，LevelDB 将该条 kv 插入内存中的<a href="https://www.qtmuniao.com/2020/07/03/leveldb-data-structures-skip-list/">查找结构</a>：memtable。</li>
<li>在 memtable 积累到一定程度后，会 rotate 为一个只读 memtable，即 immutable memtable；同时生成一个新的 memtable 以供写入。</li>
<li>当内存有压力后，会将 immutable memtable 顺序写入文件系统，生成一个 level0 层的 sstable（sorted strings table） 文件。该过程称为一次 minor compaction。</li>
<li>由于查询操作需要按层次遍历 memtable、immutable 和 sstable。当 sstable 文件生成的越来越多之后，查询性能必然越来越差，因此需要将不同的 sstable 进行归并，称为 major compaction。</li>
</ol>
<h3 id="LevelDB-层次组织"><a href="#LevelDB-层次组织" class="headerlink" title="LevelDB 层次组织"></a>LevelDB 层次组织</h3><p>所有在文件系统中的 sstable 文件，被 LevelDB 在逻辑上组织成多个层次（一般是 7层），并且满足以下性质：</p>
<ol>
<li>层次越大说明其数据写入越早，即先往上层进行“放”（minor compaction），上层“满”（达到容量限制）之后“溢”（major compaction）到下层进行合并。</li>
<li>每层文件总大小都有一定限制，并且成指数级增长。比如 level0 层文件总大小上限为10MB，level1 层为100MB，依次类推，最高层（level6层）没有限制。</li>
<li>由于 level0 每个 sstable 文件都是直接由 memtable 落盘而来， 因此多个 sstable 文件的 key 范围可能会有交叠。而其他层的多个 sstable 文件则通过一些规则保证没有交叠。</li>
</ol>
<p>对于 LevelDB 的一次读取操作，需要首先去 memtable、immutable memtable 查找，然后依次去文件系统中各层查找。可以看出，相比写入操作，读取操作实在有点效率低下。我们这种客户端进行一次读请求，进入系统后被变成多次读请求的现象为<strong>读放大</strong>。</p>
<p>为了减小读放大，LevelDB 采取了几方面措施：</p>
<ol>
<li>通过 major compaction 尽量减少 sstable 文件</li>
<li>使用快速筛选的办法，快速判断 key 是否在某个 sstable 文件中</li>
</ol>
<p>而快速判断某个 key 是否在某个 key 集合中，LevelDB 用的正是布隆过滤器。当然，布隆过滤器只能快速判断 key 一定不在某个 sstable 中，从而在层层查找时跳过某些 sstable 。之后会详述原因，此处按下不表。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/11/18/leveldb-data-structures-bloom-filter">https://www.qtmuniao.com/2020/11/18/leveldb-data-structures-bloom-filter</a>, 转载请注明出处</em></p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>Bloom Filter 是  <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3cvaW5kZXgucGhwP3RpdGxlPUJ1cnRvbl9Ib3dhcmRfQmxvb20mYWN0aW9uPWVkaXQmcmVkbGluaz0x">Burton Howard Bloom<i class="fa fa-external-link-alt"></i></span>于1970年 提出，相关论文为： [Space&#x2F;time trade-offs in hash coding with allowable errors](Space&#x2F;time trade-offs in hash coding with allowable errors)。仅让渡些许准确性，就换取了时空上的高效性，实在是很巧妙的设计。</p>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>Bloom Filter 底层使用一个位数组（bit array），初始，所表示集合为空时，所有位都为 0：</p>
<p><img src="https://i.loli.net/2020/11/22/NVvPjGsu2mkwHDM.png" alt="empty-bloom-filter.png"></p>
<p>当往集合中插入一个元素 x 时，利用 k 个<strong>独立</strong>的哈希函数分别对 x 进行散列，然后将 k 个散列值按数组长度取余后分别将数组中对应位置置为 1：</p>
<p><img src="https://i.loli.net/2020/11/22/yuSGRpPcHs9Qvki.png" alt="set-x-bloom-filter.png"></p>
<p>查找过程和插入过程类似，也是利用同样的 k 个哈希函数对待查找元素按顺序进行哈希，得到 k 个位置。如果位数组中 k 个位置上的位均为 1，则该元素<strong>有可能</strong>存在；否则，若任意一位置上值为 0，则该值<strong>一定</strong>不存在。对于下图来说，x1 有可能存在，x2 一定不存在。</p>
<p><img src="https://i.loli.net/2020/11/22/hnJRTqjL8tcUk7A.png" alt="get-x-bloom-filter.png"></p>
<p>当持续插入一些元素后，数组中会有大量位置被置 1，可以想象，肯定会有一些位置冲突，造成误判。使用 k 个独立哈希函数可以部分解决这个问题。但如果对于某个值 y，k 个 hash(y) 计算出来的位置，都恰好被其他时候插入的几个元素值设置为 1，则会误判 y 在集合中。</p>
<h3 id="时空优势"><a href="#时空优势" class="headerlink" title="时空优势"></a>时空优势</h3><p>相对于其他表示数据集的数据结构，如平衡二叉搜索树、Trie 树、哈希表，甚至更简单的数组或者链表，Bloom Filter 有着巨大的时空优势。上述提到的表示数据集的数据结构，大都需要对数据项本身存储，可能有的做了压缩，比如 Trie 树。但是 Bloom Filter 走了另一条路，并不存储数据项本身，而是存储数据项的几个哈希值，并且用高效紧凑的位数组来存，避免了指针的额外开销。</p>
<p>如此设计，使得 Bloom Filter 的大小与数据项本身大小（如字符串的长短）无关。如，具有 1% 的误差和最佳 k（哈希函数个数）的 Bloom Filter 来说，平均每个元素只需 9.6 bit。</p>
<p>这种优势的获得，可以理解为在哈希表基础上，忽略了冲突处理，从而省下了额外开销。</p>
<h3 id="参数取舍"><a href="#参数取舍" class="headerlink" title="参数取舍"></a>参数取舍</h3><p>从上面对 Bloom Filter 可以粗略的感受到，其误判率应该和以下参数有关：</p>
<ol>
<li>哈希函数的个数 k</li>
<li>底层位数组的长度 m</li>
<li>数据集大小 n</li>
</ol>
<p>这几个参数与误判率的关系的推导这里不详细展开，可以参考<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQmxvb21fZmlsdGVy">维基百科<i class="fa fa-external-link-alt"></i></span>，或者这篇 <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW9tZW5nL2FydGljbGUvZGV0YWlscy8xNDk1NTAw">CSDN 文章<i class="fa fa-external-link-alt"></i></span>。这里直接给出结论：</p>
<p>当 <code>k = ln2 * (m/n)</code> 时，Bloom Filter 获取最优的准确率。m&#x2F;n 即 bits per key（集合中每个 key 平均分到的 bit 数）。</p>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>铺垫了 Bloom Filter 背景和基本原理后，让我们来看看 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS9sZXZlbGRi">LevelDB 源码<i class="fa fa-external-link-alt"></i></span>是如何将其嵌入系统的。</p>
<h3 id="通用接口"><a href="#通用接口" class="headerlink" title="通用接口"></a>通用接口</h3><p>为了减小读放大，尤其是对磁盘访问的读放大，LevelDB 抽象出了一个 <code>FilterPolicy</code> 接口，用以在查找 key 时快速筛掉不符合条件的 SStable，这些 Filter 信息会和数据在 SSTable 文件中一起存储，并且在需要时加载到内存，这要求 Filter 占空间不能太大。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LEVELDB_EXPORT</span> FilterPolicy &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">FilterPolicy</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 过滤策略的名字，用来唯一标识该 Filter 持久化、载入内存时的编码方法。</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">const</span> <span class="type">char</span>* <span class="title">Name</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 给长度为 n 的 keys 集合（可能有重复）创建一个过滤策略，并将策略序列化为 string ，追加到 dst 最后。</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">CreateFilter</span><span class="params">(<span class="type">const</span> Slice* keys, <span class="type">int</span> n, std::string* dst)</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// “过滤” 函数。若调用 CreateFilter 时传入的集合为 keys，则如果 key 在 keys 中，则必须返回 true。</span></span><br><span class="line">  <span class="comment">// 若 key 不在 keys 中，可以返回 true，也可以返回 false，但最好大概率返回 false。</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">KeyMayMatch</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; filter)</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>抽象出该接口可以让用户根据自己需求实现一些其他的过滤策略。自然的，LevelDB 提供了实现了该接口的一个内置的过滤策略：<code>BloomFilterPolicy</code>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BloomFilterPolicy</span> : <span class="keyword">public</span> FilterPolicy &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">BloomFilterPolicy</span><span class="params">(<span class="type">int</span> bits_per_key)</span> : bits_per_key_(bits_per_key) &#123;</span></span><br><span class="line">    <span class="comment">// 根据上面提到的结论：k = ln2 * (m/n)，获取哈希函数的个数 k。</span></span><br><span class="line">    <span class="comment">// 这里对 k 进行了向下取整、限制最大值，增加了一点误判率，但是也降低了过滤成本。</span></span><br><span class="line">    k_ = <span class="built_in">static_cast</span>&lt;<span class="type">size_t</span>&gt;(bits_per_key * <span class="number">0.69</span>);  <span class="comment">// 0.69 =~ ln(2)</span></span><br><span class="line">    <span class="keyword">if</span> (k_ &lt; <span class="number">1</span>) k_ = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (k_ &gt; <span class="number">30</span>) k_ = <span class="number">30</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">const</span> <span class="type">char</span>* <span class="title">Name</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;leveldb.BuiltinBloomFilter2&quot;</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">CreateFilter</span><span class="params">(<span class="type">const</span> Slice* keys, <span class="type">int</span> n, std::string* dst)</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 计算 bloom filter 的 bit 数组长度 n，会除以 8 向上取整，因为 bit 数组最后会用 char 数组表示</span></span><br><span class="line">    <span class="type">size_t</span> bits = n * bits_per_key_;</span><br><span class="line">    <span class="keyword">if</span> (bits &lt; <span class="number">64</span>) bits = <span class="number">64</span>; <span class="comment">// 如果数组太短，会有很高的误判率，因此这里增加了一个最小长度限定。</span></span><br><span class="line">    <span class="type">size_t</span> bytes = (bits + <span class="number">7</span>) / <span class="number">8</span>;</span><br><span class="line">    bits = bytes * <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> init_size = dst-&gt;<span class="built_in">size</span>();</span><br><span class="line">    dst-&gt;<span class="built_in">resize</span>(init_size + bytes, <span class="number">0</span>);</span><br><span class="line">    dst-&gt;<span class="built_in">push_back</span>(<span class="built_in">static_cast</span>&lt;<span class="type">char</span>&gt;(k_));  <span class="comment">// 记下哈希函数的个数</span></span><br><span class="line">    <span class="type">char</span>* array = &amp;(*dst)[init_size];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">      <span class="comment">// 使用 double-hashing 方法，仅使用一个 hash 函数来生成 k 个 hash 值，近似等价于使用 k 个哈希函数的效果</span></span><br><span class="line">      <span class="comment">// 详细分析可以参考：https://www.eecs.harvard.edu/~michaelm/postscripts/rsa2008.pdf</span></span><br><span class="line">      <span class="type">uint32_t</span> h = <span class="built_in">BloomHash</span>(keys[i]);</span><br><span class="line">      <span class="type">const</span> <span class="type">uint32_t</span> delta = (h &gt;&gt; <span class="number">17</span>) | (h &lt;&lt; <span class="number">15</span>);  <span class="comment">// 循环右移 17 bits 作为步长</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; k_; j++) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">uint32_t</span> bitpos = h % bits;</span><br><span class="line">        array[bitpos / <span class="number">8</span>] |= (<span class="number">1</span> &lt;&lt; (bitpos % <span class="number">8</span>));</span><br><span class="line">        h += delta;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">KeyMayMatch</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; bloom_filter)</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> len = bloom_filter.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">if</span> (len &lt; <span class="number">2</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">char</span>* array = bloom_filter.<span class="built_in">data</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> bits = (len - <span class="number">1</span>) * <span class="number">8</span>; <span class="comment">// -1 是去掉 k 所占空间</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取出创建 Filter 时保存的哈希函数个数 k</span></span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> k = array[len - <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">if</span> (k &gt; <span class="number">30</span>) &#123;</span><br><span class="line">      <span class="comment">// 超过我们设定 k 个数，直接返回 true，不滤掉该 SSTable.</span></span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">uint32_t</span> h = <span class="built_in">BloomHash</span>(key);</span><br><span class="line">    <span class="type">const</span> <span class="type">uint32_t</span> delta = (h &gt;&gt; <span class="number">17</span>) | (h &lt;&lt; <span class="number">15</span>);  <span class="comment">// 循环右移 17 bits 作为步长</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> j = <span class="number">0</span>; j &lt; k; j++) &#123;</span><br><span class="line">      <span class="type">const</span> <span class="type">uint32_t</span> bitpos = h % bits;</span><br><span class="line">      <span class="keyword">if</span> ((array[bitpos / <span class="number">8</span>] &amp; (<span class="number">1</span> &lt;&lt; (bitpos % <span class="number">8</span>))) == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">      h += delta;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">size_t</span> bits_per_key_;</span><br><span class="line">  <span class="type">size_t</span> k_;</span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>根据上述源代码，LevelDB 在实现时，有以下几个点需要注意：</p>
<ol>
<li>之前提到的 bit 数组在 C++ 语言中，LevelDB 使用 char 数组来表示。因此计算 bit 数组长度时需要对齐到 8 的倍数，计算下标时需要进行适当转换。</li>
<li>LevelDB 实现时并未真正使用 k 个哈希函数，而是用了 <span class="exturl" data-url="aHR0cHM6Ly93d3cuZWVjcy5oYXJ2YXJkLmVkdS9+bWljaGFlbG0vcG9zdHNjcmlwdHMvcnNhMjAwOC5wZGY=">double-hashing<i class="fa fa-external-link-alt"></i></span> 方法进行了一个优化，号称可以达到相似的正确率。</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Bloom Filter 通常用于快速判断某个元素是否在集合中。其本质上是通过容忍一定的错误率，来换取时空的高效性。从实现角度来理解，是在哈希表的基础上省下了冲突处理部分，并通过 k 个独立哈希函数来减少误判，LevelDB 在实现时使用了某种优化：利用一个哈希函数来达到近似 k 个哈希函数的效果。</p>
<p>下一篇中，将继续剖析 LevelDB 中用到的另一个经典的数据结构：LRU 缓存（LRU cache）。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>LevelDB handbook：<span class="exturl" data-url="aHR0cHM6Ly9sZXZlbGRiLWhhbmRib29rLnJlYWR0aGVkb2NzLmlvL3poL2xhdGVzdC9ibG9vbWZpbHRlci5odG1s">https://leveldb-handbook.readthedocs.io/zh/latest/bloomfilter.html<i class="fa fa-external-link-alt"></i></span></li>
<li>Wikipedia：<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQmxvb21fZmlsdGVy">https://en.wikipedia.org/wiki/Bloom_filter<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>leveldb</tag>
        <tag>bloom filter</tag>
        <tag>布隆过滤器</tag>
      </tags>
  </entry>
  <entry>
    <title>Boltdb 源码导读（二）：Boltdb 索引设计</title>
    <url>/2020/12/14/bolt-index-design/</url>
    <content><![CDATA[<blockquote>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JvbHRkYi9ib2x0">boltdb<i class="fa fa-external-link-alt"></i></span> 是市面上为数不多的纯 go 语言开发的、单机 KV 库。boltdb 基于  <span class="exturl" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9oeWNfc3ltYXM=">Howard Chu’s<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cDovL3N5bWFzLmNvbS9tZGIv">LMDB 项目<i class="fa fa-external-link-alt"></i></span> ，实现的比较清爽，去掉单元测试和适配代码，核心代码大概四千多行。简单的 API、简约的实现，也是作者的意图所在。由于作者精力所限，原 boltdb 已经封版，不再更新。若想改进，提交新的 pr，建议去 etcd 维护的 fork 版本 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2V0Y2QtaW8vYmJvbHQ=">bbolt<i class="fa fa-external-link-alt"></i></span>。</p>
<p>为了方便，本系列导读文章仍以不再变动的原 repo 为基础。该项目麻雀虽小，五脏俱全，仅仅四千多行代码，就实现了一个基于 B+ 树索引、支持一写多读事务的单机 KV 引擎。代码本身简约朴实、注释得当，如果你是 go 语言爱好者、如果对 KV 库感兴趣，那 boltdb 绝对是不可错过的一个 repo。</p>
<p>本系列计划分成三篇文章，依次围绕<strong>数据组织</strong>、<strong>索引设计</strong>、<strong>事务实现</strong>等三个主要方面对 boltdb 源码进行剖析。由于三个方面不是完全正交解耦的，因此叙述时会不可避免的产生交织，读不懂时，暂时略过即可，待有全貌，再回来梳理。本文是第一篇， boltdb 数据组织。</p>
</blockquote>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>数据库中常用的索引设计有两种，一个是 B+ 树，一个是 LSM-tree。B+ 树比较经典，比如说传统单机数据库 mysql 就是 B+ 树索引，它对快速读取和范围查询（range query）比较友好。 LSM-tree 是近年来比较流行的索引结构，Bigtable、LevelDB、RocksDB 都有它的影子；<a href="https://www.qtmuniao.com/2020/11/18/leveldb-data-structures-bloom-filter/">前面文章</a>也有提到，LSM-tree 使用 WAL 和多级数据组织以牺牲部分读性能，换来强悍的随机写性能。因此，这也是一个经典的取舍问题。</p>
<p>BoltDB 在逻辑上以桶来组织数据，一个桶可以看做一个命名空间，是一组 KV 对的集合，和对象存储的桶概念类似。每个桶对应一棵 B+ 树，命名空间是可以嵌套的，因此 BoltDB 的 Bucket 间也是允许嵌套的。在实现上来说，子 bucket 的 root node 的 page id 保存在父 bucket 叶子节点上实现嵌套。</p>
<p>每个 db 文件，是一组树形组织的 B+ 树。我们知道对于 B+ 树来说，分支节点用于查找，叶子节点存数据。</p>
<ol>
<li>顶层 B+ 树，比较特殊，称为 root bucket，其所有叶子节点保存的都是子 bucket B+ 树根的 page id 。</li>
<li>其他 B+ 树，不妨称之为 data bucket，其叶子节点可能是正常用户数据，也可能是子 bucket B+ 树根的 page id。</li>
</ol>
<p><img src="https://i.loli.net/2021/01/02/QBwKIpNOHkRqzrE.png" alt="boltdb-buckets-organised.png"></p>
<p>相比普通 B+ 树，boltdb 的 B+ 树有几点特殊之处：</p>
<ol start="2">
<li>节点的分支个数不是一个固定范围，而是依据其所存元素大小之和来限制的，这个上限即为页大小。</li>
<li>其分支节点（branch node）所存分支的 key，是其所指向分支的最小 key。</li>
<li>所有叶子节点并没有通过链表首尾相接起来。</li>
<li>没有保证所有的叶子节点都在同一层。</li>
</ol>
<p>在代码组织上，boltdb 索引相关的源文件如下：</p>
<ol>
<li><strong>bucket.go</strong>：对 bucket 操作的高层封装。包括kv 的增删改查、子bucket 的增删改查以及 B+ 树拆分和合并。</li>
<li><strong>node.go</strong>：对 node 所存元素和 node 间关系的相关操作。节点内所存元素的增删、加载和落盘，访问孩子兄弟元素、拆分与合并的详细逻辑。</li>
<li><strong>cursor.go</strong>：实现了类似迭代器的功能，可以在 B+ 树上的叶子节点上进行随意游走。</li>
</ol>
<p>本文主要分三部分，由局部到整体来一步步揭示 BoltDB 是如何进行索引设计的。首先会拆解树的基本单元，其次剖析 bucket 的遍历实现，最后分析树的生长和平衡过程。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/12/14/bolt-index-design">https://www.qtmuniao.com/2020/12/14/bolt-index-design</a>, 转载请注明出处</em></p>
<h2 id="基本单元——节点（Node）"><a href="#基本单元——节点（Node）" class="headerlink" title="基本单元——节点（Node）"></a>基本单元——节点（Node）</h2><p>B+ 树的基本构成单元是节点（node），对应在<a href="https://www.qtmuniao.com/2020/11/29/bolt-data-organised/">上一篇</a>中提到过文件系统中存储的页（page），节点包括两种类型，分支节点（branch node）和叶子节点（leaf node）。但在实现时，他们复用了同一个结构体，并通过一个标志位 <code>isLeaf</code> 来区分：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// node 表示内存中一个反序列化后的 page</span></span><br><span class="line"><span class="keyword">type</span> node <span class="keyword">struct</span> &#123;</span><br><span class="line">  bucket     *Bucket   <span class="comment">// 其所在 bucket 的指针</span></span><br><span class="line">  isLeaf     <span class="type">bool</span>      <span class="comment">// 是否为叶子节点</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 调整、维持 B+ 树时使用</span></span><br><span class="line">  unbalanced <span class="type">bool</span>      <span class="comment">// 是否需要进行合并</span></span><br><span class="line">  spilled    <span class="type">bool</span>      <span class="comment">// 是否需要进行拆分和落盘</span></span><br><span class="line">  </span><br><span class="line">  key        []<span class="type">byte</span>    <span class="comment">// 所含第一个元素的 key</span></span><br><span class="line">  pgid       pgid      <span class="comment">// 对应的 page 的 id</span></span><br><span class="line">  </span><br><span class="line">  parent     *node     <span class="comment">// 父节点指针</span></span><br><span class="line">  children   nodes     <span class="comment">// 孩子节点指针（只包含加载到内存中的部分孩子）</span></span><br><span class="line">  </span><br><span class="line">  inodes     inodes    <span class="comment">// 所存元素的元信息；对于分支节点是 key+pgid 数组，对于叶子节点是 kv 数组</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="node-x2F-page-转换"><a href="#node-x2F-page-转换" class="headerlink" title="node&#x2F;page 转换"></a>node&#x2F;page 转换</h3><p>page 和 node 的对应关系为：文件系统中一组连续的物理 page，加载到内存成为一个逻辑 page ，进而转化为一个 node。下图为一个在文件系统上占用两个 pagesize 空间的一段连续数据 ，首先 mmap 到内存空间，转换为 <code>page</code> 类型，然后通过 <code>node.read</code> 转换为 <code>node</code> 的过程。</p>
<p><img src="https://i.loli.net/2021/01/02/N7OqmibTklP5DLg.png" alt="boltdb-node-load-and-dump.png"></p>
<p>其中 <code>node.read</code> 将 page 转换为 node 的代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// read 函数通过 mmap 读取 page，并转换为 node</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span></span> read(p *page) &#123;</span><br><span class="line">  <span class="comment">// 初始化元信息</span></span><br><span class="line">  n.pgid = p.id</span><br><span class="line">  n.isLeaf = ((p.flags &amp; leafPageFlag) != <span class="number">0</span>)</span><br><span class="line">  n.inodes = <span class="built_in">make</span>(inodes, <span class="type">int</span>(p.count))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 加载所包含元素 inodes</span></span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="type">int</span>(p.count); i++ &#123;</span><br><span class="line">    inode := &amp;n.inodes[i]</span><br><span class="line">    <span class="keyword">if</span> n.isLeaf &#123;</span><br><span class="line">      elem := p.leafPageElement(<span class="type">uint16</span>(i))</span><br><span class="line">      inode.flags = elem.flags</span><br><span class="line">      inode.key = elem.key()</span><br><span class="line">      inode.value = elem.value()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      elem := p.branchPageElement(<span class="type">uint16</span>(i))</span><br><span class="line">      inode.pgid = elem.pgid</span><br><span class="line">      inode.key = elem.key()</span><br><span class="line">    &#125;</span><br><span class="line">    _assert(<span class="built_in">len</span>(inode.key) &gt; <span class="number">0</span>, <span class="string">&quot;read: zero-length inode key&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 用第一个元素的 key 作为该 node 的 key，以便父节点以此作为索引进行查找和路由</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(n.inodes) &gt; <span class="number">0</span> &#123;</span><br><span class="line">    n.key = n.inodes[<span class="number">0</span>].key</span><br><span class="line">    _assert(<span class="built_in">len</span>(n.key) &gt; <span class="number">0</span>, <span class="string">&quot;read: zero-length node key&quot;</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    n.key = <span class="literal">nil</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="node-元素-inode"><a href="#node-元素-inode" class="headerlink" title="node 元素 inode"></a>node 元素 inode</h3><p>  <code>inode</code> 表示 node 所含的内部元素，分支节点和叶子节点也复用同一个结构体。对于分支节点，单个元素为 key+引用；对于叶子节点，单个元素为用户 kv 数据。</p>
<p>注意到这里对其他节点的引用类型为 <code>pgid</code> ，而非 <code>node*</code>。这是因为 <code>inode</code> 中指向的元素并不一定加载到了内存。 boltdb 在访问 B+ 树时，会按需将访问到的 page 转化为 node，并将其指针存在父节点的 <code>children</code> 字段中， 具体的加载顺序和逻辑在后面小结会详述。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> inode <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="comment">// 共有变量</span></span><br><span class="line">  flags <span class="type">uint32</span></span><br><span class="line">  key   []<span class="type">byte</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 分支节点使用</span></span><br><span class="line">  pgid  pgid   <span class="comment">// 指向的分支/叶子节点的 page id</span></span><br><span class="line">  <span class="comment">// 叶子节点使用</span></span><br><span class="line">  value []<span class="type">byte</span> <span class="comment">// 叶子节点所存的数据</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>inode</code> 会在 B+ 树中进行路由——二分查找时使用。</p>
<h3 id="新增元素"><a href="#新增元素" class="headerlink" title="新增元素"></a>新增元素</h3><p>所有的数据新增都发生在叶子节点，如果新增数据后 B+ 树不平衡，之后会通过 <code>node.spill</code> 来进行拆分调整。主要代码如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// put inserts a key/value.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *node)</span></span> put(oldKey, newKey, value []<span class="type">byte</span>, pgid pgid, flags <span class="type">uint32</span>) &#123;</span><br><span class="line">  <span class="comment">// 找到插入点</span></span><br><span class="line">  index := sort.Search(<span class="built_in">len</span>(n.inodes), <span class="function"><span class="keyword">func</span><span class="params">(i <span class="type">int</span>)</span></span> <span class="type">bool</span> &#123; <span class="keyword">return</span> bytes.Compare(n.inodes[i].key, oldKey) != <span class="number">-1</span> &#125;)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 如果 key 是新增而非替换，则需为待插入节点腾空儿</span></span><br><span class="line">  exact := (<span class="built_in">len</span>(n.inodes) &gt; <span class="number">0</span> &amp;&amp; index &lt; <span class="built_in">len</span>(n.inodes) &amp;&amp; bytes.Equal(n.inodes[index].key, oldKey))</span><br><span class="line">  <span class="keyword">if</span> !exact &#123;</span><br><span class="line">    n.inodes = <span class="built_in">append</span>(n.inodes, inode&#123;&#125;)</span><br><span class="line">    <span class="built_in">copy</span>(n.inodes[index+<span class="number">1</span>:], n.inodes[index:])</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 给要替换/插入的元素赋值</span></span><br><span class="line">  inode := &amp;n.inodes[index]</span><br><span class="line">  inode.key = newKey</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该函数的主干逻辑比较简单，就是二分查找到待插入位置，如果是覆盖写则直接覆盖；否则就要新增一个元素，并整体右移，腾出插入位置。 但是该函数签名很有意思，同时有 <code>oldKey</code> 和 <code>newKey</code> ，开始时感觉很奇怪。其调用代码有两处：</p>
<ol>
<li>在叶子节点插入用户数据时，<code>oldKey</code> 等于 <code>newKey</code>，此时这两个参数是有冗余的。</li>
<li>在 <code>spill</code> 阶段调整 B+ 树时，<code>oldKey</code> 可能不等于 <code>newKey</code>，此时是有用的，但从代码上来看，用处仍然很隐晦。</li>
</ol>
<p>在和朋友讨论后，大致得出如下结论：为了避免在叶子节点最左侧插入一个很小的值时，引起祖先节点的 <code>node.key</code> 的链式更新，而将更新延迟到了最后 B+ 树调整阶段（<code>spill</code> 函数）进行统一处理 。此时，需要利用 <code>node.put</code> 函数将最左边的 <code>node.key</code> 更新为 <code>node.inodes[0].key</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 该代码片段在 node.spill 函数中</span></span><br><span class="line"><span class="keyword">if</span> node.parent != <span class="literal">nil</span> &#123; <span class="comment">// 如果不是根节点</span></span><br><span class="line">  <span class="keyword">var</span> key = node.key <span class="comment">// split 后，最左边 node</span></span><br><span class="line">  <span class="keyword">if</span> key == <span class="literal">nil</span> &#123;    <span class="comment">// split 后，非最左边 node</span></span><br><span class="line">    key = node.inodes[<span class="number">0</span>].key</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  node.parent.put(key, node.inodes[<span class="number">0</span>].key, <span class="literal">nil</span>, node.pgid, <span class="number">0</span>)</span><br><span class="line">  node.key = node.inodes[<span class="number">0</span>].key</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/01/02/woJQh7ZSOr3yGWq.png" alt="bolt-recursive-change.png"></p>
<h2 id="节点遍历"><a href="#节点遍历" class="headerlink" title="节点遍历"></a>节点遍历</h2><p>由于 Golang 不支持 Python 中类似 <code>yield</code> 机制，boltdb 使用栈保存遍历上下文实现了一个树节点<strong>顺序遍历</strong>的迭代器：<code>cursor</code>。在逻辑上可以理解为对某 B+ 树<strong>叶子节点所存元素遍历</strong>的迭代器。之前提到，boltdb 的 B+ 树没有使用链表将所有叶子节点串起来，因此需要一些额外逻辑来进行遍历中各种细节的处理。</p>
<p>这么实现增加了遍历的复杂度，但是减少了维持 B+ 树平衡性质的难度，也是一种取舍。当然，最重要的是为了通过 COW 实现事务时，避免链式更新所有前驱节点。</p>
<p><img src="https://i.loli.net/2021/01/02/m4WE7fgn8OazSND.png" alt="cursor-implementation.png"></p>
<p><code>cursor</code> 和某个 bucket 绑定，实现了以下功能，需要注意，当遍历到的元素为嵌套 bucket 时，<code>value = nil</code>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Cursor</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Bucket() *Bucket <span class="comment">// 返回绑定的 bucket</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Delete() <span class="type">error</span> <span class="comment">// 删除 cursor 指向的 key</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> First() (key []<span class="type">byte</span>, value []<span class="type">byte</span>) <span class="comment">// 定位到并返回该 bucket 第一个 KV </span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Last() (key []<span class="type">byte</span>, value []<span class="type">byte</span>)  <span class="comment">// 定位到并返回该 bucket 最后一个 KV </span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Next() (key []<span class="type">byte</span>, value []<span class="type">byte</span>)  <span class="comment">// 定位到并返回该 bucket 下一个 KV</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Prev() (key []<span class="type">byte</span>, value []<span class="type">byte</span>)  <span class="comment">// 定位到并返回该 bucket 前一个 KV</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Seek(seek []<span class="type">byte</span>) (key []<span class="type">byte</span>, value []<span class="type">byte</span>) <span class="comment">// 定位到并返回该 bucket 内指定的 KV</span></span><br></pre></td></tr></table></figure>

<p>由于 boltdb 中 B+ 树左右叶子节点并没有通过链表串起来，因此遍历时需要记下遍历<strong>路径</strong>以进行回溯。其结构体如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Cursor <span class="keyword">struct</span> &#123;</span><br><span class="line">  bucket *Bucket    <span class="comment">// 使用该句柄来进行 node 的加载</span></span><br><span class="line">  stack  []elemRef  <span class="comment">// 保留路径，方便回溯</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>elemRef</code> 结构体如下，page 和 node 是一一对应的，如果 page 加载到了内存中（通过 page 转换而来），则优先使用 node，否则使用 page；index 表示路径经过该节点时在 <code>inodes</code> 中的位置。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> elemRef <span class="keyword">struct</span> &#123;</span><br><span class="line">  page  *page</span><br><span class="line">  node  *node</span><br><span class="line">  index <span class="type">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="辅助函数"><a href="#辅助函数" class="headerlink" title="辅助函数"></a>辅助函数</h3><p>这几个 API 在实现的时候是有一些通用逻辑可以进行复用的，因此可以作为构件拆解出来。其中<strong>移动 cursor</strong> 在实现上，就是调整 <code>cursor.stack</code> 数组所表示的路径。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 尾递归，查询 key 所在的 node，并且在 cursor 中记下路径</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> search(key []<span class="type">byte</span>, pgid pgid)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 借助 search，查询 key 对应的 value</span></span><br><span class="line"><span class="comment">// 如果 key 不存在，则返回待插入位置的 kv 对：</span></span><br><span class="line"><span class="comment">//   1. ref.index &lt; ref.node.count() 时，则返回第一个比给定 key 大的 kv</span></span><br><span class="line"><span class="comment">//   2. ref.index == ref.node.count() 时，则返回 nil</span></span><br><span class="line"><span class="comment">// 上层 Seek 需要处理第二种情况。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> seek(seek []<span class="type">byte</span>) (key []<span class="type">byte</span>, value []<span class="type">byte</span>, flags <span class="type">uint32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 移动 cursor 到以栈顶元素为根的子树中最左边的叶子节点</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> first()</span><br><span class="line"><span class="comment">// 移动 cursor 到以栈顶元素为根的子树中最右边的叶子节点</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> last()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 移动 cursor 到下一个叶子元素</span></span><br><span class="line"><span class="comment">//   1. 如果当前叶子节点后面还有元素，则直接返回</span></span><br><span class="line"><span class="comment">//   2. 否则需要借助保存的路径找到下一个非空叶子节点</span></span><br><span class="line"><span class="comment">//   3. 如果当前已经指向最后一个叶子节点的最后一个元素，则返回 nil</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> next() (key []<span class="type">byte</span>, value []<span class="type">byte</span>, flags <span class="type">uint32</span>)</span><br></pre></td></tr></table></figure>

<h3 id="组合遍历"><a href="#组合遍历" class="headerlink" title="组合遍历"></a>组合遍历</h3><p>有了以上几个基本构件，我们来梳一下主要 API 函数的实现：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1. 将根节点放入 stack 中</span></span><br><span class="line"><span class="comment">// 2. 调用 c.first() 定位到根的第一个叶子节点</span></span><br><span class="line"><span class="comment">// 3. 如果该节点为空，则调用 c.next() 找到下一个非空叶子节点</span></span><br><span class="line"><span class="comment">// 4. 返回其该叶子节点第一个元素</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> First() (key []<span class="type">byte</span>, value []<span class="type">byte</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 将根节点放入 stack 中</span></span><br><span class="line"><span class="comment">// 2. 调用 c.last() 定位到根的最后一个叶子节点</span></span><br><span class="line"><span class="comment">// 3. 返回其最后一个元素，不存在则返回空</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Last() (key []<span class="type">byte</span>, value []<span class="type">byte</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 直接调用 c.next 即可</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Next() (key []<span class="type">byte</span>, value []<span class="type">byte</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 遍历 stack，回溯到第一个有前驱元素的分支节点</span></span><br><span class="line"><span class="comment">// 2. 将节点的 ref.index--</span></span><br><span class="line"><span class="comment">// 3. 调用 c.last()，定位到该子树的最后一个叶子节点</span></span><br><span class="line"><span class="comment">// 4. 返回其最后一个元素</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Prev() (key []<span class="type">byte</span>, value []<span class="type">byte</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 调用 c.seek()，找到第一个 &gt;= key 的节点中元素。</span></span><br><span class="line"><span class="comment">// 2. 如果 key 正好落在两个叶子节点中间，调用 c.next() 找到下一个非空节点</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Cursor)</span></span> Seek(seek []<span class="type">byte</span>) (key []<span class="type">byte</span>, value []<span class="type">byte</span>) <span class="comment">// 定位到并返回该 bucket 内指定的 KV</span></span><br></pre></td></tr></table></figure>

<p>这些 API 的实现叙述起来稍显繁琐，但只要抓住其主要思想，并且把握一些边界和细节，便能很容易看懂。<strong>主要思想</strong>比较简单： cursor 最终目的是在所有叶子节点的元素进行遍历，但是叶子节点并没有通过链表串起来，因此需要借助一个 stack 数组记下遍历上下文——路径，来实现对前驱后继的快速（<em>因为前驱后继与当前叶子节点大概率共享前缀路径</em>）访问。</p>
<p>另外需要注意的一些<strong>边界和细节</strong>如下：</p>
<ol>
<li>每次移动，需要先找节点，再找节点中元素。</li>
<li>如果节点已经转换为 node，则优先访问 node；否则，访问 mmap 出来的 page。</li>
<li>分支节点所记元素的 key 为其指向的节点的 key，也即其节点所包含元素的最小 key。</li>
<li>使用 Golang 的 <code>sort.Search</code> 获取第一个小于给定 key 的元素下标需要做一些额外处理。</li>
<li>几个边界判断，node 中是否有元素、index 是否大于元素值、该元素是否为子 bucket。</li>
<li>如果 key 不存在时，seek&#x2F;search 定位到的是 key 应当插入的点。</li>
</ol>
<h2 id="树的生长"><a href="#树的生长" class="headerlink" title="树的生长"></a>树的生长</h2><p>我们分几个时间节点来展开说明下 boltdb 中 B+ 树的生命周期：</p>
<ol>
<li>数据库初始化时</li>
<li>事务开启后</li>
<li>事务提交时</li>
</ol>
<p>最后在理解这几个阶段的状态的基础上，整个串一下其生长过程。</p>
<h3 id="初始化时"><a href="#初始化时" class="headerlink" title="初始化时"></a>初始化时</h3><p>数据库初始化时，B+ 树只包含一个空的叶子节点，该叶子节点即为 root bucket 的 root node。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(db *DB)</span></span> init() <span class="type">error</span> &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="comment">// 在 pageid = 3 的地方写入一个空的叶子节点.</span></span><br><span class="line">  p = db.pageInBuffer(buf[:], pgid(<span class="number">3</span>))</span><br><span class="line">  p.id = pgid(<span class="number">3</span>)</span><br><span class="line">  p.flags = leafPageFlag</span><br><span class="line">  p.count = <span class="number">0</span></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>之后 B+ 树的生长都由<strong>写事务</strong>中对 B+ 树节点的增删、调整来完成。按 boltdb 的设计，写事务只能串行进行。boltdb 使用 COW 的方式对节点进行修改，以保证不影响并发的读事务。即，将要修改的 page 读到内存，修改并调整后，申请新的 page 将变动后的 node 落盘。</p>
<p>这种方式可以方便的实现读写并发和事务，在本系列文章下一篇中将详细分析其原因。但无疑，其代价比较高昂，即使一个 key 的修改&#x2F;删除，都会引起对应叶子节点所在 B+ 树路径上所有节点的修改和落盘。因此如果修改较频繁，最好在单个事务中做 Batch。</p>
<h3 id="Bucket-较小时"><a href="#Bucket-较小时" class="headerlink" title="Bucket 较小时"></a>Bucket 较小时</h3><p>在 bucket 包含的数据还很少时，不会给 bucket 开辟新的 page，而是将其<strong>内嵌</strong>（inline）在父 bucket 的叶子节点中。是否能内嵌的判断逻辑在 <code>bucket.inlineable</code> 中：</p>
<ol>
<li>只包含一个叶子节点</li>
<li>数据尺寸不大于 1&#x2F;4 个页</li>
<li>不包含子 bucket</li>
</ol>
<h3 id="事务开启后"><a href="#事务开启后" class="headerlink" title="事务开启后"></a>事务开启后</h3><p>在每次事务<strong>初始化时</strong>，会在内存中拷贝一份 root bucket 的句柄，以此作为之后动态加载修改路径上 node 的入口。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(tx *Tx)</span></span> init(db *DB) &#123;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 拷贝并初始化 root bucket</span></span><br><span class="line">  tx.root = newBucket(tx)</span><br><span class="line">  tx.root.bucket = &amp;bucket&#123;&#125;</span><br><span class="line">  *tx.root.bucket = tx.meta.root</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// ... </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在<em>读写事务</em>中，用户调用 <code>bucket.Put</code> 新增或者修改数据时，涉及两个阶段：</p>
<ol>
<li><strong>查找定位</strong>：利用 cursor 定位到指定 key 所在 page </li>
<li><strong>加载插入</strong>：加载路径上所有节点，并在叶子节点插入 kv</li>
</ol>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *Bucket)</span></span> Put(key []<span class="type">byte</span>, value []<span class="type">byte</span>) <span class="type">error</span> &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 1. 将 cursor 定位到 key 所在位置</span></span><br><span class="line">  c := b.Cursor()</span><br><span class="line">  k, _, flags := c.seek(key)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2. 加载路径上节点为 node，然后插入 key value</span></span><br><span class="line">  key = cloneBytes(key)</span><br><span class="line">  c.node().put(key, key, value, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>查找定位</strong>。该实现逻辑在上一节所探讨的 cursor 的 <code>cursor.seek</code> 中，其主要逻辑为从根节点出发，不断二分查找，访问对应 node&#x2F;page，直到定位到待插入 kv 的叶子节点。这里面有个关键的节点访问函数 <code>bucket.pageNode</code>，该函数不会加载 page 为 node，而只是复用已经缓存的 node ，或者直接访问 mmap 到内存空间中的相关 page。</p>
<p><strong>加载插入</strong>。在该阶段，首先通过 <code>cursor.node()</code> 将 cursor 栈中保存的所有节点索引加载为 <code>node</code>，并缓存起来，避免重复加载以进行复用；然后通过 <code>node.put</code> 通过二分查找将 key value 数据插入叶子 <code>node</code>。</p>
<p>在<em>只读事务</em>中，只会有查找定位的过程，因此只会通过 mmap 对 <code>page</code> 访问，而不会有 <code>page</code> 到 <code>node</code> 的转换过程。</p>
<p>对于 <code>bucket.Delete</code> 操作，和上述两个阶段类似，只不过<strong>加载插入</strong>变成了<strong>加载删除</strong>。可以看出，这个阶段所有的修改都发生在内存中，文件系统中保存的之前 page 组成的 B+ 树结构并未遭到破坏，因此读事务可以并发进行。</p>
<h3 id="事务提交前"><a href="#事务提交前" class="headerlink" title="事务提交前"></a>事务提交前</h3><p>在写事务开启后，用户可能会进行一系列的新增&#x2F;删除，大量的相关节点被转化为 node 加载到内存中，改动后的 B+ 树由文件系统中的 page 和内存中的 node 共同构成，且由于数据变动，可能会造成某些节点元素数量过少、而另外一些节点元素数量过多。</p>
<p>因此在事务提交前，会先按一定策略调整 B+ 树，使其维持较好的查询性质，然后将所有改动的 <code>node</code> 序列化为 <code>page</code> 增量的写入文件系统中，构成一棵新的、持久化的、平衡的 B+ 树。</p>
<p>这个阶段涉及到两个核心逻辑：<code>bucket.rebalance</code> 和 <code>bucket.spill</code>， 他们分别对应节点的 merge 和 split，是维持 boltdb B+ 树查找性质的关键函数，下面来分别梳理下。</p>
<p><strong>rebalance</strong>。该函数旨在将过小（key数太少或者总体尺寸太小）的节点合并到邻居节点上。调整的主要逻辑在 <code>node.rebalance</code> 中， <code>bucket.rebalance</code>  主要是个外包装：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *Bucket)</span></span> rebalance() &#123;</span><br><span class="line">  <span class="comment">// 对所有缓存的 node 进行调整</span></span><br><span class="line">  <span class="keyword">for</span> _, n := <span class="keyword">range</span> b.nodes &#123;</span><br><span class="line">    n.rebalance()</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 对所有子 bucket 进行调整</span></span><br><span class="line">  <span class="keyword">for</span> _, child := <span class="keyword">range</span> b.buckets &#123;</span><br><span class="line">    child.rebalance()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>node.rebalance</code> 主要逻辑如下：</p>
<ol>
<li>判断 <code>n.unbalanced</code> 标记，避免对某个节点进行重复调整。使用标记的原因有二，一是按需调整，二是避免重复调整。</li>
<li>判断该节点是需要 merge，判断标准为：<code>n.size() &gt; pageSize / 4 &amp;&amp; len(n.inodes) &gt; n.minKeys()</code> ，不需要则结束。</li>
<li>如果该节点是根节点，且只有一个孩子节点，则将其和其唯一的孩子合并。</li>
<li>如果该节点没有孩子节点，则删除该节点。</li>
<li>否则，将该节点合并到左邻。如果该节点是第一个节点，没左邻，则将右邻合并过来。</li>
<li>由于此次调整可能会导致节点的删除，因此向上递归看是否需要进一步调整。</li>
</ol>
<p>需要明确的是，只有 <code>node.del()</code> 的调用才会导致 <code>n.unbalanced</code> 被标记。只有两个地方会调用 <code>node.del()</code>:</p>
<ol>
<li>用户调用 <code>bucket.Delete</code> 函数删除数据。</li>
<li>子节点调用 <code>node.rebalance</code> 进行调整时，删除被合并的节点。</li>
</ol>
<p>而 2 又是由 1 引起的，因此可以说，只有用户在某次写事务中删除数据时，才会引起 <code>node.rebanlance</code> 主逻辑的实际执行。</p>
<p><strong>spill</strong>，该函数功能有二，将过大（尺寸大于一个 page）节点拆分、将节点写入脏页（dirty page）。与 rebalance 一样，主要逻辑在 <code>node.spill</code> 中。不同的是，<code>bucket.spill</code> 中也有相当一部分逻辑，主要是处理 inline bucket 的问题。前面提到，如果一个 bucket 内容过少，就会直接内嵌在父 bucket 的叶子节点中。否则，则先调用子 bucket 的 spill 函数，然后将子 bucket 的根节点 pageid 放在父 bucket 叶子节点中。可以看出， spill 调整是一个自下而上的过程，类似于树的后序遍历。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// spill 将尺寸大于一个节点的 page 拆分，并将调整后的节点写入脏页</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *Bucket)</span></span> spill() <span class="type">error</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 自下而上，先递归调整子 bucket</span></span><br><span class="line">  <span class="keyword">for</span> name, child := <span class="keyword">range</span> b.buckets &#123;</span><br><span class="line">    <span class="comment">// 如果子 bucket 可以内嵌，则将其所有数据序列化后内嵌到父 bucket 相应叶子节点</span></span><br><span class="line">    <span class="keyword">var</span> value []<span class="type">byte</span></span><br><span class="line">    <span class="keyword">if</span> child.inlineable() &#123;</span><br><span class="line">      child.free()</span><br><span class="line">      value = child.write()</span><br><span class="line">    <span class="comment">// 否则，先调整子 bucket，然后将其根节点 page id 作为值写入父 bucket 相应叶子节点</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> err := child.spill(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      value = <span class="built_in">make</span>([]<span class="type">byte</span>, unsafe.Sizeof(bucket&#123;&#125;))</span><br><span class="line">      <span class="keyword">var</span> bucket = (*bucket)(unsafe.Pointer(&amp;value[<span class="number">0</span>]))</span><br><span class="line">      *bucket = *child.bucket</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果该子 bucket 没有缓存任何 node（说明没有数据变动），则直接跳过</span></span><br><span class="line">    <span class="keyword">if</span> child.rootNode == <span class="literal">nil</span> &#123;</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 更新 child 父 bucket（即本 bucket）的对该子 bucket 的引用</span></span><br><span class="line">    <span class="keyword">var</span> c = b.Cursor()</span><br><span class="line">    k, _, flags := c.seek([]<span class="type">byte</span>(name))</span><br><span class="line">    <span class="keyword">if</span> !bytes.Equal([]<span class="type">byte</span>(name), k) &#123;</span><br><span class="line">      <span class="built_in">panic</span>(fmt.Sprintf(<span class="string">&quot;misplaced bucket header: %x -&gt; %x&quot;</span>, []<span class="type">byte</span>(name), k))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> flags&amp;bucketLeafFlag == <span class="number">0</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(fmt.Sprintf(<span class="string">&quot;unexpected bucket header flag: %x&quot;</span>, flags))</span><br><span class="line">    &#125;</span><br><span class="line">    c.node().put([]<span class="type">byte</span>(name), []<span class="type">byte</span>(name), value, <span class="number">0</span>, bucketLeafFlag)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如果该 bucket 没有缓存任何 node（说明没有数据变动），则终止调整</span></span><br><span class="line">  <span class="keyword">if</span> b.rootNode == <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 调整本 bucket</span></span><br><span class="line">  <span class="keyword">if</span> err := b.rootNode.spill(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line">  b.rootNode = b.rootNode.root()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 由于调整会增量写，造成本 bucket 根节点引用变更，因此需要更新 b.root</span></span><br><span class="line">  <span class="keyword">if</span> b.rootNode.pgid &gt;= b.tx.meta.pgid &#123;</span><br><span class="line">    <span class="built_in">panic</span>(fmt.Sprintf(<span class="string">&quot;pgid (%d) above high water mark (%d)&quot;</span>, b.rootNode.pgid, b.tx.meta.pgid))</span><br><span class="line">  &#125;</span><br><span class="line">  b.root = b.rootNode.pgid</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>node.spill</code> 的主要逻辑如下：</p>
<ol>
<li>判断 <code>n.spilled</code> 标记，默认为 false，表明所有节点都需要调整。如果调整过，则跳过。</li>
<li>由于是自下而上调整，因此需要递归调用以先调整子节点，再调节本节点。</li>
<li>调整本节点时，将节点按照 pagesize 进行拆分。</li>
<li>为所有新节点申请新的合适尺寸的 pages，然后将 node 写入 page（此时还没有写回文件系统）。</li>
<li>如果 spilt 生成了新的根节点，则需要向上递归调用调整其他分支。为了避免重复调整，会将本节点 <code>children</code> 置空。</li>
</ol>
<p>可以看出，boltdb 维持 B+ 树查找性质，并非像教科书 B+ 树一样，将所有分支节点的分支树维护在一个固定范围，而是直接按节点元素是否能够保存到一个 page 中来做的。这样做可以减少 page 内部碎片，实现也相对简单。</p>
<p>这两个函数都通过 put&#x2F;delete 后标记来实现按需调整，但不同的是，rebalance 先 merge 本身，再 merge 子 bucket；而 spill 先 split 子 bucket，再 split 本身。另外，调整时对他们调用顺序是有要求的，需要先调用 balance 进行无脑 merge，然后在调用 spill，按 pagesize 进行拆分后，写入脏页。</p>
<p>总结一下， 在 db 初始化时，只有一个页保存 root bucket 的根节点。之后的 B+ 树在 <code>bucket.Create</code> 的时候进行创建。初始时内嵌在父 bucket 的叶子节点中，读事务不会对 B+ 树结构造成任何改变，写事务中所有变动，会先写到内存中，在事务提交时，会进行平衡调整，然后增量的写入文件系统。随着写入数据的增多，B+ 树会不断进行拆分，变深，不在内嵌于父 bucket 中。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>boltdb 使用类 B+ 树组织数据库索引，所有数据存在叶子节点，分支节点只用于路由查找。boltdb 支持 bucket 间的嵌套，在实现上表现为 B+ 树的嵌套，通过 page id 来维持父子 bucket 间的引用。</p>
<p>boltdb 中的 B+ 树为了实现简单，没有使用链表将所有叶子节点串在一起。为了支持对数据的顺序遍历，额外实现了一个 curosr 遍历逻辑，通过保存遍历栈来提高遍历效率、快速跳转。</p>
<p>boltdb 对 B+ 树的生长以事务为周期，而且生长只发生在写事务中。在写事务开始后，会复制 root bucket 的根节点，然后将改动涉及到的节点按需加载到内存，并在内存中进行修改。在写事务结束前，在对 B+ 树调整后，将所有改动涉及到的 node 申请新的 page，写回文件系统，完成 B+ 树一次生长。释放的树节点，在没有读事务占用后，会进入 freelist 供之后使用。</p>
<h2 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h2><p><strong>节点</strong>：B+ 树中的节点，在文件系统或者 mmap 后表现为 page，在内存中转换后成为 node。</p>
<p><strong>路径</strong>：树中的路径指树的根节点到当前节点的顺序经过的所有节点。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>boltdb repo：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JvbHRkYi9ib2x0">https://github.com/boltdb/bolt<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>boltdb</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>boltdb</tag>
        <tag>kv engine</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>Boltdb 源码导读（一）：Boltdb 数据组织</title>
    <url>/2020/11/29/bolt-data-organised/</url>
    <content><![CDATA[<blockquote>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JvbHRkYi9ib2x0">boltdb<i class="fa fa-external-link-alt"></i></span> 是市面上为数不多的纯 go 语言开发的、单机 KV 库。boltdb 基于  <span class="exturl" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9oeWNfc3ltYXM=">Howard Chu’s<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cDovL3N5bWFzLmNvbS9tZGIv">LMDB 项目<i class="fa fa-external-link-alt"></i></span> ，实现的比较清爽，去掉单元测试和适配代码，核心代码大概四千多行。简单的 API、简约的实现，也是作者的意图所在。由于作者精力所限，原 boltdb 已经封版，不再更新。若想改进，提交新的 pr，建议去 etcd 维护的 fork 版本 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2V0Y2QtaW8vYmJvbHQ=">bbolt<i class="fa fa-external-link-alt"></i></span>。</p>
<p>为了方便，本系列导读文章仍以不再变动的原 repo 为基础。该项目麻雀虽小，五脏俱全，仅仅四千多行代码，就实现了一个基于 B+ 树索引、支持一写多读事务的单机 KV 引擎。代码本身简约朴实、注释得当，如果你是 go 语言爱好者、如果对 KV 库感兴趣，那 boltdb 绝对是不可错过的一个 repo。</p>
<p>本系列计划分成三篇文章，依次围绕<strong>数据组织</strong>、<strong>索引设计</strong>、<strong>事务实现</strong>等三个主要方面对 boltdb 源码进行剖析。由于三个方面不是完全正交解耦的，因此叙述时会不可避免的产生交织，读不懂时，暂时略过即可，待有全貌，再回来梳理。本文是第一篇， boltdb 数据组织。</p>
</blockquote>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>一个存储引擎最底层的构成，就是处理数据在各种物理介质（比如在磁盘上、在内存里）上的组织。而这些数据组织也体现了该存储引擎在设计上的取舍哲学。</p>
<p>在文件系统上，boltdb 采用<strong>页</strong>（page）的组织方式，将一切数据都<strong>对齐</strong>到页；在内存中，boltdb 按 B+ 树组织数据，其基本单元是<strong>节点</strong>（node），一个内存中的树节点对应文件系统上一个或者多个<strong>连续的</strong>页。boltdb 就在数据组织上就只有这两种核心抽象，可谓设计简洁。当然，这种简洁必然是有代价的，后面文章会进行详细分析。</p>
<p>本文首先对节点和页的关系进行总体说明，然后逐一分析四种页的格式及其载入内存后的表示，最后按照 db 的生命周期串一下 db 文件的增长过程以及载入内存的策略。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2020/11/29/bolt-data-organised">https://www.qtmuniao.com/2020/11/29/bolt-data-organised</a>, 转载请注明出处</em></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>本文主要涉及到 page.go 和 freelist.go 两个源文件，主要分析了 boltdb 各种 page 在磁盘上的格式和其加载到内存中后的表示。</p>
<h3 id="顶层组织"><a href="#顶层组织" class="headerlink" title="顶层组织"></a>顶层组织</h3><p>boltdb 的数据组织，自上而下来说：</p>
<ol>
<li>每个 db 对应一个文件。</li>
<li>在逻辑上：<ul>
<li>一个 db 包含多个桶（bucket），n相当于多个命名空间（namespace），桶可以无限嵌套</li>
<li>每个桶对应一棵 B+ 树</li>
</ul>
</li>
<li>在物理上：<ul>
<li>一个 db 文件是按页为单位进行顺序存储</li>
<li>一个页大小和操作系统的页大小保持一致（通常是 4KB）</li>
</ul>
</li>
</ol>
<h3 id="页和节点"><a href="#页和节点" class="headerlink" title="页和节点"></a>页和节点</h3><p>页分为四种类型：</p>
<ul>
<li><strong>元信息页</strong>：全局有且仅有两个 meta 页，保存在文件；它们是 boltdb 实现事务的关键</li>
<li><strong>空闲列表页</strong>：有一种特殊的页，存放空闲页（freelist） id 列表；他们在文件中表现为一段一段的连续的页</li>
<li><strong>两种数据页</strong>：剩下的页都是数据页，有两种类型，分别对应 B+ 树中的分支节点和叶子节点</li>
</ul>
<p>页和节点的关系在于：</p>
<ol>
<li>页是 db 文件存储的基本单位，节点是 B+ 树的基本构成节点</li>
<li>一个数据节点对应一到多个<strong>连续的</strong>数据页</li>
<li>连续的<strong>数据页</strong>序列化加载到内存中就成为一个数据节点</li>
</ol>
<p>总结一下：在文件系统上线性组织的<strong>数据页</strong>，通过页内指针，在逻辑上组织成了一棵二维的 B+ 树，该树的树根保存在<strong>元信息</strong>页中，而文件中所有其他没有用到的页的 id 列表，保存在<strong>空闲列表页</strong>中。</p>
<h2 id="页格式和内存表示"><a href="#页格式和内存表示" class="headerlink" title="页格式和内存表示"></a>页格式和内存表示</h2><p>boltdb 中的页分四种类型：元信息页、空闲列表页、分支节点页和叶子节点页。boltdb 使用常量枚举标记：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">  branchPageFlag   = <span class="number">0x01</span></span><br><span class="line">  leafPageFlag     = <span class="number">0x02</span></span><br><span class="line">  metaPageFlag     = <span class="number">0x04</span></span><br><span class="line">  freelistPageFlag = <span class="number">0x10</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>每个页都由定长 header 和数据部分组成：</p>
<p><img src="https://i.loli.net/2020/11/29/scJkTp5GSdPlHW1.png" alt="boltdb 页结构"></p>
<p>其中 ptr 指向的是页的数据部分，为了避免载入内存和写入文件系统时的序列化和反序列化操作，boltdb 使用了大量的 go unsafe 包中的指针操作。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> pgid <span class="type">uint64</span></span><br><span class="line"><span class="keyword">type</span> page <span class="keyword">struct</span> &#123;</span><br><span class="line">  id       pgid</span><br><span class="line">  flags    <span class="type">uint16</span>  <span class="comment">// 页类型，值为四种类型之一</span></span><br><span class="line">  count    <span class="type">uint16</span>  <span class="comment">// 对应的节点包含元素个数，比如说包含的 kv 对</span></span><br><span class="line">  overflow <span class="type">uint32</span>  <span class="comment">// 对应节点溢出页的个数，即使用 overflow+1 个页来保存对应节点</span></span><br><span class="line">  ptr      <span class="type">uintptr</span> <span class="comment">// 指向数据对应的 byte 数组，当 overlay&gt;0 时会跨越多个连续页；不过多个物理也在内存中也只会用一个 page 结构体来表示</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="元信息页（metaPage）"><a href="#元信息页（metaPage）" class="headerlink" title="元信息页（metaPage）"></a>元信息页（metaPage）</h3><p>boltdb 中有且仅有两个元信息页，保存在 db 文件的开头（pageid &#x3D; 0 和 1）。但是在元信息页中，ptr 指向的内容并非元素列表，而是整个 db 的元信息的各个字段。</p>
<p><img src="https://i.loli.net/2020/11/29/BjTF382uakiy4QA.png" alt="meta-page.png"></p>
<p>元信息页加载到内存后数据结构如下：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> meta <span class="keyword">struct</span> &#123;</span><br><span class="line">  magic    <span class="type">uint32</span></span><br><span class="line">  version  <span class="type">uint32</span></span><br><span class="line">  pageSize <span class="type">uint32</span> <span class="comment">// 该 db 页大小，通过 syscall.Getpagesize() 获取，通常为 4k</span></span><br><span class="line">  flags    <span class="type">uint32</span> <span class="comment">// </span></span><br><span class="line">  root     bucket <span class="comment">// 各个子 bucket 根所组成的树</span></span><br><span class="line">  freelist pgid   <span class="comment">// 空闲列表所存储的起始页 id</span></span><br><span class="line">  pgid     pgid   <span class="comment">// 当前用到的最大 page id，也即用到 page 的数量</span></span><br><span class="line">  txid     txid   <span class="comment">// 事务版本号，用以实现事务相关</span></span><br><span class="line">  checksum <span class="type">uint64</span> <span class="comment">// 校验和，用于校验 meta 页是否写完整</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="空闲列表页（freelistPage）"><a href="#空闲列表页（freelistPage）" class="headerlink" title="空闲列表页（freelistPage）"></a>空闲列表页（freelistPage）</h3><p>空闲列表页是 db 文件中一组连续的页（一个或者多个），用于保存在 db 使用过程中由于修改操作而释放的页的 id 列表。</p>
<p><img src="https://i.loli.net/2020/11/29/d84eqFEGwiLQZUu.png" alt="freelist-page.png"></p>
<p>在内存中表示时分为两部分，一部分是可以分配的空闲页列表 ids，另一部分是按事务 id 分别记录了在对应事务期间新增的空闲页列表。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 表示当前已经释放的 page 列表</span></span><br><span class="line"><span class="comment">// 和写事务刚释放的 page</span></span><br><span class="line"><span class="keyword">type</span> freelist <span class="keyword">struct</span> &#123;</span><br><span class="line">  ids        []pgid            <span class="comment">// all free and available free page ids.</span></span><br><span class="line">  pending    <span class="keyword">map</span>[txid][]pgid   <span class="comment">// mapping of soon-to-be free page ids by tx.</span></span><br><span class="line">  cache      <span class="keyword">map</span>[pgid]<span class="type">bool</span>     <span class="comment">// fast lookup of all free and pending page ids.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中 <code>pending</code> 部分需要单独记录主要是为了做 MVCC 的事务：</p>
<ol>
<li>写事务回滚时，对应事务待释放的空闲页列表要从 <code>pending</code> 项中删除。</li>
<li>某个写事务（比如 txid&#x3D;7）已经提交，但可能仍有一些读事务（如 txid &lt;&#x3D;7）仍然在使用其刚释放的页，因此不能立即用作分配。</li>
</ol>
<p>这部分内容会在 boltdb 事务中详细说明，这里只需有个印象即可。</p>
<h4 id="空闲列表转化为-page"><a href="#空闲列表转化为-page" class="headerlink" title="空闲列表转化为 page"></a>空闲列表转化为 page</h4><p>freelist 通过 <code>write</code> 函数，在<strong>事务提交时</strong>将自己写入给定的页，进行持久化。在写入时，会将 <code>pending</code> 和 <code>ids</code> 合并后写入，这是因为：</p>
<ol>
<li><code>write</code> 函数是在写事务提交时调用，写事务是串行的，因此 <code>pending</code> 中对应的写事务都已经提交。</li>
<li>写入文件是为了应对崩溃后重启，而重启时没有任何读操作，自然不用担心有读事务还在用刚释放的页。</li>
</ol>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *freelist)</span></span> write(p *page) <span class="type">error</span> &#123;</span><br><span class="line">  <span class="comment">// 设置页类型</span></span><br><span class="line">  p.flags |= freelistPageFlag</span><br><span class="line"></span><br><span class="line">  <span class="comment">// page.count 是 uint16 类型，其能表示的范围为 [0, 64k-1] 。如果空闲页 id 列表长度超出了此范围，就需要另想办法。</span></span><br><span class="line">  <span class="comment">// 这里用了个 trick，将 page.count 置为 64k 即 0xFFF，然后在数据部分的第一个元素存实际数量（以 pgid 为类型，即 uint64）。</span></span><br><span class="line">  lenids := f.count()</span><br><span class="line">  <span class="keyword">if</span> lenids == <span class="number">0</span> &#123;</span><br><span class="line">    p.count = <span class="type">uint16</span>(lenids)</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> lenids &lt; <span class="number">0xFFFF</span> &#123;</span><br><span class="line">    p.count = <span class="type">uint16</span>(lenids)</span><br><span class="line">    <span class="comment">// copyall 会将 pending 和 ids 合并并排序</span></span><br><span class="line">    f.copyall(((*[maxAllocSize]pgid)(unsafe.Pointer(&amp;p.ptr)))[:]) </span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    p.count = <span class="number">0xFFFF</span></span><br><span class="line">    ((*[maxAllocSize]pgid)(unsafe.Pointer(&amp;p.ptr)))[<span class="number">0</span>] = pgid(lenids)</span><br><span class="line">    f.copyall(((*[maxAllocSize]pgid)(unsafe.Pointer(&amp;p.ptr)))[<span class="number">1</span>:])</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>本步骤只是将 <code>freelist</code> 转化为内存中的页结构，需要额外的操作，比如 <code>tx.write()</code> 才会将对应的页真正持久化到文件。</p>
<h4 id="空闲列表从-page-中加载"><a href="#空闲列表从-page-中加载" class="headerlink" title="空闲列表从 page 中加载"></a>空闲列表从 page 中加载</h4><p>在数据库重启时，会首先从前两个元信息页恢复出一个合法的元信息。然后根据元信息中的 <code>freelist</code> 字段，找到存储 freelist 页的起始地址，进而将其恢复到内存中。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *freelist)</span></span> read(p *page) &#123;</span><br><span class="line">  <span class="comment">// count == 0xFFFF 表明实际 count 存储在 ptr 所指向的内容的第一个元素</span></span><br><span class="line">  idx, count := <span class="number">0</span>, <span class="type">int</span>(p.count)</span><br><span class="line">  <span class="keyword">if</span> count == <span class="number">0xFFFF</span> &#123;</span><br><span class="line">    idx = <span class="number">1</span></span><br><span class="line">    count = <span class="type">int</span>(((*[maxAllocSize]pgid)(unsafe.Pointer(&amp;p.ptr)))[<span class="number">0</span>])</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将空闲列表从 page 拷贝内存中 freelist 结构体中</span></span><br><span class="line">  <span class="keyword">if</span> count == <span class="number">0</span> &#123;</span><br><span class="line">    f.ids = <span class="literal">nil</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ids := ((*[maxAllocSize]pgid)(unsafe.Pointer(&amp;p.ptr)))[idx:count]</span><br><span class="line">    f.ids = <span class="built_in">make</span>([]pgid, <span class="built_in">len</span>(ids))</span><br><span class="line">    <span class="built_in">copy</span>(f.ids, ids)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 保证 ids 是有序的</span></span><br><span class="line">    sort.Sort(pgids(f.ids))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 重新构建 freelist.cache 这个 map.</span></span><br><span class="line">  f.reindex()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="空闲列表分配"><a href="#空闲列表分配" class="headerlink" title="空闲列表分配"></a>空闲列表分配</h4><p>作者原版的空闲列表分配异常简单，<strong>分配单位</strong>是页，分配策略是**<span class="exturl" data-url="aHR0cHM6Ly9iYWlrZS5iYWlkdS5jb20vaXRlbS8lRTklQTYlOTYlRTYlQUMlQTElRTklODAlODIlRTUlQkElOTQlRTclQUUlOTclRTYlQjMlOTUvMTAxNDczMzQ=">首次适应<i class="fa fa-external-link-alt"></i></span>**：即从排好序的空闲页列表 <code>ids</code> 中，找到第一段等于指定长度的连续空闲页，然后返回起始页 id。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 如果可以找到连续 n 个空闲页，则返回起始页 id</span></span><br><span class="line"><span class="comment">// 否则返回 0</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *freelist)</span></span> allocate(n <span class="type">int</span>) pgid &#123;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(f.ids) == <span class="number">0</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 遍历寻找连续空闲页，并判断是否等于 n</span></span><br><span class="line">  <span class="keyword">var</span> initial, previd pgid</span><br><span class="line">  <span class="keyword">for</span> i, id := <span class="keyword">range</span> f.ids &#123;</span><br><span class="line">    <span class="keyword">if</span> id &lt;= <span class="number">1</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(fmt.Sprintf(<span class="string">&quot;invalid page allocation: %d&quot;</span>, id))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果不连续，则重置 initial</span></span><br><span class="line">    <span class="keyword">if</span> previd == <span class="number">0</span> || id-previd != <span class="number">1</span> &#123;</span><br><span class="line">      initial = id</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (id-initial)+<span class="number">1</span> == pgid(n) &#123;</span><br><span class="line">      <span class="comment">// 当正好分配到 ids 中前 n 个 page 时，仅简单往前调整 f.ids 切片即可。</span></span><br><span class="line">      <span class="comment">// 尽管一时会造成空间浪费，但是在对 f.ids append/free 操作时，会按需</span></span><br><span class="line">      <span class="comment">// 重新空间分配，重新分配会导致这些浪费空间被回收掉</span></span><br><span class="line">      <span class="keyword">if</span> (i + <span class="number">1</span>) == n &#123;</span><br><span class="line">        f.ids = f.ids[i+<span class="number">1</span>:]</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">copy</span>(f.ids[i-n+<span class="number">1</span>:], f.ids[i+<span class="number">1</span>:])</span><br><span class="line">        f.ids = f.ids[:<span class="built_in">len</span>(f.ids)-n]</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 从 cache 中删除对应 page id</span></span><br><span class="line">      <span class="keyword">for</span> i := pgid(<span class="number">0</span>); i &lt; pgid(n); i++ &#123;</span><br><span class="line">        <span class="built_in">delete</span>(f.cache, initial+i)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> initial</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    previd = id</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个 GC 策略相当简单直接，是线性的时间复杂度。阿里似乎做过一个 patch，将所有空闲 page 按其连续长度 group by 了一下。</p>
<h3 id="叶子节点页（leafPage）"><a href="#叶子节点页（leafPage）" class="headerlink" title="叶子节点页（leafPage）"></a>叶子节点页（leafPage）</h3><p>这种页对应 <strong>B+ 树</strong>中叶子节点，叶子节点包含的元素有两种类型：普通 KV 数据、subbucket。</p>
<p>对于前者来说，页中存储的基本元素为某个 bucket 中一条用户数据。对于后者来说，页中的一个元素为该 db 中的某个 subbucket 。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// page ptr 指向的字节数组中的单个元素</span></span><br><span class="line"><span class="keyword">type</span> leafPageElement <span class="keyword">struct</span> &#123; </span><br><span class="line">  flags         <span class="type">uint32</span>    <span class="comment">// 普通 kv （flags=0）还是 subbucket（flags=bucketLeafFlag）</span></span><br><span class="line">  pos           <span class="type">uint16</span>    <span class="comment">// kv header 与对应 kv 的距离</span></span><br><span class="line">  ksize         <span class="type">uint32</span>    <span class="comment">// key 的字节数</span></span><br><span class="line">  vsize         <span class="type">uint32</span>    <span class="comment">// val 字节数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其详细结构如下：</p>
<p><img src="https://i.loli.net/2020/11/29/4eGQqLtk5fmNvH7.png" alt="leaf-page-element.png"></p>
<p>可以看出，leaf page 在组织数据时，将<strong>元素头</strong>（<code>leafPageElement</code>）和<strong>元素本身</strong>（<code>key value</code>）分开存储。这样的好处在于 <code>leafPageElement</code> 是定长的，可以按下标访问对应元素。在二分查找指定 key 时，只需按需加载相应页到内存（访问 page 时是通过 mmap 进行的，因此只有访问时才会真正将数据从文件系统中加载到内存）即可。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">inodes := p.leafPageElements()</span><br><span class="line">index := sort.Search(<span class="type">int</span>(p.count), <span class="function"><span class="keyword">func</span><span class="params">(i <span class="type">int</span>)</span></span> <span class="type">bool</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> bytes.Compare(inodes[i].key(), key) != <span class="number">-1</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<p>如果元素头和对应元素紧邻存储，则需将 <code>leafPageElement</code> 数组对应的所有页顺序读取，全部加载到内存，才能进行二分。</p>
<p>另外一个小优化是 pos 存储的是元素头的起始地址到元素的起始地址的<strong>相对偏移量</strong>，而非以 <code>ptr</code> 指针为起始地址的<strong>绝对偏移量</strong>。这样可以用尽量少的位数（<code>pos</code> 是 <code>uint16</code>） 表示尽量长的距离。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(n *branchPageElement)</span></span> key() []<span class="type">byte</span> &#123;</span><br><span class="line">  buf := (*[maxAllocSize]<span class="type">byte</span>)(unsafe.Pointer(n)) <span class="comment">// buf 是元素头起始地址</span></span><br><span class="line">  <span class="keyword">return</span> (*[maxAllocSize]<span class="type">byte</span>)(unsafe.Pointer(&amp;buf[n.pos]))[:n.ksize]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="分支节点页（branchPage）"><a href="#分支节点页（branchPage）" class="headerlink" title="分支节点页（branchPage）"></a>分支节点页（branchPage）</h3><p>分支节点页和叶子节点页的结构大体相同。不同之处在于，页中保存的数据的 value 是 page id，即该分支节点在哪些 key 上的分支分别指向的 page 。</p>
<p><img src="https://i.loli.net/2020/12/05/6SPHqWmLXkwiusj.png" alt="branch-element.png"></p>
<p><code>branchPageElement</code> 中的 key 存的是其指向的页中的起始 key。</p>
<h2 id="转换流程"><a href="#转换流程" class="headerlink" title="转换流程"></a>转换流程</h2><p>boltdb 使用 mmap 将 db 文件映射到内存空间。在构建树并且访问过程中，按需将对应的页加载到内存里，并且利用操作系统的页缓存策略进行替换。</p>
<h3 id="文件增长"><a href="#文件增长" class="headerlink" title="文件增长"></a>文件增长</h3><p>当我们打开一个 db 时，如果发现该 db 文件为空，会在内存中初始化四个页（4*4k&#x3D;16K），分别是两个元信息页、一个空的空闲列表页和一个空的叶子节点页，然后将其写入 db 文件，然后走正常打开流程。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(db *DB)</span></span> init() <span class="type">error</span> &#123;</span><br><span class="line">  <span class="comment">// 设置页大小与操作系统一致</span></span><br><span class="line">  db.pageSize = os.Getpagesize()</span><br><span class="line"></span><br><span class="line">  buf := <span class="built_in">make</span>([]<span class="type">byte</span>, db.pageSize*<span class="number">4</span>)</span><br><span class="line">  <span class="comment">// 在 buffer 中创建两个元信息页.</span></span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">2</span>; i++ &#123;</span><br><span class="line">    p := db.pageInBuffer(buf[:], pgid(i))</span><br><span class="line">    p.id = pgid(i)</span><br><span class="line">    p.flags = metaPageFlag</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化元信息页.</span></span><br><span class="line">    m := p.meta()</span><br><span class="line">    m.magic = magic</span><br><span class="line">    m.version = version</span><br><span class="line">    m.pageSize = <span class="type">uint32</span>(db.pageSize)</span><br><span class="line">    m.freelist = <span class="number">2</span></span><br><span class="line">    m.root = bucket&#123;root: <span class="number">3</span>&#125;</span><br><span class="line">    m.pgid = <span class="number">4</span></span><br><span class="line">    m.txid = txid(i)</span><br><span class="line">    m.checksum = m.sum64()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 在 pgid=2 的页写入一个空的空闲列表.</span></span><br><span class="line">  p := db.pageInBuffer(buf[:], pgid(<span class="number">2</span>))</span><br><span class="line">  p.id = pgid(<span class="number">2</span>)</span><br><span class="line">  p.flags = freelistPageFlag</span><br><span class="line">  p.count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 在 pgid=3 的页写入一个空的叶子元素.</span></span><br><span class="line">  p = db.pageInBuffer(buf[:], pgid(<span class="number">3</span>))</span><br><span class="line">  p.id = pgid(<span class="number">3</span>)</span><br><span class="line">  p.flags = leafPageFlag</span><br><span class="line">  p.count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将 buffer 中的这四个页写入数据文件并刷盘</span></span><br><span class="line">  <span class="keyword">if</span> _, err := db.ops.writeAt(buf, <span class="number">0</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> err := fdatasync(db); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>随着数据的不断写入，需要申请新的页。boltdb 首先会去 freelist 中找有无可重复利用的页，如果没有，就只能进行 re-mmap（先 mumap 在 mmap），扩大 db 文件。每次扩大会进行倍增（因此从 16K * 2 &#x3D; 32K 开始），到达 1G 后，再次扩大会每次新增 1G。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(db *DB)</span></span> mmapSize(size <span class="type">int</span>) (<span class="type">int</span>, <span class="type">error</span>) &#123;</span><br><span class="line">  <span class="comment">// 从 32KB 开始，直到 1GB.</span></span><br><span class="line">  <span class="keyword">for</span> i := <span class="type">uint</span>(<span class="number">15</span>); i &lt;= <span class="number">30</span>; i++ &#123;</span><br><span class="line">    <span class="keyword">if</span> size &lt;= <span class="number">1</span>&lt;&lt;i &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">1</span> &lt;&lt; i, <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Verify the requested size is not above the maximum allowed.</span></span><br><span class="line">  <span class="keyword">if</span> size &gt; maxMapSize &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>, fmt.Errorf(<span class="string">&quot;mmap too large&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 对齐到 maxMmapStep = 1G</span></span><br><span class="line">  sz := <span class="type">int64</span>(size)</span><br><span class="line">  <span class="keyword">if</span> remainder := sz % <span class="type">int64</span>(maxMmapStep); remainder &gt; <span class="number">0</span> &#123;</span><br><span class="line">    sz += <span class="type">int64</span>(maxMmapStep) - remainder</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 对齐到 db.pageSize</span></span><br><span class="line">  pageSize := <span class="type">int64</span>(db.pageSize)</span><br><span class="line">  <span class="keyword">if</span> (sz % pageSize) != <span class="number">0</span> &#123;</span><br><span class="line">    sz = ((sz / pageSize) + <span class="number">1</span>) * pageSize</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 不能超过 maxMapSize</span></span><br><span class="line">  <span class="keyword">if</span> sz &gt; maxMapSize &#123;</span><br><span class="line">    sz = maxMapSize</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="type">int</span>(sz), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在 32位 机器上文件最大不能超过 <code>maxMapSize</code> &#x3D; 2G；在 64 位机器上，文件上限为 256T。</p>
<h3 id="读写流程"><a href="#读写流程" class="headerlink" title="读写流程"></a>读写流程</h3><p>在打开一个已经存在的 db 时，会首先将 db 文件映射到内存空间，然后解析元信息页，最后加载空闲列表。</p>
<p>在 db 进行读取时，会按需将访问路径上的 page 加载到内存，并转换为 node，进行缓存。</p>
<p>在 db 进行修改时，使用 COW 原则，所有修改不在原地，而是在改动前先复制一份。如果叶子节点 node 需要修改，则 root bucket 到该 node 路径上所涉及的所有节点都需要修改。这些节点都需要新申请空间，然后持久化，这些和事务的实现息息相关，之后会在本系列事务文章中做详细说明。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>boltdb 在数据组织方面只使用了两个概念：页（page） 和节点 （node）。每个数据库对应一个文件，每个文件中包含一系列线性组织的页。页的大小固定，依其性质不同，分为四种类型：元信息页、空闲列表页、叶子节点页、分支节点页。打开数据库时，会渐次进行以下操作：</p>
<ol>
<li>利用 mmap 将数据库文件映射到内存空间。</li>
<li>解析元信息页，获取空闲列表页 id 和 root bucket 页 id。</li>
<li>依据空闲列表页 id ，将所有空闲页列表载入内存。</li>
<li>依据 root bucket 起始页地址，解析 root bucket 根节点。</li>
<li>根据读写需求，从树根开始遍历，按需将访问路径上的数据页（分支节点页和叶子节点页）载入内存成为节点（node）。</li>
</ol>
<p>可以看出，节点分两种类型：分支节点（branch node）和叶子节点（leaf node）。</p>
<p>另外需要注意的是，由于嵌套 bucket 的存在，导致这一块稍微有点不好理解。在下一篇 boltdb 的<strong>索引设计</strong>中，将详细剖析 boltdb 是如何组织多个 bucket 以及单个 bucket 内的 B+ 树索引的。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>github，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JvbHRkYi9ib2x0">boltdb repo<i class="fa fa-external-link-alt"></i></span></li>
<li>我叫尤加利，<span class="exturl" data-url="aHR0cHM6Ly95b3VqaWFsaTE5OTUuZ2l0aHViLmlvL3N0b3JhZ2UvYm9sdGRiLw==">boltdb 源码分析<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>boltdb</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>boltdb</tag>
        <tag>kv engine</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang 笔记（三）：一种理解 Slice 的模型</title>
    <url>/2021/01/09/go-slice/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Golang 中 slice 极似其他语言中数组，但又有诸多不同，因此容易使初学者产生一些误解，并在使用时不易察觉地掉进各种坑中。本篇小文，首先从 Go 语言官方博客出发，铺陈官方给出的 slice 的相关语法；其次以图示的方式给出一种理解 slice 的模型；最后再总结分析一些特殊的使用情况，以期在多个角度对 slice 都有个更清晰侧写。</p>
<p>如不愿看繁琐叙述过程，可直接跳到最后小结看总结。</p>
<p><img src="https://i.loli.net/2021/01/20/7fhMm3SpwtyoJ6F.png" alt="go-slice-view-derive.png"></p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/01/09/go-slice/">https://www.qtmuniao.com/2021/01/09/go-slice/</a>, 转载请注明出处</em></p>
<h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><p>本部分主要出自 Go 的<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmdvbGFuZy5vcmcvc2xpY2VzLWludHJv">官方博客<i class="fa fa-external-link-alt"></i></span>。在 Go 语言中，切片（slice）和数组（array）是伴生的，切片基于数组，但更为灵活，因此在 Go 中，作为切片底层的数组反而很少用到。但，要理解切片，须从数组说起。</p>
<h3 id="数组（array）"><a href="#数组（array）" class="headerlink" title="数组（array）"></a>数组（array）</h3><p>Go 中的数组由<strong>类型+长度</strong>构成，与 C 和 C++ 不同的是，Go 中不同长度的数组是为不同的类型，并且变量名并非指向数组首地址的指针。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 数组的几种初始化方式</span></span><br><span class="line"><span class="keyword">var</span> a [<span class="number">4</span>]<span class="type">int</span>             <span class="comment">// 变量 a 类型为 [4]int 是一个 type，每个元素自动初始化为 int 的零值（zero-value）</span></span><br><span class="line">b := [<span class="number">5</span>]<span class="type">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;     <span class="comment">// 变量 b 类型为 [5]int 是不同于 [4]int 的类型，且 b[4] 会自动初始化为 int 的零值</span></span><br><span class="line">c := [...]<span class="type">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125; <span class="comment">// 变量 c 被自动推导为 [5]int 类型，与 b 类型同</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">echo</span><span class="params">(x [4]<span class="type">int</span>)</span></span> &#123;</span><br><span class="line">  fmt.Println(x)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">echo(a)         <span class="comment">// echo 调用时，a 中所有元素都会被复制一遍， 因为 Go 函数调用是传值</span></span><br><span class="line">echo(b)         <span class="comment">// error</span></span><br><span class="line">echo(([<span class="number">4</span>]<span class="type">int</span>)c) <span class="comment">// error</span></span><br></pre></td></tr></table></figure>

<p>总结一下，Go 的数组，有以下特点：</p>
<ol>
<li>长度属于类型的一部分，因此 <code>[4]int</code> 和 <code>[5]int </code> 类型的变量不能互相赋值，也不能互相强转。</li>
<li>数组变量并非指针，因此作为参数传递时会引起全量拷贝。当然，可以使用对应指针类型作为参数类型避免此拷贝。</li>
</ol>
<p>可以看出，由于存在长度这个枷锁，Go 数组的作用大大受限。Go 不能够像 C&#x2F;C++ 一样，任意长度数组都可以转换为指向相应类型的指针，进而进行下标运算。当然，Go 也不需如此，因为它有更高级的抽象——切片。</p>
<h3 id="切片（slices）"><a href="#切片（slices）" class="headerlink" title="切片（slices）"></a>切片（slices）</h3><p>在 Go 代码中，切片使用十分普遍，但切片底层基于数组：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> slice <span class="keyword">struct</span> &#123;</span><br><span class="line">    array unsafe.Pointer <span class="comment">// 指向底层数组的指针；对，golang 也是有指针的</span></span><br><span class="line">    <span class="built_in">len</span>   <span class="type">int</span>            <span class="comment">// 切片长度</span></span><br><span class="line">    <span class="built_in">cap</span>   <span class="type">int</span>            <span class="comment">// 底层数组长度</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 切片的几种初始化方式</span></span><br><span class="line">s0 := <span class="built_in">make</span>([]<span class="type">byte</span>, <span class="number">5</span>)       <span class="comment">// 借助 make 函数，此时 len = cap = 5，每个元素初始化为 byte 的 zero-value</span></span><br><span class="line">s1 := []<span class="type">byte</span>&#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>&#125; <span class="comment">// 字面值初始化，此时 len = cap = 5</span></span><br><span class="line"><span class="keyword">var</span> s2 []<span class="type">byte</span>               <span class="comment">// 自动初始化为 slice 的“零值(zero-value)”：nil</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// make 方式同时指定 len/cap，需满足 len &lt;= cap</span></span><br><span class="line">s3 := <span class="built_in">make</span>([]<span class="type">byte</span>, <span class="number">0</span>, <span class="number">5</span>) <span class="comment">// 切片长度 len = 0, 底层数组 cap = 5</span></span><br><span class="line">s4 := <span class="built_in">make</span>([]<span class="type">byte</span>, <span class="number">5</span>, <span class="number">5</span>) <span class="comment">// 等价于 make([]byte, 5)</span></span><br></pre></td></tr></table></figure>

<p>相较数组，切片有以下好处：</p>
<ol>
<li>操作灵活，顾名思义，支持强大的切片操作。</li>
<li>脱去了长度的限制，传参时，不同长度的切片都可以以 <code>[]T</code> 形式传递。</li>
<li>切片<strong>赋值</strong>、<strong>传参</strong>时不会复制整个底层数组，只会复制上述 slice 结构体本身。</li>
<li>借助一些内置函数，如 append&#x2F;copy ，可以方便的进行扩展和整体移动。</li>
</ol>
<p><strong>切片操作</strong>。使用切片操作可以对切片进行快速的截取、扩展、赋值和移动。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 截取操作，左闭右开；若始于起点，或止于终点，则可省略对应下标</span></span><br><span class="line"><span class="comment">// 新得到的切片与原始切片共用底层数组，因此免于元素复制</span></span><br><span class="line">b := []<span class="type">byte</span>&#123;<span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;g&#x27;</span>&#125;</span><br><span class="line">b1 := b[<span class="number">1</span>:<span class="number">4</span>] <span class="comment">// b1 == []byte&#123;&#x27;o&#x27;, &#x27;l&#x27;, &#x27;a&#x27;&#125;</span></span><br><span class="line">b2 := b[:<span class="number">2</span>]  <span class="comment">// b2 == []byte&#123;&#x27;g&#x27;, &#x27;o&#x27;&#125;</span></span><br><span class="line">b3 := b[<span class="number">2</span>:]  <span class="comment">// b3 == []byte&#123;&#x27;l&#x27;, &#x27;a&#x27;, &#x27;n&#x27;, &#x27;g&#x27;&#125;</span></span><br><span class="line">b4 := b[:]   <span class="comment">// b4 == b</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 扩展操作，需借助 append 函数</span></span><br><span class="line"><span class="comment">// 可能会引起底层数组的重新分配，后面会详细分析</span></span><br><span class="line"><span class="comment">// 等价于 b = append(b, []byte&#123;&#x27;,&#x27;, &#x27;h&#x27;, &#x27;i&#x27;&#125;...)</span></span><br><span class="line">b = <span class="built_in">append</span>(b, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;i&#x27;</span>) <span class="comment">// b 现为 &#123;&#x27;g&#x27;, &#x27;o&#x27;, &#x27;l&#x27;, &#x27;a&#x27;, &#x27;n&#x27;, &#x27;g&#x27;, &#x27;,&#x27;, &#x27;h&#x27;, &#x27;i&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 赋值操作，需借助 copy 函数</span></span><br><span class="line"><span class="built_in">copy</span>(b[:<span class="number">2</span>], []<span class="type">byte</span>&#123;<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;r&#x27;</span>&#125;)  <span class="comment">// b 现为 &#123;&#x27;e&#x27;, &#x27;r&#x27;, &#x27;l&#x27;, &#x27;a&#x27;, &#x27;n&#x27;, &#x27;g&#x27;, &#x27;,&#x27;, &#x27;h&#x27;, &#x27;i&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 移动操作，需借助 copy</span></span><br><span class="line"><span class="built_in">copy</span>(b[<span class="number">2</span>:], b[<span class="number">6</span>:])  <span class="comment">// 移动长度取 min(len(dst), len(src))</span></span><br><span class="line">b = b[:<span class="number">5</span>]           <span class="comment">// b 现为 &#123;&#x27;e&#x27;, &#x27;r&#x27;, &#x27;,&#x27;, &#x27;h&#x27;, &#x27;i&#x27;&#125;</span></span><br></pre></td></tr></table></figure>

<p><strong>参数传递</strong>。不同长度、容量的切片都可以通过 <code>[]T</code> 形式传递。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">b := []<span class="type">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;</span><br><span class="line">c := []<span class="type">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">echo</span><span class="params">(x []<span class="type">int</span>)</span></span> &#123;</span><br><span class="line">  fmt.Println(x)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">echo(b) <span class="comment">// 传递参数时，会重新生成一个共享底层数组，len 和 cap 都相同的切片结构体</span></span><br><span class="line">echo(c)</span><br></pre></td></tr></table></figure>

<p><strong>相关函数</strong>。切片相关的内置函数主要有：</p>
<ol>
<li>用于创建的 <strong>make</strong></li>
<li>用于扩展的 <strong>append</strong></li>
<li>用于移动的 <strong>copy</strong></li>
</ol>
<p>下面分别说说其特点。</p>
<p><strong>make</strong> 函数在创建切片时（它还可以用来创建很多其他内置结构体）的签名为 <code>func make([]T, len, cap) []T</code> 。该函数会首先创建一个 cap 长度的数组，然后新建一个 slice 结构体，指向该数组，并根据参数初始化 len 和 cap。</p>
<p><strong>append</strong> 在修改切片底层数组后，但不会改变原切片，而是返回一个具有新长度新的切片结构体。为什么不在原地修改原切片呢？因为 Go 中函数是传值的，当然这也体现了 Go 中某种函数式思想的偏好。因此，<code>append(s, &#39;a&#39;, b&#39;&#39;)</code> 并不会修改切片 s 本身，需要对 s 重新赋值：<code>s = append(s, &#39;a&#39;, b&#39;&#39;)</code>才能达到对变量 s 的修改目的。</p>
<p>需注意，append 时，如果底层数组容量（cap） 不够，会按类似于 C++ 中的 <code>vector</code> 底层机制，新建一个足够容纳所有元素的数组，并将原数组值复制过去后，再进行追加。原切片底层数组如果没有其他切片变量引用后，会由在 GC 时进行回收。</p>
<p><strong>copy</strong> 函数更像个语法糖，将对切片的批量赋值封装为一个函数，注意拷贝长度会取两个切片中较小者。并且，不用担心同一个切片的子切片移动时出现覆盖现象，举个例子：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">&quot;fmt&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 直觉认为的 copy 函数实现</span></span><br><span class="line"><span class="comment">// 但此种实现会造成同一个切片的子切片进行复制时的覆盖现象</span></span><br><span class="line"><span class="comment">// 因此 copy 在实现时应该借助了额外的空间 or 从后往前复制</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">myCopy</span><span class="params">(dst, src []<span class="type">int</span>)</span></span> &#123;</span><br><span class="line">  l := <span class="built_in">len</span>(dst)</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">len</span>(src) &lt; l &#123;</span><br><span class="line">    l = <span class="built_in">len</span>(src)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; l; i++ &#123;</span><br><span class="line">    dst[i] = src[i]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  a := []<span class="type">int</span>&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>&#125;</span><br><span class="line">  </span><br><span class="line">  <span class="built_in">copy</span>(a[<span class="number">3</span>:], a[<span class="number">2</span>:])      <span class="comment">// a = [0 1 3 3 4 5]</span></span><br><span class="line">  <span class="comment">// myCopy(a[3:], a[2:]) // a = [0 1 3 3 3 3]</span></span><br><span class="line">  fmt.Println(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>copy</code> 一个常见的使用场景是，需要往切片中间插入一个元素时，用 <code>copy</code> 将插入点之后的片段整体后移。</p>
<h2 id="切片模型"><a href="#切片模型" class="headerlink" title="切片模型"></a>切片模型</h2><p>初用切片时，常常感觉其规则庞杂，难以尽记；于是我常想有没有什么合适的模型来刻画切片的本质。</p>
<p>某天突然冒出个不成熟的想法：切片是隐藏了底层数组的一种线性<strong>读写视图</strong>。切片这种视图规避了 C&#x2F;C++ 语言中常见的指针运算操作，因为用户可以通过切片派生来免于算偏移量。</p>
<p>切片仅用 <code>ptr/cap/len</code> 三个变量来刻画一个窗口视图，其中 <code>ptr</code> 和 <code>ptr+cap</code> 是窗口的起止界限，<code>len</code> 是当前窗口可见长度。可以通过下标来切出一个新的视图，Go 会自动计算新的 ptr&#x2F;len&#x2F;cap ，所有通过切片表达式派生的视图都指向同一个底层数组。</p>
<p><img src="https://i.loli.net/2021/01/20/7fhMm3SpwtyoJ6F.png" alt="go slice 视图"></p>
<p>切片派生会<strong>自动</strong>共享底层数组，以避免数组拷贝，提升效率；追加元素时，如果底层数组容量不够，<code>append</code> 会<strong>自动</strong>创建新数组并返回指向新数组的切片视图，而原来切片视图仍然指向原数组。</p>
<h2 id="切片使用"><a href="#切片使用" class="headerlink" title="切片使用"></a>切片使用</h2><p>本小节将汇总一些 slice 使用时的一些有意思的点。</p>
<p><strong>零值（zero-value）和空值（empty-value）</strong>。go 中所有类型都是有零值的，并以其作为初始化时的默认值。slice 的零值是 nil。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">add</span><span class="params">(a []<span class="type">int</span>)</span></span> []<span class="type">int</span> &#123; <span class="comment">// nil 可以作为参数传给 []int 切片类型</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">append</span>(a, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  fmt.Println(add(<span class="literal">nil</span>)) <span class="comment">// [0 1 2]</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以通过 make 创建一个空 slice，其 len&#x2F;cap 与零值一致，但是也会有如下小小区别，如两者皆可，推荐用 nil。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  a := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">0</span>)</span><br><span class="line">  <span class="keyword">var</span> b []<span class="type">int</span></span><br><span class="line">  </span><br><span class="line">  fmt.Println(a, <span class="built_in">len</span>(a), <span class="built_in">cap</span>(a)) <span class="comment">// [] 0 0</span></span><br><span class="line">  fmt.Printf(<span class="string">&quot;%#v\n&quot;</span>, a)         <span class="comment">// []int&#123;&#125;</span></span><br><span class="line">  fmt.Println(a==<span class="literal">nil</span>)            <span class="comment">// false</span></span><br><span class="line">  </span><br><span class="line">  fmt.Println(b, <span class="built_in">len</span>(b), <span class="built_in">cap</span>(b)) <span class="comment">// [] 0 0</span></span><br><span class="line">  fmt.Printf(<span class="string">&quot;%#v\n&quot;</span>, b)         <span class="comment">// []int(nil)</span></span><br><span class="line">  fmt.Println(b==<span class="literal">nil</span>)            <span class="comment">// true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>append 语义</strong>。append 会首先将元素追加到底层数组，然后构造一个新的 slice 返回。也就是说，即使我们不使用返回值，相应的值也会被追加到底层数组。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  a := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line">  _ = <span class="built_in">append</span>(a, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">  fmt.Println(a)     <span class="comment">// []</span></span><br><span class="line">  fmt.Println(a[:<span class="number">5</span>]) <span class="comment">// [0 1 2 0 0]；通过切片表达式，扩大窗口长度，就可以看到追加的值</span></span><br><span class="line">  fmt.Println(a[:<span class="number">6</span>]) <span class="comment">// panic；长度越界了</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>从 array 生成 slice</strong>。可以通过切片语法，通过数组 a 生成所需长度切片 s ，此时：<strong>s 底层数组即为 a</strong>。换言之，<strong>对数组使用切片语法也不会造成数组的拷贝</strong>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  a := [<span class="number">7</span>]<span class="type">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;</span><br><span class="line">  s := a[:<span class="number">4</span>]</span><br><span class="line">  fmt.Println(s) <span class="comment">// [1 2 3 0]</span></span><br><span class="line">  </span><br><span class="line">  a[<span class="number">3</span>] = <span class="number">4</span>       <span class="comment">// 修改 a，s 相应值也跟着变化，说明 s 的底层就是 a</span></span><br><span class="line">  fmt.Println(s) <span class="comment">// [1 2 3 4]</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>切片时修改视图右界</strong>。在上述提出的视图模型中，进行切片操作时，新生成的切片<strong>左界</strong>限会随着 start 参数而变化，但是<strong>右界</strong>一直未变，即为底层数组结尾。如果我们想修改其右界，可以通过三参数切片（Full slice Expression），增加一个 limited-capacity 参数。</p>
<p>该特性的一个使用场景是，如果我们想让新的 slice 在 append 时不影响原数组，就可以通过修改其右界，在 append 时发现 cap 不够强制生成一个新的底层数组。</p>
<p><img src="https://i.loli.net/2021/01/20/OIygENcWpd8S6ZB.png" alt="go-full-slice-view-derive.png"></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文核心目的在于提出一个易于记忆和理解 slice 模型，以拆解 slice 使用时千变万化的复杂度。总结一下，我们在理解 slice 时，可以从两个层面来入手：</p>
<ol>
<li>底层数据（底层数组）</li>
<li>上层视图（切片）</li>
</ol>
<p>视图有三个关键变量，数组指针（ptr）、有效长度（len）、视图容量（cap）。</p>
<p>通过切片表达式（slice expression）可以从数组生成切片、从切片生成切片，此操作不会发生数组数据的拷贝。通过 append 进行追加操作时，根据本视图的 cap 而定是否进行数组拷贝，并返回一个指向新数组的视图。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>酷壳 coolshell ：  <span class="exturl" data-url="aHR0cHM6Ly9jb29sc2hlbGwuY24vYXJ0aWNsZXMvMjExMjguaHRtbA==">Go编程模式：切片，接口，时间和性能<i class="fa fa-external-link-alt"></i></span></li>
<li>The Go Blog：  <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmdvbGFuZy5vcmcvc2xpY2VzLWludHJv">Go slices：usage and internals<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<hr>
]]></content>
      <categories>
        <category>编程语言</category>
        <category>Go</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>slice</tag>
        <tag>golang 编程范式</tag>
      </tags>
  </entry>
  <entry>
    <title>Cmu15445 数据库系统实验一：Buffer Pool Manager</title>
    <url>/2021/02/10/cmu15445-project1-buffer-pool/</url>
    <content><![CDATA[<blockquote>
<p>cmu15445 是一门关于数据库管理系统（DBMS）设计与实现的经典公开课。该课程以 <span class="exturl" data-url="aHR0cHM6Ly93d3cuZGItYm9vay5jb20vZGI3L2luZGV4Lmh0bWw=">Database System Concepts<i class="fa fa-external-link-alt"></i></span> 为教材，提供随堂讲义、笔记和视频，精心准备了几个互相勾连的小实验。该课程十分注重系统设计和编程实现，用主讲教授 <span class="exturl" data-url="aHR0cDovL3d3dy5jcy5jbXUuZWR1L35wYXZsby8=">Andy Pavlo<i class="fa fa-external-link-alt"></i></span> 的话说，这是一门可以写在简历上、并且能帮你拿到好 offer 的课程。</p>
<p>这个假期得空，翻出这门课程，即被其翔实的内容、精当的组织所折服。无奈时间有限，只能以<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvYXNzaWdubWVudHMuaHRtbA==">实验<i class="fa fa-external-link-alt"></i></span>为主线，辅以<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvc2xpZGVzLw==">讲义<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvbm90ZXMv">笔记<i class="fa fa-external-link-alt"></i></span>，简单跟一跟。如果再有时间，就去扫下<span class="exturl" data-url="aHR0cHM6Ly93d3cuZGItYm9vay5jb20vZGI3L2luZGV4Lmh0bWw=">教材<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj1vZVlCZGdoYUlqYyZsaXN0PVBMU0U4T0RoalpYamJvaGtOQldRc19vdFRyQlRyanlvaGk=">视频<i class="fa fa-external-link-alt"></i></span>。从实验一开始，每个实验 <span class="exturl" data-url="aHR0cHM6Ly93d3cuZ3JhZGVzY29wZS5jb20v">autograder<i class="fa fa-external-link-alt"></i></span> 跑过之后，出一篇笔记，聊以备忘。 <span class="exturl" data-url="aHR0cDovL3d3dy5jcy5jbXUuZWR1L35wYXZsby8=">Andy Pavlo<i class="fa fa-external-link-alt"></i></span>  教授建议不要公开实验代码仓库，因此文章尽量少贴代码，多写思路。</p>
<p>本篇是实验一，管理文件系统的页在内存中的缓存 —— buffer pool manager。</p>
</blockquote>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>实验的目标系统 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NtdS1kYi9idXN0dWI=">BusTub<i class="fa fa-external-link-alt"></i></span> 是一个面向磁盘的 DBMS，但磁盘上的数据不支持字节粒度的访问。这就需要一个管理页的中间层，但 <span class="exturl" data-url="aHR0cDovL3d3dy5jcy5jbXUuZWR1L35wYXZsby8=">Andy Pavlo<i class="fa fa-external-link-alt"></i></span>  教授坚持不使用 mmap 将页管理权力让渡给操作系统，因此<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvcHJvamVjdDEv">实验一<i class="fa fa-external-link-alt"></i></span> 的目标便在于主动管理磁盘中的页（page）在内存中的缓存，从而，最小化磁盘访问次数（时间上）、最大化相关数据连续（空间上）。</p>
<p>该实验可以分解为相对独立的两个子任务：</p>
<ol>
<li>维护替换策略的： LRU replacement policy</li>
<li>管理缓冲池的： buffer pool manager</li>
</ol>
<p>两个组件都要求线程安全。</p>
<p>本文首先从基本概念、核心数据流总体分析下实验内容，然后分别对两个子任务进行梳理。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/02/10/cmu15445-project1-buffer-pool/">https://www.qtmuniao.com/2021/02/10/cmu15445-project1-buffer-pool/</a>, 转载请注明出处</em></p>
<h2 id="实验分析"><a href="#实验分析" class="headerlink" title="实验分析"></a>实验分析</h2><p>刚开始写实验代码的时候，感觉细节很多，实现时很容易丢三落四。但随着实现和思考的深入，渐渐摸清了全貌，发现只要明确几个基本概念和核心数据流，便能够提纲挈领。</p>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>buffer pool 的操作的基本单位为一段逻辑连续的字节数组，在磁盘上表现为<strong>页（page）</strong>，有唯一的标识 <strong>page_id</strong>；在内存中表现为<strong>帧（frame）</strong>，有唯一的标识 <strong>frame_id</strong>。为了记下哪些 frame 存的哪些 page，需要使用一个<strong>页表（page table）</strong>。</p>
<p>下边行文可能会混用 page 和 frame，因为这两个概念都是 buffer pool 管理数据的<strong>基本单位</strong>，一般为 4k，其区别如下：</p>
<ol>
<li>page id 是这一段单位数据的全局标识，而 frame id 只是在内存池（frame 数组）中索引某个 page 下标</li>
<li>page 在文件系统中是一段逻辑连续的字节数组；在内存中，我们会给其附加一些元信息：<code>pin_count_</code>，<code>is_dirty_</code></li>
</ol>
<p><img src="https://i.loli.net/2021/02/19/7QSY5EtFwKxuiVN.png" alt="基本概念"></p>
<p>而管理帧的内存池大小一般来说是远小于磁盘的，因此在内存池满了后，再从磁盘加载新的页到内存池，需要<strong>某种替换策略（replacer）</strong>将一些不再使用的页踢出内存池以腾出空间。</p>
<h3 id="核心数据流"><a href="#核心数据流" class="headerlink" title="核心数据流"></a>核心数据流</h3><p>先说结论，buffer pool manager 的<strong>实现核心</strong>，在于对内存池中所有 frame 的状态的管理。因此，如果我们能梳理出 frame 的状态机，便可以把握好核心数据流。</p>
<p>buffer pool 维护了一个 frame 数组，每个 frame 有三种状态：</p>
<ol>
<li><strong>free</strong>：初始状态，没有存放任何 page</li>
<li><strong>pinned</strong>：存放了 thread 正在使用的 page</li>
<li><strong>unpinned</strong>：存放了 page，但 page 已经不再为任何 thread 所使用</li>
</ol>
<p>而待实现函数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">FetchPageImpl</span>(page_id)</span><br><span class="line"><span class="built_in">NewPageImpl</span>(page_id)</span><br><span class="line"><span class="built_in">UnpinPageImpl</span>(page_id, is_dirty)</span><br><span class="line"><span class="built_in">DeletePageImpl</span>(page_id)</span><br></pre></td></tr></table></figure>

<p>便是驱动状态机中上述状态发生改变的动作（action），状态机如下：</p>
<p><img src="https://i.loli.net/2021/02/19/VOH78FybK96IcSq.png" alt="frame 状态机"></p>
<p>对应到实现时数据结构上：</p>
<ol>
<li>保存 page 数据的 frame 数组为 <code>pages_</code> </li>
<li>所有 <strong>free</strong>  frame 的索引（frame_id）保存在 <code>free_list_</code> 中</li>
<li>所有 <strong>unpinned</strong>  frame 的索引保存在 <code>replacer_</code> 中</li>
<li>所有 <strong>pinned</strong>  frame 索引和 <strong>unpinned</strong> frame 的索引保存在 <code>page_table_</code> 中，并通过 page 中 <code>pin_count_</code> 字段来区分两个状态。</li>
</ol>
<p>上图中，NewPage1 和 NewPage2 表示在 <code>NewPage</code> 函数中，每次获取空闲 frame 时，会先去空闲列表（<code>freelist_</code>）中取一个 free frame，如果取不到，才会去 <code>replacer_</code> 中驱逐一个 unpinned 的 frame 后使用。这体现了 buffer pool manager 实现的一个目标：最小化磁盘访问，原因后面分析。</p>
<h2 id="实验组件"><a href="#实验组件" class="headerlink" title="实验组件"></a>实验组件</h2><p>把握了本实验的基本概念和核心数据流后，再来分析两个子任务。</p>
<h3 id="TASK-1-LRU-REPLACEMENT-POLICY"><a href="#TASK-1-LRU-REPLACEMENT-POLICY" class="headerlink" title="TASK #1 - LRU REPLACEMENT POLICY"></a>TASK #1 - LRU REPLACEMENT POLICY</h3><p>以前在 LeetCode 上写过相关实现，因此很自然的带入之前经验，但随后发现这两个接口有一些不同。</p>
<p>LeetCode 上提供的是 <strong>kv store 接口</strong>，在 get&#x2F;set 的时候完成新老顺序的维护，并在内存池满后自动替换最老的 KV。</p>
<p>但本实验提供的是 <strong>replacer 接口</strong>，维护一个 unpinned 的 frame_id 列表 ，在调用  <code>Unpin</code> 时将 frame_id 加入列表并维护新老顺序、在调用 <code>Pin</code> 时将 frame_id 从列表中摘除、在调用 <code>Victim</code> 的时候将最老的 frame_id 返回。</p>
<p>当然，本质上还是一样，因此本实验我也是采用 unordered_map 和 doubly linked list 的数据结构，实现细节不再赘述。需要注意的是，如果 <code>Unpin</code> 时发现 frame_id 已经在 replacer 中，则直接返回，并不改变列表的新老顺序。因为逻辑上来说，同一个 frame_id，并不能被 <code>Unpin</code> 多次，因此我们只需要考虑 frame_id 第一次 Unpin。</p>
<p>放到更大的语境中，本质上，replacer 就是一个维护了回收顺序的<strong>回收站</strong>，即我们将所有 <code>pin_count_ = 0</code> 的 page 不直接从内存中删除，而是放入回收站中。根据数据访问的时间<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTG9jYWxpdHlfb2ZfcmVmZXJlbmNl">局部性原理<i class="fa fa-external-link-alt"></i></span>，刚刚被访问的 page 很可能再次被访问，因此当我们不得不从回收站中真删（<code>Victim</code>）一个 frame 时，需要删最老的 frame。当之后我们想访问一个刚加入回收站的数据时， 只需要将 page 从这个回收站中捞出来，从而省去一次磁盘访问，这也就达到了最小化磁盘访问的目标。</p>
<h3 id="TASK-2-BUFFER-POOL-MANAGER"><a href="#TASK-2-BUFFER-POOL-MANAGER" class="headerlink" title="TASK #2 - BUFFER POOL MANAGER"></a>TASK #2 - BUFFER POOL MANAGER</h3><p>在实验分析部分已经把核心逻辑说的差不多了，这里简单罗列一下我实现中遇到的问题。</p>
<p><strong><code>page_table_</code> 的范围</strong>。在最初实现时，画出 frame 的状态机之后，感觉 <code>page_table_</code> 中只放 pinned frame id 很完美：可以使 frame id 按状态互斥的分布在 <code>free_list_</code> 、 <code>replacer_</code> 和 <code>page_table_</code> 中。但后来发现，如果不将 unpinned frame id 保存在 <code>page_table_</code> 中，就不能很好地复用 <code>pin_count_</code> &#x3D; 0 的 page 了，replacer 也就没有了意义。</p>
<p><strong>dirty page 的刷盘时机</strong>。有两种策略，一种是每次 <code>Unpin</code> 的时候都刷，这样会刷比较频繁，但能保证异常掉电重启后内容不丢；一种是在 replacer victimized 的时候 lazily 的刷，这样能保证刷的次数最少。这是性能和可靠性取舍，仅考虑本实验，两者肯定都能过。</p>
<p><strong><code>NewPage</code> 不要读盘</strong>。这个就是我写的 bug 了，毕竟 <code>NewPage</code> 的时候，磁盘上根本没有对应 page 的内容，因此会报如下错误：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2021-02-18 16:53:47 [autograder/bustub/src/storage/disk/disk_manager.cpp:121:ReadPage] DEBUG - Read less than a page</span><br><span class="line">2021-02-18 16:53:47 [autograder/bustub/src/storage/disk/disk_manager.cpp:108:ReadPage] DEBUG - I/O error reading past end of file</span><br></pre></td></tr></table></figure>

<p><strong>复用 frame 时清空元信息</strong>。在复用一个从 replacer 中驱逐的 frame 时尤其要注意，使用前一定要将 <code>pin_count_\is_dirty_</code> 这些字段清空。当然，在 <code>DeletePage</code> 的时候，也需要注意将 <code>page_id_</code> 置为 <code>INVALID_PAGE_ID</code> 、清空上述字段。否则，再次使用时， 如果 <code>pin_count_</code> 在 <code>Unpin</code> 后，数值不为 0，会导致 <code>DeletePage</code> 时删不掉该 page。</p>
<p><strong>锁的粒度</strong>。最粗暴的就是每个函数范围粒度加锁即可，后期如果需要优化，再将锁的粒度变细。</p>
<h2 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h2><p>以 <code>FetchPageImpl</code> 为例强调下一些实现的细节，注意到，实验已经通过注释给出了实现框架。</p>
<p>我使用中文注释注出了一些我认为需要注意的点。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Page *<span class="title">BufferPoolManager::FetchPageImpl</span><span class="params">(<span class="type">page_id_t</span> page_id)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// a. 使用自动获取和释放锁</span></span><br><span class="line">  <span class="function">std::scoped_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(latch_)</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 1.     Search the page table for the requested page (P).</span></span><br><span class="line">  <span class="comment">// 1.1    If P exists, pin it and return it immediately.</span></span><br><span class="line">  <span class="keyword">auto</span> target = page_table_.<span class="built_in">find</span>(page_id); <span class="comment">// b. 判断存在与访问数据只用一次查找</span></span><br><span class="line">  <span class="keyword">if</span> (target != page_table_.<span class="built_in">end</span>()) &#123;</span><br><span class="line">    <span class="type">frame_id_t</span> frame_id = target-&gt;second;</span><br><span class="line">    <span class="comment">// c. 通过指针运算获取 frame_id 处存放的 Page 结构体</span></span><br><span class="line">    Page *p = pages_ + frame_id; </span><br><span class="line">    p-&gt;pin_count_++;</span><br><span class="line">    replacer_-&gt;<span class="built_in">Pin</span>(frame_id); <span class="comment">// d. 将对应 page 从“回收站”中捞出</span></span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 1.2    If P does not exist, find a replacement page (R) from either the free list or the replacer.</span></span><br><span class="line">  <span class="comment">//        Note that pages are always found from the free list first.</span></span><br><span class="line">  <span class="type">frame_id_t</span> frame_id = <span class="number">-1</span>; </span><br><span class="line">  Page *p = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="keyword">if</span> (!free_list_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    frame_id = free_list_.<span class="built_in">back</span>(); <span class="comment">// e. 在结尾处操作效率高一点</span></span><br><span class="line">    free_list_.<span class="built_in">pop_back</span>();</span><br><span class="line">    <span class="built_in">assert</span>(frame_id &gt;= <span class="number">0</span> &amp;&amp; frame_id &lt; <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(pool_size_));</span><br><span class="line">    p = pages_ + frame_id;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// f. 从 freelist 中获取的 dirty page 已经在 delete 时写回了</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">bool</span> victimized = replacer_-&gt;<span class="built_in">Victim</span>(&amp;frame_id);</span><br><span class="line">    <span class="keyword">if</span> (!victimized) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">assert</span>(frame_id &gt;= <span class="number">0</span> &amp;&amp; frame_id &lt; <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(pool_size_));</span><br><span class="line">    p = pages_ + frame_id;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.     If R is dirty, write it back to the disk.</span></span><br><span class="line">    <span class="keyword">if</span> (p-&gt;<span class="built_in">IsDirty</span>()) &#123;</span><br><span class="line">      disk_manager_-&gt;<span class="built_in">WritePage</span>(p-&gt;<span class="built_in">GetPageId</span>(), p-&gt;<span class="built_in">GetData</span>());</span><br><span class="line">      p-&gt;is_dirty_ = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    p-&gt;pin_count_ = <span class="number">0</span>; <span class="comment">// g. 将元信息 pin_count_ 清空</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 3.     Delete R from the page table and insert P.</span></span><br><span class="line">  page_table_.<span class="built_in">erase</span>(p-&gt;<span class="built_in">GetPageId</span>()); <span class="comment">// h. 时刻注意区分 p-&gt;GetPageId() 与 page_id 是否相等，别混用</span></span><br><span class="line">  page_table_[page_id] = frame_id;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 4.     Update P&#x27;s metadata, read in the page content from disk, and then return a pointer to P.</span></span><br><span class="line">  p-&gt;page_id_ = page_id;</span><br><span class="line">  p-&gt;<span class="built_in">ResetMemory</span>();</span><br><span class="line">  disk_manager_-&gt;<span class="built_in">ReadPage</span>(page_id, p-&gt;<span class="built_in">GetData</span>());</span><br><span class="line">  p-&gt;pin_count_++;</span><br><span class="line">  <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实验相关 autograder 可以在 <span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvZmFxLmh0bWw=">FAQ<i class="fa fa-external-link-alt"></i></span> 中找到注册地址和邀请码，提交代码的时候最好不要提交 github 仓库地址，会有很多格式问题。可以每次按照实验页面的指示，将相关文件按目录结构达成 zip 包提交即可。</p>
<p><img src="https://i.loli.net/2021/02/19/5rScRYv8xPtFq39.png" alt="提交事项"></p>
<p> 仔细阅读<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvcHJvamVjdDEv">实验描述<i class="fa fa-external-link-alt"></i></span>，提交前需要注意的事项：</p>
<ol>
<li>在 build 目录运行 make format ，自动格式化。</li>
<li>在 build 目录运行 make check-lint，检查一些语法问题。</li>
<li>自己针对每个函数在本地设计一些测试，写到相关文件（本实验 buffer_pool_manager_test.cpp ）中，并且打开测试开关，在 build 文件夹下，编译 <code>make buffer_pool_manager_test</code>，运行 <code>./test/buffer_pool_manager_test</code></li>
</ol>
<p>贴一个 project1 autograder 的实验结果：</p>
<p><img src="https://i.loli.net/2021/02/19/FyefbnZIJUKYMjc.png" alt="autograder-result"></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这是 cmu15445 第一个实验，实现了在磁盘和内存间按需搬运页（page）的 buffer pool manager。本实验的关键之处在于把握基本概念，梳理出核心数据流，在此基础上注意一些实现的细节即可。</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>cmu</tag>
        <tag>15445</tag>
        <tag>database systems</tag>
        <tag>buffer pool</tag>
      </tags>
  </entry>
  <entry>
    <title>Facebook Delos 中的虚拟共识协议</title>
    <url>/2021/03/14/facebook-delos/</url>
    <content><![CDATA[<blockquote>
<p>本文整理自OSDI 2020 Virtual Consensus in Delos 论文演讲，探讨了分布式系统中控制面的存储系统，提出了一种基于分层抽象思想的分布式架构。其核心在于提出了一种逻辑协议层，使得物理层可以按需进行实现和移植，有点类似于单机系统中虚拟内存之于物理内存的味道。</p>
</blockquote>
<span id="more"></span>

<p><em>作者：木鸟杂记  <a href="https://www.qtmuniao.com/2021/03/14/facebook-delos/">https://www.qtmuniao.com/2021/03/14/facebook-delos/</a> , 转载请注明出处</em></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Facebook 的软件系统栈一般包括两层：上层是数据平面， 下层是控制平面。</p>
<p><img src="https://i.loli.net/2021/03/14/K69lS8LIh57OdnZ.png" alt="facebook software stack"></p>
<p>数据平面包括大量的服务，他们需要存储和处理海量数据。控制平面用来支撑数据平面，起到一些控制作用：调度、配置、命名、切片等等。控制平面通常是有状态的，比如控制的元信息，为了存储这些元信息，控制平面需要有自己的存储。控制平面对存储有以下要求：</p>
<ol>
<li>容错：零依赖、可持久化、高可用。</li>
<li>丰富的 API：事务，范围查询，二级索引。</li>
</ol>
<p>在 17 年的时候，  Facebook 使用几种组件来充当控制平面的存储，包括：</p>
<ol>
<li>MySQL：API 丰富，表达能力强，但是不支持容错。</li>
<li>ZooKeeper：容错，零依赖，但是 API 表达能力弱。</li>
</ol>
<p>可以看出，他们都不能很好的同时满足控制平面对存储的需求。此外，作为单体架构，上述组件都比较难改造成同时支持容错和丰富 API 的系统。此外，还有一大问题，团队当时所面临的工期非常紧。最终，他们交出的答卷是 —— Delos。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>Delos 是一个基于共享日志（shared log）的控制面存储系统。db 层的实例通过 append 和 read 与共享日志进行交互，从而保持对外状态的一致性。根据近几十年的研究，使用共享日志作为 API，可以很好的向 db 层隐藏共识协议的大量细节。</p>
<p><img src="https://i.loli.net/2021/03/14/ZRxKvi8UTp2juPY.png" alt="design based sharedlog"></p>
<h3 id="读写流程"><a href="#读写流程" class="headerlink" title="读写流程"></a>读写流程</h3><p><img src="https://i.loli.net/2021/03/14/y83jTcWDXtILAGF.png" alt="read write procedure via shared log"></p>
<p>存储服务可以分为两层，db API 层和共享日志 runtime 层。如上图，以表格存储为例，在上层，DelosTable 负责提供表格存储的 API；在下层，DelosRuntime 负责共享日志的读写。则，一个典型的写流程如下：</p>
<ol>
<li>客户端发起一个写请求</li>
<li>DelosTable 层将其转发给 DelosRuntime</li>
<li>DelosRuntime 将该请求序列化后追加到共享日志</li>
<li>各个服务器侦听到该追加后，读取其内容，以同一种顺序将其应用到本地状态机</li>
</ol>
<p>在该架构中，有两个关键的设计点：</p>
<ol>
<li>共享日志层提供了具有线性一致性保证的极简 API</li>
<li>基于该简明 API，上层可以方便的提供不同存储接口的实现</li>
</ol>
<h3 id="虚拟共识"><a href="#虚拟共识" class="headerlink" title="虚拟共识"></a>虚拟共识</h3><p>到此为止，该架构设计看起来相当简单，但我们知道，复杂性只能被转移，但不可能凭空消失。可以看到，最复杂的共识协议被隐藏在了共享日志后面，于是问题随之而来：</p>
<ol>
<li>我们需要如何快速实现一个满足共识协议的的共享日志组件？</li>
<li>随着技术的发展，如果我们之后想用更好的共识协议，该如何进行替换？</li>
</ol>
<p>为了解决这些问题，Delos 提出了<strong>虚拟共识</strong>（<strong>Virtual Consensus</strong>）。通过抽象出一层虚拟共识协议，Delos 的共享日志组件可以快速复用现有实现，比如 Zookeeper；之后为了提高性能，也可以借助此该层对下层进行不停机迁移。</p>
<p>在 Delos 中，虚拟共识协议的承载层被称为 <strong>VirtualLog</strong>。对上，db 层基于 VirtualLog 层进行实现；对下，VirtualLog 被映射成一组物理共享日志，称为 <strong>Loglets</strong>。每个 loget 提供和共享日志同样的 API，外加一个 seal 命令。 一旦被 seal，Loglet 便不再接受追加。为了存储 VirtualLog 逻辑空间到 Loglets 物理空间的映射，Delos 引入了新的组件： <strong>MetaStore</strong>。</p>
<p>MetaStore 是一个带版本的简单 KV 存储。通过存储的不同版本的 Loglet 的切换，VirtualLog 就自然的将流量打到新的 Loglet 上。如下图展示了 VirtualLog 向 MetaStore put 一个新版本（ver0 -&gt; ver1）的映射信息，将流量无宕机的从 Zookeeper 切换到了 LogDevice 的过程 。</p>
<p><img src="https://i.loli.net/2021/03/14/M8HJ7LX3m14NxpD.png" alt="virtualizing consensus via the VirtualLog"></p>
<h2 id="定制-Loglet"><a href="#定制-Loglet" class="headerlink" title="定制 Loglet"></a>定制 Loglet</h2><p>在满足基本需求后，为了进一步提升性能，Delos 想自己定制 Loglet，以满足以下特点：</p>
<ol>
<li>简单：simple</li>
<li>快速：fast</li>
<li>容错：fault tolerant</li>
</ol>
<h3 id="NativeLoglet"><a href="#NativeLoglet" class="headerlink" title="NativeLoglet"></a>NativeLoglet</h3><p>只实现其中两点，比较容易；若要三者皆得，有点困难。Delos 通过分治策略，将其分解为两个组件：</p>
<ol>
<li>MetaStore：进行容错</li>
<li>Loglet：专注性能</li>
</ol>
<p>此时，所有一致性的来源便都移到了 MetaStore 之上。 而 MetaStore 功能相对简单，只需保存空间映射，并提供容错的 <strong>reconfiguration</strong> 源语（即对映射进行操作，比如 loglet 切换），且 reconfiguration 是个低频操作。因此 MetaStore 的实现无需关注性能优化，只需要按照 Lamport 最初的 Paxos 进行实现即可，可以保证 MetaStore 实现的简洁性。</p>
<p>同时，将 Loglet 职能弱化，不再需要提供完全的容错机制，只需提供一个高可用的 seal 命令即可。如此一来，当一个 Loget 不可用时，VirtualLog 只需将其 seal，然后将流量切向其他 Loglet 即可。</p>
<p>据此，Delos 实现了新的 Loglet 实例——<strong>NativeLoglet</strong> 。</p>
<p> <img src="https://i.loli.net/2021/03/14/aIFxzr2EpYmbluf.png" alt="the NativeLoglet"></p>
<p>直观感觉来说，NativeLoglet 类似一个弱化版的 LogDevice。其交互流程如下：</p>
<ol>
<li>正常运行时，集群中某个 LogServer 充当 Sequencer</li>
<li>所有 DelosRuntime 发出的 Append 请求都要通过 Sequencer 定序后，追加到各个 LogServer</li>
<li>当 Sequencer 所在 LogServer 宕机后，DelosRuntime 直接向所有 LogServer 发送 CheckTail 请求，以 quorum 协议确定 tail</li>
<li>所有 DelosRuntime 都可以发起 seal 请求，对 NativeLoglet 进行 seal</li>
</ol>
<p>注意，NativeLoget 中所有 LogServer 可以和 DelosRuntime 部署在一块（称作 Converged 模式），也可以单独部署（称作 Disaggregated 模式）。前者能够获取更好的本地读性能，并且让数据库实例和日志实例生命周期绑定。后者将数据库层和日志层分离，可以避免不同层的资源争夺，并允许各自按需伸缩。</p>
<p><img src="https://i.loli.net/2021/03/14/Namb2vlGL5kcXP3.png" alt="converged vs disaggregated"></p>
<p>下图是一个替换 NativeLoglet 后的性能提升对比：</p>
<p><img src="https://i.loli.net/2021/03/14/4W3M8gxISfwUVJk.png" alt="NativeLoglet compare"></p>
<h3 id="StripedLoglet"><a href="#StripedLoglet" class="headerlink" title="StripedLoglet"></a>StripedLoglet</h3><p> 为了进一步提升性能，在 VirtualLog 的抽象下，Delos 利用分片思想又造出了一种叫做 <strong>StripedLoglet</strong> 的实现。该实现在底层组合了多个 Loglets 实例，当 Append 请求到来时，将其 round robin 的打到各个底层 Loglet 系统中，从而极大提升性能。</p>
<p>此外，StripedLoglet 允许多个 DelosRuntime 使用不同策略进行并行 Append，并且允许暂时的空洞存在，之后使用类似滑动窗口的机制，进行捎带 ACK，从而进一步提升性能。</p>
<p>底层多个 Loglet 系统可以视情况共享一个集群或分散到多个集群。</p>
<p><img src="https://i.loli.net/2021/03/14/Chg4esWOuHBXk8a.png" alt="striped loglet"></p>
<h2 id="The-Last-Thing：VirtualLog-Triming"><a href="#The-Last-Thing：VirtualLog-Triming" class="headerlink" title="The Last Thing：VirtualLog Triming"></a>The Last Thing：VirtualLog Triming</h2><p>此外值得一说的细节是，VirtualLog 提供的 Trim 操作。得益于虚拟化的抽象，Delos 可以通过删除映射，将老的日志进行移除。当然，一种更好的做法是，将老的日志移动到 BackupLoget 的冷集群中，然后改变映射，对外提供一种无限日志的抽象，进而允许按年龄对不同日志段进行细粒度的存储控制。</p>
<p>另一方面，通过修改 MetaStore 中的映射，Delos 允许修改单个日志记录，对某些有问题的日志进行删除，以避免系统 hang 住或者反复重启宕机。这是之前的一致性协议无法做到的。</p>
<p><img src="https://i.loli.net/2021/03/14/LSXWgwsxFVO6cQa.png" alt="trimming the VirtualLog"></p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>Delos 位于 Facebook 系统的底层（用于控制面的存储），它采用分层的设计，使得：</p>
<ol>
<li>在项目之初，可以在某些层复用现有系统，进行快速上线，投入使用。</li>
<li>在上线之后，允许不停机的替换更高性能的组件、实验更新的一致性协议。</li>
</ol>
<p><img src="https://i.loli.net/2021/03/14/UzctHaiYvb9pFfh.png" alt="summary"></p>
<p>虚拟共识之于分布式系统，有点像虚拟内存之于单机系统，通过分层解耦，使得设计者在系统构建时有更多腾挪空间。至于该思想是否能够实至名归，还得等待时间和实践的检验。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><p>OSDI 20 该论文的讲解视频：<span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj13ZC1HQ19YaEEyZw==">https://www.youtube.com/watch?v=wd-GC_XhA2g<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>谷歌工程文章：<span class="exturl" data-url="aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vMjAxOS8wNi8wNi9kYXRhLWNlbnRlci1lbmdpbmVlcmluZy9kZWxvcy8=">https://engineering.fb.com/2019/06/06/data-center-engineering/delos/<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p>论文 Virtual Consensus in Delos：<span class="exturl" data-url="aHR0cHM6Ly9yZXNlYXJjaC5mYi5jb20vcHVibGljYXRpb25zL3ZpcnR1YWwtY29uc2Vuc3VzLWluLWRlbG9zLw==">https://research.fb.com/publications/virtual-consensus-in-delos/<i class="fa fa-external-link-alt"></i></span></p>
</li>
</ol>
<hr>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>Facebook</tag>
        <tag>Delos</tag>
        <tag>共识协议</tag>
      </tags>
  </entry>
  <entry>
    <title>Cmu15445 课程介绍</title>
    <url>/2021/02/15/cmu15445-introduction/</url>
    <content><![CDATA[<h2 id="小引"><a href="#小引" class="headerlink" title="小引"></a>小引</h2><p>大学时，数据库学的不是很深，现在有印象的也就 SQL、ER 图、范式、事务等<strong>使用上</strong>的寥寥概念。对于其<strong>实现上</strong>一直没有过系统性的了解，但既然走上了存储这条路，数据库知识肯定要补一下。先前，知乎上很多地方看到大家推荐 cmu15445 这门课，也早就将课程主页收藏到了文件夹，但一直没得空来看。念念不忘，必有回响，到这个假期，恰逢换工作，才有点大块的时间开个头。</p>
<h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a>大纲</h2><p>简单介绍下 <span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAv">cmu15445<i class="fa fa-external-link-alt"></i></span> 的<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvc3lsbGFidXMuaHRtbA==">教学大纲<i class="fa fa-external-link-alt"></i></span>，该课以 <span class="exturl" data-url="aHR0cHM6Ly93d3cuZGItYm9vay5jb20vZGI3L2luZGV4Lmh0bWw=">Database System Concepts<i class="fa fa-external-link-alt"></i></span> 为辅助教材， 讲述了数据库管理系统（DBMS）设计和实现的方方面面，包括：</p>
<ol>
<li>数据模型（关系型，文档型，键值型）</li>
<li>存储模型（n-ary，decomposition，可以理解为行式、列式）</li>
<li>查询语言（sql，存储过程 stored procedures）</li>
<li>存储结构（heaps，基于日志 log-structured）</li>
<li>索引设计（排序树，哈希表）</li>
<li>事务处理（ACID，并发控制）</li>
<li>数据恢复（日志、快照）</li>
<li>执行引擎（joins，排序，聚集，优化）</li>
<li>并发架构（多核，分布式）</li>
</ol>
<p>可以看出，内容十分翔实，课程使用一个开源的商业数据库作为案例进行讲解，以深入探讨数据库设计时，在上述各个方面进行取舍的过程。本课程十分重视编程实践，设计了一系列前后勾连但又足够简洁的<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvYXNzaWdubWVudHMuaHRtbA==">代码实验<i class="fa fa-external-link-alt"></i></span>。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记  <a href="https://www.qtmuniao.com/2021/02/15/cmu15445-introduction/">https://www.qtmuniao.com/2021/02/15/cmu15445-introduction/</a> , 转载请注明出处</em></p>
<h2 id="计划"><a href="#计划" class="headerlink" title="计划"></a>计划</h2><p>这次学习目标主要以实验为主，兼顾看点讲义和教科书。视频暂时就随缘了，不然战线会拉很长，导致最后都搞不完。一共有五个实验：</p>
<ol>
<li>环境准备：<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvcHJvamVjdDAv">C++ Primer<i class="fa fa-external-link-alt"></i></span> </li>
<li>缓冲控制：<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvcHJvamVjdDEv">Buffer Pool Manager<i class="fa fa-external-link-alt"></i></span></li>
<li>B+ 树索引：<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvcHJvamVjdDIv">B+Tree Index<i class="fa fa-external-link-alt"></i></span></li>
<li>查询引擎：<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvcHJvamVjdDMv">Query Execution<i class="fa fa-external-link-alt"></i></span></li>
<li>并发控制：<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvcHJvamVjdDQv">Concurrency Control<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<p>五个实验组成了一个用于教学的简单的关系型数据库 —— <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NtdS1kYi9idXN0dWI=">BusTub<i class="fa fa-external-link-alt"></i></span>。 实验方式基本都是实现一些规定的接口，跑通写好的测试用例。需要说明的是，代码中给的测试用例十分简单，基本只测试了一些主干路径，因此跑过了测试用例并不一定说明你代码写的没问题，这就要求在实现的过程中务必理解实验各个接口的关系、可以进行取舍实现的要点。为了达到此目的，当自己做完并跑过测试用例后，可以在网上找一些前人实现的材料，对比学习。</p>
<p>初步打算，除了第一个环境准备外，每个实验做完之后写一篇总结，探讨一些实现中遇到的问题和有趣的地方。</p>
<h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><p>课程本身相关的资料都可以去<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjAvc3lsbGFidXMuaHRtbA==">课程网站<i class="fa fa-external-link-alt"></i></span>上寻找，我计划做 fall2020 年的实验，但<span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vcGxheWxpc3Q/bGlzdD1QTFNFOE9EaGpaWGpib2hrTkJXUXNfb3RUckJUcmp5b2hp">视频<i class="fa fa-external-link-alt"></i></span>似乎只有 2019 年的。</p>
<p>在实现过程中如果遇到比较好的博客或者资料，我会逐渐补充到这里。</p>
<h3 id="讲义解读"><a href="#讲义解读" class="headerlink" title="讲义解读"></a>讲义解读</h3><p>我将课程讲义逐章进行了翻译和解读，都放在了我的大规模数据系统专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">系统日知录<i class="fa fa-external-link-alt"></i></span>》，欢迎订阅</p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzJhOWZhNmYxLWZjNGMtNGNjNC05ZTQ2LTE0ZTMzNGE4NDAyZg==">【每天学点数据库】Lecture #12：执行模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzYwMGE2MGZkLTg3ODEtNGIxMy05MzRjLWY2MTllNmMwNzMxOQ==">【每天学点数据库】Lecture #11：Join 算法<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2QxY2ZmNGViLTJjNWItNDg4MC1iMzI0LWNiODFjOTJmNjlmMA==">【每天学点数据库】Lecture #10: 排序和聚合算法<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2I5Y2Y0MWIzLTZjY2ItNDZjYi1iOTE5LTczNzI5NDQ0YjdkOA==">【每天学点数据库】Lecture #09：索引的并发安全<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Y5MDM1MTU0LWQ0Y2QtNGZkYS04YzhhLWIzNDZiMzJjZWI5NA==">【每天学点数据库】Lecture #09：Locks 和 Latches<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2FmYTU4OGYyLThmNGMtNDQzMC1iNWVkLTFhMTc1Yjg0N2I1YQ==">【每天学点数据库】Lecture #08：B+ 树的权衡和优化<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzM1MjRmNzU3LTY0MDItNDcxNy1iOTFjLTNjZjM0ZTIzYTlmMA==">【每天学点数据库】Lecture #07：哈希表概要<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzVlZjM1YmYyLWYyZDEtNDc0Yi1iOWJhLTQwYzkyZWMzZGNhNQ==">【每天学点数据库】Lecture #07：哈希模式<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzMwMzRkNzJlLTAzZTItNGQ4OS05OTE5LTVhYzdjOGUzMzI4OA==">【每天学点数据库】Lecture #08：树型索引<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2E0OTIyOTllLWRkMGUtNDY5ZS04NzA2LTI4MzZlMjBmODFmMA==">【每天学点数据库】Lecture #06：内存管理<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzgxOWMwMjk0LTBlZDQtNDE2MS1iM2M2LThhNjIzMTM2ZmE2Mg==">【每天学点数据库】Lecture #05：数据压缩<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzA1ZWEyY2Y2LTRiM2QtNDE2YS05MjRhLTNjMWY3YWQzN2ExZQ==">【每天学点数据库】Lecture #05：负载类型和存储模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzdlNjk1N2Q2LTRmZWUtNDJkYi1hNTFkLWQ3MmYyODRlMjczMw==">【每天学点数据库】Lecture #04：数据编码<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzVlMzRlZTBmLThmYTMtNGM3ZS05YjA5LTIxMjg3ZTBkYTYzOQ==">【每天学点数据库】Lecture #04：日志构型存储<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzZDZmNDk5LWVlZTctNDFiMi1iOGRlLTU1ZmIwMDAwN2NkNA==">【每天学点数据库】Lecture #03：Data Layout<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2IzYWQ4MTU0LTJlMjktNGVjMS1hNjI3LWZkMzI4OGI1ZDJhOQ==">【每天学点数据库】Lecture #03: Database and OS<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2FlMmUxZTM1LTNkY2MtNGZiZC05ZjZiLTM5ZTY0NWU5OTA2NQ==">【每天学点数据库】Lecture #03：存储层次体系<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2E2ZTVmOTc2LTBlOTktNDExMS1hMWU5LWMwZWE4NTNiMjJiYg==">【每天学点数据库】Lecture #01：关系代数<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzFkM2U5OGE4LTBkZWUtNGI3OS05M2Q0LWE5NjQwOTQxMzI1Mw==">【每天学点数据库】Lecture #01：关系模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2M0NDE2OGNmLTljM2ItNGM1My1iNDllLWEzZTUxZTg1NzZhZA==">【每天学点数据库】Lecture #01：数据模型<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
        <category>公开课</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>cmu</tag>
        <tag>database systems</tag>
        <tag>cmu15445</tag>
      </tags>
  </entry>
  <entry>
    <title>京郊徒步 霾下山桃</title>
    <url>/2021/03/30/beijing-hiking-big-crack/</url>
    <content><![CDATA[<p>北京周边的山上山桃特别多，像物种入侵一样密密麻麻的散落在山坡上、龟缩在山谷中。其他时节徒步时对此没有特别的感觉，但唯独春天，大为惊喜。远处望去，像团团粉色的烟雾般缥缈。然而疫情初定的帝都春日，雾霾又起。亲眼看着漫山的山桃，却只能凭空想象通透天空下的丽景。</p>
<p><img src="http://photo.tuchong.com/15470921/f/1147079771.jpg" alt="山桃虽艳 抵不过老霾"></p>
<span id="more"></span>

<p><img src="http://photo.tuchong.com/15470921/f/1091832932.jpg" alt="霾下的远山竟然也有些许意境"></p>
<p>这次跟着一个户外组织，循着“六只脚”的轨迹，在门头沟雁翅镇的山脉间穿梭。总里程大概十五左右，爬升大概有千米，为了摄取远景而带上的“小白兔”，在这太阳也照不透的霾中，成了一个最大的累赘。</p>
<p>开始是无尽的上山，偶有下坡，立便迎来更峭的山脊。 慢慢挨上去，某刻，前面的人忽说，快到大裂缝了。期待前行，收入眼前的，却是很短的一段，延伸至山谷的小豁口。</p>
<p><img src="http://photo.tuchong.com/15470921/f/1032654027.jpg" alt="略有失望的“小裂缝”"></p>
<p>跳上去，拍了几个角度，收工。反倒是向山下望去，山势甚棒，但视线依然受霾所阻，无以游目骋怀。</p>
<p>冬雪方化，下山泥泞，只能收起相机。经过一段漫长的林中小径，膝盖下侧痛感愈加强烈，后悔没买护膝。到了下半程，前面看到不人、后面听不到声，甚为惶恐。再三比对 APP上的“寻迹”，确认无误，心下稍安，但转而开始怀疑我们是最后两人。</p>
<p>后来走到了村民开辟出的较宽的土路，再后来有了新铺的沥青路，脚下渐轻，景色渐无，最后找到大巴，发现竟然还算靠前。但此时腿脚酸痛肿胀，无力欣喜，还得强忍着拉伸一通。</p>
<p>无尽的上山时、连绵的下山间，身体的疲累不断冲击着你，让你无暇去想平时的烦心事。适度品味身体的苦涩，反而能让人释怀心里的纠结。</p>
]]></content>
      <categories>
        <category>生活</category>
        <category>徒步</category>
      </categories>
      <tags>
        <tag>徒步</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员五一晒图小贴士</title>
    <url>/2021/05/08/adjust-scene-photo/</url>
    <content><![CDATA[<p>强行凑出来的五一小长假即将结束，一年一度的朋友圈晒图大赛又将起航。虽然手机自带的图片自动<em>润色功能</em>越来越强大，但毕竟不能满足我们程序员想掌控一切的精细化调整需求。下面就我一些浅薄的调色经验，以我在长沙游天心阁玩拍的一张图片的调色过程为例，教你一套李鬼变李逵的风景调色屠龙技。最后会给一个简单的修图原理的总结，一探图片调色背后的本质。</p>
<h2 id="先来个对比"><a href="#先来个对比" class="headerlink" title="先来个对比"></a>先来个对比</h2><p>为了说明图片调色确实有奇效，先上一个对比图给大家直观感受下：</p>
<p><img src="https://i.loli.net/2021/05/08/6m34cMHoDyUuKEf.jpg" alt="对比图-调色前.jpg"></p>
<p><img src="https://i.loli.net/2021/05/08/SQ19HFBJnIr3bER.jpg" alt="对比图-调色后.jpg"></p>
<p>此图摄于老长沙制高点——天心阁。是日乌云密布，暴雨将至，从天心阁二层远眺，黄瓦蓝天，车水马龙，一动一静，似有雷霆之势。</p>
<p>下面分步骤讲解下调色过程和原理，尽量简洁一点，并且附上参考资料，留给有兴趣深挖的同学。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记  <a href="https://www.qtmuniao.com/2021/05/08/adjust-scene-photo/">https://www.qtmuniao.com/2021/05/08/adjust-scene-photo/</a>, 转载请注明出处</em></p>
<h2 id="拍照"><a href="#拍照" class="headerlink" title="拍照"></a>拍照</h2><p><strong>器材</strong>以 iPhone 为例，如果是 iPhone 12 pro，遇到奇佳的风景一定要祭出 raw 格式，可以在苹果 <span class="exturl" data-url="aHR0cHM6Ly9zdXBwb3J0LmFwcGxlLmNvbS96aC1jbi9IVDIxMTk2NQ==">官方文档<i class="fa fa-external-link-alt"></i></span>中找到相关设置方法。有数码相机使用经验的同学一定对 raw 格式不陌生，它能让你在拍摄时保留更多细节，给后期更多的发挥空间。可以说支持 raw 格式是我买 iPhone 12 pro 的一个最主要动机。</p>
<p><strong>构图</strong>十分重要，但是与本篇主题无关，这里不详细展开，只提示一点，一定要把九宫格网格线打开，它能让你看到你所要拍摄的主体的在画面中的相对位置。如果对构图方法感兴趣，可以看看 Thomas 看看世界的<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvMzhaWTBfWUZpNlV1eHBFcHJyLXdYQQ==">这篇教程<i class="fa fa-external-link-alt"></i></span>。顺便多说一嘴，他的摄影<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvQUpaWU5JdDdIM0FDNmFLTElER192Zw==">入门文章<i class="fa fa-external-link-alt"></i></span>都挺好的，恰巧，他曾经也是一枚程序员。</p>
<h2 id="修图软件"><a href="#修图软件" class="headerlink" title="修图软件"></a>修图软件</h2><p>ios 平台的图片调色软件非常多，但我只推荐基本没有争议的 Top 1：Adobe 的 Lightroom。该软件基本功能都免费，只有一些高阶功能需要付费，但是我们一般用不到。</p>
<p><img src="https://i.loli.net/2021/05/08/9vQzgByVROsx8EL.png" alt="lr图标.png"></p>
<p>印象中 Android 平台也有。</p>
<h2 id="调色步骤"><a href="#调色步骤" class="headerlink" title="调色步骤"></a>调色步骤</h2><p>下面就以开始提到的”天心阁远眺“图片为例，串下我拿到一张图片后的调色思路和过程。</p>
<h3 id="Step-1：导入校正"><a href="#Step-1：导入校正" class="headerlink" title="Step 1：导入校正"></a>Step 1：导入校正</h3><p>在 ios <code>照片</code> app 中打开待调色原图，点左下角分享图标，找到 Lightroom （没有的话可以在<code>更多</code>里找找）导入，并且选择<code>立即启动 Lightroom</code>：</p>
<p><img src="https://i.loli.net/2021/05/08/MDPybESVmsfphkl.jpg" alt="导入.jpeg"></p>
<p>打开 Lightroom 后选择刚才导入的图片，在下边导航栏中找到<code>光学</code>栏目，勾选<code>移除色差</code>和<code>启用镜头矫正</code>。对于任何照片，这两个选项无脑勾选就行，因为他俩基本只会起到正向作用：比如去除紫边，比如矫正镜头畸变。</p>
<p><img src="https://i.loli.net/2021/05/08/YSHVQrLtKGlg4oM.jpg" alt="移除色差-镜头校正.jpeg"></p>
<h3 id="Step2：图片基调"><a href="#Step2：图片基调" class="headerlink" title="Step2：图片基调"></a>Step2：图片基调</h3><p>就像写作文一样，开始就要奠定一下图片基调。</p>
<p>我一般通过调整<code>颜色</code>导航栏中的<code>白平衡</code>来达到目的。想表达清冷的氛围可以将<strong>色温</strong>往左移动，整体变蓝；想表达温暖、怀旧的氛围，可以将<strong>色温</strong>往右移动，整体变黄。</p>
<p>回到这张图，发现有黄瓦、蓝色玻璃、蓝天。于是就想做一个时下比较流行的 <strong><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3M/X19iaXo9TXpJNE5EQTVNekU1TlE9PSZtaWQ9MjI0NzQ5MDMxMiZpZHg9MSZzbj1iMzU5ZTI0YjAzNjhkNTYxY2U2MmEyMTliOWRmODE2MiZjaGtzbT1lYjgxZTU2Y2RjZjY2YzdhNTQ5OWVhNzFjM2FmMTA0NWI1YjQzZjQ5YTkyNWQxNDcyNzk4MTZlYjAzYzNiODc2NzljOWNhMDY4ZTdmJnNjZW5lPTIxI3dlY2hhdF9yZWRpcmVjdA==">青橙色调<i class="fa fa-external-link-alt"></i></span></strong> 。由于这两个色调方向相反，因此并不能简单地调整图片整体的白平衡。这里进行了几处组合调整，基本思路是加强（增加饱和度）青橙色调，减弱（降低饱和度）其他色调：</p>
<ol>
<li><strong>蓝色变青色，并增加两者饱和度</strong>。在<code>颜色</code>-<code>混合</code>中，调整蓝色向青色，然后适当向右调整两者饱和度滑块。</li>
<li><strong>黄色变橙色，并增加两者饱和度</strong>。在<code>颜色</code>-<code>混合</code>中，调整黄色向橙色，然后适当向右调整两者饱和度滑块。</li>
<li><strong>减弱剩余颜色饱和度</strong>。</li>
</ol>
<p><img src="https://i.loli.net/2021/05/08/zycUEtkFfuMBxHh.jpg" alt="青橙色调.jpeg"></p>
<p>为了增加云彩的<strong>层次感</strong>，可以调整下<code>亮度</code>-<code>曲线</code>中的<code>蓝色通道</code>。<code>曲线</code>这个操作比较有意思，<code>曲线</code>本质上是个亮度调整函数的物化，输入 x 表示所有对应像素点的亮度值，输出 y 表示你想让他变成的亮度值。使用方法是你可以在曲线的任意地方增加锚点，然后通过拖动，来改变曲线的形状，即改变映射函数。更多曲线知识可以看<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MveDlHWVlZNFBHZjlmYWJMZFBVXzlVZw==">这篇<i class="fa fa-external-link-alt"></i></span>。</p>
<p>我一般的使用方法是：</p>
<ol>
<li>在斜线中间增加一个锚点，定住中间调的映射。</li>
<li>增加其他锚点，调整高光或者阴影。</li>
</ol>
<p>由于天空是高光部分，因此在斜线右上部分再加一个锚点，稍稍往下拉，即给云彩中白色部分增加了一些黄色（蓝色的反色是黄色）。</p>
<p><img src="https://i.loli.net/2021/05/08/CNUW8uVkXIHsdD2.jpg" alt="蓝色曲线.jpeg"></p>
<h3 id="Step3：对比度"><a href="#Step3：对比度" class="headerlink" title="Step3：对比度"></a>Step3：对比度</h3><p>如果拿到一张图片，感觉灰蒙蒙的，说明其像素点大多集中在中间色调（即不太暗，也不太亮）。我们这张图就有点这个倾向，可以<code>右上角三个点</code>-<code>视图选项</code>-<code>显示/隐藏直方图</code>调出直方图看一下：</p>
<p><img src="https://i.loli.net/2021/05/08/ZhCrR8XzD1xG9cj.jpg" alt="直方图.jpeg"></p>
<p>发现”山峰“集中在中部，猜想得到验证。关于直方图的知识，可以看看<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvQXU4TnpNLWg4Rm9Gb0l4aHJmMkE2UQ==">这篇<i class="fa fa-external-link-alt"></i></span>，本质上刻画的是图像平面上的像素点的亮度数量分布。</p>
<p>增加对比度有几种方法：</p>
<ol>
<li>最简单的就是<code>亮度</code>-<code>对比度</code>，将滑块往右拉。但是这种方法不太精细，我一般用<code>曲线</code>。</li>
<li>选择<code>亮度</code>-<code>曲线</code>，可以发现曲线有四个，分别是<code>总体</code>、<code>红</code>、<code>绿</code>、<code>蓝</code>。这里调整总体曲线即可。增加对比度的经典曲线形状是一个 S，即让高光部分更亮，阴影部分更暗，对比度一下就出来了。</li>
</ol>
<p><img src="https://i.loli.net/2021/05/08/IPvyhDYqAJrH4os.jpg" alt="曲线-全局.jpeg"></p>
<h3 id="Step-4：增加通透感"><a href="#Step-4：增加通透感" class="headerlink" title="Step 4：增加通透感"></a>Step 4：增加通透感</h3><p>通过调整图片中物体的轮廓，让他们更加清晰，就能让图片看起来更加通透。当然，调整对比度也有这个效果。可以在<code>效果</code>栏目中调节<code>纹理</code>，<code>清晰度</code>，<code>去朦胧</code>三个滑块进行调整。三个滑块的作用边缘依次变大，<code>纹理</code>针对一些细微的边缘，<code>清晰度</code>针对更大的物体轮廓，<code>去朦胧</code>就有点类似于改变对比度了。因此一般来说<code>纹理</code>调整的最多，<code>清晰度</code>次之，<code>去朦胧</code>再次之：</p>
<p><img src="https://i.loli.net/2021/05/08/xbylmzvPUAfDcBN.jpg" alt="效果-通透.jpeg"></p>
<p>可以看到物体的边缘更加清晰，质感就进一步突出出来了。</p>
<p>另外，适当增加高光和阴影的局部对比度，也可以使得照片更加通透。具体做法是修改<code>亮度</code>栏目中的：</p>
<ol>
<li><code>白色色阶</code>右移，<code>高光</code>左移，让最亮的部分更亮，次亮的部分压暗，增加高光对比。</li>
<li><code>黑色色阶</code>左移，<code>阴影</code>右移，让最暗的部分更暗，次暗的部分提亮，增加阴影对比。</li>
</ol>
<p><img src="https://i.loli.net/2021/05/08/iQdJCRygwPtOvZo.jpg" alt="高光阴影-局部对比.jpeg"></p>
<h3 id="Step-5：扫尾"><a href="#Step-5：扫尾" class="headerlink" title="Step 5：扫尾"></a>Step 5：扫尾</h3><p>这部可以根据癖好，增加一些<code>效果</code>，比如<code>晕影</code>（可以令主题更加突出）啊、比如<code>颗粒</code>（造出胶片的质感，给人一种怀旧的分为）啊等等。对于风景图片，我一般会增加些晕影：</p>
<p><img src="https://i.loli.net/2021/05/08/RPpVq2fGUidLEou.jpg" alt="效果-晕影.jpeg"></p>
<h3 id="Step-6：导出"><a href="#Step-6：导出" class="headerlink" title="Step 6：导出"></a>Step 6：导出</h3><p>至此，一张图片基本就调色完成了，最后点击右上角分享-导出为，按自己喜好选择图片品质即可。</p>
<h2 id="原理剖析"><a href="#原理剖析" class="headerlink" title="原理剖析"></a>原理剖析</h2><p>下面是知其所以然阶段，对理论不感兴趣的小伙伴可以跳过。</p>
<p>图片调色的本质是：”选择——调整”。选择就是选出所想要施加影响的像素点集合，调整即是改变该集合的某种属性值。选择的手段和角度都有很多，取决于你如何看待这张图片的像素点集：</p>
<ol>
<li><strong>看成是不同亮度的点集</strong>。<code>亮度</code>栏目下的，<code>黑色色阶-阴影-高光-白色色阶</code>，可以分别选择由暗到亮不同亮度的点集，然后将这些集合变得更亮或者更暗。另外，图像直方图是对全图亮度分布更细粒度的刻画，因此在修图时要一直关注 Lightroom 右上角的直方图变化，直方图又被称为图片的 <strong>X 光片</strong>。</li>
<li><strong>看成是不同颜色的点集</strong>。任何一个像素点的颜色值向量都可以按 RGB （红绿蓝）三维进行分解，每个通道的取值范围一般是 0~255 的整数值。当然也可以按 CMYK（打印四原色：青洋红黄黑）进行分解。可以在<code>颜色</code>-<code>混合</code>中对这些点集进行选择，以调整其<code>色相</code>、<code>饱和度</code>和<code>明亮度</code>。</li>
<li><strong>看成是不同物理区域的点集</strong>。即将物理相邻的一些点归到一起，比如可以调整某个物体轮廓——一棵树、一个人等等，但在手机上一般不会进行这样精细的调整，因为手指难以进行如此细致的操作。但是在电脑上这种选择方式用的相当多，比如抠图。</li>
<li><strong>看成是不同的特点的点集</strong>。将一类具有相同的某种特点的像素点作为集合，比如选出图片中所有的物体边缘，进行锐化，可以使得图片整体变清晰。</li>
</ol>
<p>最后想提一嘴的是，工具毕竟是工具，最重要的还是想表达某种情绪的思路。但那就是具有闲情逸致的同学的，艺术向的高级话题了，我们不得闲的苦逼程序员不懂。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>苹果官方文档，关于 Apple ProRAW：<span class="exturl" data-url="aHR0cHM6Ly9zdXBwb3J0LmFwcGxlLmNvbS96aC1jbi9IVDIxMTk2NQ==">https://support.apple.com/zh-cn/HT211965<i class="fa fa-external-link-alt"></i></span></li>
<li>Thomas 看看世界入门文章，里面有文中提到的曲线、直方图的知识详细讲解：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvQUpaWU5JdDdIM0FDNmFLTElER192Zw==">https://mp.weixin.qq.com/s/AJZYNIt7H3AC6aKLIDG_vg<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>修图</tag>
      </tags>
  </entry>
  <entry>
    <title>Boltdb 源码导读（三）：Boltdb 事务实现</title>
    <url>/2021/04/02/bolt-transaction/</url>
    <content><![CDATA[<blockquote>
<p>boltdb 是市面上为数不多的纯 go 语言开发的、单机 KV 库。boltdb 基于 Howard Chu’s LMDB 项目 ，实现的比较清爽，去掉单元测试和适配代码，核心代码大概四千多行。简单的 API、简约的实现，也是作者的意图所在。由于作者精力所限，原 boltdb 已经封版，不再更新。若想改进，提交新的 pr，建议去 etcd 维护的 fork 版本 bbolt。</p>
<p>为了方便，本系列导读文章仍以不再变动的原 repo 为基础。该项目麻雀虽小，五脏俱全，仅仅四千多行代码，就实现了一个基于 B+ 树索引、支持一写多读事务的单机 KV 引擎。代码本身简约朴实、注释得当，如果你是 go 语言爱好者、如果对 KV 库感兴趣，那 boltdb 绝对是不可错过的一个 repo。</p>
<p>本系列计划分成三篇文章，依次围绕<a href="https://www.qtmuniao.com/2020/11/29/bolt-data-organised/"><strong>数据组织</strong></a>、<a href="https://www.qtmuniao.com/2020/12/14/bolt-index-design/"><strong>索引设计</strong></a>、<strong>事务实现</strong>等三个主要方面对 boltdb 源码进行剖析。由于三个方面不是完全正交解耦的，因此叙述时会不可避免的产生交织，读不懂时，暂时略过即可，待有全貌，再回来梳理。本文是第三篇， boltdb 事务实现。</p>
</blockquote>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>在分析 boltd 的事务之前，我们有必要对事务概念做一个界定，以此来明确我们的讨论范围。<strong>数据库事务</strong>（简称：<strong>事务</strong>）是数据库管理系统执行过程中的一个逻辑单位，由一个有限的<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU2JTk1JUIwJUU2JThEJUFFJUU1JUJBJTkz">数据库<i class="fa fa-external-link-alt"></i></span>操作序列构成<a href="%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E4%BA%8B%E5%8A%A1%EF%BC%9Ahttps://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1">^1</a>。wiki 上的定义有点拗口，理解时只需抓住几个关键点即可：</p>
<ol>
<li>执行：计算层面</li>
<li>逻辑单位：意味着不可分割</li>
<li>操作序列有限：一般粒度不会太大</li>
</ol>
<p>那为什么要有事务呢？事务出现于上世纪七十年代，是为了解放数据库用户的心智而出现的：事务帮助用户组织一组操作、并在出错时自动进行扫尾。后来，NoSQL 和一些分布式存储为了高性能而舍弃了完整事务的支持。然而，历史是螺旋上升的，事务的便利性让 NewSQL 等新一代分布式数据库又将其重新请回。</p>
<p>提起事务，最脍炙人口的便是 ACID 四大特性。 其实 ACID 更像一种易于记忆的口号而非严格的描述，因为他们在概念上并不怎么对称，而且依赖于一些上下文阐释。本文仍然会按照这四个方面对 boltdb 对事务的支持进行剖析，但在每个小结开始，会先参考 Martin Kleppmann 的演讲[^2]，试着从不同角度先阐释其内涵；然后在再分析 boltdb 对其实现。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记  <a href="https://www.qtmuniao.com/2021/04/02/bolt-transaction/">https://www.qtmuniao.com/2021/04/02/bolt-transaction/</a> , 转载请注明出处</em></p>
<p><img src="https://i.loli.net/2021/04/10/vpQ6KmdieFGyAjV.png" alt="transaction.png"></p>
<p>boltdb 只支持一写多读的事务，即同时至多有一个<strong>读写</strong>事务，而可以有多个<strong>只读</strong>事务，算是一种弱化的事务模型，好处在于容易实现，坏处在于牺牲了写并发的性能。也因此，boltdb 适合读多写少的应用。</p>
<p>boltdb 事务实现的主要代码在 <code>tx.go</code> 中，但这个源文件大抵算一个事务实现入口，事务提交时的一些行为，主要在数据库索引逻辑中实现，可以参考<a href="https://www.qtmuniao.com/2020/12/14/bolt-index-design/">之前文章</a>。</p>
<h2 id="持久性（Durability）"><a href="#持久性（Durability）" class="headerlink" title="持久性（Durability）"></a>持久性（Durability）</h2><p>在早期，数据库将数据刷到<strong>磁带</strong>上，即获得持久性，断电重启后数据不会丢失。后来磁带变成<strong>磁盘</strong>，再后来到分布式系统时代，海量磁盘场景下单盘不可靠，便又衍生出<strong>多副本</strong>等冗余策略。虽然策略一直在演变，但其目大抵相同：事务一旦提交，对应更改便会无视各种<strong>常见</strong>故障，而进行长久保持。</p>
<p>boltdb 是一个单机数据库引擎，因此暂不必考虑磁盘故障，数据刷到磁盘上即可认为完成了持久化。其实现代码在函数 <code>func (tx *Tx) Commit() error</code> 中。需要说明的是，boltdb 中只有读写事务才须提交，只读事务提交会报错，但只读事务需要在结束时调用 <code>tx.Rollback</code> 以释放资源（比如锁）。这个设定有点反直觉，毕竟对于只读事务来说，明明是关闭，却叫 <code>Rollback</code>。</p>
<p>读写事务提交时，为了保证事务的持久性，boltdb 主要做了两方面的工作：</p>
<ol>
<li>改动数据刷盘</li>
<li>元信息刷盘</li>
</ol>
<h3 id="改动数据刷盘"><a href="#改动数据刷盘" class="headerlink" title="改动数据刷盘"></a>改动数据刷盘</h3><p>在一个读写事务中，所有用户的直接改动（增加、删除、改动）都发生在<strong>叶子节点</strong>，但为了维持 B+ 树的性质，会在 <code>Commit</code> 前进行调整，会引起<strong>中间节点</strong>的级联变动。所有这些节点（Node）在 <code>spill</code> 阶段通过 <code>node.write(p)</code> 转化为页（Page），所有变动的页（包括复用 freelist 中的和新申请的）称为<strong>脏页</strong>（dirty pages）。在 <code>spill</code>  为 page 后，boltdb 会通过 <code>func (tx *Tx) write() error</code> 将这些脏页进行刷盘，大体逻辑为：</p>
<ol>
<li>将脏页按 page id 排序后逐个遍历</li>
<li>将 page id 转化为 offset </li>
<li>通过 <code>db.ops.writeAt</code> 将脏页在 offset 处刷盘</li>
<li>通过 page pool 复用 page size &#x3D; 1 的脏页，以备 allocate 时复用</li>
</ol>
<p>需要注意的是，这个过程中有个可配置项 <code>db.NoSync</code>。如果 <code>db.Nosync = true</code> ，每次 Commit 时不会立即刷盘，只是写到操作系统的缓冲区，由操作系统决定真正落盘时机，性能较好。但是意外宕机会导致缓冲区数据丢失，从而不能保证严格持久性。</p>
<h3 id="元信息刷盘"><a href="#元信息刷盘" class="headerlink" title="元信息刷盘"></a>元信息刷盘</h3><p>元信息包括 freelist 表和整个 db 的元信息页刷盘，刷盘过程不再赘述。需要注意的是元信息页刷盘一定在最后，以保证事务所有改动生效的原子性，这个点在后面也会强调。</p>
<h2 id="一致性（Consistency）"><a href="#一致性（Consistency）" class="headerlink" title="一致性（Consistency）"></a>一致性（Consistency）</h2><p>此处的一致性要和分布式系统中的一致性区分开来。在分布式系统中，一致性主要指多副本间的数据一致性。而此处的 C，更像是为了让 ACID 念着顺口来凑数的，他的官方表述是：在事务开始之前和事务结束以后，数据库能够保持某些不变性（invariants）。这表示写入的数据必须完全符合所有的预设<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU2JTk1JUIwJUU2JThEJUFFJUU1JUFFJThDJUU2JTk1JUI0JUU2JTgwJUE3">约束<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU4JUE3JUE2JUU1JThGJTkxJUU1JTk5JUE4XyglRTYlOTUlQjAlRTYlOEQlQUUlRTUlQkElOTMp">触发器<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU3JUJBJUE3JUU4JTgxJTk0JUU1JTlCJTlFJUU2JUJCJTlB">级联回滚<i class="fa fa-external-link-alt"></i></span>等[^3]。举个例子来说，A 给 B 转账，转账前后，A 和 B 的账户总额应该保持不变。</p>
<p>该性质描述侧重于应用层面，而非数据库本身。boltdb 是一个简单的 KV 引擎，不支持用户自定义约束，这里不再展开。</p>
<h2 id="原子性（Atomicity）"><a href="#原子性（Atomicity）" class="headerlink" title="原子性（Atomicity）"></a>原子性（Atomicity）</h2><p>原子性，从字面意义上来理解是将事务所包含的一组操作打包为一个逻辑单元。但这个角度很容易和并发编程中的原子性相混淆。在事务中，原子性其实更侧重于出现问题时的<strong>可回滚性</strong>（<code>rollback</code>），或者说<strong>可丢弃性</strong>（<code>abortability</code>），即事务中的操作不能部分执行，要么都成功执行，要么都未执行。</p>
<p>那么 boltdb 是如何实现原子性的呢？可以从主动和被动两个方面来分析。</p>
<p><strong>主动方面</strong>。用户遇到一些问题，可以主动调用 <code>tx.Rollback</code> 进行回滚，undo 该事务到目前为止的所有操作。其主要逻辑包括回滚使用的 freelist，释放一些资源（如锁和节点内存引用）。只读事务结束时必须要调用回滚函数，以关闭事务，防止对读写事务的阻塞，之前文章分析过原因（主要是争抢 remap 时候的锁）。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Rollback 关闭事务，并且放弃之前的更新. 只读事务结束时必须调用 Rollback。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(tx *Tx)</span></span> rollback() &#123;</span><br><span class="line">  <span class="keyword">if</span> tx.db == <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> tx.writable &#123;</span><br><span class="line">    tx.db.freelist.rollback(tx.meta.txid)</span><br><span class="line">    tx.db.freelist.reload(tx.db.page(tx.db.meta().freelist))</span><br><span class="line">  &#125;</span><br><span class="line">  tx.<span class="built_in">close</span>()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(tx *Tx)</span></span> <span class="built_in">close</span>() &#123;</span><br><span class="line">  <span class="comment">// ... </span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> tx.writable &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放锁</span></span><br><span class="line">    tx.db.rwtx = <span class="literal">nil</span></span><br><span class="line">    tx.db.rwlock.Unlock()</span><br><span class="line">    tx.db.statlock.Unlock()</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 删除读事务</span></span><br><span class="line">    tx.db.removeTx(tx)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 清除引用，释放相关内存.</span></span><br><span class="line">  tx.db = <span class="literal">nil</span></span><br><span class="line">  tx.meta = <span class="literal">nil</span></span><br><span class="line">  tx.root = Bucket&#123;tx: tx&#125;</span><br><span class="line">  tx.pages = <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>被动方面</strong>。在读写事务进行到一半时，如果 boltdb 实例意外挂掉重启后，boltdb 如何保证事务的原子性？这个不体现在某些具体细节的代码中，而是体现在 boltdb 整体的设计里：</p>
<ol>
<li>读写事务执行过程中，所有的改动都是增量改动，不影响其他只读事务</li>
<li>最后提交时，元信息页落盘成功，才会使得所有增量改动对用户可见</li>
</ol>
<p>也就是说，使用元信息页作为“全局指针”，以该指针的写入原子性来保证事务的原子性。如果宕机时，元信息页没有写入完成，所有改动便不会生效，达到了自动回滚的效果。</p>
<h2 id="隔离性（Isolation）"><a href="#隔离性（Isolation）" class="headerlink" title="隔离性（Isolation）"></a>隔离性（Isolation）</h2><p>隔离性在数据库系统中是一块重要内容。说起隔离性，一般会提到四个隔离级别：</p>
<ol>
<li>读未提交（Read uncommitted）</li>
<li>读已提交（Read committed）</li>
<li>可重复读（Repeatable read）</li>
<li>序列化（Serializable ）</li>
</ol>
<p>从上到下，四个级别的隔离性依次变强，性能依次变差。我在初学这几个隔离级别时，看过好几次都没有记住。后来才了解到描述的不是是什么（概念特征），而是怎么做（实现细节），而且是上个世纪特定数据库的实现。只不过这些名词后来延续了下来，所以如果你也曾为这些名词而苦恼，不要自我怀疑，是这些概念本身有问题——他们英文名字就没起好，中文翻译就更差了。</p>
<p>这里不会详细展开，只是粗略说下他们直觉上的理解，改天有时间单开一篇文章来说说，其中牵扯的东西还挺多。</p>
<p>隔离性是由并发引起的，最好的隔离——序列化，性能最差。理解隔离性的关键，是要注意到，每个事务有起止时间，不是瞬间完成。我们可以把每个事务执行过程看作是时间维度上的一个线段，多个线段并发交错，就会引出各种隔离性问题。而隔离性越差，用户代码编写就越难受，需要自行处理各种不一致的情况。比如你开始读到的一个记录，在后面使用时，还得再次进行检查读出的值是否和数据库当前状态仍然一致。</p>
<p><img src="https://i.loli.net/2021/04/10/SzeTKMk1glF5Pwu.png" alt="isolation-levels.png"></p>
<p>下面依次简单介绍下四种隔离级别：</p>
<ol>
<li><p>读未提交 ：对应<strong>脏读</strong>，在本事务的线段内，会读到其他线段的中间状态。</p>
</li>
<li><p>读已提交：对应<strong>不可重复读</strong>，比上个好一些。该级别下不能读到其他事务的未提交状态。但如上图，如果事务 t2 在执行时，多次读某个记录 x 的状态，在事务 t1 未启动前，发现 x &#x3D; 2，在事务 t1 提交后，发现 x &#x3D; 3，这便出现了不一致。</p>
</li>
<li><p>可重复读：如上图，事务 t2 在整个执行期间，多次读取数据库 x 的状态，无论他事务（如 t1）是否改变 x 状态并提交，事务 t2 都不会感觉到。但是会存在<strong>幻读</strong>的风险。怎么理解呢？最关键的原因在于<strong>写</strong>并发。因为读不到，不代表其他事务的影响不存在。比如事务 t2 开始时，通过查询发现 <code>id = &quot;qtmuniao&quot;</code> 的记录为空，于是创建了 <code>id=&quot;qtmuniao&quot;</code> 的记录，然而在提交时，发现报错说该 id 已经存在。这可能是因为有一个开始的比较晚的事务 t2，也创建了一个 <code>id=&quot;qtmuniao&quot;</code> 的记录，但是先提交了。于是用户就郁闷了，明明你说没有，但我写又报错，难道我出现幻觉了？这就太扯淡了，但是此级别就只能做到这样了。反而，因为兼顾了性能和隔离性，他是大多数据库的默认级别。</p>
<p><img src="https://i.loli.net/2021/04/10/3S7jYQwvKfGJO46.png" alt="phantom-problem.png"></p>
</li>
<li><p>序列化：最简单的实现办法就是一把锁来串行化所有的事务。在此基础上如果能提高并发，就需要做很多优化。</p>
</li>
</ol>
<p>对于 boltdb 来说，因为不允许并发写，可重复读和序列化在此含义就是一样的。总结来说，boltdb 实现隔离性的方法是：</p>
<ol>
<li>增量写内存。</li>
<li>穿透读磁盘。</li>
</ol>
<p>读写事务的变动都在内存中，而只读事务通过 mmap 直接读取的磁盘上的内容，因此读写事务的改动不会为只读事务所见。多个读写事务是串行的，也不会互相影响。而每个只读事务期间所看到的状态，就是该只读事务开始执行时的状态。</p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>[^2]: “Transactions: myths, surprises and opportunities” by Martin Kleppmann：<span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj01WmpoTlRNOFhVOA==">https://www.youtube.com/watch?v=5ZjhNTM8XU8<i class="fa fa-external-link-alt"></i></span><br>[^3]: 维基百科ACID：<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvQUNJRA==">https://zh.wikipedia.org/wiki/ACID<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>boltdb</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>boltdb</tag>
        <tag>transaction</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统学习资料汇总</title>
    <url>/2021/05/16/distributed-system-material/</url>
    <content><![CDATA[<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>时下，随着通信技术的发展、移动互联网的普及、物联网车联网人工智能的兴起，每天所产生的数据呈爆炸性的增长。这种尺度的数据不是传统单机系统可以独立处理的，而只能借助于大规模的分布式系统，因而分布式系统渐渐的变成一门“显学”。而作为一个分布式系统初学者，面对网上未加归类、浩如烟海的学习资料，很容易两眼抓瞎。</p>
<p>但分布式系统有其基本研究内容和独特发展脉络，比如：</p>
<ol>
<li>一些基本研究问题：时序问题、一致性问题、容错技术、共识算法、并发控制等等。</li>
<li>一些基本定理：CAP、PACELC、FLP</li>
<li>渐次发展的工业系统：MapReduce、Spark、GFS、Dynamo、Cosmos</li>
</ol>
<p>因此只需要在“时空”两个维度对分布式系统进行把握，就能提纲挈领，愈学愈明。“<strong>时</strong>”表示分布式系统的演进脉络，可以通过阅读不同时期、学术界工业界的一些论文来把握。“<strong>空</strong>”表示分布式系统中所研究的基本问题的拆解，可以通过阅读一些书籍建立分布式系统的知识体系。本文将我在学习分布式系统知识过程搜集到的一些资料，按类别简单汇总，以飨诸君。资料排名没有先后，请按需采用。</p>
<p><strong>注：</strong>文中推荐的资料大多为英文，如果阅读有困难，推荐使用 Chrome 浏览器，并且给 Chrome 装一个 “<span class="exturl" data-url="aHR0cHM6Ly9jaHJvbWUuZ29vZ2xlLmNvbS93ZWJzdG9yZS9kZXRhaWwvZ29vZ2xlLXRyYW5zbGF0ZS9hYXBiZGJkb21qa2tqa2FvbmZoa2tpa2ZnamxsY2xlYg==">google 翻译<i class="fa fa-external-link-alt"></i></span>”的插件，可以点击一键“翻译此页面”。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/05/16/distributed-system-material/">https://www.qtmuniao.com/2021/05/16/distributed-system-material/</a>, 转载请注明出处</em></p>
<h2 id="书籍"><a href="#书籍" class="headerlink" title="书籍"></a>书籍</h2><h3 id="Dr-Martin-Kleppmann-Designing-Data-Intensive-Applications"><a href="#Dr-Martin-Kleppmann-Designing-Data-Intensive-Applications" class="headerlink" title="Dr. Martin Kleppmann. Designing Data-Intensive Applications"></a>Dr. Martin Kleppmann. Designing Data-Intensive Applications</h3><p>《构建数据密集型应用》，<span class="exturl" data-url="aHR0cHM6Ly9kYXRhaW50ZW5zaXZlLm5ldC9idXkuaHRtbA==">https://dataintensive.net/buy.html<i class="fa fa-external-link-alt"></i></span>，作者提供免费英文版下载，网上也可以搜到。</p>
<p>全书分为三大部分：</p>
<ol>
<li>系统基石（Foundations of Data System）</li>
<li>分散数据（Distributed Data）</li>
<li>衍生数据（Derived Data）</li>
</ol>
<p><strong>系统基石</strong>部分探讨了数据系统的一些通用侧面：</p>
<ol>
<li>可靠性、可扩展性、可维护性（Reliable, Scalable, and Maintainable Applications）</li>
<li>数据模型和查询语言（Data Models and Query Languages）</li>
<li>数据存储和检索（Storage and Retrieval）</li>
<li>数据编码和演进（Encoding and Evolution）</li>
</ol>
<p><strong>分散数据</strong>部分讨论了构建分散在多机上的数据系统和一些原则和面临的问题：</p>
<ol>
<li>冗余（replication）</li>
<li>分片（Partition）</li>
<li>事务（Transactions）</li>
<li>分布式系统存在的问题（The Trouble With Distributed Systems）</li>
<li>一致性和共识（Consistency and Consensus）</li>
</ol>
<p><strong>衍生数据</strong>部分其实是在探讨分散在多机上的系统的处理问题。包括：</p>
<ol>
<li>批处理（Batch Processing）</li>
<li>流式处理（Stream Processing）</li>
<li>数据系统的未来（The Future of Data Systems）</li>
</ol>
<p>近年来流批系统趋于融合，从而让用户能够更加灵活、高效的对原始数据进行处理和变换。</p>
<p>这些章节拆分的都非常棒。熟读本书，让你在遇到一个新系统时，可以如庖丁解牛一般熟练拆解成为多个构件，并了每个构件背后的权衡取舍（trade off）。</p>
<h3 id="M-van-Steen-and-A-S-Tanenbaum-Distributed-Systems-3rd-ed-distributed-systems-net-2017"><a href="#M-van-Steen-and-A-S-Tanenbaum-Distributed-Systems-3rd-ed-distributed-systems-net-2017" class="headerlink" title="M. van Steen and A.S. Tanenbaum, Distributed Systems, 3rd ed., distributed-systems.net, 2017."></a>M. van Steen and A.S. Tanenbaum, Distributed Systems, 3rd ed., <span class="exturl" data-url="aHR0cDovL2Rpc3RyaWJ1dGVkLXN5c3RlbXMubmV0Lw==">distributed-systems.net<i class="fa fa-external-link-alt"></i></span>, 2017.</h3><p>《分布式系统》第三版，<span class="exturl" data-url="aHR0cHM6Ly93d3cuZGlzdHJpYnV0ZWQtc3lzdGVtcy5uZXQvaW5kZXgucGhwL2Jvb2tzL2RzMy8=">https://www.distributed-systems.net/index.php/books/ds3/<i class="fa fa-external-link-alt"></i></span>。作者提供英文版 PDF 免费下载链接，简介：</p>
<p>本书分为九个小结：</p>
<ul>
<li>简介（Introduction）</li>
<li>架构（Architecture）</li>
<li>进程（Processes）</li>
<li>通信（Communication）</li>
<li>命名系统（Naming）</li>
<li>协同（Coordination）</li>
<li>一致性和多副本（Consistency and replication）</li>
<li>容错（Fault Tolerance）</li>
<li>安全（Security）</li>
</ul>
<p>作者还提供了 Python 示例代码和图表下载。</p>
<h3 id="Mikito-Takada-Distributed-System-for-fun-and-profit"><a href="#Mikito-Takada-Distributed-System-for-fun-and-profit" class="headerlink" title="Mikito Takada. Distributed System for fun and profit"></a>Mikito Takada. Distributed System for fun and profit</h3><p>一本免费的分布式系统小书：<span class="exturl" data-url="aHR0cDovL2Jvb2subWl4dS5uZXQvZGlzdHN5cy8=">http://book.mixu.net/distsys/<i class="fa fa-external-link-alt"></i></span>，介绍了分布式系统中的一些关键概念和设计考量，助你了解知名的商用系统如 Dynamo、BigTable、MapReduce、Hadoop 背后的设计原理。作者将分布式编程的考量归结为两个方面：</p>
<ol>
<li>信息以光速传递</li>
<li>分离组件会独立出错</li>
</ol>
<p>然后将全书分为五个小结：</p>
<ol>
<li><strong>分布式系统基础（Basics）</strong>：粗粒度的介绍了一些名词和概念，探讨了系统的目标以及实现的难度</li>
<li><strong>自上而下的层层抽象（Up and down the level of abstraction）</strong>：介绍了 CAP 定理和 FLP impossibility ，然后探讨了多种一致性模型。</li>
<li><strong>时与序（time and order</strong>）。理解分布系统的关键之一，便是要理解分散的组件如何确定时间的先后顺序。</li>
<li><strong>多副本：避免分裂（Replication: preventing divergence）</strong>：多副本间如何保持一致</li>
<li><strong>多副本：接受分歧（Replication: accepting divergence）</strong>：多副本间如何处理冲突</li>
</ol>
<h2 id="公开课"><a href="#公开课" class="headerlink" title="公开课"></a>公开课</h2><h3 id="MIT-6-824-Distributed-Systems"><a href="#MIT-6-824-Distributed-Systems" class="headerlink" title="MIT 6.824: Distributed Systems"></a>MIT 6.824: Distributed Systems</h3><p>最经典的分布式系统课程之一：<span class="exturl" data-url="aHR0cHM6Ly9wZG9zLmNzYWlsLm1pdC5lZHUvNi44MjQvc2NoZWR1bGUuaHRtbA==">https://pdos.csail.mit.edu/6.824/schedule.html<i class="fa fa-external-link-alt"></i></span>。</p>
<p>课程亮点在于：</p>
<ol>
<li>精选的论文列表</li>
<li>精巧的实验设计</li>
</ol>
<p>非常适合自学。</p>
<h3 id="Cambridge-Concurrent-and-Distributed-Systems"><a href="#Cambridge-Concurrent-and-Distributed-Systems" class="headerlink" title="Cambridge Concurrent and Distributed Systems"></a>Cambridge Concurrent and Distributed Systems</h3><p>剑桥大学的并发和分布式课程， <span class="exturl" data-url="aHR0cHM6Ly93d3cuY2wuY2FtLmFjLnVrL3RlYWNoaW5nLzIwMjEvQ29uY0Rpc1N5cy9tYXRlcmlhbHMuaHRtbA==">https://www.cl.cam.ac.uk/teaching/2021/ConcDisSys/materials.html<i class="fa fa-external-link-alt"></i></span></p>
<p>DDIA 作者 Martin Kleppmann 主讲。</p>
<h3 id="CMU-15-440-Distributed-Systems"><a href="#CMU-15-440-Distributed-Systems" class="headerlink" title="CMU 15-440: Distributed Systems"></a>CMU 15-440: Distributed Systems</h3><p>cmu 的分布式系统：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MuY211LmVkdS9+ZGdhLzE1LTQ0MC9TMTQvc3lsbGFidXMuaHRtbA==">https://www.cs.cmu.edu/~dga&#x2F;15-440&#x2F;S14&#x2F;syllabus.html<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="standford-cs244b-Distributed-System"><a href="#standford-cs244b-Distributed-System" class="headerlink" title="standford cs244b Distributed System"></a>standford cs244b Distributed System</h3><p>斯坦福的分布式系统课程：<span class="exturl" data-url="aHR0cDovL3d3dy5zY3Muc3RhbmZvcmQuZWR1LzIwc3AtY3MyNDRiLw==">http://www.scs.stanford.edu/20sp-cs244b/<i class="fa fa-external-link-alt"></i></span></p>
<p>CS244b 是一个讨论课，也给了一些经典的论文列表。</p>
<h3 id="UW-CSE490H-Distributed-Systems"><a href="#UW-CSE490H-Distributed-Systems" class="headerlink" title="UW CSE490H: Distributed Systems"></a>UW CSE490H: Distributed Systems</h3><p>华盛顿大学的分布式系统课程：<span class="exturl" data-url="aHR0cHM6Ly9jb3Vyc2VzLmNzLndhc2hpbmd0b24uZWR1L2NvdXJzZXMvY3NlNDkwaC8xMXdpLw==">https://courses.cs.washington.edu/courses/cse490h/11wi/<i class="fa fa-external-link-alt"></i></span>。最近几年的课程没有开还是没有公开，最近的是 2011 年的。也提供了一个不错的论文阅读列表。</p>
<h2 id="开源项目"><a href="#开源项目" class="headerlink" title="开源项目"></a>开源项目</h2><h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><ol>
<li>Hadoop， <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FwYWNoZS9oYWRvb3A=">https://github.com/apache/hadoop<i class="fa fa-external-link-alt"></i></span> ，Java：可以通过 tag 看早期代码，包含 MapReduce 和 GFS 的开源实现</li>
<li>seaweedfs ，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NocmlzbHVzZi9zZWF3ZWVkZnM=">https://github.com/chrislusf/seaweedfs<i class="fa fa-external-link-alt"></i></span>， Golang：参考了 Facebook Haystack 和 F4</li>
<li>Minio，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL21pbmlvL21pbmlv">https://github.com/minio/minio<i class="fa fa-external-link-alt"></i></span>， Golang：一个经典的开源实现的对象存储</li>
<li>TiDB，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3BpbmdjYXAvdGlkYg==">https://github.com/pingcap/tidb<i class="fa fa-external-link-alt"></i></span>，Golang，提供 MySql 访问接口的分布式数据库</li>
</ol>
<h2 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h2><ol>
<li>Etcd，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2V0Y2QtaW8vZXRjZA==">https://github.com/etcd-io/etcd<i class="fa fa-external-link-alt"></i></span>，Golang：Raft 的一个实现，用于 k8s 中。也可以用于任何分布式系统的控制面的数据存储。</li>
<li>Zookeeper，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FwYWNoZS96b29rZWVwZXI=">https://github.com/apache/zookeeper<i class="fa fa-external-link-alt"></i></span>，Java：实现了 Zab 共识协议，最初用于 Hadoop 中存储元信息，地位和 Etcd 类似。</li>
</ol>
<h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><ol>
<li>Spark，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FwYWNoZS9zcGFyaw==">https://github.com/apache/spark<i class="fa fa-external-link-alt"></i></span>，Scala：一个大数据处理、分析引擎</li>
<li>Flink，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FwYWNoZS9mbGluaw==">https://github.com/apache/flink<i class="fa fa-external-link-alt"></i></span>，Java：流批一体的数据处理引擎</li>
<li>Ray，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JheS1wcm9qZWN0L3JheQ==">https://github.com/ray-project/ray<i class="fa fa-external-link-alt"></i></span>，Python&#x2F;C++：表达能力强大的通用计算引擎</li>
</ol>
<h2 id="系列博客"><a href="#系列博客" class="headerlink" title="系列博客"></a>系列博客</h2><h3 id="写给分布式系统初学者的一些笔记"><a href="#写给分布式系统初学者的一些笔记" class="headerlink" title="写给分布式系统初学者的一些笔记"></a>写给分布式系统初学者的一些笔记</h3><p>Jeff Hodges <span class="exturl" data-url="aHR0cHM6Ly93d3cuc29tZXRoaW5nc2ltaWxhci5jb20vMjAxMy8wMS8xNC9ub3Rlcy1vbi1kaXN0cmlidXRlZC1zeXN0ZW1zLWZvci15b3VuZy1ibG9vZHMv">https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/<i class="fa fa-external-link-alt"></i></span></p>
<p>博主将从事分布式系统工作所得到的经验教训做了一个概要性的总结，对新人进入分布式领域转换思想很有启发性作用。包括：</p>
<ol>
<li>故障频发是分布式系统区别于其他系统的显著特点</li>
<li>构建健壮的分布式系统要远难于单机系统</li>
<li>分布式系统的开源协作不同于单机系统</li>
<li>多机协同很难</li>
<li>很慢这个事情在分布式系统中很难定位</li>
<li>寻找使服务部分可用的手段</li>
<li>充分利用局部性原理</li>
<li>使用 CAP 原理来审视你的分布式系统</li>
<li>…</li>
</ol>
<h3 id="给分布式系统工程师的一些分布式理论"><a href="#给分布式系统工程师的一些分布式理论" class="headerlink" title="给分布式系统工程师的一些分布式理论"></a>给分布式系统工程师的一些分布式理论</h3><p><span class="exturl" data-url="aHR0cHM6Ly93d3cudGhlLXBhcGVyLXRyYWlsLm9yZy9wb3N0LzIwMTQtMDgtMDktZGlzdHJpYnV0ZWQtc3lzdGVtcy10aGVvcnktZm9yLXRoZS1kaXN0cmlidXRlZC1zeXN0ZW1zLWVuZ2luZWVyLw==">https://www.the-paper-trail.org/post/2014-08-09-distributed-systems-theory-for-the-distributed-systems-engineer/<i class="fa fa-external-link-alt"></i></span></p>
<p>博主给出了分布式系统的一个入门路径和参考资料：</p>
<ol>
<li><strong>第一步（First steps）：</strong>推荐了一些书</li>
<li><strong>故障和时序（Failure and Time）</strong>：分布系统中最重要的两个基石，给出了一些经典论文引用</li>
<li><strong>容错的基本考量（The basic tension of fault tolerance）</strong>：要做冗余以容错，但过分冗余又会浪费性能</li>
<li><strong>基本源语（Basic primitives）</strong>：分布系统中的一些基本概念论文链接，包括选举算法、一致性快照、共识协议、分布式状态机、广播、链式冗余。</li>
<li><strong>一些工业系统论文列表</strong>：谷歌的居多，非谷歌的也有一些</li>
</ol>
<h2 id="Meetup"><a href="#Meetup" class="headerlink" title="Meetup"></a>Meetup</h2><h3 id="Papers-we-love"><a href="#Papers-we-love" class="headerlink" title="Papers we love"></a>Papers we love</h3><p>PapersWeLove计算机论文分享： <span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL2NvbHVtbi9jXzEzNTM2NzgxODAzOTAxNjI0MzI=">https://www.zhihu.com/column/c_1353678180390162432<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="Microsoft-Distributed-System-Meetup"><a href="#Microsoft-Distributed-System-Meetup" class="headerlink" title="Microsoft-Distributed-System-Meetup"></a>Microsoft-Distributed-System-Meetup</h3><p>微软同学搞的一个分布式系统 meetup，包括 一块学 6.824、一块读 DDIA、有意思的主题演讲等等：<span class="exturl" data-url="aHR0cHM6Ly9taWNyb3NvZnQtZGlzdHJpYnV0ZWQtc3lzdGVtLW1lZXR1cC5naXRodWIuaW8vaG9tZS8=">https://microsoft-distributed-system-meetup.github.io/home/<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="Distributed-Systems-Reading-Group"><a href="#Distributed-Systems-Reading-Group" class="headerlink" title="Distributed Systems Reading Group"></a>Distributed Systems Reading Group</h3><p>MIT 同学在 2013 年搞的一个论文阅读小组：<span class="exturl" data-url="aHR0cDovL2RzcmcucGRvcy5jc2FpbC5taXQuZWR1L3BhcGVycy8=">http://dsrg.pdos.csail.mit.edu/papers/<i class="fa fa-external-link-alt"></i></span></p>
<p>包括共识协议、数据冗余、事务相关、并发问题等等。</p>
<h3 id="计算机系统学习小组"><a href="#计算机系统学习小组" class="headerlink" title="计算机系统学习小组"></a><strong>计算机系统学习小组</strong></h3><p>@<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9odS1qaW4tbWluZy0zMQ==">胡津铭<i class="fa fa-external-link-alt"></i></span> 组织的系统学习小组：<span class="exturl" data-url="aHR0cHM6Ly9sZWFybi1zeXMuZ2l0aHViLmlvL2NuLw==">https://learn-sys.github.io/cn/<i class="fa fa-external-link-alt"></i></span></p>
<h3 id="The-Last-Thing"><a href="#The-Last-Thing" class="headerlink" title="The Last Thing"></a>The Last Thing</h3><p>最后，附赠一个 github 上经典的 awesome 系列中，分布式系统的 repo：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RoZWFuYWx5c3QvYXdlc29tZS1kaXN0cmlidXRlZC1zeXN0ZW1z">https://github.com/theanalyst/awesome-distributed-systems<i class="fa fa-external-link-alt"></i></span></p>
<hr>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>存储</tag>
        <tag>资料汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式存储面试经验</title>
    <url>/2021/04/17/storage-interview/</url>
    <content><![CDATA[<p>前一段时间由于一些原因工作变动，面了一些分布式存储的相关岗位，感觉市面上相关经验分享较少，因此拿出来和大家分享一下。由于公司隐私政策问题，不会按公司对题目进行罗列，仅仅就一些面试的方向和内容进行简单梳理。水平经验所限，谬误之处，可以留言交流指正。</p>
<h2 id="相关岗位"><a href="#相关岗位" class="headerlink" title="相关岗位"></a>相关岗位</h2><p>分布式存储方向的岗位涵盖甚广，一般可以按照方向分为：</p>
<ol>
<li>分布式文件存储</li>
<li>对象存储</li>
<li>分布式 KV or 缓存</li>
<li>分布式数据库（new sql）</li>
<li>表格存储</li>
<li>块存储</li>
</ol>
<p>其定位方向也稍有不同：</p>
<p><strong>分布式文件存储</strong>。支持 POSIX 语义或者裁剪 POSIX。可以作为存储和计算分离的存储基座，也可以直接为应用所用，比如说深度学习的一些训练，大数据处理的一些中间存储。常见产品有盘古文件系统、Polarfs、JuiceFS 等。</p>
<p><strong>对象存储</strong>。一般是存储图片和视频之类的非结构化数据，通常兼容亚马逊的 S3 接口。常见产品如 Amazon S3、阿里云 OSS、腾讯云 COS。</p>
<p><strong>分布式 KV or 缓存</strong>。通常兼容 redis 接口，或者更简化 KV 接口。一般求快，基于内存或者SSD，甚至可持久化内存等新硬件。用于低延迟需求的业务缓存或者存储计算分离系统的底座。产品如字节的 ABase、阿里云的 Tair、PingCAP 的 TiKV。</p>
<p><strong>分布式数据库（or new sql）</strong>。通常提供 SQL 接口以及无限水平扩展能力。常见产品有 PingCAP 的 TiDB、阿里云的 PolarDB、腾讯云的 TDSQL。</p>
<p><strong>表格存储</strong>。经典的接口可以参考按列存储的 HBase，大数据领域应用比较多。产品如 HBase，字节的 ByteTable。</p>
<p><strong>块存储</strong>。提供块设备接口，一般用于云主机的系统盘。产品如 smartX 的超融合。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记  <a href="https://www.qtmuniao.com/2021/04/17/storage-interview/">https://www.qtmuniao.com/2021/04/17/storage-interview/</a> , 转载请注明出处</em></p>
<h2 id="考察内容"><a href="#考察内容" class="headerlink" title="考察内容"></a>考察内容</h2><p>分布式存储的面试考察一般分为几块：</p>
<ol>
<li>项目经验</li>
<li>基础知识</li>
<li>算法代码</li>
<li>领域知识</li>
<li>系统设计</li>
<li>编程语言</li>
</ol>
<p><strong>项目经验</strong>。如果项目经验匹配的话，对其他方面要求就会相对降低一些，但项目本身会考察的很细致。每个面试官聊项目的切入点可能不太一样，但一定是带有某种考察目的，按目的可以粗分为以下几种类型：</p>
<ol>
<li><strong>沟通表达</strong>。这一条最虚，但一般最重要，因为面试官都会自觉或不自觉的有一个隐形标准：<strong>即我以后愿意不愿意跟该候选人共事</strong>。这时候问的项目经历可能甚至和面试岗位无关。面对这类考察时，特别注意不要一上来就直接介绍大量实现细节。一个符合认知的回答思路是，按你拿到一个新项目的工作历程来<strong>简述</strong>（注意一定是简述，因为没人喜欢又臭又长的无病呻吟，时间也不允许。这时候很考察抽象概括能力）：项目背景和需求是什么、市面上有什么开源解决方案、我们是如何进行技术选型的、我负责哪一个模块等等。态度上，要<strong>不卑不亢</strong>，既不要表现出“这都不懂”的傲慢，也不要表现出“您是爸爸”的谄媚，会的就清楚表述，不会的大方说不会即可。</li>
<li><strong>匹配经验</strong>。如果你的经验和面试岗位很匹配，面试官可能会让你迅速介绍一下项目概要后深入某个细节考察。这也是不要在项目介绍阶段用时太长的原因，不然面试官虽然想重点发问，但又不好打断你的介绍。这里的考察点一般会和某个模块的设计思路、性能优化相关。这种问题只需要跟着面试官思路做个简单复盘即可。</li>
<li><strong>引出其他</strong>。有的面试官问项目，只是为了引出项目可能会涉及到的某些计算机的基础知识，以考察你的求知欲、知识深度等能力。毕竟项目涉及到的知识，一般会了解的比较深入。如果说我只是用过，其他一概不知，多少会有些减分。</li>
</ol>
<p><strong>基础知识</strong>。由于分布式系统和底层打交道还挺多，为了极致优化性能，会需要很多操作系统、计算机网络的知识。考察的比较多的是 Linux IO 栈、文件系统、进程调度、TCP 协议细节等方面。</p>
<p><strong>算法代码</strong>。虽然形式上都表现为做题，但算法和代码考察侧重点还不太一样，算法方向侧重常用算法思路，题目可能会比较新，通常以二分、贪心、分治、搜索甚至动态规划为主；代码方向侧重编程的熟练程度、代码风格等，题目可能会比较老，但是写起来会比较繁琐，通常以链表、二叉树、图为主。LRU 和链表 k 个一组翻转是高频题目。</p>
<p><strong>领域知识</strong>。主要是分布式系统和存储方向的经典概念。考的最多的就是共识协议，比如 raft，初阶考察形式就是介绍一下大体概念和基本流程；高阶一点会问如何线性读、如何处理惊群、选举日志要求、选举细节等等。其他的就是一些经典项目和论文，比如 GFS 一些设计细节，比如 LSMtree 的一些 compact 细节。</p>
<p><strong>系统设计</strong>。因为也工作几年了，所以会考一些系统的基本设计问题。最长考察的点就是负载均衡、宕机容错、消息队列。比如设计一个高可用、低延迟的分布式 KV 系统；比如设计一个延迟触发的事件（Event ）管理系统；比如设计一个线程安全的 LRU 等等。</p>
<p><strong>编程语言</strong>。存储方向还是用 C++ 比较多，因此可能会考一些 C++ 的知识点。为什么说可能呢，因为我之前主要用 Go，因此大多面试官不怎么考这一项。但如果考察的话，Go 中最常见的考察点就是其 runtime了，包括 Goroutine MN 调度模型和三色垃圾回收的细节。C++ 我只写过小东西，没有做过大项目，特性懂的也不是很多，这里就不妄言了。</p>
<h2 id="面试流程"><a href="#面试流程" class="headerlink" title="面试流程"></a>面试流程</h2><p>面试一般是2~4 面技术面，一面 HR 面。技术面一般分为基础技术面和大佬 behavior 面。</p>
<p>技术面基本是前两三面，其面试官一般是你以后的同事和小 leader ，主要考察内容如上节所述。面试是一个双向选择的过程，而这几个面试官直接决定了你以后的工作幸福度，因此一定也要注意考察他们，看齐性格上否和你合拍、技术上是否能助你进步。</p>
<p>大佬面一般是技术面的最后一面，可能是你所面岗位的部门经理把把关，也可能是其他组的 leader 来交叉面。这一面通常不会问技术细节，考察方式也相对套路化。基本就是问你印象最深刻的一个问题是啥、怎么解决的、你的优点是什么、缺点是什么。主要考察候选者的表达能力、聪明程度、behavior等等，不过一般来说这步不会卡人。</p>
<p>HR 面同样很套路化，一般就是三板斧：</p>
<ol>
<li><strong>期望薪资</strong>：现在薪资构成，有无其他 offer，期望薪资总包。期望薪资是个老大难，我也不知道怎么说合适。</li>
<li><strong>离开原因</strong>：公司现在情况如何，为什么要离开，对新公司有什么期望。不要贬损前司，捡一些客观事实陈述即可。</li>
<li><strong>性格测试</strong>：说一件工作中印象最深刻的问题，解决方法，需要提高的地方。也有就是直接问你内向外向、爱好缺点啥的。不卑不亢，别给自己挖坑就行。</li>
</ol>
<p>注意 HR 面的时候可以打听下工作岗位的工作节奏，看是否符合你预期，如果有第三方信息来源那就更好了。此外，还可以通过 HR 加一下之前技术面试官微信，详细了解下以后的工作内容。</p>
<h2 id="题目汇总"><a href="#题目汇总" class="headerlink" title="题目汇总"></a>题目汇总</h2><p>算是一个附录吧，按分类汇总下详细问题。</p>
<p><strong>领域知识</strong></p>
<ol>
<li>GFS 如何保证数据的高可用？遇到错误如何进行重试？</li>
<li>raft 如何实现从 follower 读取？</li>
<li>raft 中大多数节点提交某条日志后，未包含该日志的某个节点能成为 leader 吗？</li>
<li>leveldb 中如果经过多次 compact，底层文件系统产生了很多碎片，WAL 还能保持高效的顺序写性能吗？</li>
<li>raft 论文中 peer 启动的时候是 follower，可以是 candidate 吗？</li>
<li>raft 如何避免惊群效应？</li>
</ol>
<p><strong>基础知识</strong></p>
<ol>
<li>tcp 的三次握手简述</li>
<li>tcp 序号的含义和初始值？是否随机？</li>
<li>socket 编程的几个源语？</li>
<li>tcp  listen 对应状态机中什么状态？</li>
<li>磁盘负载百分之百代表什么？</li>
<li>cpu 负载过高代表什么？</li>
<li>文件系统 open 函数执行时，背后从上层到底层发生了什么？</li>
<li>虚拟内存的设计有什么好处？</li>
<li>mmap 共享内存是否破坏了进程间的隔离性？</li>
</ol>
<p><strong>系统设计</strong></p>
<ol>
<li>设计一个支持用户元信息和用户 Follow 关系的分布式 KV 存储。</li>
<li>设计一个线程安全的 LRU。</li>
</ol>
<p><strong>代码算法</strong></p>
<ol>
<li>randomset，设计一个支持 random 接口的 set，random 要求以 O(1) 的复杂度等概率的返回一个值</li>
<li>LRU</li>
<li>链表快排</li>
<li>链表 k 个一组翻转</li>
<li>链表 shuffle：Node0-&gt;Node1-&gt;…-&gt;Noden-1，shuffle 成以下：Node0-&gt;Noden-1-&gt;Node1…</li>
<li>Python 中判断两个 dict 相同？动态语言，类型相同，值相同，可能有环</li>
<li>使用互斥锁实现一个读写锁</li>
<li>五只弹钢琴。给定一个无序自然数序列，作为钢琴键的位置，单只手最多可以接触五个连续位置，求弹出该序列所有位置，手的最小移动次数</li>
<li>将长度为 m 的木棒切为 n 段，有多少种切法？（mn 都是正整数）</li>
</ol>
<p><strong>项目相关</strong></p>
<ol>
<li>如何定位系统延迟的瓶颈？</li>
<li>如何降低 GC 对主干流量的影响？</li>
<li>多副本如何选主？</li>
<li>多个副本写入如何保证一致性和可靠性？</li>
</ol>
<p><strong>编程语言</strong></p>
<ol>
<li>golang：defer 的开销，如何进行优化？</li>
<li>golang：runtime 是以什么形式存在？库还是二进制？</li>
<li>golang：为什么 goroutine 更为轻量？</li>
<li>golang：channel 如何实现？</li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>存储</tag>
        <tag>面经</tag>
        <tag>分布式存储</tag>
      </tags>
  </entry>
  <entry>
    <title>Paxos Made Simple 论文导读</title>
    <url>/2021/06/14/paxos-zhixing/</url>
    <content><![CDATA[<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>Paxos 是分布式系统中绕不过去的一个算法，但出了名的难以理解。因此我看到 Paxos 也是一直绕着走，但是绕的多了总感觉有些遗憾。于是过去一周闲暇时间搜集了很多资料，尝试了很多打开方式，总算初窥门径。便趁着新鲜，将脑中的理解赶到纸上，做个小结，以备后日不时之需。</p>
<p>Paxos 算法的发明人 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTGVzbGllX0xhbXBvcnQ=">Leslie Lamport<i class="fa fa-external-link-alt"></i></span>  是分布式系统的奠基人之一，轶事颇多，从 Paxos 这个名字也能窥得一斑：Paxos 是 Lamport 为了引出分布式系统共识问题，所虚拟的一个古希腊城邦。在最初的相关论文 <span class="exturl" data-url="aHR0cHM6Ly9sYW1wb3J0LmF6dXJld2Vic2l0ZXMubmV0L3B1YnMvbGFtcG9ydC1wYXhvcy5wZGY=">The Part-Time Parliament<i class="fa fa-external-link-alt"></i></span> 发表于 1998 年后，很多人都表示理解不能。于是 Lamport 在  2001 年，又使用相对简练的语言和逻辑，将其主干思想重新阐述了一遍，便有了 <span class="exturl" data-url="aHR0cHM6Ly9sYW1wb3J0LmF6dXJld2Vic2l0ZXMubmV0L3B1YnMvcGF4b3Mtc2ltcGxlLnBkZg==">Paxos made simple<i class="fa fa-external-link-alt"></i></span>。</p>
<p>Lamport 在 Paxos made simple 论文的摘要只有一句话：</p>
<blockquote>
<p>The Paxos algorithm, when presented in plain English, is very simple</p>
</blockquote>
<p>然而，我却无法理解这种 simple。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/06/14/paxos/zhixing">https://www.qtmuniao.com/2021/06/14/paxos/zhixing</a>, 转载请注明出处</em></p>
<h2 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h2><p>按我的一贯理论，如果你理解不了一个简单的东西，一定是打开方式（建模方式）不对。既然作者说该理论很 simple，那么只要能找到契合我上下文的解析，一定能知道他在干什么。</p>
<p>于是我搜索了很多资料，在看了<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUx0NDExbTdjVw==">知行学社——paxos和分布式系统<i class="fa fa-external-link-alt"></i></span>视频后，茅塞顿开。该视频用了程序员熟悉的 Client-Server + 锁的模型来层层递进地讲解了 Paxos 的一些概念和约束条件，让我在感性上对 Paxos 要解决的问题和解决的思路有个初步的把握，之后再去读论文，很多地方便通了。</p>
<p>那么知行学社是如何拆解这个共识算法的呢？下面依照我对论文的理解，来简要梳理下视频内容，<strong>部分内容有改动</strong>。没看过视频的，强烈推荐先去看看视频。</p>
<p><strong>注</strong>：本文没有涉及到 Learner，也没有对原论文进行详细解读，更没有对 Paxos 工程化进行探讨。本来想将他们写到一篇文章中，但后来发现实在是太长了，于是拆成一个系列吧。</p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>作为一个程序员来理解 Paxos，肯定会有两个疑问：Paxos 是用来解决什么问题的？Paxos 在工程中如何应用到分布式系统？</p>
<p><strong>Paxos 算法是用来确定一个不可变量的取值的</strong>。不可变的、单个取值，貌似对分布式系统用处不大。但我们通过一个桥梁——写前日志（WAL），也可以叫操作日志，来构建一个对外表现的像单机一样的分布式系统。</p>
<p>一方面，操作日志可以视为一组不可变的操作记录组成的序列，对于不可变的单个操作记录来说，多机达成共识正是 Paxos 所解决的问题。只要稍加扩展，便能让多机就确定操作的序列达成共识。另一方面，如果我们有一份全局唯一的操作序列，每个副本便可以按相同顺序执行此操作序列，构建相同的状态机，而状态机的表达能力是很强的，可以解决一大类系统问题。</p>
<p>对于日志在分布式系统的作用，Confluent 的创始人 <span class="exturl" data-url="aHR0cHM6Ly9lbmdpbmVlcmluZy5saW5rZWRpbi5jb20vYmxvZy9hdXRob3JzL2ovamF5LWtyZXBz">Jay Kreps<i class="fa fa-external-link-alt"></i></span> 有过一篇旁征博引的的<span class="exturl" data-url="aHR0cHM6Ly9lbmdpbmVlcmluZy5saW5rZWRpbi5jb20vZGlzdHJpYnV0ZWQtc3lzdGVtcy9sb2ctd2hhdC1ldmVyeS1zb2Z0d2FyZS1lbmdpbmVlci1zaG91bGQta25vdy1hYm91dC1yZWFsLXRpbWUtZGF0YXMtdW5pZnlpbmc=">文章<i class="fa fa-external-link-alt"></i></span>，其以日志（ write-ahead logs or commit logs or transaction logs）的视角同一了分布式系统、实时处理系统、数据整合系统，推荐一读。</p>
<h2 id="问题抽象"><a href="#问题抽象" class="headerlink" title="问题抽象"></a>问题抽象</h2><p>下面，回到对 Paxos 算法本身的理解。视频首先抽象出一个实际工程问题，并逐步给出更好的解决方案，来拆解 Paxos 算法约束。</p>
<p><strong>问题描述：</strong>设计一个系统，存储名称为 var 的变量。</p>
<p><strong>系统角色</strong>：</p>
<ol>
<li>系统内部由多个 <strong>Acceptor</strong> 组成，负责存储和管理 var 变量。</li>
<li>系统外部有多个 <strong>Proposer</strong> 并发的调用系统 API，向系统提交不同的 var 取值。</li>
</ol>
<p><strong>系统 API</strong>：<code>propose(var, V) → &lt;OK, f&gt; or &lt;Error&gt;</code> 其中 f 是 Acceptor 中 var 保存的值。</p>
<p><strong>系统要求</strong>：</p>
<ol>
<li>一旦 var 的值确定，便不能更改，之后可以一直读到该值</li>
<li>可以容忍任意 Proposer 出现故障</li>
<li>可以容忍半数以下的 Acceptor 出现故障</li>
</ol>
<p>跟解算法题一样，可以先简化问题，理出基本思路。然后泛化，逐步得到原问题的解。</p>
<h2 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h2><p>假设系统由单个 Acceptor 组成。</p>
<p>为了处理多个 Proposer 的并发调用，最简单的做法，可以在 Acceptor 上使用一把互斥锁，并且通过两阶段来进行 Propose：</p>
<p><strong>Prepare 阶段：</strong></p>
<p>某 Proposer 通过 <code>Acceptor::prepare</code> 获取 Acceptor 的锁和当前 var 的值 f。如果发现锁被占用，则 abort。</p>
<p><strong>Accept 阶段</strong>：</p>
<p>如果 f 为 null，则通过 <code>Acceptor::accept(var, V)</code>，接受该 Proposer 的数据 V。</p>
<p>如果 f 不为 null，则通过 <code>Acceptor::release()</code> 释放锁。</p>
<p>该方案存在的问题：不能容忍 Proposer 机器故障。当 Proposer 调用 <code>Acceptor::prepare</code> 获取锁之后，挂掉了，就会一直占用锁，使得 Acceptor 不可用。</p>
<h2 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h2><p>解决 Proposer 故障问题。</p>
<p>Proposer 比较多，单个 Proposer 挂掉再所难免。既然我们不能决定 Proposer 的生死，就只能在锁上做文章了。比如给锁引入超时，再比如让锁可抢占。对于前者，超时阈值不太好控制：太长性能不行，太短有可能频繁重试。后者就好一些，只有有新的 Proposer 请求时才会让原来的锁失效。</p>
<p>下面展开下可抢占锁的设计。</p>
<p>可抢占必然会引入优先级问题：高优先级 Proposer 可以抢占低优先级 Proposer 的锁。我们使用一种最简单的优先级规则：每个 Proposer 在要锁的时候，需要首先申请一个号码 n（全局逻辑时钟，分布式系统基石），号码大 Proposer 优先级高。这里没有采用视频中的 epoch 叫法。而使用了论文中的叫法 n，但意思是一样的。该号码可以由一个全局发号器来分配，保证单调递增；也可以直接用时间戳，但会有多机器间戳的同步问题。</p>
<p>视频中还提到另外一个问题，即 Proposer2 抢占了 Proposer1 的锁后发现，Acceptor 的值 var 已经被设置，此时，Proposer2 能不能修改呢？但我觉得在单个 Acceptor 中这不是问题，只要任何时候都遵循 Acceptor 的 var 被设置了不能再被修改即可。</p>
<p>方案二和方案一大体相同，Acceptor 只需要多保存一个状态：当前授予锁的 Proposer 的号码 <code>latest-n</code>。并且在两个阶段都首先比对 Proposer 的标号  <strong>proposer-n</strong> 和当前保存的标号 <strong>latest-n</strong>，来决定拒绝请求还是接纳请求。此外，每次不需要调用接口显式的释放锁。</p>
<p>该方案存在的问题：单个 Acceptor 宕机会导致系统无法提供服务。</p>
<h2 id="方案三"><a href="#方案三" class="headerlink" title="方案三"></a>方案三</h2><p>在方案二基础上引入多个 Acceptor。</p>
<p>这里假设 Acceptor 集群数量固定。该情况下，扩展方案二时会遇到几个问题：</p>
<ol>
<li>Acceptor 集群如何确定一个值？过半 Acceptor 的 var 被设置成同一值；那么对于单个 Acceptor 来说，如果先接受了一个少数派，之后就要能重新接受一个多数派的值，这就要求能多次接受值。</li>
<li>Proposer 在 prepare 阶段发现某些 Acceptor 有值，是否可以直接释放锁？不一定，因为现在有多个 Acceptor ，且过半的 Acceptor 认定同一个值才算结束。因此在该值数量没有过半时， Proposer 需要继续 accept 阶段，但此时选取什么值就需要考虑一下了：是从阶段一种获取到的值集合中随机选一个，还是按照某种规则选一个。为了快速收敛，我们选择具有最大标号的值。</li>
<li>Proposer 如何在 prepare 阶段获取 Acceptor 集群的“锁”？获取过半的 Acceptor 的锁。根据<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUGlnZW9uaG9sZV9wcmluY2lwbGU=">鸽巢原理<i class="fa fa-external-link-alt"></i></span>，某个标号 n 最多有一个 Proposer 获取到锁。</li>
</ol>
<p>解决了上述几个问题，则最终方案呼之欲出：</p>
<p><strong>对于 Proposer：</strong></p>
<p><strong>prepare 阶段</strong>：获取标号 n，向 Acceptor 集群发起 <code>prepare(n)</code> 请求，未收到过半 OK 回复则终止。收到过半 <code>OK</code> 回复时，若回复中存在非 null 的值，则选取标号最大的值 v；若回复中不存在任何值，则可以选择任意值 v 发起 accept 请求。</p>
<p><strong>accept 阶段</strong>：使用上阶段选定的值 v，向 Acceptor 集群发起 <code>accept(n, v)</code> 请求。如果收到半数以上 <code>OK</code>，则说明集群接受 v 成功。否则，说明可能被更高标号的 Proposer 抢占了或者某些 Acceptor 故障。</p>
<p><strong>注1</strong>：两个阶段并不用向集群中所有 Acceptor 全都发起请求，只要选择一个过半的集合就可。并且阶段一和阶段二选择的 Acceptor 集合也不必相同。</p>
<p><strong>注2</strong>：第一阶段我们只强调了获取逻辑“锁”的作用（快速失败），其实另外一个重要作用是获取（读取）之前决议值。</p>
<p><strong>对于 Acceptor：</strong></p>
<p>需要维护的状态：当前 accept 的值和对应标号 <code>&lt;accepted-n, accepted-v&gt;</code>，以及当前授权的锁的最大标号：<code>latest-n</code>。</p>
<p><strong>prepare 阶段</strong>：收到 Proposer 的 <code>prepare(n)</code> 请求，如果 latest-n &gt; n，则返回 <code>Error</code>。否则返回 <code>&lt;OK, accepted-n, accepted-v&gt;</code>。并更新 latest-n 为 n。</p>
<p><strong>accept 阶段</strong>：收到 Proposer 的 <code>accept(n, v)</code> 请求，如果 latest-n &gt; n，则返回 <code>Error</code>。否则接受请求，更新 latest-n 、 accepted-n、accepted-v，并返回 <code>OK</code>。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>看了知行学社视频，结合上面的梳理，再去读 Paxos made simple 论文，应该能有个比较好的理解。后来我想，直接读论文难以理解原因是什么？一方面，论文没有太多铺垫，上来就开始推理（当然，在原论文中作者还是给出了一个理解背景的），而我们脑中并没有一个合适的模型来理解论文中提到的各种概念；另一方面，论文是一个逆向组织的过程，即从结论逐步推出需要满足的条件，最后再将所有条件组合起来。这些都造成了直接拿起论文就读的困难。</p>
<p>最后，再次总结下 Paxos 的理解要点：</p>
<ol>
<li>弄明白原始 Paxos 的目的，就是多个 Acceptor 对单个不可变值达成共识。</li>
<li>使用工程中 Client-Server + 锁的模型辅助理解。</li>
<li>将算法分为两阶段可以快速失败。</li>
<li>标号 n 的引入是为了解决死锁以及抢占顺序问题。</li>
<li>阶段二选取最大标号的值，可以使得 accept 过程快速收敛。为什么选择最大而不是最小呢？由递推归纳法得知，如果未达成共识，之后更高标号的 Proposer 再提案时也会选取该值。</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li>论文：<span class="exturl" data-url="aHR0cDovL3d3dy5zY3Muc3RhbmZvcmQuZWR1LzIwc3AtY3MyNDRiL3NjaGVkL3JlYWRpbmdzL3BheG9zX21hZGVfc2ltcGxlLnBkZg==">http://www.scs.stanford.edu/20sp-cs244b/sched/readings/paxos_made_simple.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li>翻译：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20veWFvZGQvcC82MTUwNDk4Lmh0bWw=">https://www.cnblogs.com/yaodd/p/6150498.html<i class="fa fa-external-link-alt"></i></span></li>
<li>知行学社——paxos和分布式系统：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUx0NDExbTdjVw==">https://www.bilibili.com/video/BV1Lt411m7cW<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<hr>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>paxos</tag>
        <tag>consensus</tag>
        <tag>共识算法</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统协调内核——Zookeeper</title>
    <url>/2021/05/31/zookeeper/</url>
    <content><![CDATA[<h1 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h1><p>本篇要介绍 Patrick Hunt 等人在 2010 年发表的、至今仍然广泛使用的、定位于<strong>分布式系统协调组件</strong>的论文 —— Z<span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9sZWdhY3kvZXZlbnQvYXRjMTAvdGVjaC9mdWxsX3BhcGVycy9IdW50LnBkZg==">ooKeeper: Wait-free coordination for Internet-scale systems<i class="fa fa-external-link-alt"></i></span>。我们在多线程、多进程编程时，免不了进行同步和互斥，常见手段有共享内存、消息队列、锁、信号量等等。而在分布式系统中，不同组件间必然也需要类似的协调手段，于是 Zookeeper 应运而生。配合客户端库，Zookeeper 可以提供动态参数配置（configuration metadata）、分布式锁、共享寄存器（shared register）、服务发现、集群关系（group membership）、多节点选主（leader election）等一系列分布式系统的协调服务。</p>
<p>总体来看，Zookeeper 有以下特点：</p>
<ol>
<li>Zookeeper 是一个分布式协调内核，本身功能比较内聚，以保持 API 的简洁与高效。</li>
<li>Zookeeper 提供一组高性能的、保证 FIFO的、基于事件驱动的非阻塞 API。</li>
<li>Zookeeper 使用类似文件系统的目录树方式对数据进行组织，表达能力强大，方便客户端构建更复杂的协调源语。</li>
<li>Zookeeper 是一个自洽的容错系统，使用 Zab 原子广播（atomic broadcast）协议保证高可用和一致性。</li>
</ol>
<p>本文依从论文顺序，简要介绍下 Zookeeper 的服务接口设计与模块粗略实现。更多细节请参考<span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9sZWdhY3kvZXZlbnQvYXRjMTAvdGVjaC9mdWxsX3BhcGVycy9IdW50LnBkZg==">论文<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly96b29rZWVwZXIuYXBhY2hlLm9yZy8=">开源项目主页<i class="fa fa-external-link-alt"></i></span>。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/05/31/zookeeper">https://www.qtmuniao.com/2021/05/31/zookeeper</a>, 转载请注明出处</em></p>
<h2 id="服务设计"><a href="#服务设计" class="headerlink" title="服务设计"></a>服务设计</h2><p>我们在设计服务接口的时候，首先要抽象出服务组织和交互所涉及到的基本概念，进而才能厘清围绕这些基本概念的动作集合。对于 Zookeeper 来说，这些基本概念称为<strong>术语</strong>（Terminology），动作集合称为<strong>服务接口</strong>（API）。</p>
<h3 id="术语集"><a href="#术语集" class="headerlink" title="术语集"></a>术语集</h3><ol>
<li><strong>客户端</strong>：client，使用 Zookeeper 服务的用户。</li>
<li><strong>服务器</strong>：server，提供 Zookeeper 服务的进程。</li>
<li><strong>数据树</strong>：data tree，Zookeeper 中所有的数据以树形结构进行组织。</li>
<li><strong>z-节点</strong>：znode、Zookeeper Node，数据树中的节点，是基本数据单元。</li>
<li><strong>会话</strong>：session，客户端与服务器会新建一个会话来标识一个连接，之后客户端每次请求都会通过该会话句柄来进行。Watch 事件的生命周期也是和会话绑定的。</li>
</ol>
<p>后面行文中，对应术语的中英文可能会交杂使用。</p>
<h3 id="数据组织"><a href="#数据组织" class="headerlink" title="数据组织"></a>数据组织</h3><p>Zookeeper 对所存数据进行类似文件系统的树形层次化组织，可以提供给使用者更强大的灵活性。比如可以很自然的表示<strong>命名阈</strong>（namespace），比如使用同一父节点的所有孩子表示<strong>成员关系</strong>（membership）。一个路径（Path）可以定位到一个唯一的数据节点，进而能够唯一标识一个基本数据单元。</p>
<p><img src="https://i.loli.net/2021/05/31/HzoQubUVN14Pc5T.png" alt="zookeeper 层次化的命名空间组织"></p>
<p>树中支持两种类型的 znode：</p>
<ol>
<li><strong>普通节点</strong>：Regular，生命周期无限，客户端需要调用接口显式的对这类节点进行增删。</li>
<li><strong>暂态节点</strong>：Ephemeral，生命周期绑定到会话上，会话销毁，节点删除。</li>
</ol>
<p>此外，Zookeeper 允许客户端在创建 znode 时，附加一个 <em><strong>sequential</strong></em> 标志。Zookeeper 便会自动给节点名字添加一个全局自增的计数作为后缀。</p>
<p>Zookeeper 使用<em><strong>推</strong></em>的方式实现订阅机制，即用户在订阅（<strong>watch</strong>）了某个节点后，当该节点发生变化时，客户端会收到一次通知（边缘触发），一个订阅是绑定到会话上的，因此会话销毁后，订阅的事件也会消失。</p>
<p><strong>会话机制（session）</strong>。可以看到，Zookeeper 使用会话机制管理客户端一次连接的生命周期。在实现时，会话会关联一个超时间隔（timeout）。如果客户端死掉或者与 Zookeeper 断开连接，超时时限内客户端未进行心跳，Zookeeper 会在服务器端销毁该会话。</p>
<p><strong>数据模型（Data model）</strong>。Zookeeper 本质上提供树形组织的 KV 模型。除存储键值对数据外，Zookeeper 更多的是以其空间结构和生命周期管理作为表达能力，来提供协调语义。当然，Zookeeper 也允许客户端为节点附加一些<strong>元信息（meta-data）</strong>和<strong>配置信息</strong>（<strong>configuration</strong>），并且提供版本和时间戳支持，从而提供更强大的表达能力。</p>
<h3 id="API-细节"><a href="#API-细节" class="headerlink" title="API 细节"></a>API 细节</h3><p>下面是以伪码的形式列出 Zookeeper 对客户端提供的 API 细节和注释。所有操作对象都是路径（ path） 所对应的数据节点（znode）。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在路径 path 处创建一个 znode，存入数据 data</span></span><br><span class="line"><span class="comment">// 并设置 regular, ephemeral, sequential 等 flags 标志。</span></span><br><span class="line"><span class="comment">// 返回值：znode 名字</span></span><br><span class="line"><span class="built_in">create</span>(path, data, flags) </span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果 path 处的 znode 与预期 version 相同，</span></span><br><span class="line"><span class="comment">// 则删除该 znode。</span></span><br><span class="line"><span class="comment">// 指定 version 一般是为了并发安全。</span></span><br><span class="line"><span class="built_in">delete</span>(path, version)</span><br><span class="line"></span><br><span class="line"><span class="comment">// watch 让客户端在此 path 上添加一个监听</span></span><br><span class="line"><span class="comment">// 返回值：路径对应的 znode，存在时返回 true</span></span><br><span class="line"><span class="comment">// 不存在返回 false</span></span><br><span class="line"><span class="built_in">exists</span>(path, watch)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取路径 path 对应的 znode 的数据和元信息</span></span><br><span class="line"><span class="comment">// 当 znode 存在时，允许设置 watch 来监听</span></span><br><span class="line"><span class="comment">// znode 数据变化</span></span><br><span class="line"><span class="built_in">getData</span>(path, watch)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当 version 匹配时，将数据 data 写入</span></span><br><span class="line"><span class="comment">// path 对应的 znode</span></span><br><span class="line"><span class="built_in">setData</span>(path, data, version)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取路径 path 对应的 znode 的所有孩子</span></span><br><span class="line"><span class="built_in">getChildren</span>(path, watch)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同步最新数据，通常放在 getData 前面</span></span><br><span class="line"><span class="built_in">sync</span>(path)</span><br></pre></td></tr></table></figure>

<p>上面的 API 有以下特点：</p>
<ol>
<li><strong>异步支持</strong>。所有接口都有<strong>同步（synchronous）</strong>和<strong>异步（asynchronous）</strong>版本。异步版本以回调函数方式进行执行，客户端可以根据业务需求，选择阻塞等待以获取重要更新，或者异步调用以获得更好性能。</li>
<li><strong>路径而非句柄</strong>。为了简化接口设计，并减少服务端维护的状态， Zookeeper 使用路径而非 znode 句柄的形式来提供对 znode 的操作接口。毕竟，句柄类似于 session，是有状态的，会增加分布式系统的实现复杂度。使用路径，可以配合版本信息做成类似幂等的接口，在处理多客户端并发时，更容易实现。</li>
<li><strong>版本信息</strong>。所有的<strong>更新操作（set&#x2F;delete）</strong>都需要指明对应数据的版本号，版本号不匹配则终止更新并返回异常。但可以通过指定特殊版本号 -1 ，跳过版本号检查。</li>
</ol>
<h3 id="语义保证"><a href="#语义保证" class="headerlink" title="语义保证"></a>语义保证</h3><p>在处理多个客户端向 Zookeeper 发出的并发请求时， API 有两个基本顺序的保证：</p>
<ol>
<li><strong>线性化写（Linearizable writes）</strong>。所有 Zookeeper 状态的更新请求会被串行化执行。</li>
<li><strong>客户端内的先入先出（FIFO client order）</strong>。给定客户端的请求会按其发送的顺序进行执行。</li>
</ol>
<p>但这里的线性化是一种异步线性化： A-linearizability。即单个客户端可以同时有多个正在执行的请求（multiple outstanding operations），但是这些请求会按发出顺序进行执行。对于读请求，可以在每个服务器本地（不需要通过主）执行。因此，可以通过增加服务器（Observer）提升读请求的吞吐。</p>
<p>此外，Zookeeper 还提供可用性和持久性的保证：</p>
<ol>
<li><strong>可用性（liveness）</strong>：Zookeeper 集群中过半数节点可用，则可对外正常提供服务。</li>
<li><strong>持久性（durability）</strong>：任何被成功返回给客户端的修改请求，都会作用到 Zookeeper 状态机中。即使不断有节点故障重启，只要 Zookeeper 能正常提供服务，就不会影响这一特性。</li>
</ol>
<h2 id="Zookeeper-架构"><a href="#Zookeeper-架构" class="headerlink" title="Zookeeper 架构"></a>Zookeeper 架构</h2><p>为了提供高可靠性，Zookeeper 使用多台服务器对数据进行冗余存取。然后使用 Zab 共识协议处理所有的更新请求，然后写入 WAL，进而应用到本地内存状态机（data tree）。</p>
<p>在 Zab 协议中，所有节点分为两种角色，Leader 和 Followers，前者只有一个，剩余的都是 Followers。但后来实践中，可能有 Observers。</p>
<p><img src="https://i.loli.net/2021/05/31/HMBh9nmPE3w1oDx.png" alt="zookeeper 组件与请求流程"></p>
<p>如上图所示，当 Server 收到一个请求时，首先进行预处理（Request Processor），如果是写请求，则通过 Zab 协议（Atomic Broadcast）达成一致，然后各自提交到本地数据库（Replicated Database）。对于读请求，直接读取本地数据库中状态后返回。</p>
<h3 id="请求处理（Request-Processor）"><a href="#请求处理（Request-Processor）" class="headerlink" title="请求处理（Request Processor）"></a>请求处理（Request Processor）</h3><p>所有更新请求都会被转为<strong>幂等（idempotent）</strong>的事务（txn），具体方法为获取当前状态、计算出目标状态，封装为事务，即可使用类似 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQ29tcGFyZS1hbmQtc3dhcA==">CAS<i class="fa fa-external-link-alt"></i></span> 的方式处理并发请求。因此，只要保证所有事务按固定顺序执行，就能避免不同服务器上的数据副本分裂。</p>
<h3 id="原子广播（Atomic-Broadcast）"><a href="#原子广播（Atomic-Broadcast）" class="headerlink" title="原子广播（Atomic Broadcast）"></a>原子广播（Atomic Broadcast）</h3><p>所有更新请求都会被转给 Zookeeper 的 Leader，Leader 首先将事务追加到本地 WAL，然后将变动使用 Zab 协议广播到各个节点，收到过半成功回复之后，Leader 将变动提交（Commit）到本地内存数据库，并广播该 Commit 给 Followers。</p>
<p>由于 Zab 使用多数票原则，因此 2k+1 个节点的集群最多可以容忍 k 个节点的故障（failures）。</p>
<p>为了提高系统吞吐，Zookeeper 使用流水线（pipelined）方式优化多个请求处理过程。</p>
<h3 id="复制状态机（Replicated-Database）"><a href="#复制状态机（Replicated-Database）" class="headerlink" title="复制状态机（Replicated Database）"></a>复制状态机（Replicated Database）</h3><p>每个服务器都会在本机内存中维护一个 Zookeeper 中所有状态的副本（replica），为了应对宕机重启，ZooKeeper 会定期将状态做快照。不同于普通快照，Zookeeper 称其快照为 <em>fuzzy</em> <em>snapshots</em>，即在做快照时并不上锁，通过 DFS 的方式遍历文件树 Dump 到本地。之后由于异常宕机重启时，只需加最新快照，然后重新执行最新快照之后几条 WAL 即可。由于 WAL 中记录的事务的幂等性特点，即使快照和 WAL 的时间点不完全对应，也不会影响副本间的一致性。</p>
<h3 id="客户端服务器交互事宜（Client-Server-Interactions）"><a href="#客户端服务器交互事宜（Client-Server-Interactions）" class="headerlink" title="客户端服务器交互事宜（Client-Server Interactions）"></a>客户端服务器交互事宜（Client-Server Interactions）</h3><p><strong>串行写</strong>。无论是在全局范围还是具体到一个 Server 本地，所有更新操作都是串行的。在执行某个 Path 数据更新时，该 Server 会触发所有与之连接的 Client 所订阅的 Watch 事件。需要注意，这些事件只保存在 Server 本地，因为他们是和会话关联的，如果 Client 与该 Server 断开连接，会话便会销毁，这些事件也随之消亡。</p>
<p><strong>本地读</strong>。为了获取极致性能，Zookeeper 的 Server 直接在本地处理读请求。但这有可能造成客户端拿到陈旧数据（比如其他客户端在另外的 Server 更新了同一 Path）。于是 Zookeeper 设计出了 Sync 操作，会将调用 Sync 时刻的最新提交数据同步到与该 Client 连接的 Server 上，然后将最新数据返回给 Client。即，Zookeeper 将<strong>性能</strong>与<strong>时效性</strong>的选择权交给了用户，方法是是否调用 Sync。</p>
<p><strong>一致性视图</strong>。Zookeeper 全局会维持一个事务自增标识：zxid，它本质上是个逻辑时钟，可以标识 Zookeeper 一个时刻的数据视图。Client 在故障重启后重新连接到一个新的 Server 时，如果该 Server 未执行到客户端所存 zxid，则要么 Server 执行到该 zxid 后再回复 Client，要么 Client 换一个更新的 Server 进行连接。如此，可以保证 Client 不会看到回退的视图。</p>
<p><strong>会话过期</strong>。会话在 Zookeeper 中本质上标识一个 Client 到 Server 的连接。会话有超时时间，如果 Client 长时间（大于超时间隔）不发<strong>请求</strong>或者<strong>心跳</strong>，Server 便会删除该会话。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Zookeeper 使用目录树组织数据、使用 Zab 协议同步数据、使用非阻塞方式提供接口，构建了一个表达能力强大的分布式协调性内核。可以用于分布式系统的控制面以进行协调、调度和控制。近年来基于 Raft 的 Etcd 也是类似地位。</p>
<hr>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>Zookeeper</tag>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统架构（一）—— Master-Workers 架构</title>
    <url>/2021/07/03/distributed-system-1-master-workers/</url>
    <content><![CDATA[<blockquote>
<p>分布式系统有很多经典的套路，也即设计模式。每个设计模式可以解决经典的一类问题，积累的多了，便可以稍加变化，进行取舍，设计出贴合需求的架构组织。但似乎大家在这方面经验分享的不太多，因此之后打算总结一些工作和学习的经验，既是备忘，也希望对大家有些助益。篇幅所限、能力所囿，难以面面俱到，又或疏于精确。不当之处，欢迎指正。</p>
<p>每篇将以概述背景、架构模块、总结延伸来分别解析，本篇是第一篇：Master-Workers 架构。</p>
</blockquote>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Master-Workers 架构（粗译为<strong>主从架构</strong>）是分布式系统中常见的一种组织方式，如 GFS 中的 Master、ChunkServers；MapReduce 中的 Master、Workers。面对分布式系统中一堆分离的机器资源，主从架构是一种最自然、直白的组织方式——就像一群人，有个说了算 leader 进行组织、协调，才能最大化这群人的对外输出能力。</p>
<p>这也是计算机系统中常见的一种分而治之思想的体现。即将一个复杂的系统，拆解成几个相对高内聚、低耦合的子模块，定义清楚其<strong>功能边界</strong>和<strong>交互接口</strong>，使得系统易于理解、维护和扩展。对于主从架构来说，<strong>主（Master）</strong> 通常会维护集群元信息、进而依靠这些元信息进行调度，<strong>从（Workers）</strong> 通常负责具体<strong>数据切片</strong>（存储系统）的读写或者作为<strong>子任务</strong>（计算系统）的执行单元。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/07/03/distributed/system/1/master/worekrs">https://www.qtmuniao.com/2021/07/03/distributed/system/1/master/worekrs</a>, 转载请注明出处</em></p>
<h2 id="架构模块"><a href="#架构模块" class="headerlink" title="架构模块"></a>架构模块</h2><p>主从架构系统，通常由单个 Master ，多个 Worker 组成。插一句，这里<strong>从</strong>英文翻译没有用 Slave 的原因是，我觉得 Worker 更中性一些。当然，单个 Master 会有性能瓶颈和可用性问题，通常也有多种解决方案，后面详说。但单个 Master 的好处是显而易见的：Master 作为一个控制节点，而不用处理由多副本带来的一致性问题，大大降低实现难度。</p>
<p>以我更熟悉一点的<strong>存储系统</strong>架构为例，其架构图通常长这样。</p>
<p><img src="https://i.loli.net/2021/07/03/tkfQJ4KMydGbjZU.png" alt="master-workers-architecture.png"></p>
<p>除了系统内部的 Master 和 Worker 外，还有使用系统的外部用户。我们通常称之为<strong>客户端（Client），</strong>Client 通过系统暴露的接口（如 RPC、HTTP）与系统进行交互。</p>
<h3 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h3><p>Master 通常会存储系统的<strong>元信息</strong>，什么是元信息呢？可以理解为集群组织信息在 Master 脑中的一个倒影，或者说视图（View）：比如集群有多少 Worker、每个 Worker 有多少剩余容量、负载如何、哪些 Worker 存储了哪些数据等等。</p>
<p>那元信息是怎么收集的呢？主要分两种情况：</p>
<ol>
<li><strong>配置</strong>。可以理解为集群<strong>静态信息</strong>，比如系统初始有多少个 Worker、Worker 的物理拓扑、每个 Worker 的容量等等，Master 会在启动时加载这些配置信息。</li>
<li><strong>汇报</strong>。主要是集群<strong>动态信息</strong>，Worker 在运行时，主动将自身状态汇报给 Master，比如 Worker 是否存活、Worker 负载信息、Worker 存了哪些数据等等。在系统运行中，Worker 会定时地通过<strong>心跳（Heartbeat）</strong>等方式，持续给 Master 汇报。</li>
</ol>
<p>有了这些元信息，Master 就可以对整个集群情况有个掌握，从而做出一系列的决策，试举几例：</p>
<ol>
<li><strong>调度（Schedule）</strong>。一个新的写数据请求来了，要分配给哪个 Worker 负责？通常会选择一个负载小的。</li>
<li><strong>均衡（Balance）</strong>。随着 Worker 变动、数据增删，数据在不同机器中分布可能不再均匀，在某些机器形成读写热点、在另一些机器却存在资源浪费，从而影响系统整体性能。因此需要实时监测，适时迁移。</li>
<li><strong>路由（Locate&#x2F;Route）</strong>。一个读写请求来了，不知道去找哪个 Worker？Master 便会查询元信息，给出对应数据的 Worker 信息。</li>
</ol>
<h3 id="Master-的可用性"><a href="#Master-的可用性" class="headerlink" title="Master 的可用性"></a>Master 的可用性</h3><p>可以看出整个系统的可用性全系 Master 一身。业界也有很多解决办法，比如：</p>
<ol>
<li><strong>使用主备</strong>。即给 Master 做个分身，备 Master 所有元信息要时刻跟主 Master 保持一致，一旦主 Master 挂掉，分身立刻跟上。Hadoop 后来这么干过。</li>
<li><strong>使用共识算法</strong>（<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQ29uc2Vuc3VzXyhjb21wdXRlcl9zY2llbmNlKQ==">consensus<i class="fa fa-external-link-alt"></i></span> algorithm）。简单来说，就是由一堆 Master 机器来组成<em>委员会</em>，每个状态变更都要通过某种算法达成共识。Google 的 <span class="exturl" data-url="aHR0cHM6Ly9zdGF0aWMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL21lZGlhL3Jlc2VhcmNoLmdvb2dsZS5jb20vemgtQ04vL2FyY2hpdmUvc3Bhbm5lci1vc2RpMjAxMi5wZGY=">Spanner<i class="fa fa-external-link-alt"></i></span> 就是这么干的。</li>
<li><strong>无主</strong>。系统中不再有 Master，人人平等，然后通过某种策略，比如说一致性哈希（<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQ29uc2lzdGVudF9oYXNoaW5n">consistent hash<i class="fa fa-external-link-alt"></i></span>），来分活干。Amazon 的 <a href="https://www.qtmuniao.com/2020/06/13/dynamo/">Dynamo</a> 是这么干的。</li>
</ol>
<p>每种策略都是比较大的主题，以后可以分别单开一篇，本文限于篇幅不再展开。</p>
<h3 id="Workers"><a href="#Workers" class="headerlink" title="Workers"></a>Workers</h3><p>在存储系统中，Workers 会存储实际数据，并对外提供数据 IO 服务。</p>
<p><strong>从单机视角来看</strong>，Worker 需要设计一个贴合业务需求的单机引擎，高效的存储数据。单机引擎设计也是一个很大的话题，这里简要提一嘴：</p>
<ol>
<li><strong>索引设计</strong>：比如 B+ 树、LSM-tree、哈希索引等等。</li>
<li><strong>底层系统</strong>：是用裸盘还是文件系统。</li>
<li><strong>存储介质</strong>：使用可持久化内存、固态硬盘还是机械硬盘。</li>
</ol>
<p><strong>从多机视角来看</strong>，机器的数量一上去，系统中单台机器出现故障的概率便大大提高。为了应对这种常态化的故障，需要：</p>
<ol>
<li><strong>运维的自动化</strong>。机器不可用后要自动剔除，修好后要便捷上线。</li>
<li><strong>数据的冗余化</strong>。机器故障后数据不能丢，因此每份数据要多副本存放、使用 EC 算法做冗余。</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Master-Workers 架构是分布式系统中最常用的一种组织方式。该架构类似于人类社群的组织方式，将系统的职责进行拆解，Master 收集元信息，并据此进行任务调度；Workers 负责实际工作负载，需要设计高效的单机引擎，并配合全局做冗余。该架构简单直接，但威力强大。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>分布式系统</tag>
        <tag>pattern</tag>
      </tags>
  </entry>
  <entry>
    <title>忆影流年</title>
    <url>/2021/07/10/memory-photos/</url>
    <content><![CDATA[<p>走过很多路，待日子久远，记忆日渐模糊。幸有摄影，定格流连瞬间，勾起尘封情趣。今日午后有闲，辑录一二，漫步时光，略熨燥气。</p>
<h2 id="北京"><a href="#北京" class="headerlink" title="北京"></a>北京</h2><p>求学帝都，至今十余载，这是一个有太多回忆的地方，自然要单拎一辑。不过，照片基本成于近两年，不能表现京城美景什一。故宫的庄重，古籍馆的积淀，北海的闲趣，孔庙的肃穆，土城的热闹，长城的苍凉，海坨的开发，不可胜记。</p>
<blockquote>
<p>景山远眺故宫</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/822679172.jpg"></p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/07/10/memory/photos">https://www.qtmuniao.com/2021/07/10/memory/photos</a>, 转载请注明出处</em></p>
<blockquote>
<p> 国家图书馆古籍馆</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/1189153453.jpg"></p>
<blockquote>
<p>北海 群雀乍起</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/887489333.jpg"></p>
<blockquote>
<p>孔庙 辟雍</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/282377569.jpg"></p>
<blockquote>
<p>元大都城垣遗址公园 海棠花溪</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/294899664.jpg"></p>
<blockquote>
<p>撞道口长城 雄关苍凉</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/218286748.jpg"></p>
<blockquote>
<p>海坨山 冬奥会滑雪场</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/732699161.jpg"></p>
<h2 id="游玩-城市篇"><a href="#游玩-城市篇" class="headerlink" title="游玩 城市篇"></a>游玩 城市篇</h2><p>城市多高楼，城市亦多气质。长沙，文夕大火，天星阁硕果仅存。广州，珠江淌过，岭南午后的安逸。重庆，两江交汇，渝中半岛熙熙攘攘。丽江，避过人潮，郊区觅得做古水库。</p>
<blockquote>
<p>长沙天心阁</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/905515835.jpg"></p>
<blockquote>
<p>广州小蛮腰</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/1166150262.jpg"></p>
<blockquote>
<p>重庆渝北</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/65457483.jpg"></p>
<blockquote>
<p>丽江清溪水库</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/198891963.jpg"></p>
<h2 id="游玩-风景篇"><a href="#游玩-风景篇" class="headerlink" title="游玩 风景篇"></a>游玩 风景篇</h2><p>基建愈好，重新发现祖国大好河山！稻城亚丁终年氤氲的水汽，桂林山水秀丽的十万大山，青海沁人心脾的一抹蓝湖，额济纳千年生长的胡杨林，居延古泽重新焕发的生机，乌兰布统古皇家围场的清凉，塞罕坝万亩人工林的郁郁葱葱，甘南年保玉则的玉妆神山，陕西龙洲丹霞的鬼斧神工，林州南太行大峡谷的大气磅礴，皆世间奇景。</p>
<blockquote>
<p>稻城亚丁 云帽五色海</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/600561991.jpg"></p>
<blockquote>
<p>桂林山水 十万大山</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/524408317.jpg"></p>
<blockquote>
<p>沁蓝青海湖</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/397003839.jpg"></p>
<blockquote>
<p>额济纳 古居延泽 野骆驼过水</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/611106984.jpg"></p>
<blockquote>
<p>乌兰布统草原</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/212386545.jpg"></p>
<blockquote>
<p>塞罕坝林原 造林人的奇迹</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/261606157.jpg"></p>
<blockquote>
<p>甘南 年保玉则 乱石岗</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/520667561.jpg"></p>
<blockquote>
<p>陕西 龙洲丹霞 山势若奔</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/495304091.jpg"></p>
<blockquote>
<p>额济纳 胡杨林海 </p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/270450047.jpg"></p>
<blockquote>
<p>河南林州 南太行大峡谷 太行天路</p>
</blockquote>
<p><img src="https://photo.tuchong.com/15470921/f/585416141.jpg"></p>
]]></content>
      <categories>
        <category>生活</category>
        <category>摄影</category>
      </categories>
      <tags>
        <tag>摄影</tag>
        <tag>相册</tag>
      </tags>
  </entry>
  <entry>
    <title>社交网络场景下大规模图存储实践——Facebook TAO</title>
    <url>/2021/10/07/facebook-tao/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Facebook TAO[1] ，即 The Associations and Objects 的缩写，点（对象，Object）和边（联结，Associations）是”图“中最基本的抽象，用来做 Facebook 图存储名字倒是恰如其分。</p>
<p>概括来说，TAO 是 Facebook 为了解决社交场景下，超大数据的更新与关联读取问题，其核心特点如下：</p>
<ol>
<li>提供面向 Facebook 社交信息流场景特化的图 API ，比如点查、一度关联查询、按时间的范围查询。</li>
<li>两层架构，MySQL 做存储层，MemeCache 做缓存层；缓存层又可细分为主从两层。</li>
<li>可多机房扩展，高度面向读性能优化，只提供最终一致性保证。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/10/07/facebook-tao/">https://www.qtmuniao.com/2021/10/07/facebook-tao/</a>, 转载请注明出处</em></p>
<h2 id="历史沿革"><a href="#历史沿革" class="headerlink" title="历史沿革"></a>历史沿革</h2><p>Facebook 早期沉淀的数据就在 MySQL 上[2]，MySQL 扛不住后，在 2005 年时，扎克伯格便引入了 MemCache 做缓存层，应对更高频的读请求。自此之后，MySQL 和 MemCache 便成为了 Facebook 存储层技术栈的一部分。</p>
<p>Facebook 数据请求负载通常符合时间局部性（即最近更新的数据最容易被访问），而非空间局部性。但 MySQL 中的数据通常不是按照时间有序存储的，因此 MySQL InnoDB 引擎自带的 block cache 并不匹配这一特点。另外，MemCache 本身只提供基于内存的 KV 访问模型，为了更高效的利用这些内存，Facebook 需要针对社交场景自己定制缓存策略，以尽可能多的让读请求命中。</p>
<p>将这些工程细节，包括两层存储集群，包括自行组织缓存，都暴露给应用层工程师，带来了很大的工程复杂度，引发了更多的 bug，降低了产品迭代速率。为了解决这个问题，Facebook 在 2007 年使用 PHP 在服务端做了一个抽象层，基于图存储模型，围绕点（对象）和边（联结）提供 API。由于社交场景中的喜欢、事件、页面等都可以通过图模型来方便表达，这一抽象层极大的降低了应用层工程师的心智负担。</p>
<p>但随着所需 API 越来越多，将图模型层（在 webserver 上）和数据层（在 MySQL和MemCache 集群）分离实现的缺点逐渐暴露了出来：</p>
<ol>
<li>从边集合的微小更新，会导致整个边集合失效，从而降低缓存命中率。</li>
<li>请求边列表的一个微小子集也需要将整个边列表从存储端拉倒服务端。</li>
<li>缓存一致性很难维持。</li>
<li>当时的 MemCache 集群很难协同支持实现一个纯客户端侧的惊群避免策略。</li>
</ol>
<p>所有这些问题，都可以通过重新设计统一的、基于图模型的存储层来实现。从 2009 年开始，TAO 便在 Facebook 内部的一个团队开始酝酿。再之后，TAO 逐渐发展成了支撑每秒数十亿次读取、数百万次写入，部署于跨地区海量机器上的分布式服务。</p>
<h2 id="图模型-amp-API"><a href="#图模型-amp-API" class="headerlink" title="图模型 &amp; API"></a>图模型 &amp; API</h2><p>图的最基本组成就是点和边，对应到 TAO 里就是，<strong>对象</strong>（Objects）和<strong>联结</strong>（Associations）。对象和联结都可以包含一系列由键值对表示的属性。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Object: (id) → (otype, (key  value)*)</span><br><span class="line">Assoc.: (id1, atype, id2) → (time, (key  value)*)</span><br></pre></td></tr></table></figure>

<p><strong>注</strong>：TAO 中的边都是有向边。</p>
<p>以社交网络为例，对象可以是用户、打卡、地点、评论，联结可以是朋友关系、发表评论、进行打卡、打卡于某地等等。</p>
<p>如下图 a)，假设在 Facebook 上有这么一事件：<em>Alice 和 Bob 在金门大桥打了个卡，Cathy 评论：真希望我也在那。David 喜欢了这条评论</em>。</p>
<p>用图模型表示后，如下图 b)：</p>
<p><img src="https://i.loli.net/2021/10/07/7pSWBqb4Vm2IPUO.png" alt="一个栗子"></p>
<p>可以看到，所有的数据条目如用户、地点、打卡、评论都被表示成了<strong>带类型的对象</strong>（typed objec），而对象间的关系如被谁喜欢（LIKED_BY）、是谁的朋友（FRIEND）、被谁评论（COMMENT），则被表示成了<strong>带类型的联结</strong>（typed associations）。</p>
<p>另外，尽管 TAO 中联结都是单向的，但实际中大部分关系是双向的。这时，可以增加一个反向边（inverse edges）来表示此种双向关系。</p>
<p>最后，由于联结是三元组，因此两个对象间可以有多条不同类型的边，但是同一类型的边，只能有一条。但在有些非社交场景中，可能需要相同类型的边也有多条。</p>
<h3 id="Object-API"><a href="#Object-API" class="headerlink" title="Object API"></a>Object API</h3><p>围绕 Object 的操作，是常见的增删改查（<code>create / delete / set-fields / get</code>  ）。</p>
<p>同一<strong>对象类型</strong>（object type）的对象具有同样的<strong>属性集</strong>（fields，即上面提到的 <code>(key value)*</code>），也就是说，一个对象类型对应固定的属性集。可以通过修改对象类型的 Schema 来对其所含属性进行增删。</p>
<h3 id="Association-API"><a href="#Association-API" class="headerlink" title="Association API"></a>Association API</h3><p>围绕 Association 的基本操作，也是增删改查。其中增删改如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">assoc_add(id1, atype, id2, time, (k→v)*) – 新增或者覆盖</span><br><span class="line">assoc_delete(id1, atype, id2) – 删除</span><br><span class="line">assoc_change_type(id1, atype, id2, newtype) - 修改</span><br></pre></td></tr></table></figure>

<p>值得一说的是，如果其反向边（<code>(id1, inv(atype), id2)</code>）存在，则上述 API 会同时作用于其反向边。由于多数场景下的联结是双向的，因此 Facebook 将其边的 API 默认行为同时作用于两条边。</p>
<p>另外，每个 Association 都会自动打上一个重要的特殊属性：<strong>联结时间</strong>（association time）。由于 Facebook 负载具有时间局部性，利用此时间戳可以对缓存数据集进行优化，以提高缓存命中率。</p>
<h3 id="Association-Query-API"><a href="#Association-Query-API" class="headerlink" title="Association Query API"></a>Association Query API</h3><p>围绕 Association 的查询 API，是 TAO 的核心 API，流量最大。这负载类型包括：</p>
<ol>
<li>指定 <code>(id1, type, id2)</code> 的点查，通常用来确定两个对象间是否存在对应联结，或者获取对应联结的属性。</li>
<li>指定 <code>(id1, type)</code> 的范围查询，要求结果集按时间降序排列。比如一个常见场景：<em>该条内容最新的 50 条评论是什么？</em>。此外，最好能提供迭代器形式的访问。</li>
<li>指定 <code>(id1, type)</code> 出边数查询。比如查询<em>某条评论的喜欢数是多少？</em>此种查询很常见，因此最好将其直接存下来，以能够在常数时间内返回结果。</li>
</ol>
<p>尽管联结千千万，但最近的范围是重点查询对象（时间局部性），因此联结的查询 API 主要围绕时间的范围查询展开。</p>
<p>为此，TAO 将最基本的<strong>联结集</strong>定义为 Association List。一个 Association List 是以 <code>id1</code> 为起点，出边类型为 <code>atype</code> 的所有联结的集合，按<strong>时间降序</strong>排列。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Association List: (id1, atyle) -&gt; [a_new, ..., a_old]</span><br></pre></td></tr></table></figure>

<p>基于此，定义更细粒度的几个接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 返回以 id1 为起点，以 id2set 集合所包含点为终点</span></span><br><span class="line"><span class="comment">// 创建时间 time 满足 low &lt;= time &lt;= high</span></span><br><span class="line"><span class="comment">// 的联结集合。</span></span><br><span class="line">assoc_get(id1, atype, id2set, high?, low?) </span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回联结集合的数量</span></span><br><span class="line">assoc_count(id1, atype)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回下标满足 [pos, pos+limit) 的联结集合子集</span></span><br><span class="line"><span class="comment">// pos 即 Association List 中的下标</span></span><br><span class="line">assoc_range(id1, atype, pos, limit) </span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回创建时间 time 满足，从 time &lt;= high **倒序**起始，</span></span><br><span class="line"><span class="comment">// 到 time &gt;= low 终止，不超过 limit 条联结</span></span><br><span class="line">assoc_time_range(id1, atype, high, low, limit)</span><br></pre></td></tr></table></figure>

<p>为什么结果集按时间降序排列呢？因为在 Facebook 页面信息流展示时，总是先展示最新的，然后随着不断下拉，依次加载较旧的数据。</p>
<p>举个栗子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">• “<span class="number">50</span> most recent comments on Alice’s checkin” ⇒ assoc_range(<span class="number">632</span>, COMMENT, <span class="number">0</span>, <span class="number">50</span>)</span><br><span class="line">• “How many checkins at the GG Bridge?” ⇒ assoc_count(<span class="number">534</span>, CHECKIN)</span><br></pre></td></tr></table></figure>

<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="https://i.loli.net/2021/10/07/HohFUZujB7J28ig.png" alt="TAO 架构"></p>
<p>TAO 架构整体分两层，缓存层（caching layer）和存储层（storage layer）。</p>
<h3 id="存储层"><a href="#存储层" class="headerlink" title="存储层"></a>存储层</h3><p>由于前面所说的历史原因，TAO 使用 MySQL 作为存储层。</p>
<p>因此，TAO 对外的 API 最终会被转化成 MySQL 语句作用于存储层，但对 MySQL 的查询语句都相对简单。当然，存储层也可以使用 LevelDB 这种 NoSQL 存储引擎，这样查询语句就会对应翻译为前缀遍历。当然，选择存储引擎不止要看 API 翻译方便与否，还要看数据备份、批量导入导出、多副本同步等非 API 因素。</p>
<p>单个 MySQL 服务肯定存不下所有 TAO 数据，因此 TAO 使用了 MySQL 集群支撑存储层。为了将数据均匀的分到多个 MySQL 机器上，TAO 使用一致性哈希算法将数据在逻辑上进行了切片（shard）。每个切片存到一个 MySQL db 中。每个 Object 在创建时会关联一个 shard，并将 shard_id 做到 object_id 中，因此在 Object 整个生命周期中其 shard 都不会再改变。</p>
<p>具体来说，MySQL 中所存数据主要包括两张表，一个点表，一个是边表。其中，点和其出边会存在同一个 MySQL db 中，以最小化关联查询代价。所有的点属性在保存时，会被序列化到一个叫做 data 的列。如此，可以将具有不同类型的 Object 保存到一张表中。边和点保存时类似，但是会额外在 <code>id1,atype,andtime</code>  字段上做索引，以方便基于某个点的出边的范围查询。此外，为了避免对边的数量的查询所带来的高昂开销，会额外用一张表来保存 associations 的数量。</p>
<h3 id="缓存层"><a href="#缓存层" class="headerlink" title="缓存层"></a>缓存层</h3><p><strong>读写穿透。</strong>TAO 的存储层实现了所有对外 API，对客户端（ Client ）完全屏蔽了存储层。即，Clients 只和缓存层进行交互，缓存层负责将数据同步到存储层。缓存层也是由多个缓存服务器构成，能够 Serve 任意 TAO 请求的一组缓存服务器称为一个 Tier。单个请求会路由到单个缓存服务器，不会跨多个服务器。</p>
<p><strong>缓存策略</strong>使用经典的 LRU。值得一提的是，由于 TAO 的边默认是双向的，在 Client 写入边时，由缓存层变成负责将其变为写去边和回边的两个有向边，但 TAO 并不保证其原子性。失败了会通过垃圾回收来删除中间结果。</p>
<p><strong>两层架构</strong>。TAO 中的每个逻辑分片（Shard）基本是同构的。每个逻辑分片的缓存层包括一组缓存服务器，由单个 Leader 缓存服务器和一组 Follower 缓存服务器构成。</p>
<p>其中，Followers 缓存服务器是外层，Leader 服务器是内层。所有客户端只和 Followers 打交道，Followers 缓存服务器本身只负责读请求，如果发现读未命中或者有写请求，就将其转发给所对应  Leader 缓存服务器。</p>
<p>如果读请求负载持续增加，对 Follower 缓存服务器扩容即可。</p>
<p>如果对某些 object 访问显著高于其他，TAO 会通过记录访问频次对其识别，然后进行客户端侧的缓存，并通过版本号来维持一致性。</p>
<p><strong>一致性。</strong>Leader 收到多个 Follower 的并行写请求后会将其进行定序，序列化后到存储层进行同步读写后返回；对于写请求来说，还会<strong>异步</strong>的通知其他 Follower 服务进行对应数据的更新，因此 TAO 最终只能提供最终一致性保证。这样做的好处是换来了读请求的高吞吐。</p>
<p><strong>多地扩展</strong>。由于 TAO 的读请求频次约为写频次的 25 倍，而单地数据中心（datacenter）又不能满足 Facebook 全球场景。因此 TAO 整体上使用了主从架构，两个 datacenter 都部署一套存储层+缓存层作为主从（Primary-Secondary），所有写请求都要由从数据中心的 Leader Cache 路由到主数据中心（见上图），然后由主数据中心存储层<strong>异步</strong>传回从数据中心。但从数据中心的 Leader Cache 并不等本地存储层同步回数据，即进行更新，并通知 Followers 到自己这 Refill。TAO 的这种设计，能够最大化的保证一个读取请求在一个 DataCenter 内被满足，代价是客户端可能会读到过时数据。即牺牲一致性，来降请求低延迟，提高吞吐。</p>
<h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><p>TAO 在一致性和可用性取舍方面时，选择了后者。为了高可用性和极致的性能，选择了弱化的一致性模型——最终一致性。因为在 Facebook 的大部分场景下，不可用要比不正确更加糟糕。在大部分常见场景下，TAO 能做到更强的写后读一致性（read after write consistency）。</p>
<p>TAO 中同一份数据，首先，会进行 Master-Slave Region 进行主从备份；其次，在同一 Region 中，会使用 Leader-Follower Cache 做两层缓存。更新时，不同位置的数据不同步，便会造成数据的不一致。在 TAO 中，在更新后给足够时间间隔，所有的数据副本都会趋向一致，并且体现最新更新。而通常，这个时间间隔不会超过 1s 。这在 Facebook 中大多数场景是没有问题的。</p>
<p>对于那些对一致性有特殊要求的场景，应用层可以将请求标记为 critical。TAO 在接到有此标记的请求时，会将其转发到 Master Region 进行处理，进而获取强一致性。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] TAO 论文：<span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9zeXN0ZW0vZmlsZXMvY29uZmVyZW5jZS9hdGMxMy9hdGMxMy1icm9uc29uLnBkZg==">https://www.usenix.org/system/files/conference/atc13/atc13-bronson.pdf<i class="fa fa-external-link-alt"></i></span></p>
<p>[2] Facebook 技术博客，TAO——图的威力：<span class="exturl" data-url="aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vMjAxMy8wNi8yNS9jb3JlLWRhdGEvdGFvLXRoZS1wb3dlci1vZi10aGUtZ3JhcGgv">https://engineering.fb.com/2013/06/25/core-data/tao-the-power-of-the-graph/<i class="fa fa-external-link-alt"></i></span></p>
<p>[3] meetup TAO：<span class="exturl" data-url="aHR0cHM6Ly93d3cubm90aW9uLnNvL01lZXR1cC0xLUZhY2Vib29rLVRBTy0yOGU4ODgzNmEzZjY0OWJhOWIzZTNlYTgzODU4YzU5Mw==">https://www.notion.so/Meetup-1-Facebook-TAO-28e88836a3f649ba9b3e3ea83858c593<i class="fa fa-external-link-alt"></i></span></p>
<p>[4] stanford 6.S897 课件： <span class="exturl" data-url="aHR0cHM6Ly9jcy5zdGFuZm9yZC5lZHUvfm1hdGVpL2NvdXJzZXMvMjAxNS82LlM4OTcvc2xpZGVzL3Rhby5wZGY=">https://cs.stanford.edu/~matei/courses/2015/6.S897/slides/tao.pdf<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>存储</tag>
        <tag>facebook</tag>
        <tag>TAO</tag>
        <tag>图存储</tag>
      </tags>
  </entry>
  <entry>
    <title>漫谈 LevelDB 数据结构（三）：LRU 缓存（ LRUCache）</title>
    <url>/2021/05/09/levedb-data-structures-lru-cache/</url>
    <content><![CDATA[<blockquote>
<p>早对 LevelDB 有所耳闻，这次心血来潮结合一些资料粗略过了遍代码，果然名不虚传。如果你对存储感兴趣、如果你想优雅使用 C++、如果你想学习如何架构项目，都推荐来观摩一下。更何况作者是 Sanjay Ghemawat 和 Jeff Dean 呢。<br>看过一遍如果不输出点什么，以我的记性，定会很快抛诸脑后。便想写点东西说说 LevelDB 之妙，但又不想走寻常路：从架构概览说起，以模块分析做合。读代码的这些天，一直在盘算从哪下笔比较好。在将将读完之时，印象最深的反而是 LevelDB 的各种精妙的数据结构：贴合场景、从头构建、剪裁得当、代码精到。不妨， LevelDB 系列就从这些边边角角的小构件开始吧。<br>本系列主要想分享 LevelDB 中用到的三个工程中常用的经典数据结构，分别是用以快速读写 memtable 的 Skip List、用以快速筛选 sstable 的 Bloom Filter 和用以部分缓存 sstable 的 LRUCache 。这是第三篇，LRUCache。</p>
</blockquote>
<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>LRU 是工程中多见的一个数据结构，常用于缓存场景。近年来，LRU 也是面试中一道炙手可热的考题，一来工程用的多，二来代码量较少，三来涉及的数据结构也很典型。LeetCode 中有一道相应的题目：<span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS5jb20vcHJvYmxlbXMvbHJ1LWNhY2hlLw==">lru-cache<i class="fa fa-external-link-alt"></i></span>。相对实际场景，题目进行了简化：本质上要求维护一个按访问时间有序的 kv 集合，且 kv 皆是整数。经典解法是使用一个哈希表（unordered_map）和一个双向链表，哈希表解决索引问题，双向链表维护访问顺序。这是我当时的一个<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NvbmdwZW5nd2VpL0FsZ29yaXRobXMvYmxvYi9tYXN0ZXIvZW5naW5lZXJpbmcvbHJ1LWNhY2hlLmNj">解法<i class="fa fa-external-link-alt"></i></span>，特点是用了两个辅助函数，并且可以返回节点自身，以支持链式调用，从而简化了代码。</p>
<p>说回 LevelDB 源码，作为一个工业品，它使用 的 LRUCache 又做了哪些优化和变动呢？下面让我们一块来拆解下 LevelDB 中使用的 LRUCache，看看有什么不同。</p>
<p>本文首先明确 LRUCache 的使用方法，然后总览分析 LRUCache 的实现思路，最后详述相关数据结构的实现细节。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/05/09/levedb-data-structures-lru-cache/">https://www.qtmuniao.com/2021/05/09/levedb-data-structures-lru-cache/</a>, 转载请注明出处</em></p>
<h2 id="缓存使用"><a href="#缓存使用" class="headerlink" title="缓存使用"></a>缓存使用</h2><p>在分析 LRUCache 的实现之前，首先了解下 LRUCache 的使用方法，以明确 LRUCache 要解决的问题。以此为基础，我们才能了解为什么要这么实现，甚至更进一步，探讨有没有更好的实现。</p>
<p>首先来看下 LevelDB 的导出接口 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS9sZXZlbGRiL2Jsb2IvbWFzdGVyL2luY2x1ZGUvbGV2ZWxkYi9jYWNoZS5o">Cache<i class="fa fa-external-link-alt"></i></span>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 插入一个键值对（key，value）到缓存（cache）中，</span></span><br><span class="line"><span class="comment">// 并从缓存总容量中减去该键值对所占额度（charge） </span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// 返回指向该键值对的句柄（handle），调用者在用完句柄后，</span></span><br><span class="line"><span class="comment">// 需要调用 this-&gt;Release(handle) 进行释放</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 在键值对不再被使用时，键值对会被传入的 deleter 参数</span></span><br><span class="line"><span class="comment">// 释放</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Handle* <span class="title">Insert</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">void</span>* value, <span class="type">size_t</span> charge,</span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">void</span> (*deleter)(<span class="type">const</span> Slice&amp; key, <span class="type">void</span>* value))</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果缓存中没有相应键（key），则返回 nullptr</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 否则返回指向对应键值对的句柄（Handle）。调用者用完句柄后，</span></span><br><span class="line"><span class="comment">// 要记得调用 this-&gt;Release(handle) 进行释放</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Handle* <span class="title">Lookup</span><span class="params">(<span class="type">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 释放 Insert/Lookup 函数返回的句柄</span></span><br><span class="line"><span class="comment">// 要求：该句柄没有被释放过，即不能多次释放</span></span><br><span class="line"><span class="comment">// 要求：该句柄必须是同一个实例返回的</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Release</span><span class="params">(Handle* handle)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取句柄中的值，类型为 void*（表示任意用户自定义类型）</span></span><br><span class="line"><span class="comment">// 要求：该句柄没有被释放</span></span><br><span class="line"><span class="comment">// 要求：该句柄必须由同一实例所返回</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span>* <span class="title">Value</span><span class="params">(Handle* handle)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果缓存中包含给定键所指向的条目，则删除之。</span></span><br><span class="line"><span class="comment">// 需要注意的是，只有在所有持有该条目句柄都释放时，该条目所占空间才会真正被释放</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Erase</span><span class="params">(<span class="type">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回一个自增的数值 id。当一个缓存实例由多个客户端共享时，</span></span><br><span class="line"><span class="comment">// 为了避免多个客户端的键冲突，每个客户端可能想获取一个独有</span></span><br><span class="line"><span class="comment">// 的 id，并将其作为键的前缀。类似于给每个客户端一个单独的命名空间。</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">uint64_t</span> <span class="title">NewId</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 驱逐全部没有被使用的数据条目</span></span><br><span class="line"><span class="comment">// 内存吃紧型的应用可能想利用此接口定期释放内存。</span></span><br><span class="line"><span class="comment">// 基类中的 Prune 默认实现为空，但强烈建议所有子类自行实现。</span></span><br><span class="line"><span class="comment">// 将来的版本可能会增加一个默认实现。</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Prune</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回当前缓存中所有数据条目所占容量总和的一个预估</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">size_t</span> <span class="title">TotalCharge</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<p>依据上述接口，可捋出 LevelDB 缓存相关需求：</p>
<ol>
<li>多线程支持</li>
<li>性能需求</li>
<li>数据条目的生命周期管理</li>
</ol>
<p>用状态机来表示 Cache 中的 Entry 的生命周期如下：</p>
<p><img src="https://i.loli.net/2021/05/09/cCweIyiS3oaKOMD.png" alt="leveldb-entry-lifecycle.png"></p>
<p>可以看出该状态机要比 LeetCode 中复杂一些，首先增加了多线程的引用，其次需要区分被引用（inuse） 和空闲（idle） 状态。</p>
<p>多个线程可以通过 <code>Insert</code>、<code>Lookup</code> 对同一个条目进行插入和引用，因此缓存需要维护每个条目（entry）的引用数量。只有引用数量为 0 的条目才会进入一个待驱逐（idle）的状态，将所有待驱逐的条目按 LRU 顺序排序，在用量超过容量时，将依据上述顺序对最久没使用过的条目进行驱逐。</p>
<p>此外，需要进行线程间同步和互斥，以保证 Cache 是线程安全的，最简单的方法是整个 Cache 使用一把锁，但这样多线程间争抢比较严重，会有性能问题。</p>
<p>接下来看看 LevelDB 的 LRUCache 是如何解决这些问题的。</p>
<h2 id="思路总览"><a href="#思路总览" class="headerlink" title="思路总览"></a>思路总览</h2><p>总体上来说，LevelDB 的 LRUCache 也使用了哈希表和双向链表的实现思路，但又有些不同：</p>
<ol>
<li>使用数组+链表处理冲突定制了一个极简哈希表，便于控制分配以及伸缩。</li>
<li>多线程支持。了提高并发，引入了分片；为了区分是否被客户端引用，引入两个双向链表。</li>
</ol>
<p>整个代码相当简洁，思想也比较直观。</p>
<h3 id="定制哈希表"><a href="#定制哈希表" class="headerlink" title="定制哈希表"></a>定制哈希表</h3><p>LevelDB 中哈希表保持桶的个数为 2 的次幂，从而使用位运算来通过键的哈希值快速计算出桶位置。通过 key 的哈希值来获取桶的句柄方法如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">LRUHandle** ptr = &amp;list_[hash &amp; (length_ - <span class="number">1</span>)];</span><br></pre></td></tr></table></figure>

<p>每次调整时，在扩张时将桶数量增加一倍，在缩减时将桶数量减少一半，并需要对所有数据条目进行重新分桶。</p>
<h3 id="两个链表"><a href="#两个链表" class="headerlink" title="两个链表"></a>两个链表</h3><p>LevelDB 使用两个双向链表保存数据，<strong>缓存</strong>中的所有数据要么在一个链表中，要么在另一个链表中，但不可能同时存在于两个链表中。这两个链表分别是：</p>
<ol>
<li><strong>in-use 链表</strong>。所有正在被客户端使用的数据条目（an kv item）都存在该链表中，该链表是无序的，因为在容量不够时，此链表中的条目是一定不能够被驱逐的，因此也并不需要维持一个驱逐顺序。</li>
<li><strong>lru 链表</strong>。所有已经不再为客户端使用的条目都放在 lru 链表中，该链表按最近使用时间有序，当容量不够用时，会驱逐此链表中最久没有被使用的条目。</li>
</ol>
<p>另外值得一提的是，哈希表中用来处理冲突的链表节点与双向链表中的节点使用的是同一个数据结构（<code>LRUHandle</code>），但在串起来时，用的是 <code>LRUHandle</code> 中不同指针字段。</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>LRUCache 实现主要涉及到了四个数据结构：<code>LRUHandle</code>、<code>HandleTable</code>、<code>LRUCache</code> 和 <code>ShardedLRUCache</code>。前三者组织形式如下：</p>
<p><img src="https://i.loli.net/2021/05/09/iUc8ywmJATEH7pl.png" alt="lru-cache-architecture.png"></p>
<p><code>ShardedLRUCache</code> 由一组 <code>LRUCache</code> 组成，每个 <code>LRUCache</code> 作为一个分片，同时是一个加锁的粒度，他们都实现了 <code>Cache</code> 接口。下面示意图只画了 4 个分片，代码中是 16 个。</p>
<p><img src="https://i.loli.net/2021/05/09/Dgba6dWsNerO28F.png" alt="shared-lru-cache.png"></p>
<h3 id="LRUHandle——基本数据单元"><a href="#LRUHandle——基本数据单元" class="headerlink" title="LRUHandle——基本数据单元"></a>LRUHandle——基本数据单元</h3><p><code>LRUHandle</code> 是双向链表和哈希表的基本构成单位，同时也是数据条目缓存和操作的基本单元。其结构如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">LRUHandle</span> &#123;</span><br><span class="line">  <span class="type">void</span>* value;</span><br><span class="line">  <span class="built_in">void</span> (*deleter)(<span class="type">const</span> Slice&amp;, <span class="type">void</span>* value); <span class="comment">// 释放 key,value 空间的用户回调</span></span><br><span class="line">  LRUHandle* next_hash;  <span class="comment">// 用于 hashtable 中链表处理冲突</span></span><br><span class="line">  LRUHandle* next;       <span class="comment">// 用于双向链表中维护 LRU 顺序</span></span><br><span class="line">  LRUHandle* prev;</span><br><span class="line">  <span class="type">size_t</span> charge;     <span class="comment">// TODO(opt): Only allow uint32_t?</span></span><br><span class="line">  <span class="type">size_t</span> key_length;</span><br><span class="line">  <span class="type">bool</span> in_cache;     <span class="comment">// 该 handle 是否在 cache table 中</span></span><br><span class="line">  <span class="type">uint32_t</span> refs;     <span class="comment">// 该 handle 被引用的次数</span></span><br><span class="line">  <span class="type">uint32_t</span> hash;     <span class="comment">// key 的 hash 值，用于确定分片和快速比较</span></span><br><span class="line">  <span class="type">char</span> key_data[<span class="number">1</span>];  <span class="comment">// key 的起始</span></span><br><span class="line"></span><br><span class="line">  <span class="function">Slice <span class="title">key</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="comment">// next_ is only equal to this if the LRU handle is the list head of an</span></span><br><span class="line">    <span class="comment">// empty list. List heads never have meaningful keys.</span></span><br><span class="line">    <span class="built_in">assert</span>(next != <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Slice</span>(key_data, key_length);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>特别要注意的是，<code>LRUHandle</code> 中的 <code>refs</code>  和我们前一小节中所画图中的状态机中 ref 含义并不一样。LevelDB 实现时，把 Cache 的引用也算一个引用。因此在 <code>Insert</code>  时，会令 <code>refs</code> &#x3D; 2，一个为客户端的引用，一个为 <code>LRUCache</code> 的引用。 <code>refs==1 &amp;&amp; in_cache</code>即说明该数据条目只被 <code>LRUCache</code> 引用了。</p>
<p>这个设计开始看着有点别扭，但是想了想反而觉得很贴切自然。</p>
<h3 id="HandleTable——哈希表索引"><a href="#HandleTable——哈希表索引" class="headerlink" title="HandleTable——哈希表索引"></a>HandleTable——哈希表索引</h3><p>使用位操作来对 key 进行路由，使用链表来处理冲突，实现比较直接。链表中节点是无序的，因此每次查找都需要全链表遍历。</p>
<p>其中值得一说的是 <code>FindPointer</code> 这个查找辅助函数，该函数用了双重指针，在增删节点时比较简洁，开始时可能不太好理解。在通常实现中，增删节点时，我们需要找其前驱节点。但其实增删操作只用到了前驱节点中的 <code>next_hash</code> 指针：</p>
<ol>
<li>删除：会修改 <code>next_hash</code> 的指向。</li>
<li>新增：首先读取 <code>next_hash</code>，找到下一个链节，将其链到待插入节点后边，然后修改前驱节点 <code>next_hash</code> 指向。</li>
</ol>
<p>由于本质上只涉及到前驱节点 <code>next_hash</code> 指针的读写，因此返回前驱节点 <code>next_hash</code> 指针的指针是一个更简洁的做法：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">LRUHandle** <span class="title">FindPointer</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span> </span>&#123;</span><br><span class="line">  LRUHandle** ptr = &amp;list_[hash &amp; (length_ - <span class="number">1</span>)];</span><br><span class="line">  <span class="keyword">while</span> (*ptr != <span class="literal">nullptr</span> &amp;&amp; ((*ptr)-&gt;hash != hash || key != (*ptr)-&gt;<span class="built_in">key</span>())) &#123;</span><br><span class="line">    ptr = &amp;(*ptr)-&gt;next_hash;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该函数首先使用 hash 值通过位运算，定位到某个桶。然后在该桶中逐个遍历节点：</p>
<ol>
<li>如果节点的 hash 或者 key 匹配上，则返回该节点的双重指针（<strong>前驱节点的 next_hash 指针的指针</strong>）。</li>
<li>否则，返回该链表的最后一个节点的双重指针（边界情况，如果是空链表，最后一个节点便是桶头）。</li>
</ol>
<p>由于返回的是其前驱节点 <code>next_hash</code> 的地址，因此在删除时，只需将该 next_hash 改为待删除节点后继节点地址，然后返回待删除节点即可。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">LRUHandle* <span class="title">Remove</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span> </span>&#123;</span><br><span class="line">  LRUHandle** ptr = <span class="built_in">FindPointer</span>(key, hash);</span><br><span class="line">  LRUHandle* result = *ptr;</span><br><span class="line">  <span class="keyword">if</span> (result != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    *ptr = result-&gt;next_hash;</span><br><span class="line">    --elems_;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在插入时，也是利用 <code>FindPointer</code> 函数找到待插入桶的链表尾部节点 <code>next_hash</code> 指针的指针，对于边界条件空桶来说，会找到桶的空头结点。之后需要判断是新插入还是替换，如果替换，则把被替换的旧节点返回，下面是插入新节点示意图：</p>
<p><img src="https://i.loli.net/2021/05/09/TrNCxo3evBZIuSA.png" alt="leveldb-table-insert.png"></p>
<p>如果是新插入节点，节点总数会变多，如果节点总数多到大于某个阈值后，为了保持哈希表的性能，就需要进行 <code>resize</code>，以增加桶的个数，同时将所有节点进行重新分桶。LevelDB 选定的阈值是 <code>length_</code> —— 桶的个数。</p>
<p><code>resize</code> 的操作比较重，因为需要对所有节点进行重新分桶，而为了保证线程安全，需要加锁，但这会使得哈希表一段时间不能提供服务。当然通过分片已经减小了单个分片中节点的数量，但如果分片不均匀，仍然会比较重。<span class="exturl" data-url="aHR0cHM6Ly9sZXZlbGRiLWhhbmRib29rLnJlYWR0aGVkb2NzLmlvL3poL2xhdGVzdC9jYWNoZS5odG1sI2R5bmFtaWMtc2l6ZWQtbm9uYmxvY2tpbmctaGFzaC10YWJsZQ==">这里<i class="fa fa-external-link-alt"></i></span>有提到一种渐进式的迁移方法：Dynamic-sized NonBlocking Hash table，可以将迁移时间进行均摊，有点类似于 Go GC 的演化。</p>
<h2 id="LRUCache——-哈希表索引-双向环形链表"><a href="#LRUCache——-哈希表索引-双向环形链表" class="headerlink" title="LRUCache—— 哈希表索引+双向环形链表"></a>LRUCache—— 哈希表索引+双向环形链表</h2><p>将之前分析过的导出接口 <code>Cache</code> 所包含的函数去掉后，<code>LRUCache</code> 类简化如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LRUCache</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">LRUCache</span>();</span><br><span class="line">  ~<span class="built_in">LRUCache</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 从构造函数分离出此参数的设置方法，可以让调用者在使用时进行灵活的调整</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetCapacity</span><span class="params">(<span class="type">size_t</span> capacity)</span> </span>&#123; capacity_ = capacity; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 辅助函数：将链节 e 从双向链表中摘除</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">LRU_Remove</span><span class="params">(LRUHandle* e)</span></span>;</span><br><span class="line">  <span class="comment">// 辅助函数：将链节 e 追加到链表头</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">LRU_Append</span><span class="params">(LRUHandle* list, LRUHandle* e)</span></span>;</span><br><span class="line">  <span class="comment">// 辅助函数：增加链节 e 的引用</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Ref</span><span class="params">(LRUHandle* e)</span></span>;</span><br><span class="line">  <span class="comment">// 辅助函数：减少链节 e 的引用</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Unref</span><span class="params">(LRUHandle* e)</span></span>;</span><br><span class="line">  <span class="comment">// 辅助函数：从缓存中删除单个链节 e</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">FinishErase</span><span class="params">(LRUHandle* e)</span> <span class="title">EXCLUSIVE_LOCKS_REQUIRED</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 在使用 LRUCache 前必须先初始化此值</span></span><br><span class="line">  <span class="type">size_t</span> capacity_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// mutex_ 用以保证此后的字段的线程安全</span></span><br><span class="line">  <span class="keyword">mutable</span> port::Mutex mutex_;</span><br><span class="line">  <span class="function"><span class="type">size_t</span> usage_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// lru 双向链表的空表头</span></span><br><span class="line">  <span class="comment">// lru.prev 指向最新的条目，lru.next 指向最老的条目</span></span><br><span class="line">  <span class="comment">// 此链表中所有条目都满足 refs==1 和 in_cache==true</span></span><br><span class="line">  <span class="comment">// 表示所有条目只被缓存引用，而没有客户端在使用</span></span><br><span class="line">  <span class="function">LRUHandle lru_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// in-use 双向链表的空表头</span></span><br><span class="line">  <span class="comment">// 保存所有仍然被客户端引用的条目</span></span><br><span class="line">  <span class="comment">// 由于在被客户端引用的同时还被缓存引用，</span></span><br><span class="line">  <span class="comment">// 肯定有 refs &gt;= 2 和 in_cache==true.</span></span><br><span class="line">  <span class="function">LRUHandle in_use_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 所有条目的哈希表索引</span></span><br><span class="line">  <span class="function">HandleTable table_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>可以看出该实现有以下特点：</p>
<ol>
<li>使用两个双向链表将整个缓存分成两个不相交的集合：被客户端引用的 <code>in-use</code> 链表，和不被任何客户端引用的 <code>lru_</code> 链表。</li>
<li>每个双向链表使用了一个空的头指针，以便于处理边界情况。并且表头的 <code>prev</code> 指针指向最新的条目，<code>next</code> 指针指向最老的条目，从而形成了一个双向环形链表。</li>
<li>使用 <code>usage_</code> 表示缓存当前已用量，用 <code>capacity_</code> 表示该缓存总量。</li>
<li>抽象出了几个基本操作：<code>LRU_Remove</code>、<code>LRU_Append</code>、<code>Ref</code>、<code>Unref</code> 作为辅助函数进行复用。</li>
<li>每个 <code>LRUCache</code> 由一把锁 <code>mutex_</code> 守护。</li>
</ol>
<p>了解了所有字段，以及之前的状态机，每个函数的实现应该比较容易理解。下面不再一一罗列所有函数的实现，仅挑比较复杂的 <code>Insert</code> 进行注释说明：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">Cache::Handle* <span class="title">LRUCache::Insert</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash, <span class="type">void</span>* value,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">size_t</span> charge,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">void</span> (*deleter)(<span class="type">const</span> Slice&amp; key,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                <span class="type">void</span>* value))</span> </span>&#123;</span><br><span class="line">  <span class="function">MutexLock <span class="title">l</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构建数据条目句柄</span></span><br><span class="line">  LRUHandle* e =</span><br><span class="line">      <span class="built_in">reinterpret_cast</span>&lt;LRUHandle*&gt;(<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(LRUHandle) - <span class="number">1</span> + key.<span class="built_in">size</span>()));</span><br><span class="line">  e-&gt;value = value;</span><br><span class="line">  e-&gt;deleter = deleter;</span><br><span class="line">  e-&gt;charge = charge;</span><br><span class="line">  e-&gt;key_length = key.<span class="built_in">size</span>();</span><br><span class="line">  e-&gt;hash = hash;</span><br><span class="line">  e-&gt;in_cache = <span class="literal">false</span>;</span><br><span class="line">  e-&gt;refs = <span class="number">1</span>;  <span class="comment">// 客户端引用</span></span><br><span class="line">  std::<span class="built_in">memcpy</span>(e-&gt;key_data, key.<span class="built_in">data</span>(), key.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (capacity_ &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    e-&gt;refs++;  <span class="comment">// 缓存本身引用</span></span><br><span class="line">    e-&gt;in_cache = <span class="literal">true</span>;</span><br><span class="line">    <span class="built_in">LRU_Append</span>(&amp;in_use_, e);</span><br><span class="line">    usage_ += charge;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">FinishErase</span>(table_.<span class="built_in">Insert</span>(e)); <span class="comment">// 如果是替换，要删除原来数据</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;  <span class="comment">// capacity_==0 时表示关闭缓存，不进行任何缓存</span></span><br><span class="line">    <span class="comment">// next 会在 key() 函数中被 assert 测试，因此要初始化一下</span></span><br><span class="line">    e-&gt;next = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 当超数据条目超出容量时，根据 LRU 策略将不被客户端引用的数据条目驱逐出内存</span></span><br><span class="line">  <span class="keyword">while</span> (usage_ &gt; capacity_ &amp;&amp; lru_.next != &amp;lru_) &#123;</span><br><span class="line">    LRUHandle* old = lru_.next;</span><br><span class="line">    <span class="built_in">assert</span>(old-&gt;refs == <span class="number">1</span>);</span><br><span class="line">    <span class="type">bool</span> erased = <span class="built_in">FinishErase</span>(table_.<span class="built_in">Remove</span>(old-&gt;<span class="built_in">key</span>(), old-&gt;hash));</span><br><span class="line">    <span class="keyword">if</span> (!erased) &#123;  <span class="comment">// to avoid unused variable when compiled NDEBUG</span></span><br><span class="line">      <span class="built_in">assert</span>(erased);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">reinterpret_cast</span>&lt;Cache::Handle*&gt;(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="ShardedLRUCache——分片-LRUCache"><a href="#ShardedLRUCache——分片-LRUCache" class="headerlink" title="ShardedLRUCache——分片 LRUCache"></a>ShardedLRUCache——分片 LRUCache</h2><p>引入 <code>SharedLRUCache</code> 的目的在于减小加锁的粒度，提高读写并行度。策略比较简洁—— 利用 key 哈希值的前 <code>kNumShardBits = 4</code> 个 bit 作为分片路由，可以支持 <code>kNumShards = 1 &lt;&lt; kNumShardBits</code>  16 个分片。通过 key 的哈希值计算分片索引的函数如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">uint32_t</span> <span class="title">Shard</span><span class="params">(<span class="type">uint32_t</span> hash)</span> </span>&#123; <span class="keyword">return</span> hash &gt;&gt; (<span class="number">32</span> - kNumShardBits); &#125;</span><br></pre></td></tr></table></figure>

<p>由于 <code>LRUCache</code> 和 <code>ShardedLRUCache</code> 都实现了 Cache 接口，因此 <code>ShardedLRUCache</code> 只需将所有 Cache 接口操作路由到对应 Shard 即可，总体来说 <code>ShardedLRUCache</code> 没有太多逻辑，更像一个 Wrapper，这里不再赘述。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>LevelDB 缓存代码：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS9sZXZlbGRiL2Jsb2IvbWFzdGVyL3V0aWwvY2FjaGUuY2M=">https://github.com/google/leveldb/blob/master/util/cache.cc<i class="fa fa-external-link-alt"></i></span></li>
<li>LevelDB handbook 缓存系统： <span class="exturl" data-url="aHR0cHM6Ly9sZXZlbGRiLWhhbmRib29rLnJlYWR0aGVkb2NzLmlvL3poL2xhdGVzdC9jYWNoZS5odG1sI2R5bmFtaWMtc2l6ZWQtbm9uYmxvY2tpbmctaGFzaC10YWJsZQ==">https://leveldb-handbook.readthedocs.io/zh/latest/cache.html#dynamic-sized-nonblocking-hash-table<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>leveldb</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>leveldb</tag>
        <tag>LRU</tag>
        <tag>LRU缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>微软提出的无锁 B 族树 —— Bw-Tree</title>
    <url>/2021/10/17/bwtree-index/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Bw-tree 是 2013 年微软发表的<span class="exturl" data-url="aHR0cHM6Ly8xNTcyMS5jb3Vyc2VzLmNzLmNtdS5lZHUvc3ByaW5nMjAxNy9wYXBlcnMvMDgtb2x0cGluZGV4ZXMyL2J3dHJlZS1pY2RlMjAxMy5wZGY=">相关论文<i class="fa fa-external-link-alt"></i></span>提出的数据结构。考虑到多核机器和 SSD 日趋普及，结合两大存储引擎 B+-tree 和 LSM-tree 特点，提出了一种 latch-free、delta update、log structured 的 B族树 —— Bw-tree。</p>
<p>由于上述论文在实现细节上语焉不详，cmu 几个作者在 2015 年时实现了一版基于内存的 Bw-tree，然后又发表了一篇论文，补充了一些实现上的细节，并将代码开源在了 github 上，称为 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3dhbmd6aXFpMjAxMy9Cd1RyZWU=">open bwtree<i class="fa fa-external-link-alt"></i></span>。</p>
<p>例行地总结下（太长不看版），Bw tree 的主要特点有：</p>
<ol>
<li>总体分三层：bwtree 索引层，缓存控制层和 Flash 存储层。</li>
<li>bwtree 在整体上是一棵 B+ 树，同时借鉴了 B-link 树的思想，每个节点存在一个指向右兄弟的 side pointer。</li>
<li>bwtree 在单个树节点上表现为类似 LSM-tree 的 Log-Structure，每个逻辑节点由 a base node + a delta records chain 组成。</li>
<li>bwtree 实现 latch-free 的核心数据结构叫 Mapping Table，通过 CAS 进行 installing 操作，修改一个 mapping entry 可以同时完成多个逻辑指针的修改。</li>
<li>bwtree flash 层也使用 Log-Structure Store （append only）对逻辑页的物理存储（base page 和 delta record）进行管理。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/10/17/bwtree-index">https://www.qtmuniao.com/2021/10/17/bwtree-index</a>, 转载请注明出处</em></p>
<h2 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h2><p>新数据结构的设计往往是为了适应硬件的变化。那么近些年，硬件层面有什么变化趋势呢？一方面，在单核性能压榨到极致后（摩尔定律失效），单机多核架构成为一个主要发展方向，但传统基于锁控制并发的数据结构难以充分利用多核性能。这是因为，过多的锁会导致频繁的等待和上下文切换。另一方面，闪存（Flash）的价格越来越便宜，逐渐成为主力存储类型。但闪存有其独特读写特点：顺序写比随机写快几倍，随机读并发要远强过传统磁盘。</p>
<p><img src="https://i.loli.net/2021/10/17/mNhqJSairLp6Y2n.png" alt="flash 读写性能对比"></p>
<p>针对上述两个观察，微软设计出了 bwtree。bwtree 在内存中使用无锁结构进行增量更新：</p>
<ol>
<li>无锁结构能够减少上下文切换，提高并行吞吐。</li>
<li>增量更新避免了原地更新引发的 cache miss。</li>
</ol>
<p>在外存中使用 Log Structure Store 管理物理数据存储：</p>
<ol>
<li>追加写能够充分利用闪存顺序写速度快、吞吐高的特点。</li>
<li>虽然可能带来更多随机读，但正好闪存随机读并发更高。</li>
</ol>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>bwtree 的架构图如下：</p>
<p><img src="https://i.loli.net/2021/10/17/Z26gsaCcykPNHDT.png" alt="bwtree 架构图"></p>
<p>bwtree 总体上分三个层次，逻辑上的 Bw-tree 索引层，物理上的 Log Structured Store 存储层和沟通两者的中间缓存层。缓存层使用一个核心数据结构——<strong>映射表</strong>（Mapping Table），记录 Page ID 到物理指针的映射，并控制数据在内存和闪存间移动。</p>
<h2 id="Bw-tree-索引"><a href="#Bw-tree-索引" class="headerlink" title="Bw-tree 索引"></a>Bw-tree 索引</h2><p>Bw-tree 对外提供 record（key value）级别的接口，整体结构如下图。</p>
<p>Bw-tree 的节点（Node）是弹性可变的，由一个<strong>基础节点（</strong>a base node） 和一个<strong>增量记录链</strong>（a delta records chain）组成。所有对节点的修改，包括插入（insert）、更改（modify）和删除（delete） ，都会以增量记录（delta record）的形式追加到<strong>链表头</strong>。</p>
<p>Bw-tree 中指针包括两种：节点内的<strong>物理指针（Physical link）</strong>和节点间的<strong>逻辑指针（Logical link）</strong>。逻辑指针即 page id，需要配合 Mapping Table 使用，因为后者记录了 page id 到物理指针的映射。物理指针，在内存中表现为 pointer，在闪存上表现为文件系统 or 块存储上的地址。Bw-tree 节点，如果在内存中，便通过内存指针链接到一块；如果刷到闪存上，就会通过物理地址串在一起。Bw-tree 节点间的逻辑指针，即 page id，是能够进行 CAS 方式进行并发控制的关键，后面会详细说原因。</p>
<p><strong>注</strong>：下图中的 Delta node 叫法不太科学，叫 Delta record 更合理些，因为其保存的信息粒度比 node 细要一些，一般就是单个 record 级别。</p>
<p><img src="https://i.loli.net/2021/10/17/k4heQxmIEwtVAX5.png" alt="cmu 论文中 bwtree 索引示意图"></p>
<p>Delta record 是 Bw-tree 中很重要的一个数据结构。主要有两种类型，一种是针对<strong>叶子节点</strong>（Leaf Node）的 kv 增量修改；一种是针对<strong>中间节点</strong>（Inner Node）的树结构修改。Delta record 中有几个比较重要的字段：low Key，high Key 和 side pointer。</p>
<p>我们不妨站在设计者的角度考虑一下，delta record  应该包含哪些信息？简单罗列下：</p>
<ol>
<li>包含必要的增量信息（kv 值），使之能 apply 到原节点。</li>
<li>包含一些冗余信息（low key，high key），使之对查找进行优化。</li>
<li>包含一些指向（借鉴 B-link 的 side pointer），使之能够在树结构调整时不影响并发的扫描。</li>
</ol>
<p><img src="https://i.loli.net/2021/10/17/aWj2nDw3hCxSoA7.png" alt="bwtree 逻辑节点"></p>
<p>下面来通过一些典型的场景来串一下上述设计。常见的场景有两个，一是只针对单个节点的修改（追加包含 kv 的 delta record），一般是针对叶子节点；一是针对树结构的大范围修改，一般是由于新增或者删除太多引发的子树的分裂与合并，叶子节点和中间点都会涉及。</p>
<h3 id="单节点操作"><a href="#单节点操作" class="headerlink" title="单节点操作"></a>单节点操作</h3><p>对于单个节点的操作主要包含更新（插入、删除、更改），查询（点查，范围查）和合并（<strong>consolidation</strong>）。其中，更新操作都是通过引入增量记录来完成，<strong>点查</strong>会从头开始遍历增量链直到基础节点，<strong>范围查</strong>会提前准备好节点对应的 kv vector，<strong>合并</strong>本质上是节点内的 compact。</p>
<p>单个节点改变一般只发生在叶子节点上，其类型都是对于单条记录（一个 kv）的修改操作引起的，包括：插入、删除、更改。Bw-tree 将这些修改做成一条 delta record，追加到节点内的修改链上，之后修改映射表中的链表头指向，完成修改。</p>
<p><img src="https://i.loli.net/2021/10/17/BFMUbKdoL2EyRwZ.png" alt="bwtree 单节点操作"></p>
<p>如上图 a，<strong>增量修改</strong> Page P 时，其步骤如下：</p>
<ol>
<li>在内存中新申请一个增量记录（图中 △D）。</li>
<li>给其赋值，包含增量信息（如修改类型、待修改 KV），查找优化信息（如 low key，high key）以及指向当前增量链的物理指针。</li>
<li>通过 CAS 操作，修改 Mapping Table 中对应项进行 installing，使之指向新的增量链的头。</li>
</ol>
<p>对于单节点，为了释放空间，还会进行<strong>合并操作</strong>（consolidating），如上图 b，步骤如下：</p>
<ol>
<li>在内存中新申请一个页。</li>
<li>将增量记录和基础页合并，拷贝到新申请的页中。</li>
<li>通过 CAS 操作，修改 Mapping Table 中对应项进行 installing。</li>
</ol>
<p>合并操作有点类似于 LSM-tree 中的 compact，只不过粒度更小。</p>
<h3 id="树结构变化"><a href="#树结构变化" class="headerlink" title="树结构变化"></a>树结构变化</h3><p>树结构变化，微软论文中称为SMO（index structure modification operation），包括分裂（split）与合并（merge）。由于一次树结构调整，难以通过单个 CAS 操作来完成，因此 Bw-tree 将其分解为多步。但为了保证调整中间状态时节点的对外可见性，Bw-tree 借鉴了 B-link tree 的思想：</p>
<ol>
<li>每个节点维护了一个右指针（side pointer），指向右边兄弟节点。</li>
<li>每次分裂，只允许向右边分裂。</li>
</ol>
<p>其作用在于，即使新分裂的节点的索引没有加入父节点，仍然可以通过前驱节点的右指针来访问到。</p>
<p>即，虽然子节点分裂了，但藕断丝连，仍然通过指针串在一起。</p>
<p>此外，不同于叶子节点的 kv 修改增量，中间节点的修改增量是一些特殊增量，下面会详细介绍。</p>
<p>树结构调整包括节点分裂（node split）和合并（node merge）。</p>
<p><strong>节点分裂。</strong></p>
<p><img src="https://i.loli.net/2021/10/17/1uyLlpMUFvBg395.png" alt="bwtree 节点分裂过程"><img src="/bwtree%202680f294d92b468ca412d253f01f3fd7/Untitled%203.png" alt="Untitled"></p>
<p>如上图，<strong>分裂 Page P</strong>，分为两个阶段：child split（对应上图 a、b），parent Update（对应上图 c），每个阶段使用一个 CAS 操作将<strong>修改对外可见</strong>：</p>
<ol>
<li>创建 Page Q 。容纳 Page P 的右半部分 kv 值，并将其 side pointer 逻辑指向 Page P 右兄弟 Page R。此时，Page Q 对外不可见，即通过 Bw-tree 根节点不可达。</li>
<li>安装<strong>分裂增量</strong>（Split Delta）。为了将 Page Q 对外可见，Bw-tree 引入了一个特殊增量记录：分裂增量。该分裂增量包含原 Page P 中的 split key，用以查找时在 Page P 和 Q 间进行路由；同时记录下 Page Q 作为其 side pointer。最后通过 CAS 操作，将分裂增量安装到映射表中。</li>
<li>安装<strong>索引增量</strong>（Index Entry Delta）。Page Q 从 Page Q 分裂后，需要在父节点添加一个 index entry，指向新增的节点 page Q。Bw-tree 通过引入索引增量，来完成这个操作。索引增量中除了包含 SplitKey-PQ 和 Pointer-PQ 外，还包含一个 SplitKey-QR，这样落在 <code>[SplitKey-PQ, SplitKey-QR]</code> 间的查询就可以直接路由到 Page Q 上。</li>
</ol>
<p>虽然图中各种指针看起来眼花缭乱，但理清他们只需要把握几个特点：</p>
<ol>
<li>实线是真实物理指针，虚线是逻辑指针，即 Page ID。</li>
<li>节点内的物理指针在增量记录创建时完成，Mapping Table 中物理指针通过 CAS 操作来更新。</li>
<li>更新完 Mapping Table 中的记录后，图中的虚线指针就随之改变了指向。</li>
</ol>
<p><strong>节点合并</strong>。</p>
<p><img src="https://i.loli.net/2021/10/17/57G68sOEnF1p4if.png" alt="bwtree 节点合并过程"></p>
<p>如上图，将 Page R 合并到 Page L ，分为三个阶段，每个阶段包含一个 CAS 操作：</p>
<ol>
<li><strong>标记删除</strong>（Marking for Delete）：引入<strong>移除节点增量</strong>（Remove Node Delta），追加到 Page R ，然后通过 CAS 操作更新映射表中的 Page R 对应值，将 Page R 标记删除。但此时，Page R 仍然可以通过 Page L 的 side pointer 访问到，即移除节点增量只屏蔽了来自父节点的访问。</li>
<li><strong>合并孩子节点</strong>（Merging Children）：引入<strong>节点合并增量</strong>（Node Merge Delta，遵从论文中名字，但是和 Remove Node Delta 命名不对称啊，不知道有什么特殊考虑没）。该增量记录了到 Page L 和 Page R 的物理指针，然后通过 CAS 操作，更新映射表中 Page L 的值，即该增量是逻辑页 L 的一部分。</li>
<li><strong>父节点更新</strong>（Parent Update）。引入<strong>索引删除增量</strong>（Index Term Delete Delta），追加到父节点，逻辑删除其中原先指向 Page R 的 key 和指针，然后通过 CAS 操作，更新映射表中父节点 P 的值。</li>
</ol>
<p>从图 a 中可以看出，更新映射表中 Page R 的值安装 Remove Node Delta 时，同时修改了两条逻辑指向：</p>
<ol>
<li>Page L 指向 Page R 的 side pointer。</li>
<li>父节点 Page P 指向 Page R 的 child pointer。</li>
</ol>
<p><strong>这也是映射表与逻辑指针的意义所在：通过 CAS 修改一个映射表项，达到同时修改多个逻辑指向的目的。</strong></p>
<h3 id="处理冲突"><a href="#处理冲突" class="headerlink" title="处理冲突"></a>处理冲突</h3><p>如果有一个节点进行 SMO 操作的同时，另一个线程要进行单节点更新，但与 SMO 操作产生了冲突（比如操作同一个 Page），该如何解决冲突？</p>
<p>一般来说， Bw-tree 会作为一个存储引擎嵌入到 DBMS 中，DBMS 中的事务管理模块会尽量处理外部冲突，将多个 SMO 操作进行序列化（个人猜测）。然后 Bw-tree 来处理 SMO 操作与单节点更新的冲突。</p>
<p>Bw-tree 采用了一种叫 “<strong>the help-along protocol</strong>“ 的方案，即任何线程如果发现有 SMO 操作正在进行，就先去执行 SMO 操作，再去执行自己的操作（增删改查）。即：</p>
<ol>
<li>将 SMO 的优先级提高以确定两类更新（SMO 与单节点更新）顺序。</li>
<li>所有线程遇到冲突的 SMO 时，不管是否属于本线程操作，都先去完成 SMO，这样总有一个线程完成 SMO 并得以继续，其他线程则直接放弃。</li>
</ol>
<h2 id="缓存管理（Cache-Management）"><a href="#缓存管理（Cache-Management）" class="headerlink" title="缓存管理（Cache Management）"></a>缓存管理（Cache Management）</h2><p><img src="https://i.loli.net/2021/10/17/Q3uw57fJHKDyROj.png" alt="bwtree 映射表"></p>
<h3 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h3><p>缓存层主要功能有：</p>
<ol>
<li>维护<strong>映射表</strong>（Mapping Table），保存逻辑 PID 到物理地址间的映射。物理地址可能是内存中的指针，也可能是闪存文件系统中的地址。</li>
<li>负责页面在内存和闪存之间移动，包括读取（reading）、交换（swapping）、下刷（flushing）。</li>
</ol>
<h3 id="映射表更新"><a href="#映射表更新" class="headerlink" title="映射表更新"></a>映射表更新</h3><p>所有对映射表更新都通过 latch-free 的 CAS 来完成，包括：</p>
<ol>
<li>叶子节点和中间节点的追加增量记录造成的物理指针的变化。</li>
<li>页在闪存和内存间交换造成的内存指针和文件地址的替换。</li>
</ol>
<h3 id="增量下刷"><a href="#增量下刷" class="headerlink" title="增量下刷"></a>增量下刷</h3><p>引起缓存中的页下刷的原因有很多种，比如上层事务要求做检查点，比如内存使用达到阈值需要换出。之前提到，一个逻辑页包含一个基础页和一个增量链，并且增量链在阈值范围内还会不断延长，因此对一个逻辑页的下刷不是一次性完成的，也是增量进行的。为此 Bw-tree 又引入了一种特殊的<strong>下刷增量</strong>（flush delta），记录下刷点，并添加到逻辑页中。这样如果有修改，在下次下刷时，只需要下刷增连链之后的增量记录即可。</p>
<p><img src="https://i.loli.net/2021/10/17/cbjLdiZqefr9TJ1.png" alt="bwtree 存储结构和增量下刷"></p>
<h2 id="闪存层（Log-Structured-Store，LSS）"><a href="#闪存层（Log-Structured-Store，LSS）" class="headerlink" title="闪存层（Log-Structured Store，LSS）"></a>闪存层（Log-Structured Store，LSS）</h2><p>闪存层和内存对应，都是增量刷盘，单个逻辑 page 的数据并不相连，page 内通过文件系统地址串起来。</p>
<p>会使用<strong>重写</strong>的方式进行垃圾回收，回收时可以将逻辑页的多个部分挪到一块，以减小之后的读放大。</p>
<h2 id="待读"><a href="#待读" class="headerlink" title="待读"></a>待读</h2><p>单独读微软的 bwtree 论文，存储和事务部分不太好读懂，是因为本论文只详细了描述了 bwtree 索引部分细节。至于存储和事务部分，得看微软套娃般的另外两篇论文，之后有机会我会再出两篇相关文章：</p>
<ol>
<li>缓存层和闪存层：LLAMA: A Cache&#x2F;Storage Subsystem for Modern Hardware，<span class="exturl" data-url="aHR0cDovL3d3dy52bGRiLm9yZy9wdmxkYi92b2w2L3A4NzctbGV2YW5kb3NraS5wZGY=">http://www.vldb.org/pvldb/vol6/p877-levandoski.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li>事务相关：Deuteronomy: Transaction Support for Cloud Data，<span class="exturl" data-url="aHR0cHM6Ly93d3cubWljcm9zb2Z0LmNvbS9lbi11cy9yZXNlYXJjaC93cC1jb250ZW50L3VwbG9hZHMvMjAxNi8wMi9EZXV0LVRDLnBkZg==">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Deut-TC.pdf<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>微软 2013 bwtree 论文： <span class="exturl" data-url="aHR0cHM6Ly8xNTcyMS5jb3Vyc2VzLmNzLmNtdS5lZHUvc3ByaW5nMjAxNy9wYXBlcnMvMDgtb2x0cGluZGV4ZXMyL2J3dHJlZS1pY2RlMjAxMy5wZGY=">https://15721.courses.cs.cmu.edu/spring2017/papers/08-oltpindexes2/bwtree-icde2013.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li>淘宝数据库内核月报 2018&#x2F;11 期：<span class="exturl" data-url="aHR0cDovL215c3FsLnRhb2Jhby5vcmcvbW9udGhseS8yMDE4LzExLzAxLw==">http://mysql.taobao.org/monthly/2018/11/01<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>存储引擎</tag>
        <tag>bwtree</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统是什么</title>
    <url>/2021/10/10/what-is-distributed-system/</url>
    <content><![CDATA[<blockquote>
<p>在技术领域中，分布式系统越来越成为绕不过去的一个名词。原因在于，这个时代的数据尺度与单机存储、处理能力的不匹配。于是有两条路子：机器大型化和机器互联。前者成本高昂且不灵活，于是后者越来越受青睐。根据代价守恒定律，代价不会凭空消失，硬件成本降下来了，软件设计成本便会提升。而分布式系统理论，则是帮我们降低这个软件成本的钥匙。</p>
</blockquote>
<h2 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h2><p>分布式系统奠基者 Leslie Lamport [1] 在其最重要的论文之一 ”Time, Clocks, and the Ordering of Events in a Distributed System“ [2] 中提到：</p>
<blockquote>
<p>A system is distributed if the message transmission delay is not negligible compared to the time between events in a single process.</p>
</blockquote>
<p>Lamport 是用类似相对论的思想来阐释这个问题。我们考虑两个时间尺度：<strong>进程</strong>间<strong>消息</strong>传递延迟和进程内<strong>事件</strong>间隔，如果前者相对后者不可忽略，则这组进程就是一个分布式系统。</p>
<p>理解这个定义，需要理解几个重要的概念（形式化的定义总是这样，摊手）：进程（process）、消息（message）和事件（event）。为了避免套娃，这里不做过多展开，仅给出一个形象的理解：进程就是一个负责干活的劳工，其干的活可以分解为多个步骤，每个步骤就是一个事件，消息便是劳工交流的方式。</p>
<p>这也印证了维基百科中 distributed computing [3]（分布式系统又称分布式计算）给的定义：</p>
<ol>
<li>There are several autonomous computational entities ( computers or nodes ), each of which has its own local <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTWVtb3J5Xyhjb21wdXRlcnMp">memory<i class="fa fa-external-link-alt"></i></span>.</li>
<li>The entities communicate with each other by <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTWVzc2FnZV9wYXNzaW5n">message passing<i class="fa fa-external-link-alt"></i></span>.</li>
</ol>
<p>这里面涉及到了计算机系统中最重的几种资源：计算（computational），存储（memory），以及沟通他们的网络（network）。</p>
<p>总结下，我们可以从另一个角度来对分布式系统进行描述：</p>
<p>对外，分布式系统表现为一个整体，基于总体的存储和计算能力，提供特定功能。</p>
<p>对内，分布式系统表现为一组个体，基于网络消息进行通信，分工合作。</p>
<p>而分布式系统的设计目标是，最大化整体资源利用率的同时，处理局部错误、保持对外可用性。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/10/10/what-is-distributed-system">https://www.qtmuniao.com/2021/10/10/what-is-distributed-system</a>, 转载请注明出处</em></p>
<h2 id="有什么特点"><a href="#有什么特点" class="headerlink" title="有什么特点"></a>有什么特点</h2><p>在构建分布式系统时，在逻辑上要注意以下这些方面：</p>
<ol>
<li><strong>可扩展性</strong>：可扩展性是对分布式系统最本质的要求，即系统设计允许我们只通过增加机器来应对不断增长的外部需求。</li>
<li><strong>容错性\可用性</strong>：这是可扩展性所带来的一个副作用，即在系统规模不断变大之后，单个机器故障便会成为常态。系统需要自动处理这些故障，对外保持可用性。</li>
<li><strong>并发性</strong>：由于没有全局时钟进行协调，分散的机器天然处在“平行宇宙”中。系统需要引导这些并发变为协作，以拆解并执行集群任务。</li>
<li><strong>异构性</strong>（对内）：系统需要处理进群内部不同硬件、不同操作系统、不同中间件的差异性，并且能够容纳新的异构组件加入系统。</li>
<li><strong>透明性</strong>（对外）：对外屏蔽系统复杂性，提供逻辑上的单一性。</li>
</ol>
<h2 id="有几种类型"><a href="#有几种类型" class="headerlink" title="有几种类型"></a>有几种类型</h2><p>在组织分布式系统时，在物理上可以有以下几种类型：</p>
<ol>
<li><strong>主从架构（<a href="https://www.qtmuniao.com/2021/07/03/distributed-system-1-master-workers/">master-workers</a>）</strong>：有一个负责指挥的机器，其他机器负责干活，如 Hadoop。好处是设计和实现相对容易，坏处是单点瓶颈和故障。</li>
<li><strong>点对点架构（peer-to-peer）</strong>：所有机器逻辑等价。如亚马逊 Dynamo，好处是没有单点故障，坏处是机器协调不好做、一致性也不好保证。不过，如果系统是无状态的，则这种架构很合适。</li>
<li><strong>多层架构（multi-tier）</strong>：这是一种复合架构，实际中也最常用，比如今年来常说存储计算分离。每一层可以根据不同特点（IO 密集型、计算密集型）进行设计，甚至可以复用现有组件（云原生）。</li>
</ol>
<h2 id="有哪些优劣"><a href="#有哪些优劣" class="headerlink" title="有哪些优劣"></a>有哪些优劣</h2><p>再次明确，分布式系统是由于单机能力不匹配数据尺度的一种无奈之举。因此，在做系统设计时，优先考虑单机系统。毕竟，分布式系统的复杂度是指数上升的。</p>
<p>现在来归纳下分布系统的优缺点。</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>高可用、高吞吐、高可扩展性</p>
<ol>
<li><strong>无限扩展</strong>：只要设计的好，可以通过线性的增加机器资源来应对不断增长的需求。</li>
<li><strong>低延迟</strong>：多地部署，将用户请求按地理路由到最近机房处理。</li>
<li><strong>高可用</strong>、<strong>容错</strong>：一部分机器坏掉，仍可以正常对外提供服务。</li>
</ol>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>最大的问题是复杂性。</p>
<ol>
<li><strong>数据的一致性</strong>。考虑到大量的机器故障：宕机、重启、关机，数据可能丢失、陈旧、出错，如何让系统容纳这些问题，对外保证数据的正确性，需要相当复杂的设计。</li>
<li><strong>网络和通信故障</strong>。网络的不可靠，消息可能丢失、早到、迟到、Hang 住，这给机器间的协调带来了极大的复杂度。像 TCP 等网络基础协议，能解决部分问题，但更多的需要系统层面自己处理。更不用说，开放式网络上可能存在的消息伪造。</li>
<li><strong>管理复杂度</strong>。机器数量到达一定数量级时，如何对他们进行有效监控、收集日志、负载均衡，都是很大挑战。</li>
<li><strong>延迟</strong>。网络通信延迟要比机器内通信高出几个数量级，而组件越多、网络跳数越多，延迟便会更高，这些最终都会作用于系统对外服务质量上。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>维基百科 Leslie Lamport：<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTGVzbGllX0xhbXBvcnQ=">https://en.wikipedia.org/wiki/Leslie_Lamport<i class="fa fa-external-link-alt"></i></span></li>
<li>Leslie Lamport Time, Clocks, and the Ordering of Events in a Distributed System <span class="exturl" data-url="aHR0cHM6Ly9sYW1wb3J0LmF6dXJld2Vic2l0ZXMubmV0L3B1YnMvdGltZS1jbG9ja3MucGRm">https://lamport.azurewebsites.net/pubs/time-clocks.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li>维基百科，分布式计算：<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRGlzdHJpYnV0ZWRfY29tcHV0aW5n">https://en.wikipedia.org/wiki/Distributed_computing<i class="fa fa-external-link-alt"></i></span></li>
<li>confluent 分布式系统完全指南：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY29uZmx1ZW50LmlvL2xlYXJuL2Rpc3RyaWJ1dGVkLXN5c3RlbXMv">https://www.confluent.io/learn/distributed-systems/<i class="fa fa-external-link-alt"></i></span></li>
<li>splunk 什么是分布式系统：<span class="exturl" data-url="aHR0cHM6Ly93d3cuc3BsdW5rLmNvbS9lbl91cy9kYXRhLWluc2lkZXIvd2hhdC1hcmUtZGlzdHJpYnV0ZWQtc3lzdGVtcy5odG1s">https://www.splunk.com/en_us/data-insider/what-are-distributed-systems.html<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>distributed system</tag>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>布谷鸟哈希和布谷鸟过滤器</title>
    <url>/2021/12/07/cuckoo-hash-and-cuckoo-filter/</url>
    <content><![CDATA[<h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>哈希的本质是从一个较大空间映射到一个较小的空间，因此在插入数据足够多之后，根据鸽巢原理，一定会存在位置冲突。常见的<strong>哈希表（Hash Table 或者字典，dictionary）</strong>会通过<strong>链表</strong>、<strong>开放地址探测</strong>等方式来处理冲突。单桶多函数的布谷鸟哈希，便是开放地址法处理冲突的一种哈希表，只不过有冲突后，不是通过线性寻找新的位置，而是通过额外哈希函数来寻找。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/12/07/cuckoo-hash-and-cuckoo-filter">https://www.qtmuniao.com/2021/12/07/cuckoo-hash-and-cuckoo-filter</a>, 转载请注明出处</em></p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>布谷鸟哈希最早是<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUmFzbXVzX1BhZ2g=">Rasmus Pagh<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3cvaW5kZXgucGhwP3RpdGxlPUZsZW1taW5nX0ZyaWNoZV9Sb2RsZXImYWN0aW9uPWVkaXQmcmVkbGluaz0x">Flemming Friche Rodler<i class="fa fa-external-link-alt"></i></span> 在 2001 年一次会议上公开的[1]。其基本思想为：</p>
<ol>
<li>使用两个哈希函数 h1(x) 、 h2(x) 和两个哈希桶 T1、T2 。</li>
<li>插入元素 x：<ol>
<li>如果 T1[h1(x)] 、T2[h2(x)] 有一个为空，则插入；两者都空，随便选一个插入。</li>
<li>如果 T1[h1(x)] 、T2[h2(x)] 都满，则随便选择其中一个（设为 y ），将其踢出，插入 x。</li>
<li>重复上述过程，插入元素 y。</li>
<li>如果插入时，踢出次数过多，则说明哈希桶满了。则进行扩容、ReHash 后，再次插入。</li>
</ol>
</li>
<li>查询元素 x：<ol>
<li>读取  T1[h1(x)] 、T2[h2(x)]  和 x 比对即可</li>
</ol>
</li>
</ol>
<p><img src="https://s2.loli.net/2021/12/07/ifWcXxkJCNYbuph.png" alt="cuckoo-insert.png"></p>
<p>布谷鸟（Cuckoo），即大杜鹃，喜欢在别的鸟窝里产蛋。布谷鸟幼鸟出生后，会将其他蛋踢出，借巢长大。布谷鸟哈希的关键设计正在于“踢出”（kicks out）这个动作，该设计和名字都堪称神来之笔。</p>
<h2 id="变种"><a href="#变种" class="headerlink" title="变种"></a>变种</h2><p>布谷鸟哈希可以有很多变种，比如：</p>
<ol>
<li>使用两个哈希函数和<strong>一个</strong>哈希桶。</li>
<li>使用两个哈希函数和<strong>四路</strong>哈希桶。</li>
</ol>
<p><img src="https://s2.loli.net/2021/12/07/hgCO7cPzUbxBlAZ.png" alt="cuckoo-hash.png"></p>
<p>可以证明，后者的桶的利用率会更高，感兴趣可以去看原论文[3]查看论证过程。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>cmu 大学的 Bin Fan 等人，在 2014 年发表了一篇名为：Cuckoo Filter: Practically Better Than Bloom [3] 的论文，基本思想是将布谷鸟哈希（key-value queries）的思想应用于集合（set membership）方向，可以替代工程中常用的 Bloom Filter，有以下优势：</p>
<ol>
<li>支持删除元素</li>
<li>更高的查询效率，尤其在高负载因子时</li>
<li>相比其他支持删除的 Filter 更容易实现</li>
<li>如果期望误报率在 3% 以下，所用空间比 Bloom Filter 少</li>
</ol>
<p>为了达到以上效果，Cuckoo Filter 对原 Cuckoo Hash 做了如下改变：</p>
<ol>
<li>为了提高桶的利用率，使用多路哈希桶。</li>
<li>为了减少内存的使用，只存储 key 指纹。</li>
</ol>
<p>此外，当某个值 x 被踢出时，需要找到另外一个位置。 Cuckoo Hash 是通过额外哈希函数作用于 x 计算而出：<code>h2(x)</code>。但在 Cuckoo Filter 中为了节省内存，保存的是定长的指纹 <code>finger(x)</code>而非原值 x。当 x 被踢出时，如何找到其另外一个位置？直观的，我有两种想法：</p>
<p>方法一：通过 <code>h2(finger(x))</code> 计算出另外一个位置。但这样在计算第二个位置时，相当于将原数据空间强行压缩到了指纹空间，会损失很多信息，加大碰撞概率。</p>
<p>方法二：在值中记下另外一个位置， <code>pair(finger, the other position)</code>，但这样空间占用会大大增加。</p>
<p>Cuckoo Filter 用了一个巧妙地做法，将<strong>位置</strong>（<code>h1(x)</code>）和<strong>对应值</strong>的哈希（<code>hash(finger(x))</code>）进行<strong>异或</strong>得到另外一个位置。我们指导，异或运算满足性质：三值中的任意两值异或都能得到第三值。在另一个位置 x 被踢出时，也能通过同样的方法得到原位置，如下图所示。</p>
<p><img src="https://s2.loli.net/2021/12/07/dNBWZwc43poO7CL.png" alt="xor-position-val.png"></p>
<p>为什么不直接和<code>finger(x)</code>进行异或计算另外位置呢？因为 <code>finger(x)</code> 一般位数比较少，比如 8 bit。如果按照这种方法，从物理意义上理解，即是在原位置±2^8 &#x3D; 256 的范围内找到另一个位置，因为异或只会改变低 8 bit 的值。这个范围太小了，不利于均衡散列。</p>
<p>另外有两点需要注意。一是不借助额外信息， Cuckoo Filter 是不能扩容的，因为我们已经丢失了原值 x，则无法计算扩容后新的位置 <code>hash(x)</code>。当然，如果保存有相应的 key 集合，也可以扩容后，将原来的 key 集合重新插入一遍。二是，如果两个不同值 x 和 y，恰巧满足 <code>hash(x) == hash(y) &amp;&amp; finger(x) == finger(y)</code> 则会出现假阳性。理解假阳性，我们可以从哈希的本质出发。如开篇所述，哈希本质是从大空间映射到小空间，则小空间中一定会出现碰撞，出现碰撞的两个原值一个存在，便会让人以为另一个也存在。回到 Cuckoo Filter 上，如果 x 和 y 都存在于 Cuckoo Filter 中，删除 x 或者 y 时，删除两个相同 finger 中的任何一个即可。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>布谷鸟过滤器的实现很简单， 论文中也给出了伪代码，贴在这里。</p>
<p><strong>插入 Insert(x)</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">f = <span class="built_in">fingerprint</span>(x);</span><br><span class="line">i1 = <span class="built_in">hash</span>(x);</span><br><span class="line">i2 = i1 ⊕ <span class="built_in">hash</span>(f);</span><br><span class="line"><span class="keyword">if</span> bucket[i1] <span class="keyword">or</span> bucket[i2] has an empty entry then</span><br><span class="line">  add f to that bucket;</span><br><span class="line">  <span class="keyword">return</span> Done;</span><br><span class="line"></span><br><span class="line"><span class="comment">// must relocate existing items;</span></span><br><span class="line">i = randomly pick i1 <span class="keyword">or</span> i2;</span><br><span class="line"><span class="keyword">for</span> n = <span class="number">0</span>; n &lt; MaxNumKicks; n++ <span class="keyword">do</span></span><br><span class="line">  randomly select an entry e from bucket[i];</span><br><span class="line">  swap f <span class="keyword">and</span> the fingerprint stored in entry e;</span><br><span class="line">  i = i ⊕ <span class="built_in">hash</span>(f);</span><br><span class="line">  <span class="keyword">if</span> bucket[i] has an empty entry then</span><br><span class="line">    add f to bucket[i];</span><br><span class="line">    <span class="keyword">return</span> Done;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Hashtable is considered full;</span></span><br><span class="line"><span class="keyword">return</span> Failure;</span><br></pre></td></tr></table></figure>

<p><strong>查找 Lookup(x)</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">f = <span class="built_in">fingerprint</span>(x);</span><br><span class="line">i1 = <span class="built_in">hash</span>(x);</span><br><span class="line">i2 = i1 ⊕ <span class="built_in">hash</span>(f);</span><br><span class="line"><span class="keyword">if</span> bucket[i1] <span class="keyword">or</span> bucket[i2] has f then</span><br><span class="line">  <span class="keyword">return</span> True;</span><br><span class="line"><span class="keyword">return</span> False;</span><br></pre></td></tr></table></figure>

<p><strong>删除 Delete(x)</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">f = <span class="built_in">fingerprint</span>(x);</span><br><span class="line">i1 = <span class="built_in">hash</span>(x);</span><br><span class="line">i2 = i1 ⊕ <span class="built_in">hash</span>(f);</span><br><span class="line"><span class="keyword">if</span> bucket[i1] <span class="keyword">or</span> bucket[i2] has f then</span><br><span class="line">  remove a copy of f from <span class="keyword">this</span> bucket;</span><br><span class="line">  <span class="keyword">return</span> True;</span><br><span class="line"><span class="keyword">return</span> False;</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>布谷鸟哈希和布谷鸟过滤器</p>
<ol>
<li>布谷鸟哈希：<span class="exturl" data-url="aHR0cHM6Ly93d3cuaXR1LmRrL3Blb3BsZS9wYWdoL3BhcGVycy9jdWNrb28tam91ci5wZGY=">https://www.itu.dk/people/pagh/papers/cuckoo-jour.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li>布谷鸟哈希维基百科：<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQ3Vja29vX2hhc2hpbmcjY2l0ZV9ub3RlLUN1Y2tvby0x">https://en.wikipedia.org/wiki/Cuckoo_hashing#cite_note-Cuckoo-1<i class="fa fa-external-link-alt"></i></span></li>
<li>布谷鸟过滤器 Cuckoo Filter: Practically Better Than Bloom <span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MuY211LmVkdS9+YmluZmFuL3BhcGVycy9jb25leHQxNF9jdWNrb29maWx0ZXIucGRm">https://www.cs.cmu.edu/~binfan&#x2F;papers&#x2F;conext14_cuckoofilter.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li>布谷鸟过滤器实现：[<span class="exturl" data-url="aHR0cHM6Ly9jb29sc2hlbGwuY24vYXJ0aWNsZXMvMTcyMjUuaHRtbF0=">https://coolshell.cn/articles/17225.html]<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<hr>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>cuckoo hash</tag>
        <tag>cuckoo filter</tag>
      </tags>
  </entry>
  <entry>
    <title>《水大鱼大》——我们一起经历的黄金十年</title>
    <url>/2021/11/02/big-water-big-fish/</url>
    <content><![CDATA[<blockquote>
<p>最近有兴致，想看点中国经济的书，受朋友推荐知道这本书。在微信读书上用差不多一周的时间赶着读完，虽然囫囵吞枣，倒也酣畅淋漓。以前看过吴晓波《激荡三十年》的一些章节，本书算是后传，风格一致，但是读起来会更有共鸣，因为这也正是初代九零后我们的人生中的黄金十年。作为“渐有意识”的亲历者，回放感很强。</p>
</blockquote>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>吴晓波很擅长宏大叙事和情绪铺垫，在本书中全景式的再现了 2008~2018 这十年间中国经济和企业的波澜起伏。书名“水大鱼大”乍一看很俗，看完后细想，倒也形象。市场和企业的关系，正是鱼和水的关系——水大容纳了鱼的成长厮杀，鱼大成就了水的鲜活壮阔。</p>
<p>这十年也是我从懵懂少年到步入青年的一个人生阶段。作为这段经济史的亲身经历者，对于其间的很多现象，有的没太留意，有的不得其解。作者以类似编年体的方式，以更高维的视角，紧扣时空二象，将各种线头有机的组织在一块，并带出了一些当时不广为人知的秘辛。通过这些冰山之下的暗线，让我们在重新审视这段历史时，隐隐然摸到了一些脉络。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/11/02/big-water-big-fish">https://www.qtmuniao.com/2021/11/02/big-water-big-fish</a>, 转载请注明出处</em></p>
<h2 id="脉络"><a href="#脉络" class="headerlink" title="脉络"></a>脉络</h2><p>08 年作为本书肇始，是大事频发的一年。年初的南方暴雪，年中的汶川地震，尔后的北京奥运，无一不值得重重着墨。但要说起对中国经济走向影响最大的事件，无疑是爆发于美国的次贷危机，以及中国进行应对的四万亿。中国从年初收紧银根到年末量化宽松，政策一百八十度转弯，以投资拉动增长来缓解出口下降造成的经济失速。之后的大基建、家电下乡、土地红利、房价高企、产能过剩、供给侧改革、一带一路，皆和此有诸多干系。</p>
<p>10 年开始，随着 3G 落地，运营商“降费增速”，智能机普及，中国开始进入移动互联网时代。微博重塑了公共舆论传播方式，微信极大影响了人们的通信手段，电子购物、移动支付则深刻改变中国人的购物习惯。围绕移动设备、移动互联网、物联网、O2O的大发展，带动了中国的产业变革，并吸纳了转移出去低端制造业大量服务人员，从而获得了经济发展的第二春。但同时也对国家的立法政策、金融监管、垄断治理提出了新的挑战。</p>
<p>12 年时，在体型上，中国经济已十分庞大，并形成了一定的生态；在成长模式上，又面临制度瓶颈和路径依赖问题。原先支持经济增长的基本要素，如廉价劳动力、低环境成本、低征地成本，开始渐次消失。种种迹象表明，改革开放上半场已经进入尾声。此时，新一届政府上台，政治上加大反腐力度，经济上简政放权，金融体系的证券化再造，中国经济开始在不断调整中转型。之后的一带一路、供给侧改革、自贸区试点、碳中和、雄安新区探索等等，都能看见一些影子。</p>
<h2 id="健壮性"><a href="#健壮性" class="headerlink" title="健壮性"></a>健壮性</h2><p>中国在这十年的发展是幸运的，外媒多次预言中国崩溃。比如保罗·克鲁格曼 2011 年在《纽约时报》撰文“Will China Break？”？断言中国内需不足、出口盈余下降、房地产泡沫严重，中国的情况似乎与我们在其它地方业已见到的崩溃几乎别无二致。不过，让人意外的是，中国经济总是有新的树枝突然出现。这些树枝在不同的时期有不同的名称，比如制度红利、人口红利、土地红利、国际化红利、货币泡沫或者消费升级。在2011年，那根最粗、最醒目的树枝，叫作互联网冲击波。</p>
<p>中国经济成长到今天这个体量，内部已经形成相当复杂的生态，一来能够抵御各种外部冲击，二来能够在海量实践中形成更多的创新，不断产出新的增长引擎。再加上稳定长效的政府，才能够一次次破除崩溃论，在蹒跚中转型继续向前。</p>
<h2 id="附：书中大事记"><a href="#附：书中大事记" class="headerlink" title="附：书中大事记"></a>附：书中大事记</h2><h3 id="2008"><a href="#2008" class="headerlink" title="2008"></a>2008</h3><p>雪灾、汶川地震、奥运、次贷危机。</p>
<p>国美创始人黄光裕事件。</p>
<p>三鹿奶粉三聚氰胺超标。</p>
<h3 id="2009"><a href="#2009" class="headerlink" title="2009"></a>2009</h3><p>民间集资吴英案，引起的民间资本管制放开的讨论。</p>
<p>产业刺激计划造成的中国汽车产量超过美国、恒大由濒死到重生。</p>
<p>吉利李书福借（金融危）机从福特手中收购沃尔沃。</p>
<p>腾讯借 QQ 和游戏跻身全球三大互联网公司、阿里双十一开年、新浪微博上线。</p>
<h3 id="2010"><a href="#2010" class="headerlink" title="2010"></a>2010</h3><p>GDP 超越日本、上海世博会。</p>
<p>中国制造的背后——富士康十三跳。</p>
<p>诺基亚衰落、iPad 发布。</p>
<p>QQ 日活过亿、互联网无序竞争——3Q 大战。</p>
<p>凡客诚品的快速扩张。</p>
<p>欧债危机——希腊陷入债务危机。</p>
<p>房产和农副产品价格暴涨——蒜泥狠、豆你玩。</p>
<p>微博爆火，成为左右舆论的大V聚集地。</p>
<h3 id="2011"><a href="#2011" class="headerlink" title="2011"></a>2011</h3><p>微信上线、小米第一代手机发布、支付宝独立、千团大战。</p>
<p>运动服饰行业危机——李宁，晋江系线下关门大潮。</p>
<p>铁道部长刘志军落马。</p>
<h3 id="2012"><a href="#2012" class="headerlink" title="2012"></a>2012</h3><p>新一届政府上台，改革开放进入下半场。</p>
<p>布洛克的浑水公司做空中概股，引发中概股信任危机。</p>
<p>传统机械行业产能过剩、利润下滑。</p>
<p>阿迪达斯等传统外资制造业开始将产能转移到东南亚。</p>
<p>微信在线突破一亿，公众号功能开创新媒体行业。</p>
<p>张一鸣推出今日头条、程维上线滴滴打车。</p>
<p>网络文化空前繁荣、屌丝文化、泰囧取得空前票房。</p>
<h3 id="2013"><a href="#2013" class="headerlink" title="2013"></a>2013</h3><p>中央八项规定、加大反腐力度。</p>
<p>克强经济学，简政放权，供给侧改革、金融体系的证券化再造。</p>
<p>上海自贸区、余额宝上线、李嘉诚从大陆撤资。</p>
<p>德国经济技术部提出工业 4.0。</p>
<p>雷军和董明珠十亿赌局、华为开始自有品牌手机、罗永浩开始做锤子。</p>
<h3 id="2014"><a href="#2014" class="headerlink" title="2014"></a>2014</h3><p>政策转向，央行降息，新一轮的楼市松绑周期突然到来，上证指数大涨。</p>
<p>政府提出“新常态”，放低 GDP 增速预期，开始重视环境保护。</p>
<p>京东、阿里上市，乌镇世界互联网大会。</p>
<p>快滴滴滴补贴大战。</p>
<h3 id="2015"><a href="#2015" class="headerlink" title="2015"></a>2015</h3><p>微信红包带动微信支付份额极大提升。</p>
<p>股市震荡，由年初的极盛到年末极衰，徐翔被捕，救市失败。</p>
<p>宝能试图收购万科。</p>
<p>以e租宝为代表的 p2p 泡沫。</p>
<p>乐视的泡沫金融帝国。</p>
<p>互联网合并高潮——滴滴快滴、58同城与赶集网、美团大众点评、腾讯盛大、世纪佳缘百合美丽说蘑菇街。</p>
<p>90 后带来的消费市场转型。</p>
<h3 id="2016"><a href="#2016" class="headerlink" title="2016"></a>2016</h3><p>陆奇加入百度。</p>
<p>alphago 击败李世石。</p>
<p>特朗普当选美国总统。</p>
<p>共享单车泡沫、全民直播热潮。</p>
<p>消费升级和农民工红利消失。</p>
<h3 id="2017"><a href="#2017" class="headerlink" title="2017"></a>2017</h3><p>新零售。</p>
<p>网易严选。</p>
<p>小米发布 小米6 ，扭转颓势。</p>
<p>战狼2 上映。</p>
<h3 id="2018"><a href="#2018" class="headerlink" title="2018"></a>2018</h3><p>总结和前瞻</p>
<p>继往和开来</p>
<hr>
]]></content>
      <categories>
        <category>生活</category>
        <category>读书</category>
      </categories>
      <tags>
        <tag>吴晓波</tag>
        <tag>读书</tag>
      </tags>
  </entry>
  <entry>
    <title>DDIA 读书笔记（一）：可靠、可扩展、可维护</title>
    <url>/2022/02/19/ddia-reading-chapter1/</url>
    <content><![CDATA[<blockquote>
<p>DDIA 读书分享会，会逐章进行分享，结合我在工业界分布式存储和数据库的一些经验，补充一些细节。每两周左右分享一次，欢迎加入，Schedule 和所有文字稿在<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">这里<i class="fa fa-external-link-alt"></i></span>。我们有个对应的分布式&amp;数据库讨论群，每次分享前会在群里通知。如想加入，可以加我的微信号：qtmuniao，简单自我介绍下，并注明：分布式系统群。</p>
</blockquote>
<p>第一章是很容易被跳过的一章，因为概念较多，容易泛泛而谈。但其给出的三个概念，确实是构建系统避不开的三个重点方向。</p>
<p>ps. <span class="exturl" data-url="aHR0cDovL2RkaWEudm9ubmcuY29tLw==">开源中文版本<i class="fa fa-external-link-alt"></i></span>有些地方翻译的不是很地道，读起来可能会有些难受，不过这是所有翻译难免的。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/02/19/ddia-reading-chapter1">https://www.qtmuniao.com/2022/02/19/ddia-reading-chapter1</a> 转载请注明出处</em></p>
<h2 id="本书为什么以数据系统为主题"><a href="#本书为什么以数据系统为主题" class="headerlink" title="本书为什么以数据系统为主题"></a>本书为什么以数据系统为主题</h2><p><strong>数据系统</strong>（data system）是一种模糊的统称。在信息社会中，一切皆可信息化，或者，某种程度上来说——数字化。这些数据的采集、存储和使用，是构成信息社会的基础。我们常见的绝大部分应用背后都有一套数据系统支撑，比如微信、京东、微博等等。</p>
<p><img src="https://s2.loli.net/2022/02/19/XJczNiq9SbhHLuy.png" alt="data-society.png"></p>
<p>因此，作为 IT 从业人员，有必要系统性的了解一下现代的、分布式的数据系统。学习本书，能够学习到数据系统的背后的原理、了解其常见的实践、进而将其应用到我们工作的系统设计中。</p>
<h2 id="常见的数据系统有哪些"><a href="#常见的数据系统有哪些" class="headerlink" title="常见的数据系统有哪些"></a>常见的数据系统有哪些</h2><ul>
<li>存储数据，以便之后再次使用——<strong>数据库</strong></li>
<li>记住一些非常“重”的操作结果，方便之后加快读取速度——<strong>缓存</strong></li>
<li>允许用户以各种关键字搜索、以各种条件过滤数据——<strong>搜索引擎</strong></li>
<li>源源不断的产生数据、并发送给其他进程进行处理——<strong>流式处理</strong></li>
<li>定期处理累积的大量数据——<strong>批处理</strong></li>
<li>进行消息的传送与分发——<strong>消息队列</strong></li>
</ul>
<p>这些概念如此耳熟能详以至于我们在设计系统时拿来就用，而不用去想其实现细节，更不用从头进行实现。当然，这也侧面说明这些概念抽象的多么成功。</p>
<h2 id="数据系统的日益复杂化"><a href="#数据系统的日益复杂化" class="headerlink" title="数据系统的日益复杂化"></a>数据系统的日益复杂化</h2><p>但这些年来，随着应用需求的进一步复杂化，出现了很多新型的数据采集、存储和处理系统，它们不拘泥于单一的功能，也难以生硬的归到某个类别。随便举几个例子：</p>
<ol>
<li><strong>Kafka</strong>：可以作为存储持久化一段时间日志数据、可以作为消息队列对数据进行分发、可以作为流式处理组件对数据反复蒸馏等等。</li>
<li><strong>Spark</strong>：可以对数据进行批处理、也可以化小批为流，对数据进行流式处理。</li>
<li><strong>Redis</strong>：可以作为缓存加速对数据库的访问、也可以作为事件中心对消息的发布订阅。</li>
</ol>
<p>我们面临一个新的场景，以某种组合使用这些组件时，在某种程度上，便是创立了一个新的数据系统。书中给了一个常见的对用户数据进行采集、存储、查询、旁路等操作的数据系统示例。从其示意图中可以看到各种 Web Services 的影子。</p>
<p><img src="https://s2.loli.net/2022/02/19/2fYma6MCUVpq1oy.png" alt="data-system.png"></p>
<p>但就这么一个小系统，在设计时，就可以有很多取舍：</p>
<ol>
<li>使用何种缓存策略？是旁路还是写穿透？</li>
<li>部分组件机器出现问题时，是保证可用性还是保证一致性？</li>
<li>当机器一时难以恢复，如何保证数据的正确性和完整性？</li>
<li>当负载增加时，是增加机器还是提升单机性能？</li>
<li>设计对外的 API 时，是力求简洁还是追求强大？</li>
</ol>
<p>因此，有必要从根本上思考下如何评价一个好数据系统，如何构建一个好的数据系统，有哪些可以遵循的设计模式？有哪些通常需要考虑的方面？</p>
<p>书中用了三个词来回答：<em><strong>可靠性（Reliability）、可伸缩性（Scalability）、可维护性（Maintainability）</strong></em></p>
<h2 id="可靠性（Reliability）"><a href="#可靠性（Reliability）" class="headerlink" title="可靠性（Reliability）"></a>可靠性（Reliability）</h2><p>如何衡量可靠性？</p>
<ul>
<li><p><strong>功能上</strong></p>
<ol>
<li>正常情况下，应用行为满足 API 给出的行为</li>
<li>在用户误输入&#x2F;误操作时，能够正常处理</li>
</ol>
</li>
<li><p><strong>性能上</strong></p>
<p>  在给定硬件和数据量下，能够满足承诺的性能指标。</p>
</li>
<li><p><strong>安全上</strong></p>
<p>  能够阻止未授权、恶意破坏。</p>
</li>
</ul>
<p>可用性也是可靠性的一个侧面，云服务通常以多少个 9 来衡量可用性。</p>
<hr>
<p>两个易混淆的概念：<strong>Fault（系统出现问题）</strong> and <strong>Failure（系统不能提供服务）</strong></p>
<p>不能进行 Fault-tolerance 的系统，积累的 fault 多了，就很容易 Failure。</p>
<p>如何预防？混沌测试：如 Netflix 的 <span class="exturl" data-url="aHR0cHM6Ly9uZXRmbGl4LmdpdGh1Yi5pby9jaGFvc21vbmtleS8=">chaosmonkey<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="硬件故障"><a href="#硬件故障" class="headerlink" title="硬件故障"></a>硬件故障</h3><p>在一个大型数据中心中，这是常态：</p>
<ol>
<li>网络抖动、不通</li>
<li>硬盘老化坏道</li>
<li>内存故障</li>
<li>机器过热导致 CPU 出问题</li>
<li>机房断电</li>
</ol>
<p>数据系统中常见的需要考虑的硬件指标：</p>
<ul>
<li><p><strong>MTTF mean time to failure</strong></p>
<p>  单块盘 平均故障时间 5 ~10 年，如果你有 1w+ 硬盘，则均匀期望下，每天都有坏盘出现。当然事实是硬盘会一波一波坏。</p>
</li>
</ul>
<p>解决办法，增加冗余度：</p>
<p>机房多路供电，双网络等等。</p>
<p>对于数据：</p>
<p><strong>单机</strong>：可以做RAID 冗余。如：EC 编码。</p>
<p><strong>多机</strong>：多副本 or  EC 编码。</p>
<h3 id="软件错误"><a href="#软件错误" class="headerlink" title="软件错误"></a>软件错误</h3><p>相比硬件故障的随机性，软件错误的相关性更高：</p>
<ol>
<li>不能处理特定输入，导致系统崩溃。</li>
<li>失控进程（如循环未释放资源）耗尽 CPU、内存、网络资源。</li>
<li>系统依赖组件变慢甚至无响应。</li>
<li>级联故障。</li>
</ol>
<p>在设计软件时，我们通常有一些<strong>环境假设</strong>，和一些<strong>隐性约束</strong>。随着时间的推移、系统的持续运行，如果这些假设不能够继续被满足；如果这些约束被后面维护者增加功能时所破坏；都有可能让一开始正常运行的系统，突然崩溃。</p>
<h3 id="人为问题"><a href="#人为问题" class="headerlink" title="人为问题"></a>人为问题</h3><p>系统中最不稳定的是人，因此要在设计层面尽可能消除人对系统影响。依据软件的生命周期，分几个阶段来考虑：</p>
<ul>
<li><p><strong>设计编码</strong></p>
<ol>
<li>尽可能消除所有不必要的假设，提供合理的抽象，仔细设计 API</li>
<li>进程间进行隔离，对尤其容易出错的模块使用沙箱机制</li>
<li>对服务依赖进行熔断设计</li>
</ol>
</li>
<li><p><strong>测试阶段</strong></p>
<ol>
<li>尽可能引入第三方成员测试，尽量将测试平台自动化</li>
<li>单元测试、集成测试、e2e 测试、混沌测试</li>
</ol>
</li>
<li><p><strong>运行阶段</strong></p>
<ol>
<li>详细的仪表盘</li>
<li>持续自检</li>
<li>报警机制</li>
<li>问题预案</li>
</ol>
</li>
<li><p><strong>针对组织</strong></p>
<p>  科学的培训和管理</p>
</li>
</ul>
<h3 id="可靠性有多重要？"><a href="#可靠性有多重要？" class="headerlink" title="可靠性有多重要？"></a>可靠性有多重要？</h3><p>事关用户数据安全，事关企业声誉，企业存活和做大的基石。</p>
<h2 id="可伸缩性（Scalability）"><a href="#可伸缩性（Scalability）" class="headerlink" title="可伸缩性（Scalability）"></a>可伸缩性（Scalability）</h2><p>可伸缩性，即系统应对负载增长的能力。它很重要，但在实践中又很难做好，因为存在一个基本矛盾：<strong>只有能存活下来的产品才有资格谈伸缩，而过早为伸缩设计往往活不下去</strong>。</p>
<p>但仍是可以了解一些基本的概念，来应对<strong>可能会</strong>暴增的负载。</p>
<h3 id="衡量负载"><a href="#衡量负载" class="headerlink" title="衡量负载"></a>衡量负载</h3><p>应对负载之前，要先找到合适的方法来衡量负载，如<strong>负载参数（load parameters）</strong>：</p>
<ul>
<li>应用日活月活</li>
<li>每秒向Web服务器发出的请求</li>
<li>数据库中的读写比率</li>
<li>聊天室中同时活跃的用户数量</li>
</ul>
<p>书中以 Twitter 2012年11 披露的信息为例进行了说明：</p>
<ol>
<li>识别主营业务：发布推文、首页 Feed 流。</li>
<li>确定其请求量级：发布推文（平均 4.6k请求&#x2F;秒，峰值超过 12k请求&#x2F;秒），查看其他人推文（300k请求&#x2F;秒）</li>
</ol>
<p><img src="https://s2.loli.net/2022/02/19/TY4N7gA39hFtxcH.png" alt="twitter-table.png"></p>
<p>单就这个数据量级来说，无论怎么设计都问题不大。但 Twitter 需要根据用户之间的关注与被关注关系来对数据进行多次处理。常见的有推拉两种方式：</p>
<ol>
<li><strong>拉</strong>。每个人查看其首页 Feed 流时，从数据库现<strong>拉取</strong>所有关注用户推文，合并后呈现。</li>
<li><strong>推</strong>。为每个用户保存一个 Feed 流视图，当用户发推文时，将其插入所有关注者 Feed 流视图中。</li>
</ol>
<p><img src="https://s2.loli.net/2022/02/19/vKsokpb5XaMlSTA.png" alt="twitter-push.png"></p>
<p>前者是 Lazy 的，用户只有查看时才会去拉取，不会有无效计算和请求，但每次需要现算，呈现速度较慢。而且流量一大也扛不住。</p>
<p>后者实现算出视图，而不管用户看不看，呈现速度较快，但会引入很多无效请求。</p>
<p>最终，使用的是一种推拉结合的方式，这也是外国一道经典的系统设计考题。</p>
<h3 id="描述性能"><a href="#描述性能" class="headerlink" title="描述性能"></a>描述性能</h3><p>注意和系统负载区分，系统负载是从用户视角来审视系统，是一种<strong>客观指标</strong>。而系统性能则是描述的系统的一种<strong>实际能力</strong>。比如：</p>
<ol>
<li><strong>吞吐量（throughput）：</strong>每秒可以处理的单位数据量，通常记为 QPS。</li>
<li><strong>响应时间（response time）：</strong>从用户侧观察到的发出请求到收到回复的时间。</li>
<li><strong>延迟（latency）</strong>：日常中，延迟经常和响应时间混用指代响应时间；但严格来说，延迟只是只请求过程中排队等休眠时间，虽然其在响应时间中一般占大头；但只有我们把请求真正处理耗时认为是瞬时，延迟才能等同于响应时间。</li>
</ol>
<p>响应时间通常以百分位点来衡量，比如 p95，p99和 p999，它们意味着95％，99％或 99.9％ 的请求都能在该阈值内完成。在实际中，通常使用滑动窗口滚动计算最近一段时间的响应时间分布，并通常以折线图或者柱状图进行呈现。</p>
<h3 id="应对负载"><a href="#应对负载" class="headerlink" title="应对负载"></a>应对负载</h3><p>在有了描述和定义负载、性能的手段之后，终于来到正题，如何应对负载的不断增长，即使系统具有可伸缩性。</p>
<ol>
<li><strong>纵向伸缩（scaling up）or 垂直伸缩（vertical scaling）</strong>：换具有更强大性能的机器。e.g.  大型机机器学习训练。</li>
<li><strong>横向伸缩（scaling out）or 水平伸缩（horizontal scaling）</strong>：“并联”很多廉价机，分摊负载。 e.g. 马斯克造火箭。</li>
</ol>
<p>负载伸缩的两种方式：</p>
<ul>
<li><p><strong>自动</strong></p>
<p>  如果负载不好预测且多变，则自动较好。坏处在于不易跟踪负载，容易抖动，造成资源浪费。</p>
</li>
<li><p><strong>手动</strong></p>
<p>  如果负载容易预测且不长变化，最好手动。设计简单，且不容易出错。</p>
</li>
</ul>
<p>针对不同应用场景：</p>
<p>首先，如果规模很小，尽量还是用性能好一点的机器，可以省去很多麻烦。</p>
<p>其次，可以上云，利用云的可伸缩性。甚至如 Snowflake 等基础服务提供商也是 All In 云原生。</p>
<p>最后，实在不行再考虑自行设计可伸缩的分布式架构。</p>
<p>两种服务类型：</p>
<ul>
<li><p><strong>无状态服务</strong></p>
<p>  比较简单，多台机器，外层罩一个 gateway 就行。</p>
</li>
<li><p><strong>有状态服务</strong></p>
<p>  根据需求场景，如读写负载、存储量级、数据复杂度、响应时间、访问模式，来进行取舍，设计合乎需求的架构。</p>
</li>
</ul>
<p><strong>不可能啥都要，没有万金油架构！</strong>但同时：万变不离其宗，组成不同架构的原子设计模式是有限的，这也是本书稍后要论述的重点。</p>
<h2 id="可维护性（Maintainability）"><a href="#可维护性（Maintainability）" class="headerlink" title="可维护性（Maintainability）"></a>可维护性（Maintainability）</h2><p>从软件的整个生命周期来看，维护阶段绝对占大头。</p>
<p>但大部分人都喜欢挖坑，不喜欢填坑。因此有必要，在刚开就把坑开的足够好。有三个原则：</p>
<ul>
<li><p><em><strong>可维护性（Operability）</strong></em></p>
<p>  便于运维团队无痛接手。</p>
</li>
<li><p><em><strong>简洁性（Simplicity）</strong></em></p>
<p>  便于新手开发平滑上手：这需要一个合理的抽象，并尽量消除各种复杂度。如，层次化抽象。</p>
</li>
<li><p><strong><em>可演化性（</em>Evolvability</strong><em><strong>）</strong></em></p>
<p>  便于后面需求快速适配：避免耦合过紧，将代码绑定到某种实现上。也称为<strong>可扩展性（extensibility）</strong>，<strong>可修改性（modifiability）</strong> 或<strong>可塑性（plasticity）</strong>。</p>
</li>
</ul>
<h3 id="可运维性（Operability）：人生苦短，关爱运维"><a href="#可运维性（Operability）：人生苦短，关爱运维" class="headerlink" title="可运维性（Operability）：人生苦短，关爱运维"></a><strong>可运维性（Operability）：人生苦短，关爱运维</strong></h3><p>有效的运维绝对是个高技术活：</p>
<ol>
<li>紧盯系统状态，出问题时快速恢复。</li>
<li>恢复后，复盘问题，定位原因。</li>
<li>定期对平台、库、组件进行更新升级。</li>
<li>了解组件间相互关系，避免级联故障。</li>
<li>建立自动化配置管理、服务管理、更新升级机制。</li>
<li>执行复杂维护任务，如将存储系统从一个数据中心搬到另外一个数据中心。</li>
<li>配置变更时，保证系统安全性。</li>
</ol>
<p>系统具有良好的可维护性，意味着将<strong>可定义</strong>的维护过程编写<strong>文档和工具</strong>以自动化，从而解放出人力关注更高价值事情：</p>
<ol>
<li>友好的文档和一致的运维规范。</li>
<li>细致的监控仪表盘、自检和报警。</li>
<li>通用的缺省配置。</li>
<li>出问题时的自愈机制，无法自愈时允许管理员手动介入。</li>
<li>将维护过程尽可能的自动化。</li>
<li>避免单点依赖，无论是机器还是人。</li>
</ol>
<h3 id="简洁性（Simplicity）：复杂度管理"><a href="#简洁性（Simplicity）：复杂度管理" class="headerlink" title="简洁性（Simplicity）：复杂度管理"></a><strong>简洁性（Simplicity）：复杂度管理</strong></h3><p><img src="https://s2.loli.net/2022/02/19/zfFMc8RXsW6iTok.png" alt="recommand-book.png"></p>
<p>推荐一本书：**<span class="exturl" data-url="aHR0cHM6Ly9ib29rLmRvdWJhbi5jb20vc3ViamVjdC8zMDIxODA0Ni8=">A Philosophy of Software Design<i class="fa fa-external-link-alt"></i></span> ，**讲述在软件设计中如何定义、识别和降低复杂度。</p>
<p>复杂度表现：</p>
<ol>
<li>状态空间的膨胀。</li>
<li>组件间的强耦合。</li>
<li>不一致的术语和<a href="https://www.qtmuniao.com/2021/12/12/how-to-write-code-scrutinize-names/">命名</a>。</li>
<li>为了提升性能的 hack。</li>
<li>随处可见的补丁（ workaround）。</li>
</ol>
<p>需求很简单，但不妨碍你实现的很复杂 😉：过多的引入了<strong>额外复杂度（<em>accidental</em> complexity<br>）——</strong>非问题本身决定的，而由实现所引入的复杂度。</p>
<p>通常是问题理解的不够本质，写出了“<strong>流水账</strong>”（没有任何<strong>抽象，abstraction</strong>）式的代码。</p>
<p>如果你为一个问题找到了合适的抽象，那么问题就解决了一半，如：</p>
<ol>
<li>高级语言隐藏了机器码、CPU 和系统调用细节。</li>
<li>SQL 隐藏了存储体系、索引结构、查询优化实现细节。</li>
</ol>
<p>如何找到合适的抽象？</p>
<ol>
<li>从计算机领域常见的抽象中找。</li>
<li>从日常生活中常接触的概念找。</li>
</ol>
<p>总之，一个合适的抽象，要么是<strong>符合直觉</strong>的；要么是和你的读者<strong>共享上下文</strong>的。</p>
<p>本书之后也会给出很多分布式系统中常用的抽象。</p>
<h3 id="可演化性：降低改变门槛"><a href="#可演化性：降低改变门槛" class="headerlink" title="可演化性：降低改变门槛"></a>可演化性：降低改变门槛</h3><p>系统需求没有变化，说明这个行业死了。</p>
<p>否则，需求一定是不断在变，引起变化的原因多种多样：</p>
<ol>
<li>对问题阈了解更全面</li>
<li>出现了之前未考虑到的用例</li>
<li>商业策略的改变</li>
<li>客户爸爸要求新功能</li>
<li>依赖平台的更迭</li>
<li>合规性要求</li>
<li>体量的改变</li>
</ol>
<p>应对之道：</p>
<ul>
<li><p>项目管理上</p>
<p>  敏捷开发</p>
</li>
<li><p>系统设计上</p>
<p>  依赖前两点。合理抽象，合理封装，对修改关闭，对扩展开放。</p>
</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9kYXRhaW50ZW5zaXZlLm5ldC8=">https://dataintensive.net/<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL2RkaWEudm9ubmcuY29tLyMvY2gx">http://ddia.vonng.com/#/ch1<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<hr>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>DDIA</category>
      </categories>
      <tags>
        <tag>DDIA</tag>
        <tag>读书笔记</tag>
        <tag>设计数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>CockroachDB 和 TiDB 中 SQL 的分布式执行</title>
    <url>/2022/04/05/crdb-tidb-dist-sql/</url>
    <content><![CDATA[<blockquote>
<p>计算下推其实是常见的思想：<strong>将计算推到数据旁</strong>。由于在数据库中，逻辑上，计算常在存储层之上，因此将一部分算子推到存储层去做，称为计算下推。其在分布式数据库中尤为重要。</p>
<p>下面是 CockroachDB 和 TiDB 的解决方案，内容来自于文档和博客，因此可能和最新代码的逻辑并不一致。</p>
</blockquote>
<h2 id="CockroachDB"><a href="#CockroachDB" class="headerlink" title="CockroachDB"></a>CockroachDB</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>CockroachDB 中相应的模块叫 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NvY2tyb2FjaGRiL2NvY2tyb2FjaC9ibG9iL21hc3Rlci9kb2NzL1JGQ1MvMjAxNjA0MjFfZGlzdHJpYnV0ZWRfc3FsLm1k">DistSQL<i class="fa fa-external-link-alt"></i></span>，其思想来源于<span class="exturl" data-url="aHR0cDovL3Jlc2VhcmNoLmdvb2dsZS5jb20vYXJjaGl2ZS9zYXd6YWxsLmh0bWw=">Sawzall<i class="fa fa-external-link-alt"></i></span>，有点类似 <span class="exturl" data-url="aHR0cHM6Ly9zdGF0aWMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL21lZGlhL3Jlc2VhcmNoLmdvb2dsZS5jb20vemgtQ04vL2FyY2hpdmUvbWFwcmVkdWNlLW9zZGkwNC5wZGY=">MapReduce<i class="fa fa-external-link-alt"></i></span>。支持的算子叫做 <strong>aggregator</strong>，本质上是对 SQL 聚合算子的一种泛化。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/04/05/crdb-tidb-dist-sql">https://www.qtmuniao.com/2022/04/05/crdb-tidb-dist-sql</a> 转载请注明出处</em></p>
<p>在<strong>逻辑</strong>上，每个 <strong><strong>aggregator</strong></strong> 接受一个输入行流（Join 会有多个），产出一个输出行流（<strong>output stream</strong> of rows）。一<strong>行</strong>（row）是由多个<strong>列</strong>值（column values）构成的<strong>元组</strong>。输入输出流中会包含每个列值的类型信息，即<strong>模式</strong>（Schema）。</p>
<p>CockroachDB 还引入了<strong>组</strong>（ group ）的概念，每个组是一个并行的单元。划分组的依据是<strong>组键</strong>（group key），可以看出思想有点类似于 MapReduce 中的 Reduce 阶段的 Key。组键其实是 SQL 中 group by 的<strong>泛化</strong>。两个极端情况：</p>
<ol>
<li><strong>所有行同属一个组</strong>。则所有的行只能在单节点执行，而不能并发。</li>
<li><strong>每一行各属一个组</strong>。则可以随意切分行的集合，进行并发。</li>
</ol>
<h3 id="aggregators"><a href="#aggregators" class="headerlink" title="aggregators"></a><strong><strong>aggregators</strong></strong></h3><p>有些 aggregator 的输入、输出或逻辑有一些特殊之处：</p>
<ol>
<li><strong>table reader</strong> 没有输入流，会直接从本机 KV 层拿数据。</li>
<li><strong>final</strong> 没有输出流，提供最终结果给 query\statement。</li>
<li><strong>final</strong> 和 <strong>limit</strong> 对输入流有顺序要求（<strong>ordering requirement</strong>）。</li>
<li><strong>evaluator</strong> 可以通过代码自定义其行为逻辑。</li>
</ol>
<h3 id="逻辑到物理"><a href="#逻辑到物理" class="headerlink" title="逻辑到物理"></a>逻辑到物理</h3><p>执行过程有点类似于 Spark 中对 DAG 的拓扑调度和执行。</p>
<ol>
<li>读取会被下发到每个 range ，由 range 的 raft leader 负责。</li>
<li>遇到非 shuffle aggregator，则在各个节点并发执行。</li>
<li>遇到 shuffle 的 aggregator（比如 group by），就使用某种哈希策略，将输出数据送到对应机器。</li>
<li>最后在 gateway 机器上执行 final aggregator。</li>
</ol>
<p><img src="https://s2.loli.net/2022/04/05/HoGzBbqNUyILDF5.png" alt="multi-aggregator.png"></p>
<h3 id="单个-Processor"><a href="#单个-Processor" class="headerlink" title="单个 Processor"></a>单个 Processor</h3><p>每个逻辑 aggregator 在物理上对应一个 Processor，都可以分为三个步骤：</p>
<ol>
<li>接受多个输入流，进行合并。</li>
<li>数据处理。</li>
<li>对输出按 group 分发到不同机器上。</li>
</ol>
<p><img src="https://s2.loli.net/2022/04/05/pWCvAZEfqiF14Q5.png" alt="single-aggregator.png"></p>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><ol>
<li>cockroachdb SQL layer query execution： <span class="exturl" data-url="aHR0cHM6Ly93d3cuY29ja3JvYWNobGFicy5jb20vZG9jcy9zdGFibGUvYXJjaGl0ZWN0dXJlL3NxbC1sYXllci5odG1sI3F1ZXJ5LWV4ZWN1dGlvbg==">https://www.cockroachlabs.com/docs/stable/architecture/sql-layer.html#query-execution<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NvY2tyb2FjaGRiL2NvY2tyb2FjaC9ibG9iL21hc3Rlci9kb2NzL3RlY2gtbm90ZXMvbGlmZV9vZl9hX3F1ZXJ5Lm1k">https://github.com/cockroachdb/cockroach/blob/master/docs/tech-notes/life_of_a_query.md<i class="fa fa-external-link-alt"></i></span></li>
<li>cockroach db rfc 20160421_distributed_sql<strong><strong>：</strong></strong> <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NvY2tyb2FjaGRiL2NvY2tyb2FjaC9ibG9iL21hc3Rlci9kb2NzL1JGQ1MvMjAxNjA0MjFfZGlzdHJpYnV0ZWRfc3FsLm1k">https://github.com/cockroachdb/cockroach/blob/master/docs/RFCS/20160421_distributed_sql.md<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<h2 id="TiDB"><a href="#TiDB" class="headerlink" title="TiDB"></a>TiDB</h2><h3 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h3><p>TiDB 中的 SQL 执行过程中主要<span class="exturl" data-url="aHR0cHM6Ly9waW5nY2FwLmNvbS96aC9ibG9nL3RpZGItc291cmNlLWNvZGUtcmVhZGluZy0z">流程<i class="fa fa-external-link-alt"></i></span>为：</p>
<ol>
<li>进行词法分析生成 AST（Parsing）</li>
<li>利用 AST 进行各种验证、变化，生成逻辑计划（Planing）</li>
<li>对逻辑计划进行基于规则的优化，生成物理计划（Optimizing）</li>
<li>对物理计划进行基于代价的优化，生成执行器（Executor）</li>
<li>运行执行器（Executing）</li>
</ol>
<p>由于 TiDB 的数据在存储层 TiKV 中，在步骤 5 ，如果将所涉及到的所有 TiKV 数据全部放到 TiDB 层进行执行，会有以下问题：</p>
<ol>
<li>存储层（TiKV）到计算层（TiDB）过大的网络开销。</li>
<li>计算层过多的数据计算对 CPU 的耗费。</li>
</ol>
<p>为了解决这个问题，并充分利用 TiKV 层的分布式特性，PingCAP 在 TiKV 层增加了 <strong><span class="exturl" data-url="aHR0cHM6Ly9waW5nY2FwLmNvbS96aC9ibG9nL3Rpa3Ytc291cmNlLWNvZGUtcmVhZGluZy0xNA==">Coprocessor<i class="fa fa-external-link-alt"></i></span></strong> ，即在 TiKV 层读取数据后进行计算的模块。在执行 SQL （主要是读取）时，将部分<strong>物理计划</strong>（即部分算子组成的 DAG）整个下推到 TiKV 层，由 Coprocessor 执行。</p>
<p><img src="https://s2.loli.net/2022/04/05/yRq4GOIvr8D13Qu.png" alt="coprocessor.png"></p>
<h3 id="Executors"><a href="#Executors" class="headerlink" title="Executors"></a>Executors</h3><p>从 TiKV 的 protobuf <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3BpbmdjYXAvdGlwYi9ibG9iL21hc3Rlci9wcm90by9leGVjdXRvci5wcm90bw==">接口定义<i class="fa fa-external-link-alt"></i></span>中可以看出，当期 TiKV 支持的 Coprocessor 算子（TiKV 中又称 Executor）类型有：</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum </span><span class="title class_">ExecType</span> &#123;</span><br><span class="line">  TypeTableScan = <span class="number">0</span>;</span><br><span class="line">  TypeIndexScan = <span class="number">1</span>;</span><br><span class="line">  TypeSelection = <span class="number">2</span>;</span><br><span class="line">  TypeAggregation = <span class="number">3</span>; </span><br><span class="line">  TypeTopN = <span class="number">4</span>;</span><br><span class="line">  TypeLimit = <span class="number">5</span>;</span><br><span class="line">  TypeStreamAgg = <span class="number">6</span>;</span><br><span class="line">  TypeJoin = <span class="number">7</span>;</span><br><span class="line">  TypeKill = <span class="number">8</span>;</span><br><span class="line">  TypeExchangeSender = <span class="number">9</span>;</span><br><span class="line">  TypeExchangeReceiver = <span class="number">10</span>;</span><br><span class="line">  TypeProjection = <span class="number">11</span>;</span><br><span class="line">  TypePartitionTableScan = <span class="number">12</span>;</span><br><span class="line">  TypeSort = <span class="number">13</span>;</span><br><span class="line">  TypeWindow = <span class="number">14</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="单个-Coprocessor"><a href="#单个-Coprocessor" class="headerlink" title="单个 Coprocessor"></a>单个 Coprocessor</h3><p>Coprocessor  接受一个由 Executor 作为节点组成的 DAGRequest，利用<strong>向量化模型</strong>：</p>
<ol>
<li>扫描指定数据</li>
<li>以 Chunk 为单位依次执行所有算子</li>
<li>将结果返回到 TiDB 层</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>CRDB 和 TiDB 在执行 SQL 时最大的区别在于：</p>
<ol>
<li>CRDB 使用类似 MapReduce 的 MPP 模型，因此多台存储节点间需要通信互相传输数据。</li>
<li>TiDB 中是存储计算分离，将能下推的计算以 DAG 的形式尽可能的下推，而需要多个节点合并计算只能在计算层做，因此多台存储节点间不需要通信以传输数据。</li>
</ol>
<p>粗浅理解，有写的不对或需要补充之处，欢迎留言。</p>
<hr>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
        <tag>SQL</tag>
        <tag>执行计划</tag>
      </tags>
  </entry>
  <entry>
    <title>DDIA 读书笔记（二）：数据模型和查询语言</title>
    <url>/2022/04/16/ddia-reading-chapter2/</url>
    <content><![CDATA[<blockquote>
<p>DDIA 读书分享会，会逐章进行分享，结合我在工业界分布式存储和数据库的一些经验，补充一些细节。每两周左右分享一次，欢迎加入，Schedule 和所有文字稿在<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">这里<i class="fa fa-external-link-alt"></i></span>。我们有个对应的分布式&amp;数据库讨论群，每次分享前会在群里通知。如想加入，可以加我的微信号：qtmuniao，简单自我介绍下，并注明：分布式系统群。</p>
</blockquote>
<h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>本节围绕两个主要概念来展开。</p>
<p>如何分析一个<strong>数据模型</strong>：</p>
<ol>
<li>基本考察点：数据基本元素，和元素之间的对应关系（一对多，多对多）</li>
<li>利用几种常用模型来比较：（最为流行的）关系模型，（树状的）文档模型，（极大自由度的）图模型。</li>
<li>schema 模式：强 Schema（写时约束）；弱 Schema（读时解析）</li>
</ol>
<p>如何考量<strong>查询语言</strong>：</p>
<ol>
<li>如何与数据模型关联、匹配</li>
<li>声明式（declarative）和命令式（imperative）</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/04/16/ddia-reading-chapter2">https://www.qtmuniao.com/2022/04/16/ddia-reading-chapter2</a> 转载请注明出处</em></p>
<h3 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h3><blockquote>
<p>A <strong>data model</strong> is an <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQWJzdHJhY3RfbW9kZWw=">abstract model<i class="fa fa-external-link-alt"></i></span> that organizes elements of <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRGF0YQ==">data<i class="fa fa-external-link-alt"></i></span> and standardizes how they relate to one another and to the properties of real-world entities.。<br> —<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRGF0YV9tb2RlbA==">https://en.wikipedia.org/wiki/Data_model<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<p><strong>数据模型</strong>：如何组织数据，如何标准化关系，如何关联现实。</p>
<p>它既决定了我们构建软件的方式（<strong>实现</strong>），也左右了我们看待问题的角度（<strong>认知</strong>）。</p>
<p>作者开篇以计算机的不同抽象层次来让大家对<strong>泛化的</strong>数据模型有个整体观感。</p>
<p>大多数应用都是通过不同的数据模型层级累进构建的。</p>
<p><img src="https://s2.loli.net/2022/04/16/lATY7U56IJO42FD.png" alt="ddia2-layered-data-models.png"></p>
<p>每层模型核心问题：如何用下一层的接口来对本层进行建模？</p>
<ol>
<li>作为<strong>应用开发者，</strong> 你将现实中的具体问题抽象为一组对象、<strong>数据结构（data structure）</strong> 以及作用于其上的 API。</li>
<li>作为<strong>数据库管理员（DBA）</strong>，为了持久化上述数据结构，你需要将他们表达为通用的<strong>数据模型（data model）</strong>，如文档数据库中的XML&#x2F;JSON、关系数据库中的表、图数据库中的图。</li>
<li>作为<strong>数据库系统开发者</strong>，你需要将上述数据模型组织为内存中、硬盘中或者网络中的<strong>字节（Bytes）</strong> 流，并提供多种操作数据集合的方法。</li>
<li>作为<strong>硬件工程师</strong>，你需要将字节流表示为二极管的电位（内存）、磁场中的磁极（磁盘）、光纤中的光信号（网络）。</li>
</ol>
<blockquote>
<p>在每一层，通过对外暴露简洁的<strong>数据模型</strong>，我们<strong>隔离</strong>和<strong>分解</strong>了现实世界的<strong>复杂度</strong>。</p>
</blockquote>
<p>这也反过来说明了，好的数据模型需有两个特点：</p>
<ol>
<li>简洁直观</li>
<li>具有组合性</li>
</ol>
<p>第二章首先探讨了关系模型、文档模型及其对比，其次是相关查询语言，最后探讨了图模型。</p>
<h2 id="关系模型-vs-文档模型"><a href="#关系模型-vs-文档模型" class="headerlink" title="关系模型 vs 文档模型"></a>关系模型 vs 文档模型</h2><h3 id="关系模型"><a href="#关系模型" class="headerlink" title="关系模型"></a>关系模型</h3><p>关系模型无疑是当今最流行的数据库模型。</p>
<p>关系模型是 <span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU1JTlGJTgzJUU1JUJFJUI3JUU1JThBJUEwJUMyJUI3JUU3JUE3JTkxJUU1JUJFJUI3">埃德加·科德（<i class="fa fa-external-link-alt"></i></span><span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRS5fRi5fQ29kZA==">E. F. Codd<i class="fa fa-external-link-alt"></i></span>）于 1969 年首先提出，并用“<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU3JUE3JTkxJUU1JUJFJUI3JUU1JThEJTgxJUU0JUJBJThDJUU1JUFFJTlBJUU1JUJFJThC">科德十二定律<i class="fa fa-external-link-alt"></i></span>”来解释。但是商业落地的数据库基本没有能完全遵循的，因此关系模型后来通指这一类数据库。特点如下：</p>
<ol>
<li>将数据以<strong>关系</strong>呈现给用户（比如：一组包含行列的二维表）。</li>
<li>提供操作数据集合的<strong>关系算子</strong>。</li>
</ol>
<p><strong>常见分类</strong></p>
<ol>
<li>事务型（TP）：银行交易、火车票</li>
<li>分析型（AP）：数据报表、监控表盘</li>
<li>混合型（HTAP）：</li>
</ol>
<p>关系模型诞生很多年后，虽有不时有各种挑战者（比如上世纪七八十年代的<strong>网状模型</strong> network model 和<strong>层次模型</strong> hierarchical model ），但始终仍未有根本的能撼动其地位的新模型。</p>
<p>直到近十年来，随着移动互联网的普及，数据爆炸性增长，各种处理需求越来越精细化，催生了数据模型的百花齐放。</p>
<h3 id="NoSQL-的诞生"><a href="#NoSQL-的诞生" class="headerlink" title="NoSQL 的诞生"></a>NoSQL 的诞生</h3><p>NoSQL（最初表示Non-SQL，后来有人转解为Not only SQL），是对不同于传统的关系数据库的数据库管理系统的统称。根据 <span class="exturl" data-url="aHR0cHM6Ly9kYi1lbmdpbmVzLmNvbS9lbi9yYW5raW5n">DB-Engines 排名<i class="fa fa-external-link-alt"></i></span>，现在最受欢迎的 NoSQL 前几名为：MongoDB，Redis，ElasticSearch，Cassandra。</p>
<p>其催动因素有：</p>
<ol>
<li>处理更大数据集：更强伸缩性、更高吞吐量</li>
<li>开源免费的兴起：冲击了原来把握在厂商的标准</li>
<li>特化的查询操作：关系数据库难以支持的，比如图中的多跳分析</li>
<li>表达能力更强：关系模型约束太严，限制太多</li>
</ol>
<h3 id="面向对象和关系模型的不匹配"><a href="#面向对象和关系模型的不匹配" class="headerlink" title="面向对象和关系模型的不匹配"></a>面向对象和关系模型的不匹配</h3><p>核心冲突在于面向对象的<strong>嵌套性</strong>和关系模型的<strong>平铺性</strong>（？我随便造的）。</p>
<p>当然有 ORM 框架可以帮我们搞定这些事情，但仍是不太方便。</p>
<p><img src="https://s2.loli.net/2022/04/16/rN967AnmIicgl25.png" alt="ddia2-bill-resume.png"></p>
<p>换另一个角度来说，关系模型很难直观的表示<strong>一对多</strong>的关系。比如简历上，一个人可能有多段教育经历和多段工作经历。</p>
<p><strong>文档模型</strong>：使用 Json 和 XML 的天然嵌套。</p>
<p><strong>关系模型</strong>：使用 SQL 模型就得将职位、教育单拎一张表，然后在用户表中使用外键关联。</p>
<p>在简历的例子中，文档模型还有几个优势：</p>
<ol>
<li><strong>模式灵活</strong>：可以动态增删字段，如工作经历。</li>
<li><strong>更好的局部性</strong>：一个人的所有属性被集中访问的同时，也被集中存储。</li>
<li><strong>结构表达语义</strong>：简历与联系信息、教育经历、职业信息等隐含一对多的树状关系可以被 JSON 的树状结构明确表达出来。</li>
</ol>
<h3 id="多对一和多对多"><a href="#多对一和多对多" class="headerlink" title="多对一和多对多"></a>多对一和多对多</h3><p>是一个对比各种数据模型的切入角度。</p>
<p>region 在存储时，为什么不直接存储纯字符串：“Greater Seattle Area”，而是先存为 region_id → region name，其他地方都引用 region_id？</p>
<ol>
<li><strong>统一样式</strong>：所有用到相同概念的地方都有相同的拼写和样式</li>
<li><strong>避免歧义</strong>：可能有同名地区</li>
<li><strong>易于修改</strong>：如果一个地区改名了，我们不用去逐一修改所有引用他的地方</li>
<li><strong>本地化支持</strong>：如果翻译成其他语言，可以只翻译名字表。</li>
<li><strong>更好搜索</strong>：列表可以关联地区，进行树形组织</li>
</ol>
<p>类似的概念还有：面向抽象编程，而非面向细节。</p>
<p>关于用 ID 还是文本，作者提到了一点：ID 对人类是<strong>无意义</strong>的，无意义的意味着不会随着现实世界的将来的改变而改动。</p>
<p>这在关系数据库表设计时需要考虑，即如何控制<strong>冗余（duplication）</strong>。会有几种<strong>范式（normalization）</strong> 来消除冗余。</p>
<p>文档型数据库很擅长处理一对多的树形关系，却不擅长处理多对多的图形关系。如果其不支持 Join，则处理多对多关系的复杂度就从数据库侧移动到了应用侧。</p>
<p>如，多个用户可能在同一个组织工作过。如果我们想找出在同一个学校和组织工作过的人，如果数据库不支持 Join，则需要在应用侧进行循环遍历来 Join。</p>
<p><img src="https://s2.loli.net/2022/04/16/DCafiUozLMQ4WBw.png" alt="ddia2-mul-to-mul.png"></p>
<p>文档 vs 关系</p>
<ol>
<li>对于一对多关系，文档型数据库将嵌套数据放在父节点中，而非单拎出来放另外一张表。</li>
<li>对于多对一和多对多关系，本质上，两者都是使用外键（文档引用）进行索引。查询时需要进行 join 或者动态跟随。</li>
</ol>
<h3 id="文档模型是否在重复历史？"><a href="#文档模型是否在重复历史？" class="headerlink" title="文档模型是否在重复历史？"></a>文档模型是否在重复历史？</h3><h3 id="层次模型-（hierarchical-model）"><a href="#层次模型-（hierarchical-model）" class="headerlink" title="层次模型 （hierarchical model）"></a>层次模型 <strong>（hierarchical model）</strong></h3><p>20 世纪 70 年代，IBM 的信息管理系统 IMS。</p>
<blockquote>
<p>A <strong>hierarchical database model</strong> is a <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRGF0YV9tb2RlbA==">data model<i class="fa fa-external-link-alt"></i></span> in which the data are organized into a <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvVHJlZV9kYXRhX3N0cnVjdHVyZQ==">tree<i class="fa fa-external-link-alt"></i></span>-like structure. The data are stored as <strong>records</strong> which are connected to one another through <strong>links.</strong> A record is a collection of fields, with each field containing only one value. The <strong>type</strong> of a record defines which fields the record contains.  — wikipedia</p>
</blockquote>
<p>几个要点：</p>
<ol>
<li>树形组织，每个子节点只允许有一个父节点</li>
<li>节点存储数据，节点有类型</li>
<li>节点间使用类似指针方式连接</li>
</ol>
<p>可以看出，它跟文档模型很像，也因此很难解决多对多的关系，并且不支持 Join。</p>
<p>为了解决层次模型的局限，人们提出了各种解决方案，最突出的是：</p>
<ol>
<li>关系模型</li>
<li>网状模型</li>
</ol>
<h3 id="网状模型（network-model）"><a href="#网状模型（network-model）" class="headerlink" title="网状模型（network model）"></a>网状模型（network model）</h3><p>network model 是 hierarchical model 的一种扩展：允许一个节点有多个父节点。它被数据系统语言会议（CODASYL）的委员会进行了标准化，因此也被称为 CODASYL 模型。</p>
<p>多对一和多对多都可以由路径来表示。访问记录的唯一方式是顺着元素和链接组成的链路进行访问，这个链路叫<strong>访问路径</strong> （access path）。难度犹如在 n-维空间中进行导航。</p>
<p>内存有限，因此需要严格控制遍历路径。并且需要事先知道数据库的拓扑结构，这就意味着得针对不同应用写大量的专用代码。</p>
<h3 id="关系模型-1"><a href="#关系模型-1" class="headerlink" title="关系模型"></a>关系模型</h3><p>在关系模型中，数据被组织成<strong>元组（tuples）</strong>，进而集合成<strong>关系（relations）</strong>；在 SQL 中分别对应行（rows）和表（tables）。</p>
<ul>
<li><p>不知道大家好奇过没，明明看起来更像表模型，为什叫<strong>关系模型</strong>？</p>
<p>  表只是一种实现。</p>
<p>  关系（relation）的说法来自集合论，指的是几个集合的笛卡尔积的子集。</p>
<p>  R ⊆ （D1×D2×D3 ··· ×Dn）</p>
<p>  （关系用符号 R 表示，属性用符号 Ai 表示，属性的定义域用符号 Di 表示）</p>
</li>
</ul>
<p>其主要目的和贡献在于提供了一种<strong>声明式</strong>的描述数据和构建查询的方法。</p>
<p>即，相比网络模型，关系模型的查询语句和执行路径相解耦，<strong>查询优化器</strong>（Query Optimizer 自动决定执行顺序、要使用的索引），即将逻辑和实现解耦。</p>
<p>举个例子：如果想使用新的方式对你的数据集进行查询，你只需要在新的字段上建立一个索引。那么在查询时，你并不需要改变的你用户代码，查询优化器便会动态的选择可用索引。</p>
<h3 id="文档型-vs-关系型"><a href="#文档型-vs-关系型" class="headerlink" title="文档型 vs 关系型"></a>文档型 vs 关系型</h3><p>根据数据类型来选择数据模型</p>
<table>
<thead>
<tr>
<th></th>
<th>文档型</th>
<th>关系型</th>
</tr>
</thead>
<tbody><tr>
<td>对应关系</td>
<td>数据有天然的一对多、树形嵌套关系，如简历。</td>
<td>通过外键+ Join 可以处理 多对一，多对多关系</td>
</tr>
<tr>
<td>代码简化</td>
<td>数据具有文档结构，则文档模型天然合适，用关系模型会使得建模繁琐、访问复杂。</td>
<td></td>
</tr>
<tr>
<td>但不宜嵌套太深，因为只能手动指定访问路径，或者范围遍历</td>
<td>主键，索引，条件过滤</td>
<td></td>
</tr>
<tr>
<td>Join 支持</td>
<td>对 Join 支持的不太好</td>
<td>支持的还可以，但 Join 的实现会有很多难点</td>
</tr>
<tr>
<td>模式灵活性</td>
<td>弱 schema，支持动态增加字段</td>
<td>强 schema，修改 schema 代价很大</td>
</tr>
<tr>
<td>访问局部性</td>
<td>1. 一次性访问整个文档，较优 <br/>2. 只访问文档一部分，较差</td>
<td>分散在多个表中</td>
</tr>
</tbody></table>
<p>对于高度关联的数据集，使用文档型表达比较奇怪，使用关系型可以接受，使用图模型最自然。</p>
<h3 id="文档模型中-Schema-的灵活性"><a href="#文档模型中-Schema-的灵活性" class="headerlink" title="文档模型中 Schema 的灵活性"></a>文档模型中 Schema 的灵活性</h3><p>说文档型数据库是 schemaless 不太准确，更贴切的应该是 <strong>schema-on-read。</strong></p>
<table>
<thead>
<tr>
<th>数据模型</th>
<th></th>
<th>编程语言</th>
<th></th>
<th>性能 &amp; 空间</th>
</tr>
</thead>
<tbody><tr>
<td>schema-on-read</td>
<td>写入时不校验，而在读取时进行动态解析。</td>
<td>弱类型</td>
<td>动态，在运行时解析</td>
<td>读取时动态解析，性能较差。写入时无法确定类型，无法对齐空间利用率较差。</td>
</tr>
<tr>
<td>schema-on-write</td>
<td>写入时校验，数据对齐到 schema</td>
<td>强类型</td>
<td>静态，编译时确定</td>
<td>性能和空间使用都较优。</td>
</tr>
</tbody></table>
<p>文档型数据库使用场景特点：</p>
<ol>
<li>有多种类型的数据，但每个放一张表又不合适。</li>
<li>数据类型和结构又外部决定，你没办法控制数据的变化。</li>
</ol>
<h3 id="查询时的数据局部性"><a href="#查询时的数据局部性" class="headerlink" title="查询时的数据局部性"></a>查询时的数据局部性</h3><p>如果你同时需要文档中所有内容，把文档顺序存会效率比较高。</p>
<p>但如果你只需要访问文档中的某些字段，则文档仍需要将文档全部加载出。</p>
<p>但运用这种局部性不局限于文档型数据库。不同的数据库，会针对不同场景，调整数据物理分布以适应常用访问模式的局部性。</p>
<ul>
<li>如 Spanner 中允许表被声明为嵌入到父表中——常见关联内嵌</li>
<li>HBase 和 Cassandra 使用列族来聚集数据——分析型</li>
<li>图数据库中，将点和出边存在一个机器上——图遍历</li>
</ul>
<h3 id="关系型和文档型的融合"><a href="#关系型和文档型的融合" class="headerlink" title="关系型和文档型的融合"></a>关系型和文档型的融合</h3><ul>
<li><p>MySQL 和 PostgreSQL 开始支持 JSON</p>
<p>  原生支持 JSON 可以理解为，MySQL 可以理解 JSON 格式。如 Date 格式一样，可以把某个字段作为 JSON 格式，可以修改其中的某个字段，可以在其中某个字段建立索引。</p>
</li>
<li><p>RethinkDB 在查询中支持 relational-link Joins</p>
</li>
</ul>
<p>科德（Codd）：<strong>nonsimple domains</strong>，记录中的值除了简单类型（数字、字符串），还可以一个嵌套关系（表）。这很像 SQL 对 XML、JSON 的支持。</p>
<h2 id="数据查询语言"><a href="#数据查询语言" class="headerlink" title="数据查询语言"></a>数据查询语言</h2><p>获取动物表中所有鲨鱼类动物。</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">getSharks</span>(<span class="params"></span>) &#123; <span class="keyword">var</span> sharks = [];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; animals.<span class="property">length</span>; i++) &#123; </span><br><span class="line">    <span class="keyword">if</span> (animals[i].<span class="property">family</span> === <span class="string">&quot;Sharks&quot;</span>) &#123;</span><br><span class="line">      sharks.<span class="title function_">push</span>(animals[i]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> sharks; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> animals <span class="keyword">WHERE</span> family <span class="operator">=</span> <span class="string">&#x27;Sharks&#x27;</span>;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th></th>
<th>声明式（declarative）语言</th>
<th>命令式（imperative）语言</th>
</tr>
</thead>
<tbody><tr>
<td>概念</td>
<td>描述控制逻辑而非执行流程</td>
<td>描述命令的执行过程，用一系列语句来不断改变状态</td>
</tr>
<tr>
<td>举例</td>
<td>SQL，CSS，XSL</td>
<td>IMS，CODASYL，通用语言如 C，C++，JS</td>
</tr>
<tr>
<td>抽象程度</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>解耦程度</td>
<td>与实现解耦。 <br/>可以持续优化查询引擎性能；</td>
<td>与实现耦合较深。</td>
</tr>
<tr>
<td>解析执行</td>
<td>词法分析→ 语法分析 → 语义分析 <br/>生成执行计划→ 执行计划优化</td>
<td>词法分析→ 语法分析 → 语义分析 <br/>中间代码生成→ 代码优化 → 目标代码生成</td>
</tr>
<tr>
<td>多核并行</td>
<td>声明式更具多核潜力，给了更多运行时优化空间</td>
<td>命令式由于指定了代码执行顺序，编译时优化空间较小。</td>
</tr>
</tbody></table>
<ul>
<li>Q：相对声明式语言，命令式语言有什么优点？<ol>
<li>当描述的目标变得复杂时，声明式表达能力不够。</li>
<li>实现命令式的语言往往不会和声明式那么泾渭分明，通过合理抽象，通过一些编程范式（函数式），可以让代码兼顾表达力和清晰性。</li>
</ol>
</li>
</ul>
<h3 id="数据库以外：Web-中的声明式"><a href="#数据库以外：Web-中的声明式" class="headerlink" title="数据库以外：Web 中的声明式"></a>数据库以外：Web 中的声明式</h3><p><strong>需求</strong>：选中页背景变蓝。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">&quot;selected&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>Sharks<span class="tag">&lt;/<span class="name">p</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">li</span>&gt;</span>Great White Shark<span class="tag">&lt;/<span class="name">li</span>&gt;</span> </span><br><span class="line">      <span class="tag">&lt;<span class="name">li</span>&gt;</span>Tiger Shark<span class="tag">&lt;/<span class="name">li</span>&gt;</span> </span><br><span class="line">      <span class="tag">&lt;<span class="name">li</span>&gt;</span>Hammerhead Shark<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>Whales<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">li</span>&gt;</span>Blue Whale<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">li</span>&gt;</span>Humpback Whale<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">li</span>&gt;</span>Fin Whale<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">ul</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>如果使用 CSS，则只需（CSS selector）：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">li</span><span class="selector-class">.selected</span> &gt; <span class="selector-tag">p</span> &#123; </span><br><span class="line">  <span class="attribute">background-color</span>: blue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果使用 XSL，则只需（XPath selector）：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&lt;xsl:template match=<span class="string">&quot;li[@class=&#x27;selected&#x27;]/p&quot;</span>&gt; </span><br><span class="line">  &lt;fo:block background-color=<span class="string">&quot;blue&quot;</span>&gt;</span><br><span class="line">    &lt;xsl:apply-templates/&gt;</span><br><span class="line">  &lt;/fo:block&gt;</span><br><span class="line">&lt;/xsl:template&gt;</span><br></pre></td></tr></table></figure>

<p>但如果使用 JavaScript（而不借助上述 selector 库）：</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> liElements = <span class="variable language_">document</span>.<span class="title function_">getElementsByTagName</span>(<span class="string">&quot;li&quot;</span>); </span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; liElements.<span class="property">length</span>; i++) &#123;</span><br><span class="line">  <span class="keyword">if</span> (liElements[i].<span class="property">className</span> === <span class="string">&quot;selected&quot;</span>) &#123; </span><br><span class="line">    <span class="keyword">var</span> children = liElements[i].<span class="property">childNodes</span>; </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> j = <span class="number">0</span>; j &lt; children.<span class="property">length</span>; j++) &#123;</span><br><span class="line">      <span class="keyword">var</span> child = children[j];</span><br><span class="line">      <span class="keyword">if</span> (child.<span class="property">nodeType</span> === <span class="title class_">Node</span>.<span class="property">ELEMENT_NODE</span> &amp;&amp; child.<span class="property">tagName</span> === <span class="string">&quot;P&quot;</span>) &#123;</span><br><span class="line">        child.<span class="title function_">setAttribute</span>(<span class="string">&quot;style&quot;</span>, <span class="string">&quot;background-color: blue&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="MapReduce-查询"><a href="#MapReduce-查询" class="headerlink" title="MapReduce 查询"></a>MapReduce 查询</h3><p><strong>Google 的 MapReduce 模型</strong></p>
<ol>
<li>借鉴自函数式编程。</li>
<li>一种相当简单的编程模型，或者说原子的抽象，现在不太够用。</li>
<li>但在大数据处理工具匮乏的蛮荒时代（03年以前），谷歌提出的这套框架相当有开创性。</li>
</ol>
<p><img src="/Chapter%202%20%2046cf1/Untitled%202.png" alt="Untitled"></p>
<p><strong>MongoDB  的 MapReduce 模型</strong></p>
<p>MongoDB 使用的 MapReduce 是一种介于</p>
<ol>
<li><strong>声明式</strong>：用户不必显式定义数据集的遍历方式、shuffle 过程等执行过程。</li>
<li><strong>命令式</strong>：用户又需要定义针对单条数据的执行过程。</li>
</ol>
<p>两者间的混合数据模型。</p>
<p><strong>需求</strong>：统计每月观察到鲨类鱼的次数。</p>
<p><strong>查询语句</strong>：</p>
<p><strong>PostgresSQL</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> date_trunc(<span class="string">&#x27;month&#x27;</span>, observation_timestamp) <span class="keyword">AS</span> observation_month, </span><br><span class="line">  <span class="built_in">sum</span>(num_animals) <span class="keyword">AS</span> total_animals</span><br><span class="line"><span class="keyword">FROM</span> observations</span><br><span class="line"><span class="keyword">WHERE</span> family <span class="operator">=</span> <span class="string">&#x27;Sharks&#x27;</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> observation_month;</span><br></pre></td></tr></table></figure>

<p><strong>MongoDB</strong></p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">db.<span class="property">observations</span>.<span class="title function_">mapReduce</span>(</span><br><span class="line">  <span class="keyword">function</span> <span class="title function_">map</span>(<span class="params"></span>) &#123; <span class="comment">// 2. 对所有符合条件 doc 执行 map</span></span><br><span class="line">    <span class="keyword">var</span> year = <span class="variable language_">this</span>.<span class="property">observationTimestamp</span>.<span class="title function_">getFullYear</span>();</span><br><span class="line">    <span class="keyword">var</span> month = <span class="variable language_">this</span>.<span class="property">observationTimestamp</span>.<span class="title function_">getMonth</span>() + <span class="number">1</span>; </span><br><span class="line">    <span class="title function_">emit</span>(year + <span class="string">&quot;-&quot;</span> + month, <span class="variable language_">this</span>.<span class="property">numAnimals</span>); <span class="comment">// 3. 输出一个 kv pair</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="keyword">function</span> <span class="title function_">reduce</span>(<span class="params">key, values</span>) &#123; <span class="comment">// 4. 按 key 聚集</span></span><br><span class="line">    <span class="keyword">return</span> <span class="title class_">Array</span>.<span class="title function_">sum</span>(values);    <span class="comment">// 5. 相同 key 加和</span></span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">query</span>: &#123; <span class="attr">family</span>: <span class="string">&quot;Sharks&quot;</span> &#125;, <span class="comment">// 1. 筛选</span></span><br><span class="line">    <span class="attr">out</span>: <span class="string">&quot;monthlySharkReport&quot;</span>    <span class="comment">// 6. reduce 结果集</span></span><br><span class="line">  &#125; </span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>上述语句在执行时，经历了：筛选→ 遍历并执行 map → 对输出按 key 聚集（shuffle）→ 对聚集的数据注意 reduce → 输出结果集。</p>
<p>MapReduce 一些特点：</p>
<ol>
<li><strong>要求 Map 和 Reduce 是纯函数</strong>。即无任何副作用，在任意地点、以任意次序执行任何多次，对相同的输入都能得到相同的输出。因此容易并发调度。</li>
<li><strong>非常底层、但表达力强大的编程模型</strong>。可基于其实现 SQL 等高级查询语言，如 Hive。</li>
</ol>
<p>但要注意：</p>
<ol>
<li>不是所有的分布式 SQL 都基于 MapReduce 实现。</li>
<li>不是只有 MapReduce 才允许嵌入通用语言（如 js）模块。</li>
<li>MapReduce 是有一定<strong>理解成本</strong>的，需要熟悉其执行逻辑才能让两个函数紧密配合。</li>
</ol>
<p>MongoDB 2.2+ 进化版，<em>aggregation pipeline:</em></p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">db.<span class="property">observations</span>.<span class="title function_">aggregate</span>([</span><br><span class="line">  &#123; <span class="attr">$match</span>: &#123; <span class="attr">family</span>: <span class="string">&quot;Sharks&quot;</span> &#125; &#125;,</span><br><span class="line">  &#123; <span class="attr">$group</span>: &#123;</span><br><span class="line">    <span class="attr">_id</span>: &#123;</span><br><span class="line">      <span class="attr">year</span>:  &#123; <span class="attr">$year</span>:  <span class="string">&quot;$observationTimestamp&quot;</span> &#125;,</span><br><span class="line">      <span class="attr">month</span>: &#123; <span class="attr">$month</span>: <span class="string">&quot;$observationTimestamp&quot;</span> &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">totalAnimals</span>: &#123; <span class="attr">$sum</span>: <span class="string">&quot;$numAnimals&quot;</span> &#125; &#125;&#125;</span><br><span class="line">]);</span><br></pre></td></tr></table></figure>

<h2 id="Graph-Like-数据模型"><a href="#Graph-Like-数据模型" class="headerlink" title="Graph-Like 数据模型"></a>Graph-Like 数据模型</h2><ul>
<li><p>文档模型的适用场景？</p>
<p>  你的数据集中存在着大量<strong>一对多</strong>（one-to-many）的关系。</p>
</li>
<li><p>图模型的适用场景？</p>
<p>  你的数据集中存在大量的<strong>多对多</strong>（many-to-many）的关系。</p>
</li>
</ul>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>图数据模型的基本概念一般有三个：<strong>点</strong>，<strong>边</strong>和附着于两者之上的<strong>属性</strong>。</p>
<p>常见的可以用图建模的场景：</p>
<table>
<thead>
<tr>
<th>例子</th>
<th>建模</th>
<th>应用</th>
</tr>
</thead>
<tbody><tr>
<td>社交图谱</td>
<td>人是点， follow 关系是边</td>
<td>六度分隔，信息流推荐</td>
</tr>
<tr>
<td>互联网</td>
<td>网页是点，链接关系是边</td>
<td>PageRank</td>
</tr>
<tr>
<td>路网</td>
<td>交通枢纽是点，铁路&#x2F;公路是边</td>
<td>路径规划，导航最短路径</td>
</tr>
<tr>
<td>洗钱</td>
<td>账户是点，转账关系是边</td>
<td>判断是否有环</td>
</tr>
<tr>
<td>知识图谱</td>
<td>概念时点，关联关系是边</td>
<td>启发式问答</td>
</tr>
</tbody></table>
<ul>
<li><p>同构（<em>homogeneous</em>）数据和异构数据</p>
<p>  图中的点可以都具有相同类型，但是，也可以具有不同类型，并且更为强大。</p>
</li>
</ul>
<p>本节都会以下图为例，它表示了一对夫妇，来自美国爱达荷州的 Lucy 和来自法国 的 Alain。他们已婚，住在伦敦。</p>
<p><img src="/Chapter%202%20%2046cf1/Untitled%203.png" alt="Untitled"></p>
<p>有多种对图的建模方式：</p>
<ol>
<li>属性图（property graph）：比较主流，如 Neo4j、Titan、InfiniteGraph</li>
<li>三元组（triple-store）：如 Datomic、AllegroGraph</li>
</ol>
<h3 id="属性图（PG，Property-Graphs）"><a href="#属性图（PG，Property-Graphs）" class="headerlink" title="属性图（PG，Property Graphs）"></a>属性图（PG，Property Graphs）</h3><table>
<thead>
<tr>
<th>点(vertices, nodes, entities)</th>
<th>边(edges, relations, arcs)</th>
</tr>
</thead>
<tbody><tr>
<td>全局唯一 ID</td>
<td>全局唯一 ID</td>
</tr>
<tr>
<td>出边集合</td>
<td>起始点</td>
</tr>
<tr>
<td>入边集合</td>
<td>终止点</td>
</tr>
<tr>
<td>属性集（kv 对表示）</td>
<td>属性集（kv 对表示）</td>
</tr>
<tr>
<td>表示点类型的 type？</td>
<td>表示边类型的 label</td>
</tr>
</tbody></table>
<ul>
<li><p>Q：有一个疑惑点，为什么书中对于 PG 点的定义中没有 Type ？</p>
<p>  如果数据是异构的，应该有才对；莫非是通过不同的属性来标记不同的类型？</p>
</li>
</ul>
<p>如果感觉不直观，可以使用我们熟悉的 SQL 语义来构建一个图模型，如下图。（Facebook TAO 论文中的单机存储引擎便是 MySQL）</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> 点表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> vertices (</span><br><span class="line">  vertex_id <span class="type">integer</span> PRIMARYKEY, properties json</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 边表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> edges (</span><br><span class="line">  edge_id <span class="type">integer</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">  tail_vertex <span class="type">integer</span> <span class="keyword">REFERENCES</span> vertices (vertex_id), </span><br><span class="line">  head_vertex <span class="type">integer</span> <span class="keyword">REFERENCES</span> vertices (vertex_id),</span><br><span class="line">  label text,</span><br><span class="line">  properties json</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> 对点的反向索引，图遍历时用。给定点，找出点的所有入边和出边。</span><br><span class="line"><span class="keyword">CREATE</span> INDEX edges_tails <span class="keyword">ON</span> edges (tail_vertex);</span><br><span class="line"><span class="keyword">CREATE</span> INDEX edges_heads <span class="keyword">ON</span> edges (head_vertex);</span><br></pre></td></tr></table></figure>

<p>图是一种很灵活的建模方式：</p>
<ol>
<li>任何两点间都可以插入边，没有任何模式限制。</li>
<li>对于任何顶点都可以高效（思考：如何高效？）找到其入边和出边，从而进行图遍历。</li>
<li>使用多种<strong>标签</strong>来标记不同类型边（关系）。</li>
</ol>
<p>相对于关系型数据来说，<strong>可以在同一个图中保存异构类型的数据和关系，给了图极大的表达能力！</strong></p>
<p>这种表达能力，根据图中的例子，包括：</p>
<ol>
<li>对同样的概念，可以用不同结构表示。如不同国家的行政划分。</li>
<li>对同样的概念，可以用不同粒度表示。比如 Lucy 的现居住地和诞生地。</li>
<li>可以很自然的进行演化。</li>
</ol>
<p>将异构的数据容纳在一张图中，可以通过<strong>图遍历</strong>，轻松完成关系型数据库中需要<strong>多次 Join</strong> 的操作。</p>
<h3 id="Cypher-查询语言"><a href="#Cypher-查询语言" class="headerlink" title="Cypher 查询语言"></a>Cypher 查询语言</h3><p>Cypher 是 Neo4j 创造的一种查询语言。</p>
<p>Cypher 和 Neo 名字应该都是来自 《黑客帝国》（The Matrix）。想想 Oracle。</p>
<p>Cypher 的一大特点是可读性强，尤其在表达路径模式（Path Pattern）时。</p>
<p>结合前图，看一个 Cypher 插入语句的例子：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span></span><br><span class="line">  (NAmerica:Location &#123;name:<span class="string">&#x27;North America&#x27;</span>, type:<span class="string">&#x27;continent&#x27;</span>&#125;),</span><br><span class="line">  (USA:Location      &#123;name:<span class="string">&#x27;United States&#x27;</span>, type:<span class="string">&#x27;country&#x27;</span>  &#125;),</span><br><span class="line">  (Idaho:Location    &#123;name:<span class="string">&#x27;Idaho&#x27;</span>,         type:<span class="string">&#x27;state&#x27;</span>    &#125;),</span><br><span class="line">  (Lucy:Person       &#123;name:<span class="string">&#x27;Lucy&#x27;</span> &#125;),</span><br><span class="line">  (Idaho) <span class="operator">-</span>[:<span class="keyword">WITHIN</span>]<span class="operator">-</span><span class="operator">&gt;</span>  (USA)  <span class="operator">-</span>[:<span class="keyword">WITHIN</span>]<span class="operator">-</span><span class="operator">&gt;</span> (NAmerica),</span><br><span class="line">  (Lucy)  <span class="operator">-</span>[:BORN_IN]<span class="operator">-</span><span class="operator">&gt;</span> (Idaho)</span><br></pre></td></tr></table></figure>

<p>如果我们要进行一个这样的查询：找出所有从美国移居到欧洲的人名。</p>
<p>转化为图语言，即为：给定条件， BORN_IN 指向美国的地点，并且 LIVING_IN 指向欧洲的地点，找到所有符合上述条件的点，并且返回其名字属性。</p>
<p>用 Cypher 语句可表示为：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">MATCH</span></span><br><span class="line">  (person) <span class="operator">-</span>[:BORN_IN]<span class="operator">-</span><span class="operator">&gt;</span>  () <span class="operator">-</span>[:<span class="keyword">WITHIN</span><span class="operator">*</span><span class="number">0.</span>.]<span class="operator">-</span><span class="operator">&gt;</span> (us:Location &#123;name:<span class="string">&#x27;United States&#x27;</span>&#125;),</span><br><span class="line">  (person) <span class="operator">-</span>[:LIVES_IN]<span class="operator">-</span><span class="operator">&gt;</span> () <span class="operator">-</span>[:<span class="keyword">WITHIN</span><span class="operator">*</span><span class="number">0.</span>.]<span class="operator">-</span><span class="operator">&gt;</span> (eu:Location &#123;name:<span class="string">&#x27;Europe&#x27;</span>&#125;)</span><br><span class="line"><span class="keyword">RETURN</span> person.name</span><br></pre></td></tr></table></figure>

<p>注意到：</p>
<ol>
<li>点 <code>()</code>，边 <code>-[]→</code>，标签\类型 <code>：</code>，属性 <code>&#123;&#125;</code>。</li>
<li>名字绑定或者说变量：<code>person</code></li>
<li>0 到多次通配符： <code>*0...</code></li>
</ol>
<p>正如声明式查询语言的一贯特点，你只需描述问题，不必担心执行过程。但与 SQL 的区别在于，SQL 基于关系代数，Cypher 类似正则表达式。</p>
<p>无论是 BFS、DFS 还是剪枝等实现细节，都不需要关心。</p>
<h3 id="使用-SQL-进行图查询"><a href="#使用-SQL-进行图查询" class="headerlink" title="使用 SQL 进行图查询"></a>使用 SQL 进行图查询</h3><p>前面看到可以用 SQL 存储点和边，以表示图。</p>
<p>那可以用 SQL 进行图查询吗？</p>
<p>Oracle 的 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLm9yYWNsZS5jb20vZW4vZGF0YWJhc2Uvb3JhY2xlL3Byb3BlcnR5LWdyYXBoLzIwLjQvc3BnZGcvcHJvcGVydHktZ3JhcGgtcXVlcnktbGFuZ3VhZ2UtcGdxbC5odG1s">PGQL<i class="fa fa-external-link-alt"></i></span>：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> PROPERTY GRAPH bank_transfers</span><br><span class="line">     VERTEX TABLES (persons KEY(account_number))</span><br><span class="line">     EDGE TABLES(</span><br><span class="line">                  transactions KEY (from_acct, to_acct, <span class="type">date</span>, amount)</span><br><span class="line">                  SOURCE KEY (from_account) <span class="keyword">REFERENCES</span> persons</span><br><span class="line">                  DESTINATION KEY (to_account) <span class="keyword">REFERENCES</span> persons</span><br><span class="line">                  PROPERTIES (<span class="type">date</span>, amount)</span><br><span class="line">       )</span><br></pre></td></tr></table></figure>

<p>其中有一个难点，就是如何表达图中的路径模式（graph pattern），如<strong>多跳查询</strong>，对应到 SQL 中，就是不确定次数的 Join：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">() <span class="operator">-</span>[:<span class="keyword">WITHIN</span><span class="operator">*</span><span class="number">0.</span>.]<span class="operator">-</span><span class="operator">&gt;</span> ()</span><br></pre></td></tr></table></figure>

<p>使用 SQL:1999 中 recursive common table expressions （PostgreSQL, IBM DB2, Oracle, and SQL Server 支持）的可以满足。但是，相当冗长和笨拙。</p>
<h3 id="Triple-Stores-and-SPARQL"><a href="#Triple-Stores-and-SPARQL" class="headerlink" title="Triple-Stores and SPARQL"></a><strong>Triple-Stores and SPARQL</strong></h3><p><strong>Triple-Stores</strong>，可以理解为三元组存储，即用三元组存储图。</p>
<p><img src="https://s2.loli.net/2022/04/16/5ptXoWNUVswrxyq.png" alt="ddia2-triple-store.png"></p>
<p>其含义如下：</p>
<table>
<thead>
<tr>
<th>Subject</th>
<th>对应图中的一个点</th>
</tr>
</thead>
<tbody><tr>
<td>Object</td>
<td>1. 一个原子数据，如 string 或者 number。<br/>2. 另一个 Subject。</td>
</tr>
<tr>
<td>Predicate</td>
<td>1. 如果 Object 是原子数据，则  &lt;Predicate, Object&gt; 对应点附带的 KV 对。<br/>2. 如果 Object 是另一个 Object，则 Predicate 对应图中的边。</td>
</tr>
</tbody></table>
<p>仍是上边例子，用 Turtle triples (一种 <strong>Triple-Stores</strong> 语法<strong>）</strong>表达为<strong>：</strong></p>
<figure class="highlight scheme"><table><tr><td class="code"><pre><span class="line">@prefix : &lt;urn:example:&gt;.</span><br><span class="line">_:lucy     a       :Person.</span><br><span class="line">_:lucy     :name   <span class="string">&quot;Lucy&quot;</span>.</span><br><span class="line">_:lucy     :bornIn _:idaho.</span><br><span class="line">_:idaho    a       :Location.</span><br><span class="line">_:idaho    :name   <span class="string">&quot;Idaho&quot;</span>.</span><br><span class="line">_:idaho    :type   <span class="string">&quot;state&quot;</span>.</span><br><span class="line">_:idaho    :within _:usa.</span><br><span class="line">_:usa      a       :Location</span><br><span class="line">_:usa      :name   <span class="string">&quot;United States&quot;</span></span><br><span class="line">_:usa      :type   <span class="string">&quot;country&quot;</span>.</span><br><span class="line">_:usa      :within _:namerica.</span><br><span class="line">_:namerica a       :Location.</span><br><span class="line">_:namerica :name   <span class="string">&quot;North America&quot;</span>.</span><br><span class="line">_:namerica :type   <span class="string">&quot;continent&quot;</span>.</span><br></pre></td></tr></table></figure>

<p>一种更紧凑的写法：</p>
<figure class="highlight scheme"><table><tr><td class="code"><pre><span class="line">@prefix : &lt;urn:example:&gt;.</span><br><span class="line">_:lucy     a: Person<span class="comment">;   :name &quot;Lucy&quot;;          :bornIn _:idaho</span></span><br><span class="line">_:idaho    a: Location<span class="comment">; :name &quot;Idaho&quot;;         :type &quot;state&quot;;     :within _:usa.</span></span><br><span class="line">_:usa      a: Location<span class="comment">; :name &quot;United States&quot;; :type &quot;country&quot;;   :within _:namerica.</span></span><br><span class="line">_:namerica a :Location<span class="comment">; :name &quot;North America&quot;; :type &quot;continent&quot;.</span></span><br></pre></td></tr></table></figure>

<h3 id="语义网（The-Semantic-Web）"><a href="#语义网（The-Semantic-Web）" class="headerlink" title="语义网（The Semantic Web）"></a>语义网（The <strong>Semantic Web</strong>）</h3><p>万维网之父Tim Berners Lee于1998年提出，知识图谱前身。其目的在于对网络中的资源进行结构化，从而让计算机能够<strong>理解</strong>网络中的数据。即不是以文本、二进制流等等，而是通过某种标准结构化互相关联的数据。</p>
<p><strong>语义</strong>：提供一种统一的方式对所有资源进行描述和<strong>结构化</strong>（机器可读）。</p>
<p><strong>网</strong>：将所有资源勾连起来。</p>
<p>下面是<strong>语义网技术栈</strong>（Semantic Web Stack）：</p>
<p><img src="https://s2.loli.net/2022/04/16/ahqP9G7c42JsNEi.png" alt="ddia2-rdf.png"></p>
<p>其中 <strong>RDF</strong> （<em>ResourceDescription Framework，资源描述框架</em>）提供了一种结构化网络中数据的标准。使发布到网络中的任何资源（文字、图片、视频、网页），都能以统一的形式被计算机理解。即，不需要让资源使用方深度学习抽取资源的语义，而是靠资源提供方通过 RDF 主动提供其资源语义。</p>
<p>感觉有点理想主义，但互联网、开源社区都是靠这种理想主义、分享精神发展起来的！</p>
<p>虽然语义网没有发展起来，但是其<strong>中间数据交换</strong>格式 RDF 所定义的 SPO三元组(Subject-Predicate-Object) 却是一种很好用的数据模型，也就是上面提到的 <strong>Triple-Stores。</strong></p>
<h3 id="RDF-数据模型"><a href="#RDF-数据模型" class="headerlink" title="RDF 数据模型"></a>RDF 数据模型</h3><p>上面提到的 Turtle 语言（SPO三元组）是一种简单易读的描述 RDF 数据的方式， RDF 也可以基于 XML 表示，但是要冗余难读的多（嵌套太深）：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">rdf:RDF</span> <span class="attr">xmlns</span>=<span class="string">&quot;urn:example:&quot;</span></span></span><br><span class="line"><span class="tag">  <span class="attr">xmlns:rdf</span>=<span class="string">&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Location</span> <span class="attr">rdf:nodeID</span>=<span class="string">&quot;idaho&quot;</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>Idaho<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>state<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">within</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">Location</span> <span class="attr">rdf:nodeID</span>=<span class="string">&quot;usa&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>United States<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">type</span>&gt;</span>country<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">within</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">Location</span> <span class="attr">rdf:nodeID</span>=<span class="string">&quot;namerica&quot;</span>&gt;</span> </span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>North America<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">type</span>&gt;</span>continent<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">Location</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">within</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">Location</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">within</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Location</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">Person</span> <span class="attr">rdf:nodeID</span>=<span class="string">&quot;lucy&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>Lucy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bornIn</span> <span class="attr">rdf:nodeID</span>=<span class="string">&quot;idaho&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">Person</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">rdf:RDF</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>为了标准化和去除二义性，一些看起来比较奇怪的点是：无论 subject，predicate 还是 object 都是由 URI 定义，如</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">lives_in 会表示为 &lt;http<span class="punctuation">:</span><span class="comment">//my-company.com/namespace#lives_in&gt;</span></span><br></pre></td></tr></table></figure>

<p>其前缀只是一个 namespace，让定义唯一化，并且在网络上可访问。当然，一个简化的方法是可以在文件头声明一个公共前缀。</p>
<h3 id="SPARQL-查询语言"><a href="#SPARQL-查询语言" class="headerlink" title="SPARQL 查询语言"></a><strong>SPARQL 查询语言</strong></h3><p>有了语义网，自然需要在语义网中进行遍历查询，于是有了 RDF 的查询语言：SPARQL Protocol and RDF Query Language, pronounced “sparkle.”</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PREFIX <span class="punctuation">:</span> &lt;urn<span class="punctuation">:</span>example<span class="punctuation">:</span>&gt;</span><br><span class="line">SELECT ?personName WHERE <span class="punctuation">&#123;</span></span><br><span class="line">  ?person <span class="punctuation">:</span>name ?personName.</span><br><span class="line">  ?person <span class="punctuation">:</span>bornIn  / <span class="punctuation">:</span>within* / <span class="punctuation">:</span>name <span class="string">&quot;United States&quot;</span>.</span><br><span class="line">  ?person <span class="punctuation">:</span>livesIn / <span class="punctuation">:</span>within* / <span class="punctuation">:</span>name <span class="string">&quot;Europe&quot;</span>.</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>他是 Cypher 的前驱，因此结构看起来很像：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">(person) -<span class="punctuation">[</span><span class="punctuation">:</span>BORN_IN<span class="punctuation">]</span>-&gt; () -<span class="punctuation">[</span><span class="punctuation">:</span>WITHIN*<span class="number">0.</span>.<span class="punctuation">]</span>-&gt; (location)   # Cypher</span><br><span class="line">?person   <span class="punctuation">:</span>bornIn /        <span class="punctuation">:</span>within*        ?location.   # SPARQL</span><br></pre></td></tr></table></figure>

<p>但 <strong>SPARQL</strong> 没有区分边和属性的关系，都用了 Predicates。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">(usa <span class="punctuation">&#123;</span>name<span class="punctuation">:</span>&#x27;United States&#x27;<span class="punctuation">&#125;</span>)   # Cypher</span><br><span class="line">?usa <span class="punctuation">:</span>name <span class="string">&quot;United States&quot;</span>.    # SPARQL</span><br></pre></td></tr></table></figure>

<p>虽然语义网没有成功落地，但其技术栈影响了后来的知识图谱和图查询语言。</p>
<h3 id="图模型和网络模型"><a href="#图模型和网络模型" class="headerlink" title="图模型和网络模型"></a>图模型和网络模型</h3><p>图模型是网络模型旧瓶装新酒吗？</p>
<p>否，他们在很多重要的方面都不一样。</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>图模型（Graph Model）</th>
<th>网络模型（Network Model）</th>
</tr>
</thead>
<tbody><tr>
<td>连接方式</td>
<td>任意两个点之间都有可以有边</td>
<td>指定了嵌套约束</td>
</tr>
<tr>
<td>记录查找</td>
<td>1. 使用全局 ID <br/>2. 使用属性索引。<br/>3. 使用图遍历。</td>
<td>只能使用路径查询</td>
</tr>
<tr>
<td>有序性</td>
<td>点和边都是无序的</td>
<td>记录的孩子们是有序集合，在插入时需要考虑维持有序的开销</td>
</tr>
<tr>
<td>查询语言</td>
<td>即可命令式，也可以声明式</td>
<td>命令式的</td>
</tr>
</tbody></table>
<h3 id="查询语言前驱：Datalog"><a href="#查询语言前驱：Datalog" class="headerlink" title="查询语言前驱：Datalog"></a>查询语言前驱：Datalog</h3><p>有点像 triple-store，但是变了下次序：(<em>subject</em>, <em>predicate</em>, <em>object</em>) → <em>predicate</em>(<em>subject</em>, <em>object</em>).<br>之前数据用 Datalog 表示为：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">name(namerica<span class="punctuation">,</span> &#x27;North America&#x27;).</span><br><span class="line">type(namerica<span class="punctuation">,</span> continent).</span><br><span class="line"></span><br><span class="line">name(usa<span class="punctuation">,</span> &#x27;United States&#x27;).</span><br><span class="line">type(usa<span class="punctuation">,</span> country).</span><br><span class="line">within(usa<span class="punctuation">,</span> namerica).</span><br><span class="line"></span><br><span class="line">name(idaho<span class="punctuation">,</span> &#x27;Idaho&#x27;).</span><br><span class="line">type(idaho<span class="punctuation">,</span> state).</span><br><span class="line">within(idaho<span class="punctuation">,</span> usa).</span><br><span class="line"></span><br><span class="line">name(lucy<span class="punctuation">,</span> &#x27;Lucy&#x27;).</span><br><span class="line">born_in(lucy<span class="punctuation">,</span> idaho).</span><br></pre></td></tr></table></figure>

<p>查询从<em>美国迁移到欧洲的人</em>可以表示为：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">within_recursive(Location<span class="punctuation">,</span> Name) <span class="punctuation">:</span>- name(Location<span class="punctuation">,</span> Name). <span class="comment">/* Rule 1 */</span></span><br><span class="line">within_recursive(Location<span class="punctuation">,</span> Name) <span class="punctuation">:</span>- within(Location<span class="punctuation">,</span> Via)<span class="punctuation">,</span> <span class="comment">/* Rule 2 */</span> </span><br><span class="line">                                    within_recursive(Via<span class="punctuation">,</span> Name).</span><br><span class="line"></span><br><span class="line">migrated(Name<span class="punctuation">,</span> BornIn<span class="punctuation">,</span> LivingIn) <span class="punctuation">:</span>- name(Person<span class="punctuation">,</span> Name)<span class="punctuation">,</span> <span class="comment">/* Rule 3 */</span> </span><br><span class="line">                                    born_in(Person<span class="punctuation">,</span> BornLoc)<span class="punctuation">,</span></span><br><span class="line">                                    within_recursive(BornLoc<span class="punctuation">,</span> BornIn)<span class="punctuation">,</span></span><br><span class="line">                                    lives_in(Person<span class="punctuation">,</span> LivingLoc)<span class="punctuation">,</span></span><br><span class="line">                                    within_recursive(LivingLoc<span class="punctuation">,</span> LivingIn).</span><br><span class="line">?- migrated(Who<span class="punctuation">,</span> &#x27;United States&#x27;<span class="punctuation">,</span> &#x27;Europe&#x27;). <span class="comment">/* Who = &#x27;Lucy&#x27;. */</span></span><br></pre></td></tr></table></figure>

<ol>
<li>代码中以大写字母开头的元素是<strong>变量</strong>，字符串、数字或以小写字母开头的元素是<strong>常量</strong>。下划线（_）被称为匿名变量</li>
<li>可以使用基本 Predicate 自定义 Predicate，类似于使用基本函数自定义函数。</li>
<li>逗号连接的多个谓词表达式为且的关系。</li>
</ol>
<p><img src="https://s2.loli.net/2022/04/16/NEP7kwqvdFp3zsK.png" alt="ddia2-triple-store-query.png"></p>
<p>基于集合的逻辑运算：</p>
<ol>
<li>根据基本数据子集选出符合条件集合。</li>
<li>应用规则，扩充原集合。</li>
<li>如果可以递归，则递归穷尽所有可能性。</li>
</ol>
<p>Prolog（Programming in Logic的缩写）是一种逻辑编程语言。它创建在逻辑学的理论基础之上。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>声明式(declarative) vs 命令式(imperative)<strong>：</strong><span class="exturl" data-url="aHR0cHM6Ly9sb3RhYm91dC5tZS8yMDIwL0RlY2xhcmF0aXZlLXZzLUltcGVyYXRpdmUtbGFuZ3VhZ2Uv">https://lotabout.me/2020/Declarative-vs-Imperative-language/<i class="fa fa-external-link-alt"></i></span></li>
<li><strong><span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9zaW1tZXJjaGFu">SimmerChan<i class="fa fa-external-link-alt"></i></span></strong> 知乎专栏，知识图谱，语义网，RDF：<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL2NvbHVtbi9rbm93bGVkZ2VncmFwaA==">https://www.zhihu.com/column/knowledgegraph<i class="fa fa-external-link-alt"></i></span></li>
<li>MySQL 为什么叫“关系”模型：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NDczMTIwNg==">https://zhuanlan.zhihu.com/p/64731206<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>DDIA</category>
      </categories>
      <tags>
        <tag>DDIA</tag>
        <tag>读书笔记</tag>
        <tag>设计数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>DDIA 读书笔记（三）：B-Tree 和 LSM-Tree</title>
    <url>/2022/04/16/ddia-reading-chapter3-part1/</url>
    <content><![CDATA[<blockquote>
<p>DDIA 读书分享会，会逐章进行分享，结合我在工业界分布式存储和数据库的一些经验，补充一些细节。每两周左右分享一次，欢迎加入，Schedule 和所有文字稿在<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">这里<i class="fa fa-external-link-alt"></i></span>。我们有个对应的分布式&amp;数据库讨论群，每次分享前会在群里通知。如想加入，可以加我的微信号：qtmuniao，简单自我介绍下，并注明：分布式系统群。</p>
</blockquote>
<p>第二章讲了上层抽象：数据模型和查询语言。<br>本章下沉一些，聚焦数据库底层如何处理查询和存储。这其中，有个<strong>逻辑链条</strong>：</p>
<blockquote>
<p>使用场景→ 查询类型 → 存储格式。</p>
</blockquote>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/04/16/ddia-reading-chapter3-part1">https://www.qtmuniao.com/2022/04/16/ddia-reading-chapter3-part1</a> 转载请注明出处</em></p>
<p>查询类型主要分为两大类：</p>
<table>
<thead>
<tr>
<th>引擎类型</th>
<th>请求数量</th>
<th>数据量</th>
<th>瓶颈</th>
<th>存储格式</th>
<th>用户</th>
<th>场景举例</th>
<th>产品举例</th>
</tr>
</thead>
<tbody><tr>
<td>OLTP</td>
<td>相对频繁，侧重在线交易</td>
<td>总体和单次查询都相对较小</td>
<td>Disk Seek</td>
<td>多用行存</td>
<td>比较普遍，一般应用用的比较多</td>
<td>银行交易</td>
<td>MySQL</td>
</tr>
<tr>
<td>OLAP</td>
<td>相对较少，侧重离线分析</td>
<td>总体和单次查询都相对巨大</td>
<td>Disk Bandwidth</td>
<td>列存逐渐流行</td>
<td>多为商业用户</td>
<td>商业分析</td>
<td>ClickHouse</td>
</tr>
</tbody></table>
<p>其中，OLTP 侧，常用的存储引擎又有两种流派：</p>
<table>
<thead>
<tr>
<th>流派</th>
<th>主要特点</th>
<th>基本思想</th>
<th>代表</th>
</tr>
</thead>
<tbody><tr>
<td>log-structured 流</td>
<td>只允许追加，所有修改都表现为文件的追加和文件整体增删</td>
<td>变随机写为顺序写</td>
<td>Bitcask、LevelDB、RocksDB、Cassandra、Lucene</td>
</tr>
<tr>
<td>update-in-place 流</td>
<td>以页（page）为粒度对磁盘数据进行修改</td>
<td>面向页、查找树</td>
<td>B族树，所有主流关系型数据库和一些非关系型数据库</td>
</tr>
</tbody></table>
<p>此外，针对 OLTP， 还探索了常见的建索引的方法，以及一种特殊的数据库——全内存数据库。</p>
<p>对于数据仓库，本章分析了它与 OLTP 的主要不同之处。数据仓库主要侧重于聚合查询，需要扫描很大量的数据，此时，索引就相对不太有用。需要考虑的是存储成本、带宽优化等，由此引出列式存储。</p>
<h1 id="驱动数据库的底层数据结构"><a href="#驱动数据库的底层数据结构" class="headerlink" title="驱动数据库的底层数据结构"></a>驱动数据库的底层数据结构</h1><p>本节由一个 shell 脚本出发，到一个相当简单但可用的存储引擎 Bitcask，然后引出 LSM-tree，他们都属于日志流范畴。之后转向存储引擎另一流派——B 族树，之后对其做了简单对比。最后探讨了存储中离不开的结构——索引。</p>
<p>首先来看，世界上“最简单”的数据库，由两个 Bash 函数构成：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="function"><span class="title">db_set</span></span> () &#123;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$1</span>,<span class="variable">$2</span>&quot;</span> &gt;&gt; database</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">db_get</span></span> () &#123;</span><br><span class="line">  grep <span class="string">&quot;^<span class="variable">$1</span>,&quot;</span> database | sed -e <span class="string">&quot;s/^<span class="variable">$1</span>,//&quot;</span> | <span class="built_in">tail</span> -n 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这两个函数实现了一个基于字符串的 KV 存储（只支持 get&#x2F;set，不支持 delete）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ db_set 123456 <span class="string">&#x27;&#123;&quot;name&quot;:&quot;London&quot;,&quot;attractions&quot;:[&quot;Big Ben&quot;,&quot;London Eye&quot;]&#125;&#x27;</span> </span><br><span class="line">$ db_set 42 <span class="string">&#x27;&#123;&quot;name&quot;:&quot;San Francisco&quot;,&quot;attractions&quot;:[&quot;Golden Gate Bridge&quot;]&#125;&#x27;</span></span><br><span class="line">$ db_get 42</span><br><span class="line">&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;San Francisco&quot;</span>,<span class="string">&quot;attractions&quot;</span>:[<span class="string">&quot;Golden Gate Bridge&quot;</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>来分析下它为什么 work，也反映了日志结构存储的最基本原理：</p>
<ol>
<li>set：在文件末尾追加一个 KV 对。</li>
<li>get：匹配所有 Key，返回最后（也即最新）一条 KV 对中的 Value。</li>
</ol>
<p>可以看出：写很快，但是读需要全文逐行扫描，会慢很多。典型的以读换写。为了加快读，我们需要构建<strong>索引：</strong>一种允许基于某些字段查找的额外数据结构。</p>
<p>索引从原数据中构建，只为加快查找。因此索引会耗费一定额外空间，和插入时间（每次插入要更新索引），即，重新以空间和写换读取。</p>
<p>这便是数据库存储引擎设计和选择时最常见的<strong>权衡（trade off）</strong>：</p>
<ol>
<li>恰当的<strong>存储格式</strong>能加快写（日志结构），但是会让读取很慢；也可以加快读（查找树、B族树），但会让写入较慢。</li>
<li>为了弥补读性能，可以构建索引。但是会牺牲写入性能和耗费额外空间。</li>
</ol>
<p>存储格式一般不好动，但是索引构建与否，一般交予用户选择。</p>
<h2 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h2><p>本节主要基于最基础的 KV 索引。</p>
<p>依上小节的例子，所有数据顺序追加到磁盘上。为了加快查询，我们在内存中构建一个哈希索引：</p>
<ol>
<li>Key 是查询 Key</li>
<li>Value 是 KV 条目的起始位置和长度。</li>
</ol>
<p><img src="https://s2.loli.net/2022/04/16/iXVWtdGLxb6RDqB.png" alt="ddia-3-1-hash-map-csv.png"></p>
<p>看来很简单，但这正是 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnJpYWsuY29tL3JpYWsva3YvMi4yLjMvc2V0dXAvcGxhbm5pbmcvYmFja2VuZC9iaXRjYXNrL2luZGV4Lmh0bWw=">Bitcask<i class="fa fa-external-link-alt"></i></span> 的基本设计，但关键是，他 Work（在小数据量时，即所有 key 都能存到内存中时）：能提供很高的读写性能：</p>
<ol>
<li>写：文件追加写。</li>
<li>读：一次内存查询，一次磁盘 seek；如果数据已经被缓存，则 seek 也可以省掉。</li>
</ol>
<p>如果你的 key 集合很小（意味着能全放内存），但是每个 key 更新很频繁，那么 Bitcask 便是你的菜。举个栗子：频繁更新的视频播放量，key 是视频 url，value 是视频播放量。</p>
<blockquote>
<p>但有个很重要问题，单个文件越来越大，磁盘空间不够怎么办？</p>
<p>在文件到达一定尺寸后，就新建一个文件，将原文件变为只读。同时为了回收多个 key 多次写入的造成的空间浪费，可以将只读文件进行紧缩（ compact ），将旧文件进行重写，挤出“水分”（被覆写的数据）以进行垃圾回收。</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/04/16/OUVfroWha34L8i7.png" alt="ddia-3-3-compaction-sim.png"></p>
<p>当然，如果我们想让其<strong>工业可用</strong>，还有很多问题需要解决：</p>
<ol>
<li><strong>文件格式</strong>。对于<strong>日志</strong>来说，CSV 不是一种紧凑的数据格式，有很多空间浪费。比如，可以用 length + record bytes 。</li>
<li><strong>记录删除</strong>。之前只支持 put\get，但实际还需要支持 delete。但日志结构又不支持更新，怎么办呢？一般是写一个特殊标记（比如墓碑记录，tombstone）以表示该记录已删除。之后 compact 时真正删除即可。</li>
<li><strong>宕机恢复</strong>。在机器重启时，内存中的哈希索引将会丢失。当然，可以全盘扫描以重建，但通常一个小优化是，对于每个 segment file， 将其索引条目和数据文件一块持久化，重启时只需加载索引条目即可。</li>
<li><strong>记录写坏、少写</strong>。系统任何时候都有可能宕机，由此会造成记录写坏、少写。为了识别错误记录，我们需要增加一些校验字段，以识别并跳过这种数据。为了跳过写了部分的数据，还要用一些特殊字符来标识记录间的边界。</li>
<li><strong>并发控制</strong>。由于只有一个活动（追加）文件，因此写只有一个天然并发度。但其他的文件都是不可变的（compact 时会读取然后生成新的），因此读取和紧缩可以并发执行。</li>
</ol>
<p>乍一看，基于日志的存储结构存在折不少浪费：需要以追加进行更新和删除。但日志结构有几个原地更新结构无法做的优点：</p>
<ol>
<li><strong>以顺序写代替随机写</strong>。对于磁盘和 SSD，顺序写都要比随机写快几个数量级。</li>
<li><strong>简易的并发控制</strong>。由于大部分的文件都是<strong>不可变（immutable）</strong>的，因此更容易做并发读取和紧缩。也不用担心原地更新会造成新老数据交替。</li>
<li><strong>更少的内部碎片</strong>。每次紧缩会将垃圾完全挤出。但是原地更新就会在 page 中留下一些不可用空间。</li>
</ol>
<p>当然，基于内存的哈希索引也有其局限：</p>
<ol>
<li><strong>所有 Key 必须放内存</strong>。一旦 Key 的数据量超过内存大小，这种方案便不再 work。当然你可以设计基于磁盘的哈希表，但那又会带来大量的随机写。</li>
<li><strong>不支持范围查询</strong>。由于 key 是无序的，要进行范围查询必须全表扫描。</li>
</ol>
<p>后面讲的 LSM-Tree 和 B+ 树，都能部分规避上述问题。</p>
<ul>
<li>想想，会如何进行规避？</li>
</ul>
<h2 id="SSTables-和-LSM-Trees"><a href="#SSTables-和-LSM-Trees" class="headerlink" title="SSTables 和 LSM-Trees"></a>SSTables 和 LSM-Trees</h2><p>这一节层层递进，步步做引，从 SSTables 格式出发，牵出 LSM-Trees 全貌。</p>
<p>对于 KV 数据，前面的 BitCask 存储结构是：</p>
<ol>
<li>外存上日志片段</li>
<li>内存中的哈希表</li>
</ol>
<p>其中外存上的数据是简单追加写而形成的，并没有按照某个字段有序。</p>
<p>假设加一个限制，让这些文件按 key 有序。我们称这种格式为：SSTable（Sorted String Table）。</p>
<p>这种文件格式有什么优点呢？</p>
<p><strong>高效的数据文件合并</strong>。即有序文件的归并外排，顺序读，顺序写。不同文件出现相同 Key 怎么办？</p>
<p><img src="https://s2.loli.net/2022/04/16/A3dwMLfSs4Imgnj.png" alt="ddia-3-4-merge-sst.png"></p>
<p><strong>不需要在内存中保存所有数据的索引</strong>。仅需要记录下每个文件界限（以区间表示：[startKey, endKey]，当然实际会记录的更细）即可。查找某个 Key 时，去所有包含该 Key 的区间对应的文件二分查找即可。</p>
<p><img src="https://s2.loli.net/2022/04/16/j8tM6IUk1QrJXuw.png" alt="ddia-3-5-sst-index.png"></p>
<p><strong>分块压缩，节省空间，减少 IO</strong>。相邻 Key 共享前缀，既然每次都要批量取，那正好一组 key batch 到一块，称为 block，且只记录 block 的索引。</p>
<h3 id="构建和维护-SSTables"><a href="#构建和维护-SSTables" class="headerlink" title="构建和维护 SSTables"></a>构建和维护 SSTables</h3><p>SSTables 格式听起来很美好，但须知数据是乱序的来的，我们如何得到有序的数据文件呢？</p>
<p>这可以拆解为两个小问题：</p>
<ol>
<li>如何构建。</li>
<li>如何维护。</li>
</ol>
<p><strong>构建 SSTable 文件</strong>。将乱序数据在外存（磁盘 or SSD）中上整理为有序文件，是比较难的。但是在内存就方便的多。于是一个大胆的想法就形成了：</p>
<ol>
<li>在内存中维护一个有序结构（称为 <strong>MemTable</strong>）。红黑树、AVL 树、条表。</li>
<li>到达一定阈值之后全量 dump 到外存。</li>
</ol>
<p><strong>维护 SSTable 文件</strong>。为什么需要维护呢？首先要问，对于上述复合结构，我们怎么进行查询：</p>
<ol>
<li>先去 MemTable 中查找，如果命中则返回。</li>
<li>再去 SSTable 按时间顺序由新到旧逐一查找。</li>
</ol>
<p>如果 SSTable 文件越来越多，则查找代价会越来越大。因此需要将多个 SSTable 文件合并，以减少文件数量，同时进行 GC，我们称之为<strong>紧缩</strong>（ Compaction）。</p>
<p><strong>该方案的问题</strong>：如果出现宕机，内存中的数据结构将会消失。 解决方法也很经典：WAL。</p>
<h3 id="从-SSTables-到-LSM-Tree"><a href="#从-SSTables-到-LSM-Tree" class="headerlink" title="从 SSTables 到 LSM-Tree"></a>从 SSTables 到 LSM-Tree</h3><p>将前面几节的一些碎片有机的组织起来，便是时下流行的存储引擎 LevelDB 和 RocksDB 后面的存储结构：LSM-Tree：</p>
<p><img src="https://s2.loli.net/2022/04/16/pHgxdn4TPwCoil6.png" alt="ddia-3-leveldb-architecture.png"></p>
<p>这种数据结构是 Patrick O’Neil 等人，在 1996 年提出的：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3MudW1iLmVkdS9+cG9uZWlsL2xzbXRyZWUucGRm">The Log-Structured Merge-Tree<i class="fa fa-external-link-alt"></i></span>。</p>
<p>Elasticsearch 和 Solr 的索引引擎 Lucene，也使用类似 LSM-Tree 存储结构。但其数据模型不是 KV，但类似：word → document list。</p>
<h3 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h3><p>如果想让一个引擎工程上可用，还会做大量的性能优化。对于 LSM-Tree 来说，包括：</p>
<p><strong>优化 SSTable 的查找。</strong>常用 <a href="https://www.qtmuniao.com/2020/11/18/leveldb-data-structures-bloom-filter/"><strong>Bloom Filter</strong></a>。该数据结构可以使用较少的内存为每个 SSTable 做一些指纹，起到一些初筛的作用。</p>
<p><strong>层级化组织 SSTable</strong>。以控制 Compaction 的顺序和时间。常见的有 size-tiered 和 leveled compaction。LevelDB 便是支持后者而得名。前者比较简单粗暴，后者性能更好，也因此更为常见。</p>
<p><img src="https://s2.loli.net/2022/04/16/yBxIZR8CusbQrPO.png" alt="ddia-sized-tierd-compact.png"></p>
<p>对于 RocksDB 来说，工程上的优化和使用上的优化就更多了。在其 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rL3JvY2tzZGIvd2lraQ==">Wiki<i class="fa fa-external-link-alt"></i></span> 上随便摘录几点：</p>
<ol>
<li>Column Family</li>
<li>前缀压缩和过滤</li>
<li>键值分离，BlobDB</li>
</ol>
<p>但无论有多少变种和优化，LSM-Tree 的核心思想——<strong>保存一组合理组织、后台合并的 SSTables</strong> ——简约而强大。可以方便的进行范围遍历，可以变大量随机为少量顺序。</p>
<h2 id="B-族树"><a href="#B-族树" class="headerlink" title="B 族树"></a>B 族树</h2><p>虽然先讲的 LSM-Tree，但是它要比 B+ 树新的多。</p>
<p>B 树于 1970 年被 R. Bayer and E. McCreight <span class="exturl" data-url="aHR0cHM6Ly9kbC5hY20ub3JnL2RvaS8xMC4xMTQ1LzE3MzQ2NjMuMTczNDY3MQ==">提出<i class="fa fa-external-link-alt"></i></span>后，便迅速流行了起来。现在几乎所有的关系型数据中，它都是数据索引标准一般的实现。</p>
<p>与 LSM-Tree 一样，它也支持高效的<strong>点查</strong>和<strong>范围查</strong>。但却使用了完全不同的组织方式。</p>
<p>其特点有：</p>
<ol>
<li>以页（在磁盘上叫 page，在内存中叫 block，通常为 4k）为单位进行组织。</li>
<li>页之间以页 ID 来进行逻辑引用，从而组织成一颗磁盘上的树。</li>
</ol>
<p><img src="https://s2.loli.net/2022/04/16/ZuLcBm6HKd2AQra.png" alt="ddia-3-6-b-tree-lookup.png"></p>
<p><strong>查找</strong>。从根节点出发，进行二分查找，然后加载新的页到内存中，继续二分，直到命中或者到叶子节点。 查找复杂度，树的高度—— O(lgn)，影响树高度的因素：分支因子（分叉数，通常是几百个）。</p>
<p><img src="https://s2.loli.net/2022/04/16/K4gXhrzf9wySko7.png" alt="ddia-3-7-b-tree-grow-by-split.png"></p>
<p><strong>插入 or 更新</strong>。和查找过程一样，定位到原 Key 所在页，插入或者更新后，将页完整写回。如果页剩余空间不够，则分裂后写入。</p>
<p><strong>分裂 or 合并</strong>。级联分裂和合并。</p>
<ul>
<li><p>一个记录大于一个 page 怎么办？</p>
<p>  树的节点是逻辑概念，page or block 是物理概念。一个逻辑节点可以对应多个物理 page。</p>
</li>
</ul>
<h3 id="让-B-树更可靠"><a href="#让-B-树更可靠" class="headerlink" title="让 B 树更可靠"></a>让 B 树更可靠</h3><p>B 树不像 LSM-Tree ，会在原地修改数据文件。</p>
<p>在树结构调整时，可能会级联修改很多 Page。比如叶子节点分裂后，就需要写入两个新的叶子节点，和一个父节点（更新叶子指针）。</p>
<ol>
<li>增加预写日志（WAL），将所有修改操作记录下来，预防宕机时中断树结构调整而产生的混乱现场。</li>
<li>使用 latch 对树结构进行并发控制。</li>
</ol>
<h3 id="B-树的优化"><a href="#B-树的优化" class="headerlink" title="B 树的优化"></a>B 树的优化</h3><p>B 树出来了这么久，因此有很多优化：</p>
<ol>
<li>不使用 WAL，而在写入时利用 Copy On Write 技术。同时，也方便了并发控制。如 LMDB、BoltDB。</li>
<li>对中间节点的 Key 做压缩，保留足够的路由信息即可。以此，可以节省空间，增大分支因子。</li>
<li>为了优化范围查询，有的 B 族树将叶子节点存储时物理连续。但当数据不断插入时，维护此有序性的代价非常大。</li>
<li>为叶子节点增加兄弟指针，以避免顺序遍历时的回溯。即 B+ 树的做法，但远不局限于 B+ 树。</li>
<li>B 树的变种，分形树，从 LSM-tree 借鉴了一些思想以优化 seek。</li>
</ol>
<h2 id="B-Trees-和-LSM-Trees-对比"><a href="#B-Trees-和-LSM-Trees-对比" class="headerlink" title="B-Trees 和 LSM-Trees 对比"></a>B-Trees 和 LSM-Trees 对比</h2><table>
<thead>
<tr>
<th>存储引擎</th>
<th>B-Tree</th>
<th>LSM-Tree</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>优势</td>
<td>读取更快</td>
<td>写入更快</td>
<td></td>
</tr>
<tr>
<td>写放大</td>
<td>1. 数据和 WAL<br/>2. 更改数据时多次覆盖整个 Page</td>
<td>1. 数据和 WAL<br/>2. Compaction</td>
<td>SSD 不能过多擦除。因此 SSD 内部的固件中也多用日志结构来减少随机小写。</td>
</tr>
<tr>
<td>写吞吐</td>
<td>相对较低：<br/>1. 大量随机写。</td>
<td>相对较高：<br/>1. 较低的写放大（取决于数据和配置）<br/>2. 顺序写入。<br/>3. 更为紧凑。</td>
<td></td>
</tr>
<tr>
<td>压缩率</td>
<td>1. 存在较多内部碎片。</td>
<td>1. 更加紧凑，没有内部碎片。<br/>2. 压缩潜力更大（共享前缀）。</td>
<td>但紧缩不及时会造成 LSM-Tree 存在很多垃圾</td>
</tr>
<tr>
<td>后台流量</td>
<td>1. 更稳定可预测，不会受后台 compaction 突发流量影响。</td>
<td>1. 写吞吐过高，compaction 跟不上，会进一步加重读放大。<br/>2. 由于外存总带宽有限，compaction 会影响读写吞吐。<br/>3. 随着数据越来越多，compaction 对正常写影响越来越大。</td>
<td>RocksDB 写入太过快会引起 write stall，即限制写入，以期尽快 compaction 将数据下沉。</td>
</tr>
<tr>
<td>存储放大</td>
<td>1. 有些 Page 没有用满</td>
<td>1. 同一个 Key 存多遍</td>
<td></td>
</tr>
<tr>
<td>并发控制</td>
<td>1. 同一个 Key 只存在一个地方<br/>2. 树结构容易加范围锁。</td>
<td>同一个 Key 会存多遍，一般使用 MVCC 进行控制。</td>
<td></td>
</tr>
</tbody></table>
<h2 id="其他索引结构"><a href="#其他索引结构" class="headerlink" title="其他索引结构"></a>其他索引结构</h2><p><strong>次级索引（secondary indexes）</strong>。即，非主键的其他属性到该元素（SQL 中的行，MongoDB 中的文档和图数据库中的点和边）的映射。</p>
<h3 id="聚集索引和非聚集索引（cluster-indexes-and-non-cluster-indexes）"><a href="#聚集索引和非聚集索引（cluster-indexes-and-non-cluster-indexes）" class="headerlink" title="聚集索引和非聚集索引（cluster indexes and non-cluster indexes）"></a><strong>聚集索引和非聚集索引（cluster indexes and non-cluster indexes）</strong></h3><p>对于存储数据和组织索引，我们可以有多种选择：</p>
<ol>
<li>数据本身<strong>无序</strong>的存在文件中，称为 <strong>堆文件（heap file）</strong>，索引的值指向对应数据在 heap file 中的位置。这样可以避免多个索引时的数据拷贝。</li>
<li>数据本身按某个字段有序存储，该字段通常是主键。则称基于此字段的索引为<strong>聚集索引</strong>（clustered index），从另外一个角度理解，即将索引和数据存在一块。则基于其他字段的索引为<strong>非聚集索引</strong>，在索引中仅存数据的引用。</li>
<li>一部分列内嵌到索引中存储，一部分列数据额外存储。称为<strong>覆盖索引（covering index）</strong><br> 或 <strong>包含列的索引（index with included columns）</strong>。</li>
</ol>
<p>索引可以加快查询速度，但需要占用额外空间，并且牺牲了部分更新开销，且需要维持某种一致性。</p>
<h3 id="多列索引（Multi-column-indexes）。"><a href="#多列索引（Multi-column-indexes）。" class="headerlink" title="多列索引（Multi-column indexes）。"></a><strong>多列索引</strong>（<strong>Multi-column indexes</strong>）。</h3><p>现实生活中，多个字段联合查询更为常见。比如查询某个用户周边一定范围内的商户，需要经度和纬度二维查询。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> restaurants <span class="keyword">WHERE</span> latitude <span class="operator">&gt;</span> <span class="number">51.4946</span> <span class="keyword">AND</span> latitude <span class="operator">&lt;</span> <span class="number">51.5079</span></span><br><span class="line">                            <span class="keyword">AND</span> longitude <span class="operator">&gt;</span> <span class="number">-0.1162</span> <span class="keyword">AND</span> longitude <span class="operator">&lt;</span> <span class="number">-0.1004</span>;</span><br></pre></td></tr></table></figure>

<p>可以：</p>
<ol>
<li>将二维编码为一维，然后按普通索引存储。</li>
<li>使用特殊数据结构，如 R 树。</li>
</ol>
<h3 id="全文索引和模糊索引（Full-text-search-and-fuzzy-indexes）。"><a href="#全文索引和模糊索引（Full-text-search-and-fuzzy-indexes）。" class="headerlink" title="全文索引和模糊索引（Full-text search and fuzzy indexes）。"></a><strong>全文索引和模糊索引（Full-text search and fuzzy indexes）</strong>。</h3><p>前述索引只提供全字段的精确匹配，而不提供类似搜索引擎的功能。比如，按字符串中包含的单词查询，针对笔误的单词查询。</p>
<p>在工程中常用 <span class="exturl" data-url="aHR0cHM6Ly9sdWNlbmUuYXBhY2hlLm9yZy8=">Apace Lucene<i class="fa fa-external-link-alt"></i></span> 库，和其包装出来的服务：<span class="exturl" data-url="aHR0cHM6Ly93d3cuZWxhc3RpYy5jby9jbi8=">Elasticsearch<i class="fa fa-external-link-alt"></i></span>。他也使用类似 LSM-tree 的日志存储结构，但其索引是一个有限状态自动机，在行为上类似 Trie 树。</p>
<h3 id="全内存数据结构"><a href="#全内存数据结构" class="headerlink" title="全内存数据结构"></a>全内存数据结构</h3><p>随着单位内存成本下降，甚至支持持久化（<em>non-volatile memory，</em>NVM，如 Intel 的 <span class="exturl" data-url="aHR0cHM6Ly93d3cuaW50ZWwuY24vY29udGVudC93d3cvY24vemgvcHJvZHVjdHMvZGV0YWlscy9tZW1vcnktc3RvcmFnZS9vcHRhbmUtZGMtcGVyc2lzdGVudC1tZW1vcnkuaHRtbA==">傲腾<i class="fa fa-external-link-alt"></i></span>），全内存数据库也逐渐开始流行。</p>
<p>根据是否需要持久化，内存数据大概可以分为两类：</p>
<ol>
<li><strong>不需要持久化</strong>。如只用于缓存的 Memcached。</li>
<li><strong>需要持久化</strong>。通过 WAL、定期 snapshot、远程备份等等来对数据进行持久化。但使用内存处理全部读写，因此仍是内存数据库。</li>
</ol>
<blockquote>
<p>VoltDB, MemSQL, and Oracle TimesTen 是提供关系模型的内存数据库。RAMCloud 是提供持久化保证的 KV 数据库。Redis and Couchbase 仅提供弱持久化保证。</p>
</blockquote>
<p>内存数据库存在优势的原因不仅在于不需要读取磁盘，而在更于不需要对数据结构进行<strong>序列化、编码</strong>后以适应磁盘所带来的<strong>额外开销</strong>。</p>
<p>当然，内存数据库还有以下优点：</p>
<ol>
<li><strong>提供更丰富的数据抽象</strong>。如 set 和 queue 这种只存在于内存中的数据抽象。</li>
<li><strong>实现相对简单</strong>。因为所有数据都在内存中。</li>
</ol>
<p>此外，内存数据库还可以通过类似操作系统 swap 的方式，提供比物理机内存更大的存储空间，但由于其有更多数据库相关信息，可以将换入换出的粒度做的更细、性能做的更好。</p>
<p>基于<strong>非易失性存储器</strong>（non-volatile memory，NVM） 的存储引擎也是这些年研究的一个热点。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>DDIA</category>
      </categories>
      <tags>
        <tag>DDIA</tag>
        <tag>读书笔记</tag>
        <tag>设计数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>好好写代码之命名篇——推敲</title>
    <url>/2021/12/12/how-to-write-code-scrutinize-names/</url>
    <content><![CDATA[<blockquote>
<p>（贾）岛初赴举京师，一日驴上得句云：“鸟宿池边树，僧敲月下门”。始欲着“推”字，又欲着“敲”字，练之未定，遂于驴上吟哦，时时引手作推敲之势。</p>
<p> —— 宋·胡仔《苕溪渔隐丛话》卷十九引《刘公嘉话》</p>
</blockquote>
<p>命名，是编码中最为紧要的事情，其之于程序，便如脸面之于少女。好的命名，能清晰的传达代码的意图，甚而，有一种韵律的美感。而懒散随意的起名，则令人如堕云雾，不忍卒读，会一遍遍地消耗维护者的精气神儿。此外，混乱的命名体系，能轻巧的掩藏 BUG，贻祸千里。</p>
<p>因此，我们在写代码时，有必要花一点时间，对关键命名进行推敲，与人方便，与己方便。对于生命周期越长的项目，其益处便越明显。那么该如何推敲呢？结合自己写代码、看代码、Review 代码的一些经验，聊聊我的一些体会。</p>
<p>最近写 golang 多一点，因此例子用的都是 golang ，但都是伪代码，有些例子并不不严格遵从语法。此外，例子大多出于现造，因此可能并不是特别贴合。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/12/12/how-to-write-code-scrutinize-names">https://www.qtmuniao.com/2021/12/12/how-to-write-code-scrutinize-names</a> 转载请注明出处</em></p>
<h2 id="诚信"><a href="#诚信" class="headerlink" title="诚信"></a>诚信</h2><p>说到命名，其实有很多原则，我思来想去，觉得最需要强调的一个思想便是——<strong>诚信</strong>（笑）。我们在写代码、改代码时决计不能挂羊头卖狗肉，做有意无意的骗子。换言之，要让命名要真实、完整的体现意图。否则，维护者很容易受命名误导，先入为主，忽略一些细节，甚而，忽略一些 bug。</p>
<p>最常见的有几种情形。</p>
<p>其一，<strong>函数在做 A 的逻辑，却随意起了一个 B 的名字</strong>。这种情况要么是起名太随意了，觉得无关紧要，要么是函数逻辑太复杂，找不到合适的名字，便随意安了一个。前者态度有问题，我们按下不表。后者一般是需要将逻辑进行拆分，拆到名字能清晰体现其逻辑为止。</p>
<p>其二，<strong>函数有副作用，但是名字中没有体现</strong>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Company)</span></span> check(p *Person) &#123;</span><br><span class="line">  <span class="keyword">if</span> p.age &lt; <span class="number">0</span> &#123;</span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">&quot;age can&#x27;t be negative&quot;</span>)</span><br><span class="line">  &#125; </span><br><span class="line"></span><br><span class="line">  c.p = p</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面代码中，既然名字说只是 <code>check</code>，便不能偷偷的 <code>set</code>。如果也想 <code>set</code>，可以改名为 <code>checkAndSet()</code>。</p>
<p>另外一个典型的例子：看起来像纯函数，却偷偷的改变了全局状态；</p>
<p>其三，<strong>对代码进行了改动，名称却没有随之变动</strong>。比如，我们改造一个函数时，塞了一些新逻辑，却维持其名字不变；甚而，我们完全改变了代码逻辑，却没有改动名字；当然最常见的是，代码变了，注释却忘改了。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pseudocode</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Content)</span></span> dumpToFile() <span class="type">error</span> &#123;</span><br><span class="line">  <span class="comment">// origin code</span></span><br><span class="line">  f, _ := os.Open(fiename)</span><br><span class="line">  f.Write()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// added code</span></span><br><span class="line">  db, _ = getDb()</span><br><span class="line">  db.Add()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其四，<strong>用一些约定俗成的名字去指代不同含义</strong>。比如在 golang 中，说到 <code>context</code>，我们一般会想到指官方库中用于控制生命周期的 <code>Context</code>。那么在命名时，就不要随意占用这个名字，如某种情况下，我们需要一个保存任务运行上下文的类，务必加上前缀，比如 <code>JobContext</code> ，这时如果直接用 <code>Context</code> 作为类名，哪怕细读之后能理解其含义，也会让人感觉很别扭。</p>
<h2 id="直白"><a href="#直白" class="headerlink" title="直白"></a>直白</h2><p>当我们实现某个功能时，会反复思考很多细节，这些细节便是我们当时思想的上下文。处在这些上下文之中，我们很容易写出一些当时觉得无比自然，后面看来无比迷惑的代码。因为随着时间流逝，你脑中的上下文会消失。</p>
<p>比如，当判断某个条件时，用了一个很隐晦、间接或者反直觉的判断语句。这种情况，可以换成更直接的信号，或者通过增加一个变量，以变量名字来进行释义。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Project)</span></span> Get(req *GetRequest) (*GetResponse, <span class="type">error</span>)&#123;</span><br><span class="line">  <span class="keyword">if</span> req.names == <span class="literal">nil</span> &#123;</span><br><span class="line">    resp := &amp;GetResponse&#123;&#125;</span><br><span class="line">    resp.Teacher = &amp;Teacher&#123;&#125;</span><br><span class="line">    <span class="keyword">return</span> resp, <span class="literal">nil</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// xxxxx</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面例子本来想表达， 当 <code>req.names</code> 是一个非空数组时，则只对该数组指定学生信息进行返回；如果 <code>req.names == nil</code> 时，则表明为项目组全部学生，需要额外返回老师的信息。但是后面这个信息就完全是隐式的、反直觉的。</p>
<p>可以通过一些手段将其变为显式，比如 <code>bool isAll = req.names == nil</code> 。同理，对于长一些匿名函数，最好也将其赋给一个变量，通过变量名来对函数进行释义。</p>
<p>因此，最好能不断带入他人视角思考，持续消除隐式上下文依赖，才能写出符合直觉、无须过多注释的代码。另外，多找几个不具有这种<strong>实现细节</strong>（但最好明白设计方案）上下文的人来 Review 也是一种很好的消除隐式依赖手段。</p>
<h2 id="简洁"><a href="#简洁" class="headerlink" title="简洁"></a>简洁</h2><p>有的命名简直又臭又长，须知超过三个词的命名并不能使语义更清楚，还会加重理解负担。出现这种情况，一般是没有仔细推敲，利用程序结构来消除信息冗余，举几个例子。</p>
<p>其一，<strong>通过层级信息消除冗余。</strong>比如包名（或者命名空间，看语言而定）、类名。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> student</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewStudent</span><span class="params">()</span></span> (*Student, <span class="type">error</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上述包名中已经表明是 <code>student</code> ，则函数名中可以省去 <code>Student</code> 字样，即改为 <code>func New()(*Student, error)</code> ，使用时 <code>student.New()</code>  便可以清楚地看出 New 的对象类型。</p>
<p>借助数据结构的视角来看，通过树形组织来概念，可以让单个<strong>树节点</strong>的命名变得相对简单，同时利用<strong>树的路径</strong>来表达足够丰富的含义。</p>
<p>其二，<strong>利用参数名来消除冗余</strong>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handleStudent</span><span class="params">(student *Student)</span></span></span><br></pre></td></tr></table></figure>

<p>参数名即函数的处理对象，因此函数名中不需要再次说明：<code>func handle(student *Student)</code> 。</p>
<p>其三，<strong>作用域越小，名字可以越短。</strong>最常见的便是迭代变量、小函数局部变量。因为作用域越小，其冲突的可能性就越小。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// case 1: iteration</span></span><br><span class="line"><span class="keyword">for</span> i, s := <span class="keyword">range</span> students &#123;</span><br><span class="line">  fmt.Println(i, s)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// case 2: small function</span></span><br><span class="line">sort.Slice(students, <span class="function"><span class="keyword">func</span><span class="params">(i, j <span class="type">int</span>)</span></span> <span class="type">bool</span> &#123; <span class="keyword">return</span> students[i].Name &lt; students[j].Name &#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>但简洁是有度的，以不引入二义性为限</strong>。仍以上面 Student 为例：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> student</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> StudentManager student&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">()</span></span> (*StudentManager, <span class="type">error</span>)</span><br></pre></td></tr></table></figure>

<p>此间的 New 函数就有点太短，因为在调用时 <code>student.New()</code> 很容易引起误解，以为返回的是 <code>Student</code> 类型，因此最好改成 <code>student.NewManager()</code> 。</p>
<h2 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h2><p>最后，但也是最重要的，命名是需要成体系的。而只有对所解决的问题有了足够的认识，才能做出足够贴切的抽象，写出足够简明扼要的代码，命出<strong>简短、对称、一致</strong>的名字。仍然借用数据结构来概括下命名系统组织原则：宏观角度看，代码是分层的树形组织；微观角度看，层与层之间是类二分图组织。</p>
<p>下面来从几个侧面举几个例子。</p>
<p>其一，<strong>一致性、相容性</strong>。在自己设计代码时，表现为多个组件间风格的一致性；在修改别人代码时，表现为延续其风格的相容性。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// student.go</span></span><br><span class="line"><span class="function">func <span class="title">get</span><span class="params">(name string)</span> <span class="params">(*Student, error)</span></span></span><br><span class="line"><span class="function">func <span class="title">process</span><span class="params">(student *Student)</span> error</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="comment">// teacher.go</span></span></span><br><span class="line"><span class="function">func <span class="title">fetch</span><span class="params">(name string)</span> <span class="params">(*Teacher, error)</span></span></span><br><span class="line"><span class="function">func <span class="title">handle</span><span class="params">(teacher *Teacher)</span> error</span></span><br></pre></td></tr></table></figure>

<p>上面例子便是一个反面，同样的意思，用了不同名字。更恶劣的是，相似的地方、相似的名字，却指代不同的含义。这会给维护者带来极大的心智负担。</p>
<p>其二，<strong>原子性、正交性</strong>。单个函数尽量短小，函数名才能完整体现代码意思；基础函数尽量正交，才能去除冗余，通过组合来表达强大的生命力。</p>
<p>一个常见的例子，是 WebService 中围绕某种实体的 CRUD，如针对 <code>Student</code> 的 <code>StudentManager</code> 。上层便可以利用这些基本的增删改查完成更细节的业务逻辑。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> StudentManager <span class="keyword">struct</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span><span class="params">(m *StudentManager)</span></span> Create(id, name <span class="type">string</span>, age <span class="type">int</span>)</span><br><span class="line"><span class="function"><span class="keyword">func</span><span class="params">(m *StudentManager)</span></span> Remove(id <span class="type">string</span>)</span><br><span class="line"><span class="function"><span class="keyword">func</span><span class="params">(m *StudentManager)</span></span> Update(s *Student)</span><br><span class="line"><span class="function"><span class="keyword">func</span><span class="params">(m *StudentManager)</span></span> Delete(id <span class="type">string</span>)</span><br></pre></td></tr></table></figure>

<p>其三，<strong>体系性</strong>。使用某种手段，将系统拆解为几个很自然的模块。这种自然，本质上是通过利用你和读者共享的上下文来做到的。</p>
<p>如需要适配多种存储后端时，关于 <code>Storage</code> 的抽象。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Storage <span class="keyword">interface</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">Create</span><span class="params">(uri <span class="type">string</span>)</span></span> (*File, <span class="type">error</span>)</span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">Remove</span><span class="params">(uri <span class="type">string</span>)</span></span> <span class="type">error</span></span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">Open</span><span class="params">(uri <span class="type">string</span>, mode <span class="type">int</span>)</span></span>(io.ReaderWriter, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如需要管理任务生命周期时 ，关于  <code>Task</code> 的抽象。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Task <span class="keyword">interface</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">Start</span><span class="params">()</span></span> <span class="type">error</span></span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">Stop</span><span class="params">()</span></span> <span class="type">error</span></span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">Suspend</span><span class="params">()</span></span> <span class="type">error</span></span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">Resume</span><span class="params">()</span></span> <span class="type">error</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">IsRunning</span><span class="params">()</span></span> <span class="type">bool</span></span><br><span class="line">  <span class="function"><span class="keyword">func</span> <span class="title">IsSuspending</span><span class="params">()</span></span> <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其惯常的做法是，参考数据结构、操作系统、数据库、网络中一些常见的抽象，比如消息队列、文件系统、进程线程、传输协议等等，做适当变化来为我们服务。大多数程序员都共享这些基本概念，因此可以很快速的理清你代码的脉络。</p>
<p>另一种常用的方式，是借鉴日常生活中大家都熟悉的概念，围绕其性状、时空等特性，对系统进行拆解。比如之前呆过的一个公司，利用鹰（Eagle），鹰眼（监控）、鹰爪（爬取）等概念来拆解一个监控系统。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>古人写文章，讲究反复推敲，方能有佳作。代码命名，也需要仔细锤炼，才能不断延长生命周期，免于过快腐烂。如果仅仅追求写代码快，第一反应是什么，就用什么做名字，代码便难逃运行一次就被重构甚至遗弃的命运。</p>
<p>见识所囿，必有诸多遗漏。关于代码命名，大家还有什么心得或吐槽，欢迎留言讨论。</p>
<hr>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程规范</tag>
        <tag>命名</tag>
      </tags>
  </entry>
  <entry>
    <title>DDIA 读书笔记（三）： TP AP 和列存</title>
    <url>/2022/04/16/ddia-reading-chapter3-part2/</url>
    <content><![CDATA[<blockquote>
<p>DDIA 读书分享会，会逐章进行分享，结合我在工业界分布式存储和数据库的一些经验，补充一些细节。每两周左右分享一次，欢迎加入，Schedule 和所有文字稿在<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">这里<i class="fa fa-external-link-alt"></i></span>。我们有个对应的分布式&amp;数据库讨论群，每次分享前会在群里通知。如想加入，可以加我的微信号：qtmuniao，简单自我介绍下，并注明：分布式系统群。</p>
</blockquote>
<h1 id="事务型还是分析型"><a href="#事务型还是分析型" class="headerlink" title="事务型还是分析型"></a>事务型还是分析型</h1><p>术语 <strong>OL</strong>（Online）主要是指交互式的查询。</p>
<p>术语<strong>事务</strong>（ transaction ）由来有一些历史原因。早期的数据库使用方多为商业交易（commercial ），比如买卖、发工资等等。但是随着数据库应用不断扩大，交易\事务作为名词保留了下来。</p>
<blockquote>
<p>事务不一定具有 ACID 特性，事务型处理多是随机的以较低的延迟进行读写，与之相反，分析型处理多为定期的批处理，延迟较高。</p>
</blockquote>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/04/16/ddia-reading-chapter3-part2">https://www.qtmuniao.com/2022/04/16/ddia-reading-chapter3-part2</a> 转载请注明出处</em></p>
<p>下表是一个对比：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>OLTP</th>
<th>OLAP</th>
</tr>
</thead>
<tbody><tr>
<td>主要读取模式</td>
<td>小数据量的随机读，通过 key 查询</td>
<td>大数据量的聚合（max,min,sum, avg）查询</td>
</tr>
<tr>
<td>主要写入模式</td>
<td>随机访问，低延迟写入</td>
<td>批量导入（ETL）或者流式写入</td>
</tr>
<tr>
<td>主要应用场景</td>
<td>通过 web 方式使用的最终用户</td>
<td>互联网分析，为了辅助决策</td>
</tr>
<tr>
<td>如何看待数据</td>
<td>当前时间点的最新状态</td>
<td>随着时间推移的</td>
</tr>
<tr>
<td>数据尺寸</td>
<td>通常 GB 到 TB</td>
<td>通常 TB 到 PB</td>
</tr>
</tbody></table>
<p>一开始对于 AP 场景，仍然使用的传统数据库。在模型层面来说，SQL 足够灵活，能够基本满足 AP 查询需求。但在实现层面，传统数据库在 AP 负载中的表现（大数据量吞吐较低）不尽如人意，因此大家开始转向在专门设计的数据库中进行 AP 查询，我们称之为<strong>数据仓库</strong>（Data Warehouse）。</p>
<h2 id="数据仓库"><a href="#数据仓库" class="headerlink" title="数据仓库"></a>数据仓库</h2><p>对于一个企业来说，一般都会有很多偏交易型的系统，如用户网站、收银系统、仓库管理、供应链管理、员工管理等等。通常要求<strong>高可用</strong>与<strong>低延迟</strong>，因此直接在原库进行业务分析，会极大影响正常负载。因此需要一种手段将数据从原库导入到专门的<strong>数仓</strong>。</p>
<p>我们称之为 <strong>ETL：extract-transform-load</strong>。</p>
<p><img src="https://s2.loli.net/2022/04/16/HAq8ekcmz65xGlO.png" alt="ddia-3-8-etl.png"></p>
<p>一般企业的数据量达到一定的量级才会需要进行 AP 分析，毕竟在小数据量尺度下，用 Excel 进行聚合查询都够了。当然，现在一个趋势是，随着移动互联网、物联网的普及，接入终端的类型和数量越来越多，产生的数据增量也越来越大，哪怕初创不久的公司可能也会积存大量数据，进而也需要 AP 支持。</p>
<p>AP 场景下的<strong>聚合查询</strong>分析和传统 TP 型有所不同。因此，需要构建索引的方式也多有不同。</p>
<h3 id="同样接口后的不同"><a href="#同样接口后的不同" class="headerlink" title="同样接口后的不同"></a>同样接口后的不同</h3><p>TP 和 AP 都可以使用 SQL 模型进行查询分析。但是由于其负载类型完全不同，在查询引擎实现和存储格式优化时，做出的设计决策也就大相径庭。因此，在同一套 SQL 接口的表面下，两者对应的数据库实现结构差别很大。</p>
<p>虽然有的数据库系统号称两者都支持，比如之前的 Microsoft SQL Server 和 SAP HANA，但是也正日益发展成两种独立的查询引擎。近年来提的较多的 HTAP 系统也是类似，其为了 serve 不同类型负载底层其实有两套不同的存储，只不过系统内部会自动的做数据的冗余和重新组织，对用户透明。</p>
<h2 id="AP-建模：星状型和雪花型"><a href="#AP-建模：星状型和雪花型" class="headerlink" title="AP 建模：星状型和雪花型"></a>AP 建模：星状型和雪花型</h2><p>AP 中的处理模型相对较少，比较常用的有<strong>星状模型</strong>，也称为<strong>维度模型</strong>。</p>
<p><img src="https://s2.loli.net/2022/04/16/VbBLmqt9grZYiPl.png" alt="ddia3-9-star-schema.png"></p>
<p>如上图所示，星状模型通常包含一张<strong>事件表（<em>fact table</em>）</strong>和多张<strong>维度表（<em>dimension tables</em></strong><strong>）</strong>。事件表以事件流的方式将数据组织起来，然后通过外键指向不同的维度。</p>
<p>星状模型的一个变种是雪花模型，可以类比雪花（❄️）图案，其特点是在维度表中会进一步进行二次细分，讲一个维度分解为几个子维度。比如品牌和产品类别可能有单独的表格。星状模型更简单，雪花模型更精细，具体应用中会做不同取舍。</p>
<p>在典型的数仓中，事件表可能会非常宽，即有很多的列：一百到数百列。</p>
<h1 id="列存"><a href="#列存" class="headerlink" title="列存"></a>列存</h1><p>前一小节提到的<strong>分维度表</strong>和<strong>事实表</strong>，对于后者来说，有可能达到数十亿行和数 PB 大。虽然事实表可能通常有几十上百列，但是单次查询通常只关注其中几个维度（列）。</p>
<p>如查询<strong>人们是否更倾向于在一周的某一天购买新鲜水果或糖果</strong>：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  dim_date.weekday,</span><br><span class="line">  dim_product.category,</span><br><span class="line">  <span class="built_in">SUM</span>(fact_sales.quantity) <span class="keyword">AS</span> quantity_sold</span><br><span class="line"><span class="keyword">FROM</span> fact_sales</span><br><span class="line">  <span class="keyword">JOIN</span> dim_date <span class="keyword">ON</span> fact_sales.date_key <span class="operator">=</span> dim_date.date_key</span><br><span class="line">  <span class="keyword">JOIN</span> dim_product <span class="keyword">ON</span> fact_sales.product_sk <span class="operator">=</span> dim_product.product_sk</span><br><span class="line"><span class="keyword">WHERE</span></span><br><span class="line">  dim_date.year <span class="operator">=</span> <span class="number">2013</span> <span class="keyword">AND</span></span><br><span class="line">  dim_product.category <span class="keyword">IN</span> (<span class="string">&#x27;Fresh fruit&#x27;</span>, <span class="string">&#x27;Candy&#x27;</span>)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">  dim_date.weekday, dim_product.category;</span><br></pre></td></tr></table></figure>

<p>由于传统数据库通常是按行存储的，这意味着对于属性（列）很多的表，哪怕只查询一个属性，也必须从磁盘上取出很多属性，无疑浪费了 IO 带宽、增大了读放大。</p>
<p>于是一个很自然的想法呼之欲出：每一个列分开存储好不好？</p>
<p><img src="https://s2.loli.net/2022/04/16/P7OJ9fHMVXvW8uD.png" alt="ddia-3-10-store-by-column.png"></p>
<p>不同列之间同一个行的字段可以通过下标来对应。当然也可以内嵌主键来对应，但那样存储成本就太高了。</p>
<h2 id="列压缩"><a href="#列压缩" class="headerlink" title="列压缩"></a>列压缩</h2><p>将所有数据分列存储在一块，带来了一个意外的好处，由于同一属性的数据相似度高，因此更易压缩。</p>
<p>如果每一列中值阈相比行数要小的多，可以用<strong>位图编码（ <em><span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQml0bWFwX2luZGV4">bitmap encoding<i class="fa fa-external-link-alt"></i></span></em> ）</strong>。举个例子，零售商可能有数十亿的销售交易，但只有 100,000 个不同的产品。</p>
<p><img src="https://s2.loli.net/2022/04/16/WaqlOFXnHUI9RGw.png" alt="ddia-3-11-compress.png"></p>
<p>上图中，是一个列分片中的数据，可以看出只有 {29, 30, 31, 68, 69, 74} 六个离散值。针对每个值出现的位置，我们使用一个 bit array 来表示：</p>
<ol>
<li>bit map 下标对应列的下标</li>
<li>值为 0 则表示该下标没有出现该值</li>
<li>值为 1 则表示该下标出现了该值</li>
</ol>
<p>如果 bit array 是稀疏的，即大量的都是 0，只要少量的 1。其实还可以使用 <strong><span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3poLyVFNiVCOCVCOCVFNyVBOCU4QiVFNyVCQyU5NiVFNyVBMCU4MQ==">游程编码<i class="fa fa-external-link-alt"></i></span>（RLE， Run-length encoding）</strong> 进一步压缩：</p>
<ol>
<li>将连续的 0 和 1，改写成 <code>数量+值</code>，比如 <code>product_sk = 29</code> 是 <code>9 个 0，1 个 1，8 个 0</code>。</li>
<li>使用一个小技巧，将信息进一步压缩。比如将同值项合并后，肯定是 0 1 交错出现，固定第一个值为 0，则交错出现的 0 和 1 的值也不用写了。则 <code>product_sk = 29</code>  编码变成 <code>9，1，8</code></li>
<li>由于我们知道 bit array 长度，则最后一个数字也可以省掉，因为它可以通过 <code>array len - sum(other lens)</code> 得到，则 <code>product_sk = 29</code>  的编码最后变成：<code>9，1</code></li>
</ol>
<p>位图索引很适合应对查询中的逻辑运算条件，比如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WHERE</span> product_sk <span class="keyword">IN</span>（<span class="number">30</span>，<span class="number">68</span>，<span class="number">69</span>）</span><br></pre></td></tr></table></figure>

<p>可以转换为 <code>product_sk = 30</code>、<code>product_sk = 68</code>和 <code>product_sk = 69</code>这三个 bit array 按位或（OR）。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">WHERE</span> product_sk <span class="operator">=</span> <span class="number">31</span> <span class="keyword">AND</span> store_sk <span class="operator">=</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>可以转换为 <code>product_sk = 31</code>和 <code>store_sk = 3</code>的 bit array 的按位与，就可以得到所有需要的位置。</p>
<h3 id="列族"><a href="#列族" class="headerlink" title="列族"></a>列族</h3><p>书中特别提到<strong>列族（column families）</strong>。它是 Cassandra 和 HBase 中的的概念，他们都起源于自谷歌的 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQmlndGFibGU=">BigTable<i class="fa fa-external-link-alt"></i></span> 。注意到他们和<strong>列式（column-oriented）存储</strong>有相似之处，但绝不完全相同：</p>
<ol>
<li>同一个列族中多个列是一块存储的，并且内嵌行键（row key）。</li>
<li>并且列不压缩（存疑？）</li>
</ol>
<p>因此 BigTable 在用的时候主要还是面向行的，可以理解为每一个列族都是一个子表。</p>
<h3 id="内存带宽和向量化处理"><a href="#内存带宽和向量化处理" class="headerlink" title="内存带宽和向量化处理"></a>内存带宽和向量化处理</h3><p>数仓的超大规模数据量带来了以下瓶颈：</p>
<ol>
<li>内存处理带宽</li>
<li>CPU 分支预测错误和<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kvJUU2JUI1JTgxJUU2JUIwJUI0JUU3JUJBJUJGJUU1JTgxJTlDJUU5JUExJUJG">流水线停顿<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<p>关于内存的瓶颈可已通过前述的数据压缩来缓解。对于 CPU 的瓶颈可以使用：</p>
<ol>
<li>列式存储和压缩可以让数据尽可能多地缓存在 L1 中，结合位图存储进行快速处理。</li>
<li>使用 SIMD 用更少的时钟周期处理更多的数据。</li>
</ol>
<h2 id="列式存储的排序"><a href="#列式存储的排序" class="headerlink" title="列式存储的排序"></a>列式存储的排序</h2><p>由于数仓查询多集中于聚合算子（比如 sum，avg，min，max），列式存储中的存储顺序相对不重要。但也免不了需要对某些列利用条件进行筛选，为此我们可以如 LSM-Tree 一样，对所有行按某一列进行排序后存储。</p>
<blockquote>
<p>注意，不可能同时对多列进行排序。因为我们需要维护多列间的下标间的对应关系，才可能按行取数据。</p>
</blockquote>
<p>同时，排序后的那一列，压缩效果会更好。</p>
<h3 id="不同副本，不同排序"><a href="#不同副本，不同排序" class="headerlink" title="不同副本，不同排序"></a>不同副本，不同排序</h3><p>在分布式数据库（数仓这么大，通常是分布式的）中，同一份数据我们会存储多份。对于每一份数据，我们可以按不同列有序存储。这样，针对不同的查询需求，便可以路由到不同的副本上做处理。当然，这样也最多只能建立副本数（通常是 3 个左右）列索引。</p>
<p>这一想法由 C-Store 引入，并且为商业数据仓库 Vertica 采用。</p>
<h2 id="列式存储的写入"><a href="#列式存储的写入" class="headerlink" title="列式存储的写入"></a>列式存储的写入</h2><p>上述针对数仓的优化（列式存储、数据压缩和按列排序）都是为了解决数仓中常见的读写负载，读多写少，且读取都是超大规模的数据。</p>
<blockquote>
<p>我们针对读做了优化，就让写入变得相对困难。</p>
</blockquote>
<p>比如 B 树的<strong>原地更新流</strong>是不太行的。举个例子，要在中间某行插入一个数据，<strong>纵向</strong>来说，会影响所有的列文件（如果不做 segment 的话）；为了保证多列间按下标对应，<strong>横向</strong>来说，又得更新该行不同列的所有列文件。</p>
<p>所幸我们有 LSM-Tree 的追加流。</p>
<ol>
<li>将新写入的数据在<strong>内存</strong>中 Batch 好，按行按列，选什么数据结构可以看需求。</li>
<li>然后达到一定阈值后，批量刷到<strong>外存</strong>，并与老数据合并。</li>
</ol>
<p>数仓 Vertica 就是这么做的。</p>
<h2 id="聚合：数据立方和物化视图"><a href="#聚合：数据立方和物化视图" class="headerlink" title="聚合：数据立方和物化视图"></a>聚合：数据立方和物化视图</h2><p>不一定所有的数仓都是列式存储，但列式存储的种种好处让其变得流行了起来。</p>
<p>其中一个值得一提的是<strong>物化聚合（materialized aggregates，或者物化汇总）</strong>。</p>
<blockquote>
<p>物化，可以简单理解为持久化。本质上是一种空间换时间的 tradeoff。</p>
</blockquote>
<p>数据仓库查询通常涉及聚合函数，如 SQL 中的 COUNT、SUM、AVG、MIN 或 MAX。如果这些函数被多次用到，每次都即时计算显然存在巨大浪费。因此一个想法就是，能不能将其缓存起来。</p>
<p>其与关系数据库中的<strong>视图</strong>（View）区别在于，视图是<strong>虚拟的、逻辑存在</strong>的，只是对用户提供的一种抽象，是一个查询的中间结果，并没有进行持久化（有没有缓存就不知道了）。</p>
<p>物化视图本质上是对数据的一个摘要存储，如果原数据发生了变动，该视图要被重新生成。因此，如果<strong>写多读少</strong>，则维持物化视图的代价很大。但在数仓中往往反过来，因此物化视图才能较好的起作用。</p>
<p>物化视图一个特化的例子，是<strong>数据立方</strong>（data cube，或者 OLAP cube）：按不同维度对量化数据进行聚合。</p>
<p><img src="https://s2.loli.net/2022/04/16/e2m8uLaoDnMrfSC.png" alt="ddia-3-12-data-cube.png"></p>
<p>上图是一个按<strong>日期和产品分类</strong>两个维度进行加和的数据立方，当针对日期和产品进行汇总查询时，由于该表的存在，就会变得非常快。</p>
<p>当然，现实中，一个表中常常有多个维度，比如 3-9 中有日期、产品、商店、促销和客户五个维度。但构建数据立方的意义和方法都是相似的。</p>
<p>但这种构建出来的视图只能针对固定的查询进行优化，如果有的查询不在此列，则这些优化就不再起作用。</p>
<blockquote>
<p>在实际中，需要针对性的识别（或者预估）每个场景查询分布，针对性的构建物化视图。</p>
</blockquote>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>DDIA</category>
      </categories>
      <tags>
        <tag>DDIA</tag>
        <tag>读书笔记</tag>
        <tag>设计数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>查理芒格推荐——《影响力》读书笔记+精要分析</title>
    <url>/2021/10/18/influence-notes/</url>
    <content><![CDATA[<blockquote>
<p>西奥迪尼在影响力方面对我的影响，其他任何科学家都比不上…… 这本畅销书呈现了六至八种方法，让你古怪精灵的想法不会再阻碍你获得最佳利益。<br>                 ——查理·芒格，巴菲特黄金搭档</p>
</blockquote>
<p>人类都有一些思维定势或固有模式，一经触发会使我们就像被按下了播放键，之后的行为便可能不受我们控制。其实这些都是源于人类避免思考的趋势。避免思考在人类原始时期确实给人类带来了不少好处，比如它能节省时间，减轻犹豫不决带来的危及生命的后果。但现在，避免思考的本能也恰恰成了最容易被顺从专家们利用的地方。</p>
<p>其实，不管是那种顺从手法，其应对的核心方法都是一个——思考。首先要从情绪中脱离出来，其次要想清楚自己真正想要的是什么，把表象和实质区分开。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2021/10/18/influence-notes">https://www.qtmuniao.com/2021/10/18/influence-notes</a>, 转载请注明出处</em></p>
<h2 id="对比原理"><a href="#对比原理" class="headerlink" title="对比原理"></a>对比原理</h2><p>第二样东西与第一样不同往往会使我们觉得区别比实际上更大。</p>
<p>坏消息要从最坏的说起，推销要从最贵的看起。</p>
<h2 id="互惠原理"><a href="#互惠原理" class="headerlink" title="互惠原理"></a>互惠原理</h2><p>别人给了我们恩惠总是会触发我们的亏欠感，进而引起回报行为，就算这个恩惠是我们不想要的。</p>
<p>类似的套路还有互惠式让步“拒绝-后撤术”。先提出一个让人难以接受的请求，对方拒绝后再提出一个看似是让步实则是自己真正的请求，会触发对方的愧疚感，进而提升对方同意请求的可能性。并且对方反而会因为觉得通过自己的努力促成了你的让步而对这个结果更加认同而不容易事后反悔。</p>
<h2 id="一致性原理"><a href="#一致性原理" class="headerlink" title="一致性原理"></a>一致性原理</h2><p>我们都会一次次欺骗自己，以便在做出决定坚信自己做的没错。</p>
<p>人都有逃避思考的趋势。一些看似不相关的小的请求，一些看似没有恶意的让步，我们一旦同意了，它就有可能影响我们对自己的认知。这个认知一旦变了，或是我们一旦当众选择了一种立场，我们自己就会产生把它维持下去的动力。</p>
<p>费尽周折得到某样东西的人比轻轻松松得到它的人更加珍视这样东西，比如，加入一个团体越困难，人们会觉得这个团体越有价值，或越认同自己的身份。</p>
<p>个人承诺能建立起一套自圆其说的系统，能为最初的承诺找到理由。这是最可怕的，也是最容易被人利用的地方，就算最初的甜头被撤了，仍然能使人坚持已做出的决定，因为这段时间内，人们已经找到足够多的支持这个决定的理由了。破局的办法是，问自己：“知道了你现在掌握的情况，如果时间能够倒流，你还会做出同样的选择吗？”</p>
<h2 id="社会认同"><a href="#社会认同" class="headerlink" title="社会认同"></a>社会认同</h2><p>95%的人都喜欢跟着别人行事，特别是跟自己相似的人。这个特点可以用在好的地方，比如自闭症治疗，但它真正可怕之处是用在坏事上。</p>
<p>我们在自己不确定、情况不明、意外性大的时候最有可能觉得别人的行为是正确的。多元无知现象，越是人多的时候大家越不容易出手相助。一个是因为所有人都觉得其他人可以帮忙，责任被分散了，就没人愿意负起责任了，一个是在情况不明的时候，所有人都喜欢显出镇定自若的样子，暗中瞟着周围人，不动声色的寻找证据，每个人都得出判断，既然没人在乎，那就应该没什么问题。所以遇到紧急情况时最佳解决办法是从人群中挑出一个负责人来，盯着他，跟他说清楚发生了什么、你需要什么帮助。另外也可以看出，一件事情多个负责任的后果就是谁也不愿意负责。</p>
<p>另一个模仿带来的可怕现象是“维特效应”。在自杀新闻曝光率高的地区，自杀率、事故率会激增，会使得他们觉得自杀的念头更站得住脚了。据统计，自杀新闻报道后的3～4天航班失事、车祸致死的人数升至最高，一个星期之后又会出现一波高峰，在第11天左右时维特效应消失，所以在这些天出行要特别当心。</p>
<p>没有哪个领导人能单枪匹马说服所有人，但一个强有力的领导人可以说服群体中相当大比例的人，光是这些人被说服了的信息本身就能另剩下的人信服。</p>
<h2 id="喜好"><a href="#喜好" class="headerlink" title="喜好"></a>喜好</h2><p>我们更容易顺从我们喜欢的人提出的要求。</p>
<p><strong>外表魅力</strong></p>
<p>长得好看的人有极大的社会优势，他们更有说服力，更频繁的得到帮助。</p>
<p><strong>相似性</strong></p>
<p>我们喜欢与自己相似的人。但这很容易被人利用，人们可能会假装和你有相同的背景或兴趣来达到某些目的。</p>
<p><strong>恭维</strong></p>
<p>光是“喜欢我们”这点就可能足以使我们还以好感、答应要求。</p>
<p><strong>接触与合作</strong></p>
<p>我们会更喜欢熟悉的事物，但前提是我们本身不讨厌它。在不愉快的条件下（挫折、竞争、冲突）持续接触某人或物，反而会使我们减少好感。改善的办法是人为创造合作的环境。</p>
<p>合作也可以被利用，比如销售看似站在你的角度上和老板据理力争，比如审讯时的“好警察和坏警察”，再运用上对比原理和互惠原理，都会让嫌犯倾向于对“好警察”招供。</p>
<p><strong>条件反射和关联</strong></p>
<p>人们普遍不喜欢带来坏消息的人，因为我们把我们的感受和这个人联系到了一起。类似的，商家也喜欢把商品和我们喜欢的事物联系起来以促进商品的销售。还有食物，人们普遍对就餐期间接触到的人或事更为喜爱。</p>
<p>另一个十分普遍的现象是，人们总是会千方百计的跟成功者扯上联系，并尽量避免和失败者之间的关系，并且越是个人价值感或威望低的人越容易真么做。他们没办法通过自身来追求荣誉，只能靠吹嘘自己与成功者的关系来挽回尊严。相反，以个人成就为傲的人便不太倾向于沾别人的光，也不太会因为别人的成败产生大的情绪波动。</p>
<p>对付喜好对我们产生的影响的方法也很简单，就是脱离。对短时间产生的较强烈的情绪（不管是喜欢还是厌恶）产生警惕，尽快从情绪中脱离出来，并把注意力集中到那件本质的事物上，而不是有人迫使我们关联起来的形象上。</p>
<h2 id="权威"><a href="#权威" class="headerlink" title="权威"></a>权威</h2><p>服从权威有好的一面，听从权威的建议，有时能帮我们做出正确的决定，还能省去思考的时间。但，便捷也必然伴随着被利用的可能。</p>
<p><strong>头衔</strong></p>
<p>头衔比当事人的本质更能影响他人的行为。头衔除了能让陌生人表现的更恭顺，还能让有头衔的那个人显得更高大。有趣的是，由于基因上的本能，这个高大就是体格上的高大。对，人们本能的认为体格和地位之间存在着联系。</p>
<p><strong>衣着</strong></p>
<p>人们普遍认为制服或西装与权威是挂钩的。比如更愿意顺从穿制服人的要求，比如穿西装的人闯红灯都能带动更多的人一起闯。</p>
<p><strong>身份标志</strong></p>
<p>比如名牌名表名车之类，能得到他人特殊尊重。比如，碰到豪车堵住路口，人们按喇叭的概率都低了很多。</p>
<p>其实，顺从策略针对的都是人们避免思考的倾向，解决的思路其实也都是同一个，就是让自己多思考一下。比如面对“权威”，我们可以问自己：“这是真正的专家吗？这个专家说的是真话吗？”</p>
<h2 id="稀缺"><a href="#稀缺" class="headerlink" title="稀缺"></a>稀缺</h2><p><strong>物以稀为贵</strong></p>
<p>失去某种东西的恐惧比获得某种东西的渴望更能激发人们的行动力。有些商家会利用这个特点设定“数量有限”或“最后期限”战术。</p>
<p><strong>逆反心理</strong></p>
<p>遭到禁止的信息不仅使我们更想得到它，而且会使我们给出对它有利的评价。这就可能带来另一种情况，如果有个人在某个问题上持有不受欢迎的立场，对他们最有利的做法其实不是公开宣传这些立场，而是让自己的信息遭到禁止，再公开这一点，这样反而可能会博取人们的赞同。</p>
<p>另外，对于一条信息，根据稀缺原理，如果我们觉得没法从别处获取它，我们就会认为它更具说服力。</p>
<p><strong>最佳条件</strong></p>
<p>较之一贯短缺，从充裕变成短缺，更能激发人们的行动。比如，最容易起义的并不是最受压迫的底层人，而是尝过美好生活之后又被夺走的人，比如经过了一段安定的发展之后又突然出现了一段倒退之后。再比如，管教前后不一致的父母最容易教出逆反心强的子女，因为他们尝到了自由的滋味，突然又夺走必定会引起他们的反抗。</p>
<p>在有竞争者时会增加我们对一样事物的想要程度。比如面对举棋不定的顾客，一个捏造的新买家就能促成这桩交易，比如特卖会或拍卖会，只要氛围使得人们变得焦躁不安，就会阻碍人们的思考能力，使之忘了自己想要的是什么，只是盲目的跟其他人争夺。</p>
<p>如何避免呢？一个是识别情绪高涨的信号，一旦意识到自己情绪高涨要及时让自己平静下来。另一个是，问自己到底想获得什么？一件稀缺物品，如果我们在乎它的附加价值，比如社会上的、心理上的，那大可以去占有它。但如果我们只是在乎它的实用价值，那就要记住，一件物品并不因为它的稀缺而变得更好吃、更好看、更好用了。</p>
<hr>
]]></content>
      <categories>
        <category>生活</category>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>影响力</tag>
      </tags>
  </entry>
  <entry>
    <title>层层剥开数据库存储层</title>
    <url>/2022/05/04/distributed-database-storage-components/</url>
    <content><![CDATA[<blockquote>
<p>做数据库有一段时间了。最近有一些在校的同学问到，在实际中，分布式数据库中存储层工作内容是什么样的？简单回答了下，想到其他人可能也有类似问题，于是来这里总结下、抛个砖头。经验所限，难免有误，欢迎交流。</p>
</blockquote>
<p><strong>注</strong>：限定下讨论范围，分布式数据库，存储计算分离，share-noting 架构，仅讨论存储层。</p>
<p>存储层涉及的东西很庞杂，想说清楚，需要有一个合适的切入角度。数据库最本质的功能，是存储数据，以对外提供数据的<strong>查询</strong>和<strong>写入</strong>接口。不妨，就首先以这两条线串一下各个模块，然后再补充下不能归到这两条线中的一些组件。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/05/04/distributed-database-storage-components">https://www.qtmuniao.com/2022/05/04/distributed-database-storage-components</a> 转载请注明出处</em></p>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>查询请求进到存储层，一般表现为下推的<strong>执行计划</strong>，进而转化为对底层存储引擎的单点查询和范围查询，为了加速查询，一般会给存储引擎配备<strong>缓存</strong>层。对于每个存储节点来说，为了应对大量的并发请求，需要做 <strong>IO 优化</strong>。</p>
<h3 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a><strong>执行计划</strong></h3><p>这是存储层的入口，是存储层向查询层暴露的接口。</p>
<p>一个查询语句经过<strong>查询层</strong>的语法分析（Parser）、语义检查（Validator）、生成计划（Planner）、计划优化（Optimizer）、执行计划（Executor）几个步骤之后，会将需要下推给存储层的算子下发到存储层对应的分片（ Partition）所在节点。</p>
<p>对于火山模型来说，我们可以将执行计划理解为一个由基本算子（Executor）组成的 DAG，甚至再简化一些可以想象成一棵树。树中下层的一些小子树，是可以直接推到存储层对应的节点去执行的，这些可以下推的算子通常包括：TableScan，Filter，Project，Limit，TopN 等等。</p>
<p>存储层拿到这些执行计划后，反序列化，组织成内存中的执行计划，以<span class="exturl" data-url="aHR0cHM6Ly9wYXBlcmh1Yi5zMy5hbWF6b25hd3MuY29tL2RhY2U1MmE0MmMwN2Y3ZjgzNDhiMDhkYzJiMTg2MDYxLnBkZg==">迭代模型<i class="fa fa-external-link-alt"></i></span>或者向量模型，来对数据进行扫描、过滤、排序、投影、聚合等操作后，将结果集返回给查询层。</p>
<p>结果集可以有几种返回方式：</p>
<ol>
<li>一次全量返回</li>
<li>流式返回</li>
<li>分页返回</li>
</ol>
<p>计算下推有诸多好处：</p>
<ol>
<li>充分利用存储层的分布式节点进行预计算。</li>
<li>减少存储层到查询层的数据传输带宽消耗。</li>
<li>提高查询层的处理速度和数据集上限。</li>
</ol>
<h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>为了对查询进行优化，对于读多写少的场景，一般会在存储引擎之上罩一个缓存层。如果是共享存储层的架构，比如存储层在云上，那么缓存层就必不可少。</p>
<p>缓存在设计时，主要需要考虑<strong>缓存粒度</strong>和<strong>生命周期</strong>两方面。</p>
<ol>
<li><strong>缓存粒度</strong>。为了保持缓存和后端的数据一致性，势必需要加锁，而缓存粒度和加锁粒度息息相关。一个节点上的不同 Partition 的缓存要不要共享一个缓存池，也是缓存粒度需要考虑的问题。</li>
<li><strong>生命周期</strong>。何时写入后端，何时让缓存失效，这涉及到缓存控制策略，是同步读写穿透，还是异步更新，都是需要根据实际情况考量的问题。</li>
</ol>
<h3 id="RPC-IO-优化"><a href="#RPC-IO-优化" class="headerlink" title="RPC IO 优化"></a>RPC IO 优化</h3><p>任何服务都是类似的，大量请求过来时，得用线程池、异步、协程等各种手段优化，提高并发，从而提高吞吐，减小延迟。</p>
<p>有的 RPC 框架能解决这些问题，比如有些 RPC 框架内置协程模型，支持 M 比 N 模型、协程窃取等等。如果 RPC 框架不管，就需要用额外的线程池库、异步库（promise、future）、协程库来手动控制请求的执行流并发执行。</p>
<h2 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h2><p>分布式系统中，一般会使用多副本来存储数据。在写入时，为了维持所有副本看到一致的写入顺序，会引入<strong>共识算法</strong>。共识算法通常都是维持一个逻辑上 endless 的逻辑操作日志，然后每个副本将逻辑日志应用到自己本地的状态机——<strong>存储引擎</strong>。在写入数据是，需要对用户数据进行<strong>数据编码</strong>，转化为二进制串，从而写入存储引擎。对于一些一致性（区别于多副本间的一致，此处是多语句间并发执行的一致）要求严苛的场景，数据库需要对用户提供多个语句原子化执行的保证，即<strong>分布式事务</strong>。</p>
<h3 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h3><p>对于 share-nothing 架构，为了保证高可用，都会使用多副本（Replication），并放到容错阈不同的多台机器上。使用多副本，就自然会引入多副本数据一致性的问题，一般我们会使用共识算法（Raft、MultiPaxos）来解决。</p>
<p>使用共识算法，对于每个数据分片（Partition），可以维护一个多机一致的操作日志（operation log，WAL）：即所有写入操作，都会序列化成操作日志记录，并在所有的副本按唯一的顺序进行追加写。有了一致的操作日志，我们再将其各种应用到本地的状态机（也就是存储引擎），辅以 log id，就可以对外提供一致的读写视图。</p>
<h3 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h3><p>这里指的是单机存储引擎，也就是上文所说的状态机。它解决的问题是，如何将数据组织在单机的存储体系中，以最少的空间，应对特定场景的高效的写入和读取。一般分为数据编码、索引组织、并发控制等等几个子模块。</p>
<p>存储引擎主要分为两个流派：原地更新的 B-Tree 流派和基于追加的 LSM-Tree 流派。这里推荐两个个学习的项目，B-Tree 的可以看看 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JvbHRkYi9ib2x0">BoltDB<i class="fa fa-external-link-alt"></i></span>；LSM-Tree 可以看看 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS9sZXZlbGRi">LevelDB<i class="fa fa-external-link-alt"></i></span>。但实际使用中会用更复杂强大一点的变种，比如 RocksDB。</p>
<p>对于 AP 场景来说，一般使用列式存储，可以更方便的进行数据压缩和进行向量化计算。</p>
<h3 id="数据编码"><a href="#数据编码" class="headerlink" title="数据编码"></a>数据编码</h3><p>数据编解码解决的问题是，如何将逻辑上的一个记录（如关系型数据库中的 Row），高效（耗时少、占空间少）的编码为二进制串，写入存储引擎。</p>
<p>在编码时，需要考虑和 Schema （该行有哪些字段，字段的类型是什么）的对应关系，也要考虑在 Schema 变化时（加字段，删字段，改字段类型），如何保证数据读取的兼容性。</p>
<h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><p>数据库的一大重要功能就是对事务的保证，利用事务模型的诸多保证（ACID），可以大大减小用户侧使用数据库的复杂度。当然，这通常是以损失性能为代价的，在分布式数据库中这点尤为明显。</p>
<p>如何保证分布式事务间的原子性和隔离性，业界有诸多方案。最基本的框架是<strong>两阶段提交</strong>配合<strong>全局时钟</strong>（有物理时钟、逻辑时钟、混合时钟和 TSO 等多种解决方案，又是一个比较大的话题），比较经典的是有谷歌的 Percolator 模型。</p>
<h2 id="其他模块"><a href="#其他模块" class="headerlink" title="其他模块"></a>其他模块</h2><p>除了能直接归到读写流程相关的组件，还有一些其他存储层交互比较频繁的模块和一些后台运行的常驻进程。</p>
<h3 id="Schema-管理"><a href="#Schema-管理" class="headerlink" title="Schema 管理"></a>Schema 管理</h3><p>如何划分命名空间，组织不同的 Schema，就涉及到 Schema 的逻辑管理，如使用树形组织。</p>
<p>另外，还需要维护 Schema 和数据的对应关系，但在分布式系统中，如何非阻塞的修改 Schema， 而不影响并发的数据写入，是一个非常费劲的事情。常见的解决方案有谷歌 F1 的 online DDL。</p>
<h3 id="集群元信息"><a href="#集群元信息" class="headerlink" title="集群元信息"></a>集群元信息</h3><p>集群元信息主要分两大块：</p>
<ol>
<li><strong>逻辑上</strong>。逻辑上的数据集组织与划分，比如 Database、Table。即以合适的粒度，对数据集按命名空间进行划分，进而针对不同的数据集进行不同的配置以及相应的多租户隔离和权限控制。</li>
<li><strong>物理上</strong>。物理上的节点的组织与划分，比如 Zone，Node。即以合适的容错阈，对不同节点进行物理组织，进而在不同节点和容错阈间处理宕机、均衡数据。</li>
</ol>
<p>管理逻辑数据到物理节点的映射，即是分布式系统中最重要的一个方面：<strong>调度</strong>。</p>
<p>调度通常发生在两个大时刻，一是数据集创建时，一时副本再均衡时（rebalancing，包括机器宕机、新增节点引起的数据再均衡）。</p>
<p>我们会依据节点的不同属性（容错阈、剩余容量）等对数据集的不同分片进行调度。在进行数据移动时，会涉及分片的多个副本的增删，为了保证一致性，也需要通过共识协议来完成。</p>
<h3 id="数据导入导出"><a href="#数据导入导出" class="headerlink" title="数据导入导出"></a>数据导入导出</h3><p>数据库最重要的周边工具就是支持数据以丰富的格式、较高的速度进行导入和导出。</p>
<p>这又可以细分为几类：</p>
<ol>
<li><strong>数据备份与恢复</strong>。即数据生产者和消费者都是本数据库，此时不用考虑支持不同的的数据格式（即可以自定义编码，只需要自己认识即可，因此可以怎么高效怎么来），而是要考虑支持不同的数据后端：本地、云上、共享文件系统中等等。同时，也要考虑同时支持全量备份和增量备份。</li>
<li><strong>其他系统导入</strong>。需要考虑支持多种数据源以及不同数据格式，最好能使用一些计算框架（如 Spark、Flink、Kafka）分布式的导入；也最好能够支持主流的数据库接入，比如 MySQL、Postgres 等等。</li>
<li><strong>数据导出</strong>。将数据导出为多种通用的数据格式，如 csv、json、sql 语句 等等。</li>
</ol>
<p>仓促成文，遗漏之处，欢迎在评论区补充。如果觉得写的还不错，欢迎分享给更多的同学。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>storage</tag>
        <tag>存储层</tag>
        <tag>数据库</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title>Meta 链式复制的对象存储——Delta</title>
    <url>/2022/05/06/meta-object-store-delta/</url>
    <content><![CDATA[<p><strong>来源</strong>：<span class="exturl" data-url="aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vMjAyMi8wNS8wNC9kYXRhLWluZnJhc3RydWN0dXJlL2RlbHRhLw==">https://engineering.fb.com/2022/05/04/data-infrastructure/delta/<i class="fa fa-external-link-alt"></i></span></p>
<p><strong>导读</strong>：偶然看到群里同学分享的 <span class="exturl" data-url="aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20v">Meta 博客<i class="fa fa-external-link-alt"></i></span>新公开的高可用、强一致、链式复制的对象存储。由于我也做过一段时间的对象存储，也分享过 Facebook 家的小文件存储：<a href="https://www.qtmuniao.com/2019/03/24/haystack/">Haystack</a>（做 batch） 和 <a href="https://www.qtmuniao.com/2019/03/30/f4/">F4</a>（冷热分开、EC）， 顿时来了兴致，好奇这次 Meta 又带来了什么干货。</p>
<p>看完之后觉得的确有点意思，下面简单梳理下文章要点，感兴趣的同学可以去看看博客原文，还有华人小姐姐解说的相关视频哦。</p>
<h3 id="Delta-是什么？"><a href="#Delta-是什么？" class="headerlink" title="Delta 是什么？"></a>Delta 是什么？</h3><p>Delta 是简单、可靠、可扩展、低依赖的对象存储，只提供四个基本操作：put、get、delete 和 list。在架构设计上，Delta 牺牲了<strong>读写延迟</strong>和<strong>存储效率</strong>，来换取架构的<strong>简单性</strong>和<strong>可靠性</strong>。</p>
<p>Delta 不是：</p>
<ol>
<li><strong>通用存储系统</strong>。Delta 只追求弹性、可靠和最小依赖。</li>
<li><strong>文件系统</strong>。Delta 只是简单的对象存储，不提供 POSIX 语义。</li>
<li><strong>为存储效率而优化的系统</strong>。Delta 并没有针对存储效率、延迟和吞吐做优化，而是专注简单和弹性。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/05/06/meta-object-store-delta">https://www.qtmuniao.com/2022/05/06/meta-object-store-delta</a> 转载请注明出处</em></p>
<p>总结来说，定位是一个基座式存储服务，就是性能可以不高，但要简单、弹性、可靠。其定位坐标如下图：</p>
<p><img src="https://s2.loli.net/2022/05/06/uJ24hBZPmwjTCnX.png" alt="storage-system-cordinate-system.png"></p>
<h3 id="Delta-的架构有何特点？"><a href="#Delta-的架构有何特点？" class="headerlink" title="Delta 的架构有何特点？"></a>Delta 的架构有何特点？</h3><ol>
<li><strong>链式复制</strong></li>
</ol>
<p>对于一个逻辑上的 Bucket（对象存储的命名空间）中的数据，首先使用<strong>一致性哈希</strong>进行分片（Partition），对于每个分片，使用<strong>链式复制</strong>（Chain Replication）进行冗余。通常每个分片有四个副本，每个副本放在不同的容错阈。</p>
<p><img src="https://s2.loli.net/2022/05/06/S52YhnFxIDR1EmK.png" alt="chain-with-4-nodes.png"></p>
<p>读写流程：所有的写入都在链表头，依照链表顺序复制后，等到链表尾复制完成后返回成功（<strong>同步复制</strong>）；所有的读取都被路由到链表尾，以保证<strong>强一致</strong>。</p>
<p>可以看出，由于是同步写，Delta 的写入延迟比较高；由于是只读尾节点，读吞吐也不高。</p>
<p>当然，Delta 对读取稍稍做了个优化——分摊查询，即允许客户端读任何一个副本，但该副本必须要和尾节点通信确定数据可靠版本（clean version）后才能返回数据给客户端，以保证一致性。</p>
<p><img src="https://s2.loli.net/2022/05/06/HB6wVu34qArG2FS.png" alt="read-all-nodes.png"></p>
<p>其依据是，相比客户端查询，内部版本确认查询要轻量的多。</p>
<ol>
<li><strong>投票剔除和挂尾加回</strong></li>
</ol>
<p>Delta 通过心跳和投票来剔除故障节点：即当同时有一定数量的节点标记某一个节点心跳超时后，就将该节点上所有副本从复制链中剔除。其中有两个阈值需要慎重选择：</p>
<ul>
<li><strong>心跳超时</strong>。过短的话，受网络抖动影响太大，过长的话又会加重相关链的写入延迟。</li>
<li><strong>可疑票数</strong>。设置为 1 显然不行，因为很可能有两个节点间网络不好会互相投票；过多也不行，会导致故障节点在链中停留过长时间。Delta 一般设置为 2，并且配合自动化的机器故障修复。</li>
</ul>
<p>在故障节点修复之后，可以通过一系列操作加回副本链：</p>
<ol>
<li>将其上副本重新追加回原链结尾</li>
<li>读取上游节点（原尾结点）同步数据</li>
<li>同步完成前将读请求都路由给上游节点</li>
<li>同步完成后变成新的正常尾结点</li>
</ol>
<p><img src="https://s2.loli.net/2022/05/06/2NUqRf1ZS7XGvAh.gif" alt="Delta-Visuals_v03-04.gif"></p>
<ol>
<li><strong>自动修复</strong></li>
</ol>
<p>Delta 使用一个控制平面服务（CPS，control plane service）对故障节点进行自动检修。每个 CPS 实例监控一组 Delta Bucket 列表，其主要策略有：</p>
<ul>
<li>在修复桶时，维持其副本的合理<strong>故障阈分布</strong>。</li>
<li>保证所有服务器上的复制链均匀分布，避免局部过载。</li>
<li>在链中副本缺失时，倾向修复而非新建，以最小化数据复制。</li>
<li>在添加新的服务器到链中，会对服务器进行严格的健康检查。</li>
<li>维护一个健康服务器池，在某个链过半副本故障时，才往其中添加一个节点。</li>
</ul>
<p>解释下最后一条：即能修复先修复，只有坏到不能再坏（超过一半）才从池子中拨出一个副本给他，从而保证池子里有充足备用弹药。</p>
<p>文中还提到了全球地理复制和与用归档服务进行冷备。并提到 Delta 下一步是想充当 Meta 中所有需要数据备份和恢复的服务的存储后端。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>storage</tag>
        <tag>Facebook</tag>
        <tag>对象存储</tag>
      </tags>
  </entry>
  <entry>
    <title>解析谷歌兼容 PostgreSQL 的云原生数据库——AlloyDB 的存储层</title>
    <url>/2022/05/15/google-alloydb-storage/</url>
    <content><![CDATA[<p>在<span class="exturl" data-url="aHR0cHM6Ly9pby5nb29nbGUvMjAyMi8=">Google I&#x2F;O 2022<i class="fa fa-external-link-alt"></i></span> 大会上，Google Cloud 发布了兼容 PostgreSQL 标准的云原生数据库 AlloyDB（注：Alloy 意为合金），号称比 Amazon 的同类产品（Aurora？）快两倍，这个口号，对老用户来说，应该不足以让其迁移，但对于新用户来说，确有一些吸引力。</p>
<p>由于笔者主要做存储，下面基于谷歌这篇介绍 AlloyDB 存储层<span class="exturl" data-url="aHR0cHM6Ly9jbG91ZC5nb29nbGUuY29tL2Jsb2cvcHJvZHVjdHMvZGF0YWJhc2VzL2FsbG95ZGItZm9yLXBvc3RncmVzcWwtaW50ZWxsaWdlbnQtc2NhbGFibGUtc3RvcmFnZQ==">博文<i class="fa fa-external-link-alt"></i></span>，剖析下 AlloyDB 存储层架构，看看其设计有何亮色。</p>
<blockquote>
<p><strong>整体架构</strong></p>
</blockquote>
<p>在整体上，AlloyDB 分为 <strong>Database 层</strong>和<strong>存储层</strong>。其中，DB 层用以兼容 PostgreSQL 协议，解析 SQL 语句，转化为读写请求，发送给存储层。对于存储层，又可以细分为三层：</p>
<ol>
<li><strong>log storage 层</strong>：DB 层会将写入转换为操作日志，或者说 WAL 写入存储层。log storage 负责这些日志记录的高效写入和存储。</li>
<li><strong>LPS 层</strong>：Log Processing Service，LPS，日志处理服务层，消费 log storage 层的 WAL ，生成 Block，本质是一个<strong>物化</strong>（Materialized）的过程。</li>
<li><strong>block storage 层</strong>：对应单机 PostgreSQL 的 block 层，用于服务查询，通过<strong>分片</strong>（shard）提供并行度、通过<strong>冗余</strong>（replication）保证跨区容错性。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/05/15/google-alloydb-storage">https://www.qtmuniao.com/2022/05/15/google-alloydb-storage</a> 转载请注明出处</em></p>
<p><img src="https://s2.loli.net/2022/05/15/lHFZw8SqjIAGCWh.png" alt="database-storage.png"></p>
<p>即，AlloyDB 将其存储层进一步拆分为<strong>两个存储层</strong>和<strong>一个计算层</strong>，以拆解复杂度：</p>
<ol>
<li>log storage 层，承接 DB 层过来的写入请求。但只支持追加（append only）写入，因此可以做到低延迟、高可用，并且可以用 LSN 做读写并发控制、分布式事务。</li>
<li>block storage 层，承接 DB 层过来的查询请求。虽然文中没提到，但盲猜其提供的 block 仅支持<strong>单次写多次读</strong>（ write once then becomes immutable)，以方便做缓存和版本控制。</li>
<li>LPS 层，两个子存储层间数据的搬运工，同时负责 block 的生成和读取，无状态，可伸缩。可根据负载、统计信息等各种信号，动态增删实例以追踪变化的负载。</li>
</ol>
<p>存储层本质上是要提供 <strong>block 的读写服务</strong>， AlloyDB 拆出 log storage 层负责写、block storage 层负责读。基于日志服务物化实现存储层，在分布式数据库领域，算是一个经典（甚至老旧）架构，但如何将其高效组合，还是比较考验工程能力。</p>
<p>基于日志服务的另一个好处是，可以对同一份数据使用不同的方式进行物化，以支持不同的工作负载（workload），比如将数据按需物化为针对 TP 和 AP 优化的数据格式，即，支持 HTAP。</p>
<blockquote>
<p><strong>读写流程</strong></p>
</blockquote>
<p><strong>写入请求</strong>（如 SQL insert），由客户端向<strong>主实例</strong>发起，在经过 DB 层解析后，变为一组 WAL Records 发到存储层。在 WAL <strong>同步</strong>写入成功后，事务提交成功返回。之后，LPS 会将日志异步的物化为 Block。<br><img src="https://s2.loli.net/2022/05/15/pLtwf1YN4vJDQsl.png" alt="write-workflow.png"></p>
<p>原文没有展开，但如何对日志进行<strong>分段</strong>和<strong>容错</strong>、如何多地部署、如何管理日志<strong>生命周期</strong>，也是很关键的设计点。</p>
<p><strong>读取请求</strong>（如 SQL query），由客户端向<strong>任何实例</strong>发起，在 DB 层解析后，如果命中该 DB 层中的缓存（Buffer Cache），则直接返回；如果请求所需数据缓存不够，则可以去更大的、类似二级缓存的 Ultra-fast Cache 中去捞，如命中，则仍可不访问存储层。</p>
<p>如 Ultra-fast Cache 中仍然缺少所需 block，则会带上 <strong>block id 和 LSN</strong>，向存储层发送 block 读取请求：</p>
<ol>
<li>block id 用于检索 block。</li>
<li>LSN 用于等待 LPS apply 进度，以保证一致性视图。</li>
</ol>
<p><img src="https://s2.loli.net/2022/05/15/rH3O8fFlT9aLQRD.png" alt="read-workflow.png"></p>
<p>在存储层中，LPS 负责 block 的读写，每个 LPS 都维护了 <strong>Buffer Cache</strong>，这个术语比较有意思：</p>
<ol>
<li>Buffer，一般用在写入时，将多个写合并到一块，以提高写吞吐。</li>
<li>Cache，一般用在读取时，弥合不同介质的访问速度，以减小延迟。</li>
</ol>
<p>在此处，两者合二为一，LPS 在日志重放（log apply）时，首先写入自己的 Buffer Cache，此时 Buffer Cache 充当 buffer，以批量刷入 block storage 中；LPS 在将 Buffer Cache 刷到 block storage 前，如收到 block 读取请求，并命中 Buffer Cache，可直接返回，此时，Buffer Cache 充当 cache。</p>
<p>当然，LPS 需要对 Buffer Cache 维护类似脏表之类的数据结构，以追踪每个 block 的生命周期和下刷失效时机。</p>
<blockquote>
<p><strong>弹性伸缩</strong></p>
</blockquote>
<p>为了应对变化的负载，LPS 实例数量被设计为可伸缩的：即调整 LPS 和 block shard 的映射关系。在进一步解释如何伸缩前，先梳理下 <strong>block、shard</strong> 和 <strong>LPS实例</strong> 的概念以及联系：</p>
<p><em>一组 block 集合为一个 shard，一个 shard 最多为一个 LPS实例 所处理，但一个 LPS实例 可同时处理多个 shards</em>。</p>
<p>以餐厅来类比，block 可理解为客人，shard 可理解为餐桌，LPS 实例可理解为服务员：</p>
<ol>
<li>当负载很低时，只需要一个服务员就能照顾餐厅内所有餐桌上的客人。</li>
<li>当负载很高时，最多可以为每个餐桌分配一个服务员。</li>
</ol>
<p>这种动态调节，可完全自动化，无需用户感知和干预。又因 LPS 没有状态（Buffer Cache 不算状态，想想为什么），因此可以<strong>快速</strong>伸缩。</p>
<p><img src="https://s2.loli.net/2022/05/15/AJ5BpdYHbLQOV64.png" alt="LPS-shard.png"></p>
<blockquote>
<p><strong>跨区多活</strong></p>
</blockquote>
<p>为了容忍区域性故障，AlloyDB  会将每个 block 分片的多个副本放到不同区域（zone）中。</p>
<p><img src="https://s2.loli.net/2022/05/15/oIkY2CdeWQxSZ7A.png" alt="zones.png"></p>
<p>文中提到两个概念，region 和 zone，没有去求证，但猜测 region 指<strong>物理区域</strong>，zone 指<strong>逻辑区域</strong>。当某个 zone 发生故障时，在同一 region 新拉起一个 zone，并进行数据恢复：</p>
<ol>
<li>首先使用其他副本的 snapshot 来恢复。</li>
<li>然后将该 snapshot 之后的 WAL 回放。</li>
</ol>
<p>正常情况下，每个 zone 可以独立的进行服务，没有特别多的跨 zone 流量。</p>
<p>此外，AlloyDB 还支持逻辑上（比如某个 database）的手动和自动备份，以防止用户误删数据。</p>
<blockquote>
<p><strong>小结</strong></p>
</blockquote>
<p>AlloyDB 的存储层基于日志服务进行实现，分为两层存储 log storage、block storage 和一层计算 LFS。基于 LSN 来控制并发，动态伸缩 LFS 以应对负载。</p>
<p>你对这种设计有什么看法？欢迎留言讨论。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title>RocksDB 优化小解（一）：Indexing SST</title>
    <url>/2022/08/21/rocksdb-file-indexer/</url>
    <content><![CDATA[<blockquote>
<p>Google LevelDB 是一个 LSM-Tree 的实现典范。但在开源出来后，为了保持轻量、简洁的风格，除了修修 Bug 之外，一直没有做太大的更新迭代。为了让其能够满足工业环境中<strong>多样性的负载</strong>， Facebook（Meta） 在 Fork 了 LevelDB 之后，做了多方面的优化。硬件方面，可以更有效地利用现代硬件，如闪存和快速磁盘、多核 CPU等；软件方面，针对读写路径、Compaction 也做了大量优化，如 SST 索引、索引分片、前缀 Bloom Filter、列族等。</p>
<p>本系列文章，依据 <span class="exturl" data-url="aHR0cHM6Ly9yb2Nrc2RiLm9yZy9ibG9nLw==">RocksDB 系列博客<i class="fa fa-external-link-alt"></i></span>，结合源码和一些使用经验，分享一些有趣的优化点，希望能对大家有所启发。水平所限，不当之处，欢迎留言讨论。</p>
</blockquote>
<p>本篇是 RocksDB 优化系列第一篇，为了优化深层查询性能，将不同层级的 SST 通过一定方式索引起来。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/08/21/rocksdb-file-indexer">https://www.qtmuniao.com/2022/08/21/rocksdb-file-indexer</a> 转载请注明出处</em></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>首先，上个<a href="https://www.qtmuniao.com/2020/11/18/leveldb-data-structures-bloom-filter/">之前文章中</a>画的 LevelDB 架构图。</p>
<p><img src="https://i.loli.net/2020/11/22/pgCWKL8ni7sAF2G.png" alt="leveldb.png"></p>
<p>其中，LevelDB 中一个 <code>Get()</code> 的请求路径，会先后经过：</p>
<ol>
<li>一个可变的 memtable</li>
<li>一系列不可变的 memtable</li>
<li>层级组织的一系列 SST 文件</li>
</ol>
<p>其中，0 层中的 SST 文件是由不可变的 memtable 直接刷盘而来的，其键范围（key range，由<code>FileMetaData.smallest</code> and <code>FileMetaData.largest</code> 界定）大部分都互相交叠。因此，在 0 层中要对所有 SST 文件逐个查找。</p>
<p>其他层的 SST 则由上层 SST 不断<strong>压实</strong>（ Compaction） 而来，由此将数据从上层到下层不断沉降。Compaction 过程会将多个 SST 合并在一块，挤出“水分”（重复的 key），然后分裂成多个 SST 文件，因此在 1 层之下，所有的 SST 文件键范围各不相交，且有序。这种组织方式，可以让我们在层内查找时，进行二分查找（<code>O(log(N))</code> 复杂度），而非线性查找（<code>O(N)</code> 复杂度）。</p>
<p>具体查找方法为，以待查找值 x 为目标，以每个文件的 <code>FileMetaData.largest</code> 组成的数组作为二分对象，不断缩小查找范围，确定目标 SST 文件。如果没有找到包含 x 的 key range 对应的 SST 文件或者对应 SST 文件中没有 x，则向下层继续搜索。</p>
<p>但在大数据量情况下，下层的文件数仍然非常多，对于高频的 Get 操作，即使是二分查找，每层的比较次数，也会线性增长。比如对于 10 的<strong>扇出因子</strong>（fan-out ration），即下层 SST 文件数量是紧邻上层的十倍，则第 3 层会有将近 1000 的文件数量，最坏情况下需要进行 10 次左右的比较。乍看起来不多，但在百万级别的 QPS 下，这是相当可观的开销。</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>可以观察到，在 LevelDB 的版本机制下，每个版本（VersionSet，由 Manifest 文件保存）内的 SST 文件数量是定死的、位置也是定死的，则不同层 SST 文件的相对位置也是确定的。</p>
<p>则，我们在每一层进行查找时，其实<strong>不用从头开始二分，上层已经二分出的一些位置信息可以进行复用</strong>。因此，可以在增加一些类似查找树（如 B+ 树）的层级间的索引结构，以减小底层的二分范围。这种思想称为 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRnJhY3Rpb25hbF9jYXNjYWRpbmc=">Fractional cascading<i class="fa fa-external-link-alt"></i></span>。</p>
<p><img src="https://s2.loli.net/2022/08/21/XLU7IvQnJDFfOgS.png" alt="indexing-sst.png"></p>
<p>举个例子，如上图，1 层有 2 个 SST 文件，2 层有 8 个 SST 文件。假设现在我们想要查找 80，首先在第一层中所有文件的 <code>FileMetaData.largest</code> 中搜索，可以得到候选文件 file 1，但通过与其上下界比较发现小于其下界。于是继续向 2 层搜索，如果 SST 上没有索引，我们需要对所有八个候选文件进行二分，但如果有索引，如上图，我们只需要对前三个文件进行二分。由此，每层搜索的比较次数可以做到常数级别 N（扇出因子，即 RocksDB 中 <code>max_bytes_for_level_multiplier</code> 配置项），不会随着层次的加深而线性增加（ <code>log(N^L) = N*L</code>）。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>RocksDB 中的版本是在每次 compaction 后确定的，只有 compaction 才会改变 SST。因此可以在 compaction 构建 SST 时构建相邻层间的 SST 索引。构建时，每个 SST 文件上下界各对应一个指针。那么如何确定每个指针的指向位置呢？与查找过程类似，拿着上界或者下界对应的 key，在下层所有 SST 文件的 <code>FileMetaData.largest</code> 构成的数组中进行搜索，将其指向下层文件该值对应的<strong>右界文件</strong>。这么选择原因在于，<strong>可以通过该指针（如 100 的指针），将下一层中指向的文件（如 file3）右边的文件（file4，file5，…）全部砍掉</strong>，从而减小搜索范围。</p>
<p>举个例子，如上图中的 1 层中 file1 的上下界分别为 100 和 200 。对于 100，搜索后落到 2 层中的 file 3 中，则其指向 file 3；对于 200 ，搜索后落到 210 左边，则指向 file 4。</p>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>但在 RocksDB 实际<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rL3JvY2tzZGIvYmxvYi8zLjAuZmIuYnJhbmNoL2RiL2ZpbGVfaW5kZXhlci5jYw==">代码中<i class="fa fa-external-link-alt"></i></span>（该功能自 3.0 引入），对于任意一个上层文件，实际上是记下了四个索引。通过细分界定范围，可以进一步减小搜索范围。其基本思想是构建 <code>FileIndexer</code> 的时候多花一倍时间、多算一倍的边界，在查找时，就可以更进一步缩小查找范围。鉴于 SST 都是一次构建，多次查询，这种 tradeoff 是值得的。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">IndexUnit</span> &#123;</span><br><span class="line">    <span class="built_in">IndexUnit</span>()</span><br><span class="line">      : <span class="built_in">smallest_lb</span>(<span class="number">0</span>), <span class="built_in">largest_lb</span>(<span class="number">0</span>), <span class="built_in">smallest_rb</span>(<span class="number">-1</span>), <span class="built_in">largest_rb</span>(<span class="number">-1</span>) &#123;&#125;</span><br><span class="line">    <span class="comment">// Point to a left most file in a lower level that may contain a key,</span></span><br><span class="line">    <span class="comment">// which compares greater than smallest of a FileMetaData (upper level)</span></span><br><span class="line">    <span class="comment">// 下层文件中比 FileMetaData.smallest 大的第一个文件下标。 </span></span><br><span class="line">    <span class="comment">// target &gt; FileMetaData.smallest 时搜索用。</span></span><br><span class="line">    <span class="type">int32_t</span> smallest_lb;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Point to a left most file in a lower level that may contain a key,</span></span><br><span class="line">    <span class="comment">// which compares greater than largest of a FileMetaData (upper level)</span></span><br><span class="line">    <span class="comment">// 下层文件中比 FileMetaData.largest 大的第一个文件下标。 </span></span><br><span class="line">    <span class="comment">// target &gt; FileMetaData.largest 时搜索用。</span></span><br><span class="line">    <span class="type">int32_t</span> largest_lb;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Point to a right most file in a lower level that may contain a key,</span></span><br><span class="line">    <span class="comment">// which compares smaller than smallest of a FileMetaData (upper level)</span></span><br><span class="line">    <span class="comment">// 下层文件中比 FileMetaData.smallest 小的最后一个文件下标。 </span></span><br><span class="line">    <span class="comment">// target &lt; FileMetaData.smallest 时搜索用。</span></span><br><span class="line">    <span class="type">int32_t</span> smallest_rb;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Point to a right most file in a lower level that may contain a key,</span></span><br><span class="line">    <span class="comment">// which compares smaller than largest of a FileMetaData (upper level)</span></span><br><span class="line">    <span class="comment">// 下层文件中比 FileMetaData.largest 小的最后一个文件下标。 </span></span><br><span class="line">    <span class="comment">// target &lt; FileMetaData.largest 时搜索用。</span></span><br><span class="line">    <span class="type">int32_t</span> largest_rb;</span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure>

<p>上面注释看起来比较拗口，但是从如何<strong>对其使用</strong>入手，就能比较容易的理解了。假设我们现在要查找的值为 <code>x</code>，待比较的某个上层文件上下界为<code>[smallest, largest]</code> ，则该上下界将键空间切分为五个区间：<code>(-∞, smallest), smallest, (smallest, largest), largest, (largest, +∞)</code>。仅考虑该文件搜索结束就要去下层搜索的情况，则有：</p>
<ol>
<li>如果 x &lt; smallest，则需要在下层中比 smallest 小的最右边那个文件（<code>smallest_rb</code>）找。</li>
<li>如果 x &#x3D;&#x3D; smallest，即 smallest ≤ x ≤ smallest，则需要在下层比 smallest 大的最左边的文件（<code>smallest_lb</code>）开始找，到比 smallest 小的最右边的文件（<code>smallest_rb</code>）停止。</li>
<li>如果 smallest &lt; x &lt; largest，则需要在下层比 smallest 大的最左边的文件（<code>smallest_lb</code>）开始找，到比 largest 小的最右边的文件（<code>largest_rb</code>）停止。</li>
<li>如果 x &#x3D;&#x3D; largest，即 largest ≤ x ≤ largest，则需要在下层比 largest 大的最左边的文件（<code>largest_lb</code>）开始找，到比 largest 小的最右边的文件（<code>largest_rb</code>）停止。</li>
<li>如果 x &gt; largest，则需要在下层比 largest 大的最左边那个文件（<code>largest_lb</code>）开始找。</li>
</ol>
<p>对应代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (cmp_smallest &lt; <span class="number">0</span>) &#123; <span class="comment">// target &lt; smallest，使用 smallest_rb 作为右界</span></span><br><span class="line">  *left_bound = (level &gt; <span class="number">0</span> &amp;&amp; file_index &gt; <span class="number">0</span>)</span><br><span class="line">                    ? index_units[file_index - <span class="number">1</span>].largest_lb</span><br><span class="line">                    : <span class="number">0</span>;</span><br><span class="line">  *right_bound = index.smallest_rb;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmp_smallest == <span class="number">0</span>) &#123;</span><br><span class="line">  *left_bound = index.smallest_lb;</span><br><span class="line">  *right_bound = index.smallest_rb;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmp_smallest &gt; <span class="number">0</span> &amp;&amp; cmp_largest &lt; <span class="number">0</span>) &#123;</span><br><span class="line">  *left_bound = index.smallest_lb;</span><br><span class="line">  *right_bound = index.largest_rb;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmp_largest == <span class="number">0</span>) &#123;</span><br><span class="line">  *left_bound = index.largest_lb;</span><br><span class="line">  *right_bound = index.largest_rb;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmp_largest &gt; <span class="number">0</span>) &#123;</span><br><span class="line">  *left_bound = index.largest_lb;</span><br><span class="line">  *right_bound = level_rb_[level + <span class="number">1</span>];</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="built_in">assert</span>(<span class="literal">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>注：</strong>当 x &#x3D;&#x3D; smallest 或者 x &#x3D;&#x3D; largest 时，对于 RocksDB 使用场景来说，上层已经找到了，无须再往查找下层。但该 <code>FileIndexer</code> 的应用场景更泛化一些，比如你可以使用其往下层寻找所有等于给定值的结果。</p>
<p>下面，仍以之前例子，来使用图解释下：</p>
<p><img src="https://s2.loli.net/2022/08/21/d2tDES7jAaofwP5.png" alt="create-indexing-sst.png"></p>
<p>可以看出，当上层文件边界（如 100）落到下层文件内（如 file 3 [95, 110]）时，该边界 lb 和 rb 指针指向相同，蜕化为单指针；当文件边界（如 400）落到下层文件<strong>空隙内</strong>（如 file 7 和 file 8 之间），lb 和 rb 才指向不同，从而在搜索时，相对单指针，总体上减少一个待扫描文件。</p>
<p>另一方面，注意到，当上层文件边界值（如 400）落在下层文件空隙内时（即该值在下层肯定不存在），有 <code>largest_rb &lt; largest_lb</code> ，如果搜索值是 400，则利用此指针直接导致 <code>left_bound &gt; right_bound</code>，搜索结束。</p>
<p>在具体实现时， RocksDB 使用了<strong>双指针比较法</strong>，一个指针迭代上层，一个指针迭代下层，一次迭代即可为所有文件建立一种索引。为减少代码中的<strong>分支判断</strong>，使逻辑清晰，RocksDB 将建立过程拆为了四趟，分别构建上述四种指针，逻辑封装在了两个函数中：<code>CalculateLB</code> 和 <code>CalculateRB</code>。</p>
<p>下面以 <code>CalculateLB</code> 代码为例，简单注释分析：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 计算 lower_files 中比某值大的最左（从左到右第一个）文件下标</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">FileIndexer::CalculateLB</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;FileMetaData*&gt;&amp; upper_files, <span class="comment">// 上层 SST 文件</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;FileMetaData*&gt;&amp; lower_files, <span class="comment">// 下层 SST 文件</span></span></span></span><br><span class="line"><span class="params"><span class="function">    IndexLevel* index_level,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::function&lt;<span class="type">int</span>(<span class="type">const</span> FileMetaData*, <span class="type">const</span> FileMetaData*)&gt; cmp_op,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::function&lt;<span class="type">void</span>(IndexUnit*, <span class="type">int32_t</span>)&gt; set_index)</span> </span>&#123;</span><br><span class="line">  <span class="type">const</span> <span class="type">int32_t</span> upper_size = <span class="built_in">static_cast</span>&lt;<span class="type">int32_t</span>&gt;(upper_files.<span class="built_in">size</span>());</span><br><span class="line">  <span class="type">const</span> <span class="type">int32_t</span> lower_size = <span class="built_in">static_cast</span>&lt;<span class="type">int32_t</span>&gt;(lower_files.<span class="built_in">size</span>());</span><br><span class="line">  <span class="type">int32_t</span> upper_idx = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int32_t</span> lower_idx = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  IndexUnit* index = index_level-&gt;index_units;</span><br><span class="line">  <span class="keyword">while</span> (upper_idx &lt; upper_size &amp;&amp; lower_idx &lt; lower_size) &#123; <span class="comment">// 双指针比较法</span></span><br><span class="line">    <span class="comment">// 总是跟 lower_files[lower_idx].largest 比较</span></span><br><span class="line">    <span class="type">int</span> cmp = <span class="built_in">cmp_op</span>(upper_files[upper_idx], lower_files[lower_idx]);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (cmp == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="built_in">set_index</span>(&amp;index[upper_idx], lower_idx);</span><br><span class="line">      ++upper_idx;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 下层 lower_idx 处文件的最大值比给定值小，则不满足条件</span></span><br><span class="line">      ++lower_idx;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 下层 lower_idx 处文件的最大值相对给定值第一次变大，满足条件，设置索引</span></span><br><span class="line">      <span class="built_in">set_index</span>(&amp;index[upper_idx], lower_idx);</span><br><span class="line">      ++upper_idx;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (upper_idx &lt; upper_size) &#123;</span><br><span class="line">    <span class="comment">// 下层文件用完了，表示现在所有余下的上层文件比所有下层文件都大</span></span><br><span class="line">    <span class="comment">// 于是让他们都指向 lower_size，即不存在（下层文件下标为 0~lower_size-1）。</span></span><br><span class="line">    <span class="built_in">set_index</span>(&amp;index[upper_idx], lower_size);</span><br><span class="line">    ++upper_idx;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如果是上层文件用完了，不做额外处理。因为函数作用是为上层文件设置索引，</span></span><br><span class="line">  <span class="comment">// 上层文件用完了，说明已经为所有上层文件设置了索引。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>四趟调用，分别为上层每一个文件索引项 <code>IndexUnit</code> 的四个字段赋值。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">CalculateLB</span>(</span><br><span class="line">    upper_files, lower_files, &amp;index_level,</span><br><span class="line">    [<span class="keyword">this</span>](<span class="type">const</span> FileMetaData* a, <span class="type">const</span> FileMetaData* b) -&gt; <span class="type">int</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> ucmp_-&gt;<span class="built_in">CompareWithoutTimestamp</span>(a-&gt;smallest.<span class="built_in">user_key</span>(),</span><br><span class="line">                                            b-&gt;largest.<span class="built_in">user_key</span>());</span><br><span class="line">    &#125;,</span><br><span class="line">    [](IndexUnit* index, <span class="type">int32_t</span> f_idx) &#123; index-&gt;smallest_lb = f_idx; &#125;);</span><br><span class="line"><span class="built_in">CalculateLB</span>(</span><br><span class="line">    upper_files, lower_files, &amp;index_level,</span><br><span class="line">    [<span class="keyword">this</span>](<span class="type">const</span> FileMetaData* a, <span class="type">const</span> FileMetaData* b) -&gt; <span class="type">int</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> ucmp_-&gt;<span class="built_in">CompareWithoutTimestamp</span>(a-&gt;largest.<span class="built_in">user_key</span>(),</span><br><span class="line">                                            b-&gt;largest.<span class="built_in">user_key</span>());</span><br><span class="line">    &#125;,</span><br><span class="line">    [](IndexUnit* index, <span class="type">int32_t</span> f_idx) &#123; index-&gt;largest_lb = f_idx; &#125;);</span><br><span class="line"><span class="built_in">CalculateRB</span>(</span><br><span class="line">    upper_files, lower_files, &amp;index_level,</span><br><span class="line">    [<span class="keyword">this</span>](<span class="type">const</span> FileMetaData* a, <span class="type">const</span> FileMetaData* b) -&gt; <span class="type">int</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> ucmp_-&gt;<span class="built_in">CompareWithoutTimestamp</span>(a-&gt;smallest.<span class="built_in">user_key</span>(),</span><br><span class="line">                                            b-&gt;smallest.<span class="built_in">user_key</span>());</span><br><span class="line">    &#125;,</span><br><span class="line">    [](IndexUnit* index, <span class="type">int32_t</span> f_idx) &#123; index-&gt;smallest_rb = f_idx; &#125;);</span><br><span class="line"><span class="built_in">CalculateRB</span>(</span><br><span class="line">    upper_files, lower_files, &amp;index_level,</span><br><span class="line">    [<span class="keyword">this</span>](<span class="type">const</span> FileMetaData* a, <span class="type">const</span> FileMetaData* b) -&gt; <span class="type">int</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> ucmp_-&gt;<span class="built_in">CompareWithoutTimestamp</span>(a-&gt;largest.<span class="built_in">user_key</span>(),</span><br><span class="line">                                            b-&gt;smallest.<span class="built_in">user_key</span>());</span><br><span class="line">    &#125;,</span><br><span class="line">    [](IndexUnit* index, <span class="type">int32_t</span> f_idx) &#123; index-&gt;largest_rb = f_idx; &#125;);</span><br></pre></td></tr></table></figure>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>对 SST 建立索引的方法比较直观（可以类比 B+ 树），容易理解。但对应到代码实现上，有诸多细节和边界情况需要处理，很容易出错。就像二分查找，能写出花来一样，无他，唯多练耳。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>RocksDB 博客，<strong><strong>Indexing SST Files for Better Lookup Performance，</strong></strong> <span class="exturl" data-url="aHR0cDovL3JvY2tzZGIub3JnL2Jsb2cvMjAxNC8wNC8yMS9pbmRleGluZy1zc3QtZmlsZXMtZm9yLWJldHRlci1sb29rdXAtcGVyZm9ybWFuY2UuaHRtbA==">http://rocksdb.org/blog/2014/04/21/indexing-sst-files-for-better-lookup-performance.html<i class="fa fa-external-link-alt"></i></span></li>
<li>维基百科，分散级联， <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRnJhY3Rpb25hbF9jYXNjYWRpbmc=">Fractional cascading<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRnJhY3Rpb25hbF9jYXNjYWRpbmc=">https://en.wikipedia.org/wiki/Fractional_cascading<i class="fa fa-external-link-alt"></i></span></li>
<li>RocksDB github FileIndexer：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rL3JvY2tzZGIvYmxvYi8zLjAuZmIuYnJhbmNoL2RiL2ZpbGVfaW5kZXhlci5jYw==">https://github.com/facebook/rocksdb/blob/3.0.fb.branch/db/file_indexer.cc<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>源码阅读</category>
        <category>RocksDB</category>
      </categories>
      <tags>
        <tag>存储</tag>
        <tag>RocksDB</tag>
      </tags>
  </entry>
  <entry>
    <title>DynamoDB 的云原生之路 —— 流控策略的演进</title>
    <url>/2022/09/24/dynamo-db-flow-control/</url>
    <content><![CDATA[<h2 id="概述：流控为啥重要"><a href="#概述：流控为啥重要" class="headerlink" title="概述：流控为啥重要"></a>概述：流控为啥重要</h2><p>上云的好处在于池化资源，让多租户共享，然后按需分配，从而降低成本。但进行：</p>
<ol>
<li><strong>多租户隔离</strong>：用户要求可以使用其买到的流量，并且不会被其他租户影响。</li>
<li><strong>资源共享</strong>：资源只能逻辑隔开，不能物理隔开，否则无法充分动态分配（超发）。</li>
</ol>
<p>是一对相对矛盾的事情，我认为，也是云原生数据库最要解决的问题。不把这个问题解决好，则数据库：</p>
<ol>
<li><strong>要么平台不赚钱</strong>：比如资源静态预留，虽然可以让用户满意，总能随时用到卖给他的资源配额，但会存在巨大资源浪费，要么价格贵，要么用户不买单。</li>
<li><strong>要么用户不满意</strong>：多用户共享物理资源，但非常容易进行互相影响，造成用户不能用到平台声称的配额。</li>
</ol>
<p>DynamoDB 从静态分配开始，逐步演化出一套全局和局部组合的准入控制机制，从而实现了物理上资源共享，但又在逻辑上给用户以配额隔离，从而实现了数据库真正的云原生。下面，我依据 <span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9zeXN0ZW0vZmlsZXMvYXRjMjItZWxoZW1hbGkucGRm">Amazon DynamoDB: A Scalable, Predictably Performant, and Fully Managed NoSQL Database Service<i class="fa fa-external-link-alt"></i></span> 这篇论文披露的细节，对其流控机制的演进过程做一个梳理，以飨诸君。</p>
<p>水平所限，谬误之处，欢迎随时指出。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/09/24/dynamo-db-flow-control">https://www.qtmuniao.com/2022/09/24/dynamo-db-flow-control</a> 转载请注明出处</em></p>
<h2 id="开始：静态预留"><a href="#开始：静态预留" class="headerlink" title="开始：静态预留"></a>开始：静态预留</h2><p>这里面对的其实是一个常见的调度问题，如何将表的分片副本（table-partition-<strong>replication</strong>）调度到集群（一组物理机）上，并兼顾以下特性：</p>
<ol>
<li><strong>可用性</strong>：将物理机划分 AZ（Availability Zones，可用域），将不同副本调度到不同 AZ。</li>
<li><strong>数据容量</strong>：其实是针对<strong>存储资源</strong>，每个物理机有容量总额，每个副本也有容量预期（能随着容量自动分裂，所以刚开始可能都比较小），表的分区副本创建时，需要为其寻找物理机资源余量大于其需求量的目标机器。比如，一个很简单的撮合策略是每次找集群中最空闲的那个机器。</li>
<li><strong>流量</strong>：文中称 performance，其实包括<strong>计算资源</strong>和<strong>网络带宽</strong>。分配方式和 2 类似。</li>
</ol>
<p>本文关注重点主要在 3 上，并且引入了流量单位：<strong>读容量单位</strong> (RCUs) 和<strong>写容量单位</strong> (WCUs)。</p>
<p>最开始的策略是将表的<strong>总配额</strong>（provisioned capacity）平均分配给每个分区，比如表的总配额是 1000 RCUs，一共十个分区，每个分区 100 RCUs。则每个分区的流量不得超过 100 RCUs。</p>
<p>这种策略最大的优点就是实现简单，而缺点繁多。让我们仔细审视下该策略，发现它其实蕴含了一个假设：<strong>分区间的流量是均匀的</strong>。但在现实中，这种模型太理想了。而一旦分区流量不均匀，就有可能出现，某些分区由于流量大，达到了该分区配额 100 WCUs 而被限流；而另外一些流量小的分区的配额却被浪费。</p>
<h2 id="初步：突发策略和自适应流量"><a href="#初步：突发策略和自适应流量" class="headerlink" title="初步：突发策略和自适应流量"></a>初步：突发策略和自适应流量</h2><p>为了给上述纯静态分配策略打个补丁，DynamoDB 开始引入了<strong>流量突发</strong>（busting）和<strong>流量自适应</strong>（adaptive）策略。</p>
<h3 id="突发策略"><a href="#突发策略" class="headerlink" title="突发策略"></a>突发策略</h3><p>为了应对某些分区<strong>短时突发流量</strong>（short-live spikes）的问题，DynamoDB 引入了一个补丁（workaround），如果发现某个分区瞬时流量较大，且分区副本所在节点还有余量，就临时给该副本调配一些。具体到实现上，DynamoDB 用了三个令牌桶：</p>
<ol>
<li><strong>分区预留令牌桶</strong>。对应前面例子中的那 100 RCUs，当分区流量不超过这个值时，允许读写且从该令牌桶中扣除相应数量令牌。</li>
<li><strong>节点总量令牌桶</strong>。对应单机容量限制，所有请求到来时，都要消耗此桶中令牌。</li>
<li><strong>分区突发令牌桶</strong>。当分区流量超过预留时，会检查节点总量令牌桶是否还有余量，如果有就允许该分区进行突发。</li>
</ol>
<p>需要注意，RCU 配额用上述策略就够了，但对于 WCU 配额，DynamoDB 还加了一条限制：<strong>需要检查该分区所有副本的 WCU 总额是否超限</strong>。其想法是，RCU 可以适当多给，但 WCU 不行。实现也很朴素，每个分区（多副本会构成一个复制组） Leader 会充当协调者，进行容量信息收集和分发。</p>
<p>最后，该策略只用于解决 300 秒内的短时突发流量，超过了时间窗口，借调的流量是要被释放出来的。因为这部分流量属于机器中的超发流量，需要随时准备调配给本机上的其他分区副本使用。</p>
<h3 id="自适应策略"><a href="#自适应策略" class="headerlink" title="自适应策略"></a>自适应策略</h3><p>那对于<strong>长时突发流量</strong>（long-live spikes）怎么解决呢？只能在不同分区中进行流量<strong>调配</strong>了。</p>
<p>DynamoDB 使用某个中心服务（论文中就叫 Adaptive capacity，不确定该组件是额外引入的还是属于某个中心服务的一部分），来监控每个表的<strong>总配额</strong>和<strong>已耗容量</strong>。</p>
<p>当某个表还有余量，但表的某些分区因为流量突发被限流时，可以通按<strong>成比例控制算法</strong>（a proportional control algorithm，应该就是按流量大小比例）来给这些分区调配一些配额。并且，如果调配后，触到了所在存储节点整机配额上限，<strong>自动管理系统</strong>（autoadmin system）会将该分区迁移到相对空闲、可以提供所需配额增量的机器。</p>
<h2 id="反思：分区和流控耦合"><a href="#反思：分区和流控耦合" class="headerlink" title="反思：分区和流控耦合"></a>反思：分区和流控耦合</h2><p>前两者最大特点是将<strong>流控</strong>和<strong>分区</strong>过紧地耦合到了一块，即在分区级别做的流量控制，因此很难对一个表进行跨分区进行流量调度。而我们对用户提供的是表级别的配额抽象，因此最好隐藏分区这个物理实现，保证只要表的总配额还有余量，就能给有突发流量的数据进行分配。而不能说，一些分区流量小，但仍然占用着配额，另外一些分区流量大，但在用完了分配给其的配额后，就要被限流。</p>
<p>虽然自适应策略在跨分区方向做了一些改进，但仍然是补丁范畴，而不是将动态流控作为第一思想来设计。为此，DynamoDB 引入全局准入控制机制来彻底解决此问题。</p>
<h2 id="改进：全局准入控制"><a href="#改进：全局准入控制" class="headerlink" title="改进：全局准入控制"></a>改进：全局准入控制</h2><p><strong>全局准入控制</strong>（global admission control，GAC）同样使用令牌桶的实现方式，但与之前<strong>局部</strong>令牌桶不同，全局准入控制使用一种全局令牌桶，或者说<em>分布式令牌桶</em>。由 GAC 服务来产生令牌，请求路由实例消费令牌，来达到表粒度准入控制。</p>
<h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><p><img src="https://blog-1301240863.cos.ap-beijing.myqcloud.com/DynamoDB-architecture.png" alt="架构图"></p>
<ol>
<li><strong>GAC 服务</strong>：由一组 GAC 实例构成，以一致性哈希的方式进行流量均摊。</li>
<li><strong>GAC 实例</strong>：使用令牌桶方式产生令牌，每个实例会维护一个或者多个表级别的令牌桶。</li>
<li><strong>请求路由器</strong>：request router，GAC 的客户端，与 GAC 服务通信，获取令牌进行流控。其中，令牌是有时限的，过期不被消费也会自动销毁。</li>
</ol>
<p>其中有个关键问题是，GAC 每次给某个请求路由实例分配多少令牌？</p>
<p>DynamoDB 会根据历史信息，追踪每个请求路由实例的消费速率，按速率等比例分配。那如何进行追踪呢？论文中没有提，估计是使用滑动时间窗口之类的，但这类信号也不太好做，总会出现刻画不准或延迟太大的情况，不知道 DynamoDB 具体是如何实现的。</p>
<h3 id="动态均衡"><a href="#动态均衡" class="headerlink" title="动态均衡"></a>动态均衡</h3><p>与静态分区和流量配额不同，GAC 视角下的分区流量会随时变化。为了避免热点聚集导致某些存储节点被打垮，DynamoDB 实现了一套可以主动根据<strong>吞吐消耗</strong>和<strong>存储量</strong>来对分区进行跨节点均衡的机制：</p>
<ol>
<li>每个存储节点会各自进行<strong>资源用量核算</strong>，如果节点资源总用量超过节点某个百分比<strong>阈值</strong>，该存储节点就会主动向<strong>自动管理服务</strong>（autoadmin service）汇报，并给出一组<strong>待迁移副本候选列表</strong>。</li>
<li>自动管理服务在收到请求后，会根据全局资源分布，为每个候选副本找到一个合适存储节点，同时满足开篇提到的<strong>可用性</strong>和<strong>资源用量</strong>约束。</li>
</ol>
<h3 id="流量拆分"><a href="#流量拆分" class="headerlink" title="流量拆分"></a>流量拆分</h3><p>如果某个分区上有很大的热点，受限于所在节点负载可能仍会被限流。DynamoDB 会追踪这些热点，并统计该分区上数据的流量分布，按流量对分区进行切分。相比单纯的按中点（均衡存储资源）进行分裂，按流量分布（计算和带宽）进行切分，对于消除热点来说，可能更为本质。分区拆分后，可以按需进行迁移。</p>
<p>分区分裂的所需时间通常在分钟量级。</p>
<p>但有一些访问热点，并不能通过分区分裂来进行消除：</p>
<ol>
<li>单数据条目热点</li>
<li>范围访问热点</li>
</ol>
<p>DynamoDB 能够识别这类访问模式，从而避免在这样的分区上进行拆分。</p>
<h3 id="自动配给"><a href="#自动配给" class="headerlink" title="自动配给"></a>自动配给</h3><p>在创建表时就为表设定<strong>固定配额</strong>是一件很难的事情，就跟你需要预知将来一样。如果设置的多了，会造成资源浪费；设置的少了，又容易触发限流。这是静态配额的一个弊端，因此 DynamoDB 提供一种<strong>动态配额表</strong>（<strong>on-demand provisioning table</strong>，然后按用实际用量计费，这也是云计算的一大特征）。</p>
<p>为了精确描述配额，DynamoDB 引入了衡量吞吐的概念：<strong>读写容量单位</strong>（read and write capacity units）。如果单纯用 QPS 刻画流量，显然不合适，因为每个请求所涉及的数据量是不等的。因此 DynamoDB 引入单位时间内单位流量额度：RCU 和 WCU 来对读写流量进行刻画。</p>
<p>在进行自动配额时，首先要准确追踪读写流量。在检测到流量突发且要触发限流时，会对配额进行指数扩充（二倍）。如果应用持续流量大于之前尖峰的二倍，则会通过按流量拆分分区等方法进一步提高整体配额。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>云上一个重要特征就是<strong>资源池化、按需分配</strong>和<strong>精准计费</strong>，从而在整体上实现资源的充分利用，通过规模化优势抵消通用性带来的成本。</p>
<p>具体到云原生数据库中，便是多租户流量的自动配给。DynamoDB 通过论文披露了其从配额静态划分、打补丁演进，到全局动态划分的一个演进过程。对于国内各路号称要做云原生数据库的厂商来说，想要在保证用户体验（资源隔离）的前提下真正赚钱（资源共享），DynamoDB 的经验想必有诸多可借鉴之处。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>DynamoDB</tag>
        <tag>流控</tag>
        <tag>云原生数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>好好写代码之素养篇——抽象和讲究</title>
    <url>/2022/10/12/how-to-write-code-abstract/</url>
    <content><![CDATA[<blockquote>
<p>知乎上有个问题，如何辨别一个程序员水平的高低？就这几年 Review 代码的体感，忍不住就工程素养这个话题吐两句槽，正好作为好好写代码系列的第二篇。</p>
</blockquote>
<h2 id="思维体系"><a href="#思维体系" class="headerlink" title="思维体系"></a>思维体系</h2><p>水平差的程序员往往在“<strong>抽象</strong>”上做的不好。</p>
<p>什么是抽象能力呢？简言之，就是分门别类、触类旁通的能力。通过大量实践和书籍输入，将所解决过的问题进行正交分解，分解过的<strong>元知识</strong>多具有很好地复用性；再利用这些元知识，进行组合推演，创造性的解决新遇到的问题。即归纳和演绎。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/10/12/how-to-write-code-abstract">https://www.qtmuniao.com/2022/10/12/how-to-write-code-abstract</a> 转载请注明出处</em></p>
<p>体现在做系统设计时，会对涉及到的概念进行精确描述：<strong>对于单个概念，定义好其内涵外延；对于多个概念，梳理好其层次关系</strong>。映射到代码上，就是不同类的职责清晰划分。</p>
<p>如果抽象能力不行，会有什么问题呢？</p>
<ol>
<li><strong>知识体系离散</strong>。不能将学到的散乱知识分门别类，梳理出体系。反应在<strong>定位问题</strong>上，东一下、西一下，看不到问题的脉络，自然也就分析不出问题的原因。</li>
<li><strong>与人交流困难</strong>。不能对一个问题在不同抽象层次上进行阐释，给别人讲其解决方案时，就会自然倾向使用“<strong>伪代码</strong>”式这种最底层抽象层次进行描述，暴露大量实现细节，如果对方和你共享的上下文很少，就很难搞懂在说啥。因此，需要对具有不同上下文的人，对问题进行不同的<strong>泛化</strong>（也是抽象）处理，通过抽象适当剪除上下文，直到能跟他对齐为止。</li>
<li><strong>代码晦涩难懂</strong>。至少可以从两方面来理解。其一，从方案设计上，对于一个问题，如果能找到对其更本质的抽象，那么对应的代码实现一定更加简洁易懂。其二，从代码组织上，如果一个问题很复杂，但是能进行合理拆解、逐层抽象，就一定比“摊大饼”式组织更容易理解。</li>
</ol>
<h2 id="工程素养"><a href="#工程素养" class="headerlink" title="工程素养"></a>工程素养</h2><p>水平差的程序员往往对代码“<strong>不讲究</strong>”，这其实是工程素养差的表现。</p>
<p>那不讲究的代码是什么样的呢？比如，同样含义的变量使用不同的名字、对偶功能（如增删改查）命名不成体系、相似代码不断重复而没有重用、反常逻辑没有任何注释、子模块间头重脚轻、好好的封装被改出几个洞等等（关于如何命名可参考我之前的一篇<a href="https://www.qtmuniao.com/2021/12/12/how-to-write-code-scrutinize-names/" title="好好写代码之命名篇">文章</a>）</p>
<p>这种不讲究有什么问题吗？</p>
<ol>
<li><strong>复杂度爆炸</strong>。软件工程最主要的一个目标就是<strong>控制复杂度</strong>。因为工程化的本质是为了解决规模化所引入的复杂度。而不讲究的代码，通过糟糕的命名、随意的破墙穿洞、混乱的数据流，使代码的复杂度指数级上升，以至于最后需要推倒重来。</li>
<li><strong>易藏污纳垢</strong>。不美观、不符合直觉、不直白的代码，非常容易掩藏一些不易察觉的 bug 。写的时候发现不了，Reviewer 也很难看出来。到后来，就会完全变成一个黑盒，纵使代码在那，你看得懂每条语句，连起来后却不知道他在干啥。</li>
<li><strong>让同事抓狂</strong>。好的代码读起来有一种韵律感，能让人一天都很开心；不好的代码看起来就像吃了苍蝇，能破坏一天的好心情。而最让人难受的是，这种不讲究的人出活还贼快，KPI 还贼好，但是他升上去后，哪管洪水滔天。关爱同事，少堆屎山，从我做起。</li>
</ol>
<p>但需要声明，不同的活对讲究程度要求是不一样的，那如何抉择呢？这里我想引入一个参考度量：<strong>生命周期</strong>。生命周期越长的代码，一定要写的越干净；临时使用代码，比如小脚本，就可以不讲究一些。反过来，也正是干净的代码才能成就超长的生命周期。</p>
<p>大家看别人和自己过去的代码时，有哪些想吐槽的呢？欢迎在留言区讨论。</p>
<hr>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>素养</tag>
      </tags>
  </entry>
  <entry>
    <title>实现一个数据库需要如何入手？</title>
    <url>/2022/12/11/how-to-build-a-database/</url>
    <content><![CDATA[<blockquote>
<p>知乎上有个问题：如何实现一个数据库？手痒忍不住又水了一篇。以计算机中最常用的分析、理解问题的思想，我们可以从两个维度：<strong>逻辑</strong>和<strong>物理</strong>，来思考如何实现一个数据库。</p>
</blockquote>
<h2 id="逻辑维度"><a href="#逻辑维度" class="headerlink" title="逻辑维度"></a>逻辑维度</h2><h3 id="数据模型（对外，面向用户）"><a href="#数据模型（对外，面向用户）" class="headerlink" title="数据模型（对外，面向用户）"></a>数据模型（对外，面向用户）</h3><p>想要实现一个数据库，首先你得定义给给用户什么样的<strong>数据模型</strong>？在前些年，这些可能不是个问题，彼时，数据库约等于关系型数据，约等于 Oracle&#x2F;SQLServer&#x2F;MySQL&#x2F;PostgreSQL 。但随着数据量的不断增大、用户需求的不断细化，关系模型已经不能一招鲜、吃遍天。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/12/11/how-to-build-a-database">https://www.qtmuniao.com/2022/12/11/how-to-build-a-database</a> 转载请注明出处</em></p>
<p>时下（2022）常见的有 Relational 模型（<span class="exturl" data-url="aHR0cHM6Ly9kYi1lbmdpbmVzLmNvbS9lbi9zeXN0ZW0vT3JhY2xl">Oracle<i class="fa fa-external-link-alt"></i></span>）、Document 模型（<span class="exturl" data-url="aHR0cHM6Ly9kYi1lbmdpbmVzLmNvbS9lbi9zeXN0ZW0vTW9uZ29EQg==">MongoDB<i class="fa fa-external-link-alt"></i></span>）、Search Engine（<span class="exturl" data-url="aHR0cHM6Ly9kYi1lbmdpbmVzLmNvbS9lbi9zeXN0ZW0vRWxhc3RpY3NlYXJjaA==">Elasticsearch<i class="fa fa-external-link-alt"></i></span>） KV 模型（<span class="exturl" data-url="aHR0cHM6Ly9kYi1lbmdpbmVzLmNvbS9lbi9zeXN0ZW0vUmVkaXM=">Redis<i class="fa fa-external-link-alt"></i></span>）、Wide Column 模型（<span class="exturl" data-url="aHR0cHM6Ly9kYi1lbmdpbmVzLmNvbS9lbi9zeXN0ZW0vQ2Fzc2FuZHJh">Cassandra<i class="fa fa-external-link-alt"></i></span>），Graph 模型（Neo4j）、Time Series 模型（<span class="exturl" data-url="aHR0cHM6Ly9kYi1lbmdpbmVzLmNvbS9lbi9zeXN0ZW0vSW5mbHV4REI=">InfluxDB<i class="fa fa-external-link-alt"></i></span>）。更多模型及其产品可见 DB-Engines 排名<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM1MzgyNTkzL2Fuc3dlci8yNzk1ODIzODY2I3JlZl8x">[1]<i class="fa fa-external-link-alt"></i></span>。</p>
<h3 id="数据组织（对内，面向系统）"><a href="#数据组织（对内，面向系统）" class="headerlink" title="数据组织（对内，面向系统）"></a>数据组织（对内，面向系统）</h3><p>数据库，本质上就是<strong>存取</strong>数据。从程序员的角度来说，就是如何在计算机存储层次体系<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM1MzgyNTkzL2Fuc3dlci8yNzk1ODIzODY2I3JlZl8y">[2]<i class="fa fa-external-link-alt"></i></span>中组织数据。</p>
<p><img src="https://pic1.zhimg.com/80/v2-4a74c29c943c966fe9b3aa5a5478e11e_1440w.webp?source=1940ef5c" alt="计算机存储层次体系"></p>
<p>学过操作系统、计算机体系结构的同学都知道，对于计算机来说：</p>
<ol>
<li>离 CPU 越近，如寄存器（Register）、缓存（Cache）、内存（Memory），速度越快、容量越小、造价越昂贵。</li>
<li>离 CPU 越远，如闪存（SSD）、磁盘（Disk）、磁带（Tape），速度越慢、容量越大、造价越便宜。</li>
</ol>
<p>近年出现了一些新产品。如<strong>可持久化内存</strong>（Persistent Memory<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM1MzgyNTkzL2Fuc3dlci8yNzk1ODIzODY2I3JlZl8z">[3]<i class="fa fa-external-link-alt"></i></span>），代表产品是 Intel 的傲腾<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM1MzgyNTkzL2Fuc3dlci8yNzk1ODIzODY2I3JlZl80">[4]<i class="fa fa-external-link-alt"></i></span>，大致介于内存和SSD 之间，但由于定位不明确（向上走不够快，向下走不够便宜），还没能大规模应用；又如云上的<strong>对象存储</strong>，代表产品是 AWS S3<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM1MzgyNTkzL2Fuc3dlci8yNzk1ODIzODY2I3JlZl81">[5]<i class="fa fa-external-link-alt"></i></span>，大致是几种非易失性存储的替代产品，价格足够感人、带宽足够高、扩展性足够强，因此大获成功，已经成为云上的存储基础设施，所有需要上云的数据库都会考虑在底层使用对象存储。</p>
<h2 id="物理维度"><a href="#物理维度" class="headerlink" title="物理维度"></a>物理维度</h2><p>数据库在物理上可以粗分为<strong>查询引擎</strong>和<strong>存储引擎</strong>。从感性上理解，存储引擎负责数据在外存的组织与将数据载入内存，查询引擎负责解析用户查询为数据层的读写与数据在内存中的计算。</p>
<p>限于篇幅，此处我们略去了另外几个重要的模块：并发控制、宕机恢复等。</p>
<h3 id="查询引擎"><a href="#查询引擎" class="headerlink" title="查询引擎"></a><strong>查询引擎</strong></h3><p>每个数据模型都有与其契合的<strong>数据查询</strong>方式。当然，我们最熟知便是 SQL 之于关系模型。SQL 也是一门计算机语言，既是语言，就需要一套所有类似编译器前端需要流程：</p>
<ol>
<li><p><strong>Parser</strong>：对使用形式语言抽象的查询语法，利用自动机模型进行解析，构建抽象语法树<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM1MzgyNTkzL2Fuc3dlci8yNzk1ODIzODY2I3JlZl82">[6]<i class="fa fa-external-link-alt"></i></span></p>
</li>
<li><p><strong>Validator</strong>：对语法树进行依据 Schema 进行校验</p>
</li>
</ol>
<p>不同的是，由于查询语言属于声明式语言<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM1MzgyNTkzL2Fuc3dlci8yNzk1ODIzODY2I3JlZl83">[7]<i class="fa fa-external-link-alt"></i></span>，因此在执行上可以有很大的自由发挥的空间，所谓：</p>
<ol>
<li><strong>Planner</strong>：使用模式信息将语法树中对用户有意义的元素（如名字），转为内部标识（如 ID）</li>
<li><strong>Optimizer</strong>：利用关系代数对计划树进行逻辑变换、利用统计信息对执行路径（比如使用哪个索引）进行选择，以期付出最小代价，实现用户查询需求</li>
<li><strong>Executor</strong>：将优化好的执行计划在存储层进行执行，真正的去访问我们存储于计算机体存储体系结构中的数据</li>
</ol>
<p><strong>树</strong>是在数据系统中应用非常深入的一种<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3NlYXJjaD9xPSVFNiU5NSVCMCVFNiU4RCVBRSVFNyVCQiU5MyVFNiU5RSU4NCZzZWFyY2hfc291cmNlPUVudGl0eSZoeWJyaWRfc2VhcmNoX3NvdXJjZT1FbnRpdHkmaHlicmlkX3NlYXJjaF9leHRyYT0lN0IlMjJzb3VyY2VUeXBlJTIyOiUyMmFuc3dlciUyMiwlMjJzb3VyY2VJZCUyMjoyNzk1ODIzODY2JTdE">数据结构<i class="fa fa-external-link-alt"></i></span>。大部分的数据查询，在逻辑上都可以抽象为<strong>对数据集的不断变换</strong>，对应到树中：</p>
<ol>
<li>叶子节点：<strong>数据集合</strong>。有不同粒度，如一列、一行、一个表</li>
<li>中间节点：<strong>变换算子</strong>。有不同类型，如 selection、project、join、dedup、top 等</li>
</ol>
<p>广义上来说，像 Hadoop、Spark、Flink 这些大数据范畴的中间件，也都有查询引擎的影子，只不过要么算子更为简单、要么侧重多机、要么侧重流等等。</p>
<h3 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a><strong>存储引擎</strong></h3><p>对应数据组织，系统程序员需要根据<strong>数据库应用场景</strong>，在<strong>外存</strong>（SSD 和 Disk 中）组织数据。如：</p>
<ul>
<li>考虑事务型还是交易型：在列存还和行存中权衡</li>
<li>考虑读写比例：在原地更新（B+ tree）和增量更新（LSM-Tree）间权衡</li>
<li>考虑安全性：在是否加密间权衡</li>
</ul>
<p>然后，考虑如何将数据从外存向内存搬运。</p>
<ul>
<li>我们知道，外存尺寸要比内存大的多，因此只能将部分数据载入内存，供用户访问。那每次载入哪些数据、每次逐出哪些数据，就是一个需要设计的策略，或者说算法——Buffer Pool，LRU</li>
<li>我们又知道，IO 相比 CPU 慢的多，数据访问多有局部性原理，因此每次去外存拿数据总倾向于“批发”，那每次批发的量，也是一个需要考量的点——Block，Page<br>  <span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzM1MzgyNTkzL2Fuc3dlci8yNzk1ODIzODY2I3JlZl84">[8]<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p>最后，还需要考虑如何将数据从内存向每个 CPU 腾挪，准确来说，这已经属于查询引擎范畴，为了逻辑连贯，我们将其放在此处。</p>
<ul>
<li>单核 CPU 遭遇瓶颈，只能向多核发展，那如何将内存中的数据喂给每个 CPU —— Cache Line 对齐</li>
<li>多个 CPU 需要进行协同，如何编排多个 CPU 的执行，如何串接多个 CPU 的输入输出——锁、信号量、队列</li>
</ul>
<p>而数据如何在内存中组织，是两个引擎都会涉及到的事情。</p>
<ul>
<li>行存还是列存。后者可以使用 SIMD 优化。</li>
<li>稀疏还是稠密。NULL 数据多少。</li>
<li>同构还是异构。是否需要支持动态类型和嵌套类型。</li>
</ul>
<p>然而，上述只考虑了数据在单机中的组织。如果单机无法提供目标<strong>存储容量</strong>和<strong>吞吐量</strong>，就需要考虑分布式系统——将多个机器通过网络连接在一起，作为一个整体对外提供服务。</p>
<p>于是我们又引入了很不靠谱（相比单机总线）的网络和难以严格同步的时钟，如何对齐进行处理，又是另外一个长长的故事了。虽然当代数据库无一不需要多机协同，但限于篇幅问题，就此打住了。对此感兴趣的可以看看我们的 DDIA 读书会的分享：<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">https://ddia.qtmuniao.com/<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>数据库权威排名 DB-Engines <span class="exturl" data-url="aHR0cHM6Ly9kYi1lbmdpbmVzLmNvbS9lbi9yYW5raW5n">https://db-engines.com/en/ranking<i class="fa fa-external-link-alt"></i></span></li>
<li>计算机存储体系 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTWVtb3J5X2hpZXJhcmNoeQ==">https://en.wikipedia.org/wiki/Memory_hierarchy<i class="fa fa-external-link-alt"></i></span></li>
<li>可持久化内存 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvUGVyc2lzdGVudF9tZW1vcnk=">https://en.wikipedia.org/wiki/Persistent_memory<i class="fa fa-external-link-alt"></i></span></li>
<li>英特尔® 傲腾™ 持久内存 <span class="exturl" data-url="aHR0cHM6Ly93d3cuaW50ZWwuY24vY29udGVudC93d3cvY24vemgvYXJjaGl0ZWN0dXJlLWFuZC10ZWNobm9sb2d5L29wdGFuZS1kYy1wZXJzaXN0ZW50LW1lbW9yeS5odG1s">https://www.intel.cn/content/www/cn/zh/architecture-and-technology/optane-dc-persistent-memory.html<i class="fa fa-external-link-alt"></i></span></li>
<li>Amazon Simple Storage Service (Amazon S3) <span class="exturl" data-url="aHR0cHM6Ly9hd3MuYW1hem9uLmNvbS9jbi9zMy8=">https://aws.amazon.com/cn/s3/<i class="fa fa-external-link-alt"></i></span></li>
<li>自动机编程 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQXV0b21hdGEtYmFzZWRfcHJvZ3JhbW1pbmc=">https://en.wikipedia.org/wiki/Automata-based_programming<i class="fa fa-external-link-alt"></i></span></li>
<li>声明式语言 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRGVjbGFyYXRpdmVfcHJvZ3JhbW1pbmc=">https://en.wikipedia.org/wiki/Declarative_programming<i class="fa fa-external-link-alt"></i></span></li>
<li>访问的局部性原理 <span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTG9jYWxpdHlfb2ZfcmVmZXJlbmNl">https://en.wikipedia.org/wiki/Locality_of_reference<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title>DDIA 读书笔记（五）：冗余</title>
    <url>/2022/10/17/ddia-reading-chapter5/</url>
    <content><![CDATA[<blockquote>
<p>DDIA 读书分享会，会逐章进行分享，结合我在工业界分布式存储和数据库的一些经验，补充一些细节。每两周左右分享一次，欢迎加入，Schedule 和所有文字稿在<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">这里<i class="fa fa-external-link-alt"></i></span>。我们有个对应的分布式&amp;数据库讨论群，每次分享前会在群里通知。如想加入，可以加我的微信号：qtmuniao，简单自我介绍下，并注明：分布式系统群。另外，我的公众号：“木鸟杂记”，有更多的分布式系统、存储和数据库相关的文章，欢迎关注<br>本书第一部分讲单机数据系统，第二部分讲多机数据系统。</p>
</blockquote>
<p><strong>冗余（Replication）</strong> 是指将同一份数据复制多份，放到通过网络互联的多个机器上去。其好处有：</p>
<ol>
<li><strong>降低延迟</strong>：可以在地理上同时接近不同地区的用户。</li>
<li><strong>提高可用性</strong>：当系统部分故障时仍然能够正常提供服务。</li>
<li><strong>提高读吞吐</strong>：平滑扩展可用于查询的机器。</li>
</ol>
<blockquote>
<p>本章假设我们的数据系统中所有数据能够存放到一台机器中，则本章只需考虑多机冗余的问题。如果数据超过单机尺度该怎么办？那是下一章要解决的事情。</p>
</blockquote>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/10/17/ddia-reading-chapter5">https://www.qtmuniao.com/2022/10/17/ddia-reading-chapter5</a> 转载请注明出处</em></p>
<p>如果数据是<strong>只读</strong>的，则冗余很好做，直接复制到多机即可。我们有时可以利用这个特性，使用分治策略，将数据分为只读部分和读写部分，则只读部分的冗余就会容易处理的多，甚至可以用 EC 方式做冗余，减小存储放大的同时，还提高了可用性。</p>
<ul>
<li><p>想想 EC 牺牲了什么？</p>
<p>  以计算换存储。</p>
</li>
</ul>
<p>但难点就在于，数据允许数据变更时，如何维护多机冗余且一致。常用的冗余控制算法有：</p>
<ol>
<li>单领导者（single leader）</li>
<li>多领导者（multi-leader）</li>
<li>无领导者（leaderless）</li>
</ol>
<p>这需要在多方面做取舍：</p>
<ol>
<li>使用同步复制还是异步复制</li>
<li>如何处理失败的副本</li>
</ol>
<p>数据库冗余问题在学术界不是一个新问题了，但在工业界，大部分人都是新手——分布式数据库是近些年才大规模的在工业界落地的。</p>
<h1 id="领导者与跟随者"><a href="#领导者与跟随者" class="headerlink" title="领导者与跟随者"></a>领导者与跟随者</h1><p>冗余存储的每份数据称为<strong>副本</strong>（replica）。多副本所带来的最主要的一个问题是：如何保证所有数据被同步到了所有副本上？</p>
<p>基于<strong>领导者（leader-based）</strong> 的同步算法，是最常用解决办法。</p>
<ol>
<li>其中一个副本称为<strong>领导者</strong>（leader），别称<strong>主副本</strong>（primary、master）。主副本作为写入的协调者，所有写入都要发给主副本。</li>
<li>其他副本称为<strong>跟随者</strong>（follower），也称为<strong>只读副本</strong>（read replicas）、<strong>从副本</strong>（slaves）、<strong>次副本</strong>（secondaries）、<strong>热备</strong>（hot-standby）。主副本将改动写到本地后，将其发送给各个从副本，从副本收变动到后应用到自己状态机，这个过程称为<strong>日志同步</strong>（replication log）、<strong>变更流</strong>（change steam）。</li>
<li>对于读取，客户端可以从主副本和从副本中读取；但写入，客户端只能将请求发到主副本。</li>
</ol>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig01.png" alt="leader based replication"></p>
<p>根据我的习惯，下面通称主副本和从副本。</p>
<p>有很多<strong>数据系统</strong>都用了此模式：</p>
<ol>
<li><strong>关系型数据库</strong>：PostgreSQL（9.0+）、MySQL 和 Oracle Data Guard 和 SQL Server 的 AlwaysOn</li>
<li><strong>非关系型数据库</strong>：MonogoDB、RethinkDB 和 Espresso</li>
<li><strong>消息队列</strong>：Kafka 和 RabbitMQ。</li>
</ol>
<h2 id="同步复制和异步复制"><a href="#同步复制和异步复制" class="headerlink" title="同步复制和异步复制"></a>同步复制和异步复制</h2><p><strong>同步（synchronously）复制</strong>和<strong>异步（asynchronously）复制</strong>和关键区别在于：请求何时返回给客户端。</p>
<ol>
<li>如果等待某副本写完成后，则该副本为同步复制。</li>
<li>如果不等待某副本写完成，则该副本为异步复制。</li>
</ol>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig02.png" alt="leader based sync and async"></p>
<p>两者的对比如下：</p>
<ol>
<li>同步复制牺牲了<strong>响应延迟</strong>和<strong>部分可用性</strong>（在某些副本有问题时不能完成写入操作），换取了所有副本的一致性（但并不能严格保证）。</li>
<li>异步复制放松了<strong>一致性</strong>，而换来了较低的写入延迟和较高的可用性。</li>
</ol>
<p>在实践中，会根据对一致性和可用性的要求，进行取舍。针对所有从副本来说，可以有以下选择：</p>
<ol>
<li><strong>全同步</strong>：所有的从副本都同步写入。如果副本数过多，可能性能较差，当然也可以做并行化、流水线化处理。</li>
<li><strong>半同步</strong>：（<strong>semi-synchronous</strong>），有一些副本为同步，另一些副本为异步。</li>
<li><strong>全异步</strong>：所有的从副本都异步写入。网络环境比较好的话，可以这么配置。</li>
</ol>
<blockquote>
<p>异步复制可能会造成副本丢失等严重问题，为了能兼顾一致性和性能，学术界也在不断研究新的复制方法。如，<strong>链式复制（chain-replication）</strong>。</p>
<p>多副本的一致性和共识性有诸多联系，本书后面章节会讨论。</p>
</blockquote>
<h2 id="新增副本"><a href="#新增副本" class="headerlink" title="新增副本"></a>新增副本</h2><p>在很多情况下，需要给现有系统新增副本。</p>
<p>如果原副本是只读（read-only）的，只需要简单拷贝即可。但是如果是可写副本，则问题要复杂很多。因此，比较简单的一种解决方法是：禁止写入，然后拷贝。这在某些情况下很有用，比如夜间没有写入流量，同时一晚上肯定能复制完。</p>
<p>如果要不停机，可以：</p>
<ol>
<li>主副本在本地做<strong>一致性</strong>快照。何谓一致性？</li>
<li>将快照复制到从副本节点。</li>
<li>从主副本拉取快照之后的操作日志，应用到从副本。如何知道快照与其后日志的对应关系？序列号。</li>
<li>当从副本赶上主副本进度后，就可以正常跟随主副本了。</li>
</ol>
<p>这个过程一般是自动化的，比如 Raft 中；当然也可以手动化，比如写一些脚本。</p>
<h2 id="宕机处理"><a href="#宕机处理" class="headerlink" title="宕机处理"></a>宕机处理</h2><p>系统中任何节点都可能在计划内或者计划外宕机。那么如何应对这些宕机情况，保持整个系统的可用性呢？</p>
<h3 id="从副本宕机：追赶恢复。"><a href="#从副本宕机：追赶恢复。" class="headerlink" title="从副本宕机：追赶恢复。"></a><strong>从副本宕机：追赶恢复</strong>。</h3><p>类似于新增从副本。如果落后的多，可以直接向主副本拉取快照+日志；如果落后的少，可以仅拉取缺失日志。</p>
<h3 id="主副本宕机：故障转移。"><a href="#主副本宕机：故障转移。" class="headerlink" title="主副本宕机：故障转移。"></a><strong>主副本宕机：故障转移。</strong></h3><p>处理相对麻烦，首先要选出新的主副本，然后要通知所有客户端主副本变更。具体来说，包含下面步骤：</p>
<ol>
<li><strong>确认主副本故障</strong>。要防止由于网络抖动造成的误判。一般会用心跳探活，并设置合理超时（timeout）阈值，超过阈值后没有收到该节点心跳，则认为该节点故障。</li>
<li><strong>选择新的主副本</strong>。新的主副本可以通过<strong>选举</strong>（共识问题）或者<strong>指定</strong>（外部控制程序）来产生。选主时，要保证备选节点数据尽可能的新，以最小化数据损失。</li>
<li><strong>让系统感知新主副本</strong>。系统其他参与方，包括从副本、客户端和旧主副本。前两者不多说，旧主副本在恢复时，需要通过某种手段，让其知道已经失去领导权，避免<strong>脑裂</strong>。</li>
</ol>
<p>主副本切换时，会遇到很多问题：</p>
<ol>
<li><strong>新老主副本数据冲突</strong>。新主副本在上位前没有同步完所有日志，旧主副本恢复后，可能会发现和新主副本数据冲突。</li>
<li><strong>相关外部系统冲突</strong>。即新主副本，和使用该副本数据的外部系统冲突。书中举了 github 数据库 MySQL 和缓存系统 redis 冲突的例子。</li>
<li><strong>新老主副本角色冲突</strong>。即新老主副本都以为自己才是主副本，称为<strong>脑裂（split brain）</strong>。如果他们两个都能接受写入，且没有冲突解决机制，数据会丢失或者损坏。有的系统会在检测到脑裂后，关闭其中一个副本，但设计的不好可能将两个主副本都关闭调。</li>
<li><strong>超时阈值选取</strong>。如果超时阈值选取的过小，在不稳定的网络环境中（或者主副本负载过高）可能会造成主副本频繁的切换；如果选取过大，则不能及时进行故障切换，且恢复时间也增长，从而造成服务长时间不可用。</li>
</ol>
<p>所有上述问题，在不同需求、不同环境、不同时间点，都可能会有不同的解决方案。因此在系统上线初期，不少运维团队更愿意手动进行切换；等积累一定经验后，再进行逐步自动化。</p>
<p>节点故障；不可靠网络；在一致性、持久化、可用性和延迟间的取舍；等等问题，都是设计分布式系统时，所面临的的基本问题。根据实际情况，对这些问题进行艺术化的取舍，便是分布式系统之美。</p>
<h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><p>在数据库中，基于领导者的多副本是如何实现的？在不同层次有多种方法，包括：</p>
<ol>
<li><strong>语句层面的复制。</strong></li>
<li><strong>预写日志的复制</strong>。</li>
<li><strong>逻辑日志的复制</strong>。</li>
<li><strong>触发器的复制</strong>。</li>
</ol>
<p>对于一个<strong>系统</strong>来说，多副本同步的是什么？<strong>增量修改</strong>。</p>
<p>具体到一个由数据库构成的<strong>数据系统</strong>，通常由数据库外部的<strong>应用层</strong>、数据库内部<strong>查询层</strong>和<strong>存储层</strong>组成。<strong>修改</strong>在查询层表现为：语句；在存储层表现为：存储引擎相关的预写日志、存储引擎无关的逻辑日志；修改完成后，在应用层表现为：触发器逻辑。</p>
<h3 id="基于语句的复制"><a href="#基于语句的复制" class="headerlink" title="基于语句的复制"></a>基于语句的复制</h3><p>主副本记录下所有更新语句：<code>INSERT</code>、<code>UPDATE</code> 或 <code>DELETE</code> 然后发给从库。主副本在这里类似于充当其他从副本的<strong>伪客户端</strong>。</p>
<p>但这种方法有一些问题：</p>
<ol>
<li><strong>非确定性函数（nondeterministic）</strong>的语句可能会在不同副本造成不同改动。如 NOW()、RAND()</li>
<li><strong>使用自增列，或依赖于现有数据</strong>。则不同用户的语句需要完全按相同顺序执行，当有并发事务时，可能会造成不同的执行顺序，进而导致副本不一致。</li>
<li><strong>有副作用</strong>（触发器、存储过程、UDF）的语句，可能不同副本由于上下文不同，产生的副作用不一样。除非副作用是确定的输出。</li>
</ol>
<p>当然也有解决办法：</p>
<ol>
<li>识别所有产生非确定性结果的语句。</li>
<li>对于这些语句同步值而非语句。</li>
</ol>
<p>但是 Corner Case 实在太多，步骤 1 需要考虑的情况太多。</p>
<h3 id="传输预写日志（-WAL）"><a href="#传输预写日志（-WAL）" class="headerlink" title="传输预写日志（ WAL）"></a>传输预写日志（ WAL）</h3><p>我们发现主流的存储引擎都有<strong>预写日志</strong>（WAL，为了宕机恢复）：</p>
<ol>
<li>对于日志流派（LSM-Tree，如 LevelDB），每次修改先写入 log 文件，防止写入 MemTable 中的数据丢失。</li>
<li>对于原地更新流派（B+ Tree），每次修改先写入 WAL，以进行崩溃恢复。</li>
</ol>
<p>所有用户层面的改动，最终都要作为状态落到存储引擎里，而存储引擎通常会维护一个：</p>
<ol>
<li>追加写入</li>
<li>可重放</li>
</ol>
<p>这种结构，天然适合备份同步。本质是因为磁盘的读写特点和网络类似：<strong>磁盘是顺序写比较高效，网络是只支持流式写</strong>。具体来说，主副本在写入 WAL 时，会同时通过网络发送对应的日志给所有从副本。</p>
<p>书中提到一个数据库版本升级的问题：</p>
<ol>
<li>如果允许旧版本代码给新版本代码（应该会自然做到后向兼容）发送日志（前向兼容）。则在升级时可以先升级从库，再切换升级主库。</li>
<li>否则，只能进行停机升级软件版本。</li>
</ol>
<h3 id="逻辑日志复制（基于行）"><a href="#逻辑日志复制（基于行）" class="headerlink" title="逻辑日志复制（基于行）"></a>逻辑日志复制（基于行）</h3><p>为了和具体的存储引擎物理格式解耦，在做数据同步时，可以使用不同的日志格式：<strong>逻辑日志</strong>。</p>
<p>对于关系型数据库来说，行是一个合适的粒度：</p>
<ol>
<li><strong>对于插入行</strong>：日志需包含所有列值。</li>
<li><strong>对于删除行</strong>：日志需要包含待删除行标识，可以是主键，也可以是其他任何可以唯一标识行的信息。</li>
<li><strong>对于更新行</strong>：日志需要包含待更新行的标志，以及所有列值（至少是要更新的列值）</li>
</ol>
<p>对于多行修改来说，比如事务，可以在修改之后增加一条事务提交的记录。 MySQL 的 binlog 就是这么干的。</p>
<p>使用逻辑日志的<strong>好处</strong>有：</p>
<ol>
<li>方便新旧版本的代码兼容，更好的进行滚动升级。</li>
<li>允许不同副本使用不同的存储引擎。</li>
<li>允许导出变动做各种<strong>变换</strong>。如导出到数据仓库进行离线分析、建立索引、增加缓存等等。</li>
</ol>
<p>之前分析过一种基于日志，统一各种数据系统的<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NTg2ODMxNjQ=">文章<i class="fa fa-external-link-alt"></i></span>，很有意思。</p>
<h3 id="基于触发器的复制"><a href="#基于触发器的复制" class="headerlink" title="基于触发器的复制"></a>基于触发器的复制</h3><p>前面所说方法，都是在<strong>数据库内部</strong>对数据进行多副本同步。</p>
<p>但有些情况下，可能需要用户决策，如何对数据进行复制：</p>
<ol>
<li>对需要复制的数据进行过滤，只复制一个子集。</li>
<li>将数据从一种数据库复制到另外一种数据库。</li>
</ol>
<p>有些数据库如 Oracle 会提供一些工具。但对于另外一些数据库，可以使用<strong>触发器和存储过程</strong>。即，将用户代码 hook 到数据库中去执行。</p>
<p>基于触发器的复制，性能较差且更易出错；但是给了用户更多的灵活性。</p>
<h1 id="复制滞后问题"><a href="#复制滞后问题" class="headerlink" title="复制滞后问题"></a>复制滞后问题</h1><p> 如前所述，使用多副本的好处有：</p>
<ol>
<li><strong>可用性</strong>：容忍部分节点故障</li>
<li><strong>可伸缩性</strong>：增加读副本处理更多读请求</li>
<li><strong>低延迟</strong>：让用户选择一个就近的副本访问</li>
</ol>
<p>对于读多写少的场景，想象中，可以通过使劲增加读副本来均摊流量。但有个<strong>隐含</strong>的条件是，多副本建的同步得做成<strong>异步</strong>的，否则，读副本一多，某些副本就很容易出故障，进而阻塞写入。</p>
<p>但若是异步复制，就会引入不一致问题：某些副本进度落后于主副本。</p>
<p>如果此时不再有写入，经过一段时间后，多副本最终会达到一致：<strong>最终一致性</strong>。</p>
<p>在实际中，网络通常比较快，<strong>副本滞后（replication lag）</strong>不太久，也即这个<em>最终</em><strong>通常</strong>不会太久，比如 ms 级别，最多 s 级别。但是，对于分布式系统，谁都不敢打包票，由于网络分区、机器高负载等等软硬件问题，在极端情况下，这个<em>最终</em>可能会非常久。</p>
<blockquote>
<p>总之，<strong>最终</strong>是一个非常不精确的限定词。</p>
</blockquote>
<p>对于这种最终一致的系统，在工程中，要考虑到由于副本滞后所带来的一致性问题。</p>
<h2 id="读你所写"><a href="#读你所写" class="headerlink" title="读你所写"></a>读你所写</h2><p><img src="https://ddia.qtmuniao.com/img/ch05-fig03.png" alt="read after write"></p>
<p>上图问题在于，在一个<strong>异步复制</strong>的分布式数据库里，同一个客户端，写入<strong>主副本</strong>后返回；稍后再去读一个落后的<strong>从副本</strong>，就会发现：读不到自己刚写的内容！</p>
<p>为了避免这种反直觉的事情发生，我们引入一种新的一致性：<strong>读写一致性（read-after-write consistency）</strong>，或者 <strong>读你所写一致性（read-your-writes consistency）</strong>。</p>
<p>若数据库提供这种一致性保证，对于<strong>单个客户端</strong>来说，就一定能够读到其所写变动。也即，这种一致性是从<strong>单个客户端</strong>角度来看的一种因果一致性。</p>
<p>那么如何提供这种保证，或者说，实现这种一致性呢？列举几种方案：</p>
<ol>
<li><strong>按内容分类</strong>。对于客户端可能修改的内容集，<strong>只从主副本读取</strong>。如社交网络上的个人资料，读自己的资料时，从主副本读取；但读其他人资料时，可以向从副本读。</li>
<li><strong>按时间分类</strong>。 如果每个客户端都能访问基本所有数据，则方案一就会退化成所有数据都要从主副本读取，这显然不可接受。此时，可以按时间分情况讨论，近期内有过改动的数据，从主副本读，其他的，向从副本读。那这个区分是否最近的<strong>时间阈值</strong>（比如一分钟）如何选取呢？可以监控从副本一段时间内的最大延迟这个经验值，来设置。</li>
<li><strong>利用时间戳</strong>。客户端记下本客户端上次改动时的时间戳，在读从副本时，利用此时间戳来看某个从副本是否已经同步了改时间戳之前内容。可以在所有副本中找到一个已同步了的；或者阻塞等待某个副本同步到改时间戳后再读取。时间戳可以是逻辑时间戳，也可以是物理时间戳（此时多机时钟同步非常重要）。</li>
</ol>
<p>会有一些实际的复杂 case：</p>
<ol>
<li><strong>数据分布在多个物理中心</strong>。所有需要发送给主副本的请求都要首先路由到主副本所在的数据中心。</li>
<li><strong>一个逻辑用户有多个物理客户端</strong>。比如一个用户通过电脑、手机多终端同时访问，此时就不能用设备 id，而需要使用用户 id，来保证用户角度的读写一致性。但不同设备有不同物理时间戳，不同设备访问时可能会路由到不同数据中心。</li>
</ol>
<h2 id="单调读"><a href="#单调读" class="headerlink" title="单调读"></a>单调读</h2><p>异步复制可能带来的另外一个问题：对于一个客户端来说，系统可能会发生<strong>时光倒流（moving backward in time）</strong>。</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig04.png" alt="monotonic reads"></p>
<p>于是，我们再引入一种一致性保证：<strong>单调读（Monotonic reads）</strong>。</p>
<ul>
<li><p>读写一致性和单调读有什么区别？</p>
<p>  写后读保证的是写后读顺序，单调读保证的是<strong>多次读</strong>之间的顺序。</p>
</li>
</ul>
<p>如何实现单调读？</p>
<ol>
<li>只从一个副本读数据。</li>
<li>前面提到的时间戳机制。</li>
</ol>
<h2 id="一致前缀读"><a href="#一致前缀读" class="headerlink" title="一致前缀读"></a>一致前缀读</h2><p><img src="https://ddia.qtmuniao.com/img/ch05-fig05.png" alt="lower partition"></p>
<p>异步复制所带来的第三个问题：有时候会违反因果关系。</p>
<p>本质在于：如果数据库由多个分区（Partition）组成，而分区间的事件顺序无法保证。此时，如果有因果关系的两个事件落在了不同分区，则有可能会出现<strong>果在前，因在后</strong>。</p>
<p>为了防止这种问题，我们又引入了一种一致性：<strong>一致前缀读（consistent prefix reads）</strong>。奇怪的名字。</p>
<p>实现这种一致性保证的方法：</p>
<ol>
<li>不分区。</li>
<li>让所有有因果关系的事件路由到一个分区。</li>
</ol>
<p>但如何追踪因果关系是个难题。</p>
<h2 id="副本滞后的终极解决方案"><a href="#副本滞后的终极解决方案" class="headerlink" title="副本滞后的终极解决方案"></a>副本滞后的终极解决方案</h2><p>事务！</p>
<p>多副本异步复制所带来的一致性问题，都可以通过<strong>事务（transaction）</strong>来解决。单机事务已经存在了很长时间，但在数据库走向分布式时代，一开始很多 NoSQL 系统抛弃了事务。</p>
<ul>
<li>这是为什么？<ol>
<li>更容易的实现。2. 更好的性能。3. 更好的可用性。</li>
</ol>
</li>
</ul>
<p>于是复杂度被转移到了应用层。</p>
<p>这是数据库系统刚大规模步入分布式（<strong>多副本、多分区</strong>）时代的一种妥，在经验积累的够多之后，事务必然会被引回。</p>
<p>于是近年来越来越多的分布式数据库开始支持事务，是为<strong>分布式事务</strong>。</p>
<h1 id="多主模型"><a href="#多主模型" class="headerlink" title="多主模型"></a>多主模型</h1><p><strong>单主模型一个最大问题</strong>：所有写入都要经过它，如果由于任何原因，客户端无法连接到主副本，就无法向数据库写入。</p>
<p>于是自然产生一种想法：多主行不行？</p>
<p><strong>多主复制（multi-leader replication）</strong>：有多个可以接受写入的主副本，每个主副本在接收到写入之后，都要转给所有其他副本。即一个系统，有多个<strong>写入点</strong>。</p>
<h2 id="多主模型应用场景"><a href="#多主模型应用场景" class="headerlink" title="多主模型应用场景"></a>多主模型应用场景</h2><p>单个数据中心，多主模型意义不大：复杂度超过了收益。总体而言，由于一致性等问题，多主模型应用场景较少，但有一些场景，很适合多主：</p>
<ol>
<li>数据库横跨多个数据中心</li>
<li>需要离线工作的客户端</li>
<li>协同编辑</li>
</ol>
<h3 id="多个数据中心"><a href="#多个数据中心" class="headerlink" title="多个数据中心"></a>多个数据中心</h3><p>假设一个数据库的副本，横跨多个数据中心，如果使用单主模型，在写入时的延迟会很大。那么每个数据中心能不能各配一个主副本？</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig06.png" alt="multi-leader across multiple data centers"></p>
<p>单主和多主，在多数据中心场景下的对比：</p>
<table>
<thead>
<tr>
<th>对比项</th>
<th>单主模型</th>
<th>多主模型</th>
</tr>
</thead>
<tbody><tr>
<td>性能</td>
<td>所有写入都要路由到一个数据中心</td>
<td>写入可以就近</td>
</tr>
<tr>
<td>可用性</td>
<td>主副本所在数据中心故障，需要有个切主的过程</td>
<td>每个数据中心可以独立工作</td>
</tr>
<tr>
<td>网络</td>
<td>跨数据中心，写入对网络抖动更敏感</td>
<td>数据中心间异步复制，对公网容错性更高</td>
</tr>
</tbody></table>
<p>但是多主模型在一致性方面有很大缺陷：如果两个数据中心同时修改同样的数据，必须合理解决写冲突。另外，对于数据库来说，多主很难保证一些自增主键、触发器和完整性约束的一致性。因此在工程实践中，多主用的相对较少。</p>
<h3 id="离线工作的客户端"><a href="#离线工作的客户端" class="headerlink" title="离线工作的客户端"></a>离线工作的客户端</h3><p>离线工作的一个应用的多个设备上的客户端，如果也允许继续写入数据。如：日历应用。在电脑上和手机上离线时如果也支持添加日程。则在各个设备联网时，需要互相同步数据。</p>
<p>则离线后还继续工作的多个副本，本质上就是一个多主模型：每个主都可以独立的写入数据，然后在网络连通后解决冲突。</p>
<p>但，如何支持离线后正常地工作，联网后优雅的解决冲突，是一个难题。</p>
<p>Apache CouchDB 的一个特点便是支持多主模型。</p>
<h3 id="协同编辑"><a href="#协同编辑" class="headerlink" title="协同编辑"></a>协同编辑</h3><p>Google Docs 等类似 SaaS 模式的在线协同应用越来越流行。</p>
<p>这种应用允许多人在线同时编辑文档或者电子表格，其背后的原理，与上一节离线工作的客户端很像。</p>
<p>为了实现协同，并解决冲突，可以：</p>
<ol>
<li><strong>悲观方式</strong>。加锁以避免冲突，但粒度需要尽可能小，否则无法允许多人同时编辑一个文档。</li>
<li><strong>乐观方式</strong>。允许每个用户无脑写入，然后如果有冲突，交由用户解决。</li>
</ol>
<p>git 也是一个类似的协议。</p>
<h2 id="处理写入冲突"><a href="#处理写入冲突" class="headerlink" title="处理写入冲突"></a>处理写入冲突</h2><p>多主模型最大的问题是：如何解决冲突。</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig07.png" alt="write conflict"></p>
<p>考虑 wiki 一个页面标题的修改：</p>
<ol>
<li>用户 1 将该页面标题从 A 修改到 B</li>
<li>用户 2 将该页面标题从 A 修改到 C</li>
</ol>
<p>两个操作在本地都修改成功，然后<strong>异步同步</strong>时，会出现冲突。</p>
<h3 id="冲突检测"><a href="#冲突检测" class="headerlink" title="冲突检测"></a>冲突检测</h3><p><strong>有同步</strong>或者<strong>异步</strong>的方式进行冲突检测。</p>
<p>对于<strong>单主模型</strong>，当检测到冲突时，由于只有一个主副本，可以同步的检测冲突，从而解决冲突：</p>
<ol>
<li>让第二个写入阻塞，直到第一个写完成。</li>
<li>让第二个写入失败，进行重试。</li>
</ol>
<p>但对于<strong>多主模型</strong>，两个写入可能会在不同主副本立即成功。然后异步同步时，发现冲突，但为时已晚（没有办法简单决定如何解决冲突）。</p>
<p>虽然，可以在多主间使用同步方式写入所有副本后，再返回请求给客户端。但这会失掉多主模型的主要优点：<strong>允许多个主副本独立接受写入</strong>。此时，蜕化成单主模型。</p>
<h3 id="冲突避免"><a href="#冲突避免" class="headerlink" title="冲突避免"></a>冲突避免</h3><p><strong>解决冲突最好的方式是在设计上避免冲突</strong>。</p>
<p>由于多主模型在冲突发生后再去解决会有很大的复杂度，因此常使用冲突避免的设计。</p>
<p>假设你的数据集可以分成多个分区，让不同分区的主副本放在不同数据中心中，那么从任何一个分区的角度来看，变成了单主模型。</p>
<p>举个栗子：对于服务全球用户的应用，每个用户就近固定路由到附近的数据中心。则，每个用户信息都有唯一的主副本。</p>
<p>但如果：</p>
<ol>
<li>用户从一个地点迁移到了另一个地点</li>
<li>某个数据中心损坏，导致路由变化</li>
</ol>
<p>就会对该设计提出一些挑战。</p>
<h3 id="冲突收敛"><a href="#冲突收敛" class="headerlink" title="冲突收敛"></a>冲突收敛</h3><p>在单主模型中，所有事件比较容易进行<strong>定序</strong>，因此我们总可以用后一个写入覆盖前一个写入。</p>
<p>但在多主模型中，很多冲突无法定序：<strong>从每个主副本来看，事件顺序是不一致的</strong>，并且没有哪个更权威一些，那么就无法让所有副本最终<strong>收敛（convergent）</strong>。</p>
<p>此时，我们就需要一些规则，来让其收敛：</p>
<ol>
<li><strong>给每个写入一个序号，并且后者胜</strong>。本质上是使用外部系统对所有事件进行定序。但可能会产生数据丢失。举个例子，对于一个账户，原有 10 元，客户端 A - 8，客户端 B - 3，任何一个单独成功都有问题。</li>
<li><strong>给每个副本一个序号，序号更高的副本有更高的优先级</strong>。这也会造成低序号副本的数据丢失。</li>
<li><strong>提供一种自动的合并冲突的方式</strong>。如，假设结果是字符串，则可以将其排序后，使用连接符进行链接，如在之前 Wiki 的冲突中，合并后的标题为 “B&#x2F;C”</li>
<li><strong>使用程序定制一种保留所有冲突值信息的冲突解决策略</strong>。也可以将这个定制权，交给用户。</li>
</ol>
<h3 id="自定义解决"><a href="#自定义解决" class="headerlink" title="自定义解决"></a>自定义解决</h3><p>由于只有用户知道数据本身的信息，因此较好的方式是，将如何解决冲突交给用户。即，允许用户编写回调代码，提供冲突解决逻。该回调可以在：</p>
<ol>
<li><strong>写时执行</strong>。在写入时发现冲突，调用回调代码，解决冲突后写入。这些代码通常在后台执行，并且不能阻塞，因此不能在调用时同步的通知用户。但打个日志之类的还是可以的。</li>
<li><strong>读时执行</strong>。在写入冲突时，所有冲突都会被保留（如使用多版本）。下次读取时，系统会将所有数据本版本返回给用户，进行交互式的或者自动的解决冲突，并将结果写回系统。</li>
</ol>
<p>上述冲突解决只限于单个记录、行、文档层面。</p>
<p>TODO（自动冲突解决）</p>
<h3 id="界定冲突"><a href="#界定冲突" class="headerlink" title="界定冲突"></a>界定冲突</h3><p>有些冲突显而易见：并发写同一个 Key。</p>
<p>有些冲突则更隐晦，考虑一个会议室预定系统。预定同一个会议室不一定会发生冲突，只有预定时间段有交叠，才会有冲突。</p>
<h2 id="多主复制拓扑"><a href="#多主复制拓扑" class="headerlink" title="多主复制拓扑"></a>多主复制拓扑</h2><p><strong>复制拓扑</strong>（replication topology）描述了数据写入从一个节点到另一个节点的传播路径。</p>
<p>在只有两个主副本时，拓扑是确定的，如图 5-7。Leader1 和 Leader 都得把数据发给对方。但随着副本数的增多，数据复制拓扑就会有多种选择，如下图：</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig08.png" alt="multi-leader topologies"></p>
<p>上图表示了 ≥ 4 个主副本时，常见的复制拓扑：</p>
<ol>
<li><strong>环形拓扑</strong>。通信跳数少，但是在转发时需要带上拓扑中前驱节点信息。如果一个节点故障，则可能中断复制链路。</li>
<li><strong>星型拓扑</strong>。中心节点负责接受并转发数据。如果中心节点故障，则会使得整个拓扑瘫痪。</li>
<li><strong>全连接拓扑</strong>。每个主库都要把数据发给剩余主库。通信链路冗余度较高，能较好的容错。</li>
</ol>
<p>对于环形拓扑和星型拓扑，为了防止广播风暴，需要对每个节点打上一个唯一标志（ID），在收到他人发来的自己的数据时，及时丢弃并终止传播。</p>
<p>全连接拓扑也有自己问题：<strong>尤其是所有复制链路速度不一致时</strong>。考虑下面一个例子：</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig09.png" alt="writes wrong order"></p>
<p>两个有因果依赖的（先插入，后更新）的语句，在复制到 Leader 2 时，由于速度不同，导致其接收到的数据违反了因果一致性。</p>
<p>要想对这些写入事件进行全局排序，仅用每个 Leader 的物理时钟是不够的，因为物理时钟：</p>
<ol>
<li>可能不能够充分同步</li>
<li>同步时可能会发生回退</li>
</ol>
<p>可以用一种叫做<strong>版本向量（version vectors）</strong>的策略，对多个副本的事件进行排序，解决因果一致性问题。下一节会详细讨论。</p>
<p>最后忠告：如果你要使用基于多主模型的系统，一定要知晓上面提到的问题，多做测试，确保其提供的保证符合你的使用场景。</p>
<h1 id="无主模型"><a href="#无主模型" class="headerlink" title="无主模型"></a>无主模型</h1><p>有主模型中，由主副本决定写入顺序，从副本在写入上不直接和客户端打交道，只是重放其对应的主副本的写入顺序（也可以理解为主副本为从副本的客户端）。</p>
<p>而无主模型，则允许任何副本接受写入。</p>
<p>在关系数据库时代，无主模型已经快被忘却。从 Amazon 的 Dynamo 论文开始，无主模型又重新大放异彩，Riak，Cassandra 和 Voldemort 都受其启发，可以统称为 <strong>Dynamo 流（Dynamo-style）</strong>。</p>
<blockquote>
<p>奇特的是，Amazon 的一款数据库产品 DynamoDB，和 Dynamo 并不是一个东西。</p>
</blockquote>
<p>通常来说，在无主模型中，写入时可以：</p>
<ol>
<li>由客户端直接写入副本。</li>
<li>由<strong>协调者（coordinator）</strong>接收写入，转发给多副本。但与主副本不同，协调者并不负责定序。</li>
</ol>
<h2 id="有节点故障时的写入"><a href="#有节点故障时的写入" class="headerlink" title="有节点故障时的写入"></a>有节点故障时的写入</h2><p>基于主副本（leader-based）的模型，在有副本故障时，需要进行故障切换。</p>
<p>但在无主模型中，简单忽略它就行。</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig10.png" alt="quorum write"></p>
<p>多数派写入，多数派读取，以及读时修复。</p>
<p>由于写入时，简单的忽略了宕机副本；在读取时，就要多做些事情了：<strong>同时读取多个副本，选取最新<em>版本</em>的值</strong>。</p>
<h3 id="读时修复和反熵"><a href="#读时修复和反熵" class="headerlink" title="读时修复和反熵"></a>读时修复和反熵</h3><p>无主模型也需要维持多个副本数据的一致性。在某些节点宕机重启后，如何让其弥补错过的数据？</p>
<p>Dynamo 流派的存储中通常有两种机制：</p>
<ol>
<li><strong>读时修复（read repair）</strong>，本质上是一种捎带修复，在读取时发现旧的就顺手修了。</li>
<li><strong>反熵过程（Anti-entropy process）</strong>，本质上是一种兜底修复，读时修复不可能覆盖所有过期数据，因此需要一些后台进程，持续进行扫描，寻找陈旧数据，然后更新。<span class="exturl" data-url="aHR0cHM6Ly93d3cuaW5mbHV4ZGF0YS5jb20vYmxvZy9ldmVudHVhbC1jb25zaXN0ZW5jeS1hbnRpLWVudHJvcHkv">这个博文<i class="fa fa-external-link-alt"></i></span>对该词有展开描述。</li>
</ol>
<h3 id="Quorum-读写"><a href="#Quorum-读写" class="headerlink" title="Quorum 读写"></a>Quorum 读写</h3><p>如果副本总数为 n，写入 w 个副本才认定写入成功，并且在查询时最少需要读取 r 个节点。只要满足 w + r &gt; n，我们就能读到最新的数据（<strong>鸽巢原理</strong>）。此时 r 和 w 的值称为 <strong>quorum 读写</strong>。即这个约束是保证数据有效所需的最低（法定）票数。</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig11.png" alt="w+r&gt;n"></p>
<p>在 Dynamo 流派的存储中，n、r 和 w 通常是可以配置的：</p>
<ol>
<li>n 越大冗余度就越高，也就越可靠。</li>
<li>r 和 w 都常都选择超过半数，如 <code>(n+1)/2</code></li>
<li>w &#x3D; n 时，可以让 r &#x3D; 1。此时是牺牲写入性能换来读取性能。</li>
</ol>
<p>考量满足 w+r &gt; n 系统对节点故障的容忍性：</p>
<ol>
<li>如果 w &lt; n，则有节点不可用时，仍然能正常写入。</li>
<li>如果 r &lt; n，则有节点不可用时，仍然能正常读取。</li>
</ol>
<p>特化一下：</p>
<ol>
<li>如果 n &#x3D; 3，r &#x3D; w &#x3D; 2，则系统可以容忍最多一个节点宕机。</li>
<li>如果 n &#x3D; 5，r &#x3D; w &#x3D; 3，则系统可以容忍最多两个节点宕机。</li>
</ol>
<p>通常来说，我们会将读或者写并行的发到全部 n 个副本，但是只要等到法定个副本的结果，就可以返回。</p>
<p>如果由于某种原因，可用节点数少于 r 或者 w，则读取或者写入就会出错。</p>
<h2 id="quorum-一致性的局限"><a href="#quorum-一致性的局限" class="headerlink" title="quorum 一致性的局限"></a>quorum 一致性的局限</h2><p>由于 w + r &gt; n 时，总会至少有一个节点（读写子集至少有一个节点的交集）保存了最新的数据，因此总是期望能读到最新的。</p>
<p>当 w + r ≤ n 时，则很可能会读到过期的数据。</p>
<p>但在 w + r &gt; n 时，有一些边角情况（corner case），也会导致客户端读不到最新数据：</p>
<ol>
<li>使用宽松的 Quorum 时（n 台机器范围可以发生变化），w 和 r 可能并没有交集。</li>
<li>对于写入并发，如果处理冲突不当时。比如使用 last-win 策略，根据本地时间戳挑选时，可能由于时钟偏差造成数据丢失。</li>
<li>对于读写并发，写操作仅在部分节点成功就被读取，此时不能确定应当返回新值还是旧值。</li>
<li>如果写入节点数 &lt; w 导致写入失败，但并没有对数据进行回滚时，客户端读取时，仍然会读到旧的数据。</li>
<li>虽然写入时，成功节点数  &gt;  w，但中间有故障造成了一些副本宕机，导致成功副本数 &lt; w，则在读取时可能会出现问题。</li>
<li>即使都正常工作，也有可能出现一些关于时序（timing）的边角情况。</li>
</ol>
<p>因此，虽然 Quorum 读写看起来能够保证返回最新值，但在工程实践中，有很多细节需要处理。</p>
<p>如果数据库不遵守之前副本滞后小节引入的几个一致性保障，前面提到的异常仍然可能会发生。</p>
<h3 id="一致性监控"><a href="#一致性监控" class="headerlink" title="一致性监控"></a>一致性监控</h3><p>对副本数据陈旧性监控，能够让你了解副本的健康情况，当其落后太多时，可以及时调查原因。  </p>
<p>基于领导者的多副本模型，由于每个副本复制顺序一致，则可以方便的给出每个副本的落后（lag）进度。</p>
<p>但对于无主模型，由于没有固定写入顺序，副本的落后进度变得难以界定。如果系统只使用读时修复策略，则对于一个副本的落后程度是没有限制的。读取频率很低数据可能版本很老。</p>
<p>最终一致性是一种很模糊的保证，但通过监控能够量化“最终”（比如到一个阈值），也是很棒的。</p>
<h2 id="放松的-Quorum-和提示转交"><a href="#放松的-Quorum-和提示转交" class="headerlink" title="放松的 Quorum 和提示转交"></a>放松的 Quorum 和提示转交</h2><p>正常的 Quorum 能够容忍一些副本节点的宕机。但在大型集群（总节点数目 &gt; n）中，可能最初选中的 n 台机器，由于种种原因（宕机、网络问题），导致无法达到法定读写数目，则此时有两种选择：</p>
<ol>
<li>对于所有无法达到 r 或 w 个法定数目的读写，直接报错。</li>
<li>仍然接受写入，并且将新的写入暂时交给一些正常节点。</li>
</ol>
<p>后者被认为是一种<strong>宽松的法定数目</strong> （<strong>sloppy quorum</strong>）：写和读仍然需要 w 和 r 个成功返回，但是其所在节点集合可以发生变化。</p>
<p><img src="ihttps://ddia.qtmuniao.com/img/ch05-sloppy-quorum.png" alt="sloppy quorum"></p>
<p>一旦问题得到解决，数据将会根据线索移回其应该在的节点（D—&gt; B），我们称之为<strong>提示移交</strong>（hinted handoff）。这个移交过程是由反熵 anti-entropy 后台进程完成的。</p>
<p>这是一种典型的牺牲部分一致性，换取更高可用性的做法。在常见的 Dynamo 实现中，放松的法定人数是可选的。在 Riak 中，它们默认是启用的，而在 Cassandra 和 Voldemort 中它们默认是禁用的</p>
<h3 id="多数据中心"><a href="#多数据中心" class="headerlink" title="多数据中心"></a>多数据中心</h3><p>无主模型也适用于系统多数据中心部署。</p>
<p>为了同时兼顾<strong>多数据中心</strong>和<strong>写入的低延迟</strong>，有一些不同的基于无主模型的多数据中心的策略：</p>
<ol>
<li>其中 Cassandra 和 Voldemort 将 n 配置到所有数据中心，但写入时只等待本数据中心副本完成就可以返回。</li>
<li>Riak 将 n 限制在一个数据中心内，因此所有客户端到存储节点的通信可以限制到单个数据中心内，而数据复制在后台异步进行。</li>
</ol>
<h2 id="并发写入检测"><a href="#并发写入检测" class="headerlink" title="并发写入检测"></a>并发写入检测</h2><p>由于 Dynamo 允许多个客户端并发写入相同 Key，则即使使用严格的 Quorum 读写，也会产生冲突：<strong>对于时间间隔很短（并发）的相同 key 两个写入，不同副本上收到的顺序可能不一致</strong>。</p>
<p>此外，读时修复和提示移交时，也可能产生冲突。</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig12.png" alt="dynamo style datastore"></p>
<p>如上图，如果每个节点不去检查顺序，而是简单的接受写入请求，就落到本地，不同副本间可能就会出现永久不一致：上图 Node1 和 Node3 上副本X 的值是 A，Node2 上副本 X 的值是 B。</p>
<p>为了使所有副本最终一致，需要有一种手段来解决并发冲突。</p>
<h3 id="后者胜（Last-Write-Win）"><a href="#后者胜（Last-Write-Win）" class="headerlink" title="后者胜（Last-Write-Win）"></a>后者胜（Last-Write-Win）</h3><p>后者胜（LWW，last write wins）的策略是，通过某种手段确定一种全局唯一的顺序，然后让后面的修改覆盖之前的修改。</p>
<p>如，为所有写入附加一个全局时间戳，如果对于某个 key 的写入有冲突，可以挑选具有最大时间戳的数据保留，并丢弃较早时间戳的写入。</p>
<p>LWW 有一个问题，就是多个并发写入的客户端，可能都认为自己成功了，但是最终只有一个值被保留了，其他都在后台被丢弃了。即，其迅速再读，会发现不是自己写入的数据。</p>
<p>使用 LWW 唯一安全的方法是：key 是一次可写，后变为只读。如 Cassandra 建议使用一个 UUID 作为主键，则每个写操作都只会有一个唯一的键。</p>
<h3 id="发生于-之前（Happens-before）和并发关系"><a href="#发生于-之前（Happens-before）和并发关系" class="headerlink" title="发生于**之前（Happens-before）和并发关系"></a>发生于**之前（Happens-before）和并发关系</h3><p>考虑之前的两个图：</p>
<ol>
<li>在 5-9 中，由于 client B 的更新依赖于 client A 的插入，因此他们是因果关系。</li>
<li>在 5-12 中，set X &#x3D; A 和 set X &#x3D; B 是并发的，因为他们都互相不知道对方存在，也不存在因果关系。</li>
</ol>
<p>系统中任意的两个写入 A 和 B，只可能存在三种关系：</p>
<ol>
<li>A happens before B</li>
<li>B happens before A</li>
<li>A B  并发</li>
</ol>
<p>从另外一个角度来说（集合运算），</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">A 和 B 并发 &lt; === &gt; A 不 happens-before B  &amp;&amp; B 不 happens-before A</span><br></pre></td></tr></table></figure>

<p>如果两个操作可以定序，则 last write win；如果两个操作并发，则需要进行冲突解决。</p>
<blockquote>
<p>并发、时间和相对性</p>
</blockquote>
<blockquote>
<p>Lamport 时钟相关论文中有详细推导相关概念关系。为了定义并发，事件发生的绝对时间先后并不重要，只要两个事件都意识不到对方的存在，则称两个操作 “并发”。 从狭义相对论上来说，只要两个事件发生的时间差，小于光在两者距离传播所用时间，则两个事件不可能互相影响。推广到计算机网络中，只要由于网络问题导致，在事件发生时间差内，两者不能互相意识到，则称其是并发的。</p>
</blockquote>
<h3 id="确定-Happens-Before-关系"><a href="#确定-Happens-Before-关系" class="headerlink" title="确定 Happens-Before 关系"></a>确定 Happens-Before 关系</h3><p>我们可以用某种算法来确定系统中任意两个事件，是否存在 happens-before 关系，还是并发关系。以一个两个 client 并发添加购物车例子来看：</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig13.png" alt="causal dependencies"></p>
<p>需要注意：</p>
<ol>
<li>不会主动读取，只有主动写入，通过写入的返回值读取数据库当前状态。</li>
<li>客户端下一次写入，<strong>依赖于</strong>（因果关系）<strong>本客户端</strong>上一次写入后获取的返回值。</li>
<li>对于并发，数据库不会覆盖，而是保留多个<strong>并发值</strong>（每个 client 一个）。</li>
</ol>
<p>上图中的数据流，如下图所示。箭头表示 happens-before 关系。本例中，客户端永远没办法完全获知服务器数据，因为总有另外的客户端进行并发操作。但是旧版本的值会被覆盖，并且不会丢失写入。</p>
<p><img src="https://ddia.qtmuniao.com/img/ch05-fig14.png" alt="graph causal dependencies"></p>
<p>总结下，该算法如下：</p>
<ol>
<li>服务器为每个键分配一个版本号 V ，每次该键有写入时，将 V + 1，并将版本号与写入的值一块保存。</li>
<li>当客户端读取该键时，服务器将返回所有未被覆盖的值以及最新的版本号。</li>
<li>客户端在进行下次写入时，必须<strong>包含</strong>之前读到的版本号 Vx（说明基于哪个版本进行新的写入），并将读取的值合并到一块。</li>
<li>当服务器收到特定版本号 Vx 的写入时，可以用其值覆盖所有 V ≤  Vx 的值。、</li>
</ol>
<p>如果又来一个新的写入，不基于任何版本号，则该写入不会覆盖任何内容。</p>
<h3 id="合并并发值"><a href="#合并并发值" class="headerlink" title="合并并发值"></a>合并并发值</h3><p>该算法可以保证所有数据都不会被无声的丢弃。但，需要客户端在随后写入时合并之前的值来清理多个值。如果简单基于时间戳进行 LWW，则有些数据又会被丢掉。</p>
<p>因此需要根据实际情况，选择一些策略来解决冲突，合并数据。</p>
<ol>
<li>对于上述购物车中只增加物品的例子，可以使用“并集”来合并冲突数据。</li>
<li>如果购物车汇总还有删除操作，就不能简单并了，但是可以将删除变为增加（写一个 tombstone 标记）。</li>
</ol>
<h3 id="版本向量"><a href="#版本向量" class="headerlink" title="版本向量"></a>版本向量</h3><p>上面例子只有单个副本。将该算法扩展到无主多副本模型时，只使用一个版本值显然不够，这时需要给每个副本的键都引入版本号，对于同一个键来说，不同副本的版本会构成<strong>版本向量（version vector）</strong>。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">    key1 </span><br><span class="line">A   Va</span><br><span class="line">B   Vb</span><br><span class="line">C   Vc</span><br><span class="line"></span><br><span class="line">key1: [Va, Vb, Vc]</span><br><span class="line"></span><br><span class="line">[Va-x, Vb-y, Vc-z] &lt;= [Va-x1, Vb-y1, Vc-z1]  &lt;==&gt; </span><br><span class="line">x &lt;= x1 &amp;&amp; y &lt;= y1 &amp;&amp; z &lt;= z1</span><br></pre></td></tr></table></figure>

<p>每个副本在遇到写入时，会增加对应键的版本号，同时跟踪从其他副本中看到的版本号，通过比较版本号大小，来决定哪些值要覆盖哪些值要保留。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>DDIA</category>
      </categories>
      <tags>
        <tag>DDIA</tag>
        <tag>读书笔记</tag>
        <tag>设计数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>DDIA 读书笔记（四）：编码和演进</title>
    <url>/2022/04/16/ddia-reading-chapter4/</url>
    <content><![CDATA[<blockquote>
<p>DDIA 读书分享会，会逐章进行分享，结合我在工业界分布式存储和数据库的一些经验，补充一些细节。每两周左右分享一次，欢迎加入，Schedule 和所有文字稿在<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">这里<i class="fa fa-external-link-alt"></i></span>。我们有个对应的分布式&amp;数据库讨论群，每次分享前会在群里通知。如想加入，可以加我的微信号：qtmuniao，简单自我介绍下，并注明：分布式系统群。</p>
</blockquote>
<p>第三章讲了存储引擎，本章继续下探，探讨编码相关问题。</p>
<p>所有涉及跨进程通信的地方，都需要对数据进行<strong>编码</strong>（<strong>Encoding</strong>），或者说<strong>序列化</strong>（<strong>Serialization</strong>）。因为持久化存储和网络传输都是面向字节流的。序列化本质上是一种“<strong>降维</strong>”操作，将内存中高维的数据结构降维成单维的字节流，于是底层硬件和相关协议，只需要处理一维信息即可。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/04/16/ddia-reading-chapter4">https://www.qtmuniao.com/2022/04/16/ddia-reading-chapter4</a> 转载请注明出处</em></p>
<p>编码主要涉及两方面问题：</p>
<ol>
<li>如何编码能够节省空间、提高性能。</li>
<li>如何编码以适应数据的演化和兼容。</li>
</ol>
<p>第一小节，以几种常见的编码工具（JSON，XML，Protocol Buffers 和 Avro）为例，逐一探讨了其如何进行编码、如何进行多版本兼容。这里引出了两个非常重要的概念：</p>
<ol>
<li>向后兼容 (backward compatibility)：当前代码可以读取旧版本代码写入的数据。</li>
<li>向前兼容(forward compatibility)：当前代码可以读取新版本代码写入的数据。</li>
</ol>
<blockquote>
<p>翻译成中文后，很容易混淆，主要原因在于“后”的歧义性，到底指<strong>身后</strong>（过去），还是指<strong>之后</strong>（将来），私以为还不如翻译为，<em>兼容过去</em>和<em>兼容将来</em>。但为了习惯，后面行文仍然用向后&#x2F;前兼容。</p>
</blockquote>
<p>其中，向后兼容比较常见，因为时间总是向前流逝，版本总是升级，那么升级之后的代码总要处理历史积压的数据，自然会产生向后兼容的问题。向前兼容比较少见，书中给出的例子是多实例滚动升级，但其持续时间也很短。</p>
<p>第二小节，结合几个具体的应用场景：数据库、服务和消息系统，来分别谈了相关数据流中涉及到的编码与演化。</p>
<h1 id="数据编码的格式"><a href="#数据编码的格式" class="headerlink" title="数据编码的格式"></a>数据编码的格式</h1><p><img src="https://s2.loli.net/2022/04/16/zDLbrhSIuscaQpO.png" alt="ddia4-encoding-decoding.png"></p>
<p>编码（Encoding）有多种称谓，如<strong>序列化（serialization）</strong>或 <strong>编组（marshalling）</strong>。对应的，解码（Decoding）也有多种别称，<strong>解析（Parsing）</strong>，<strong>反序列化（deserialization）</strong>，<strong>反编组 (unmarshalling）。</strong></p>
<ul>
<li><p>为什么内存中数据和外存、网络中的会有如此不同呢？</p>
<p>  在内存中，借助编译器，我们可以将内存解释为各种数据结构；但在文件系统和网络中，我们只能通过 seek\read 等几个有限的操作来流式的读取字节流。那 mmap 呢？</p>
</li>
<li><p>编码和序列化撞车了？</p>
<p>  在事务中，也有序列化相关的术语，所以这里专用编码，以避免歧义。</p>
</li>
<li><p>编码（encoding）和加密（<strong>encryption</strong>）？</p>
<p>  研究的范畴不太一样，编码是为了持久化或者传输，着重点在格式和演化；而加密是为了安全，着重点在于安全、防破解。</p>
</li>
</ul>
<h2 id="编程语言内置"><a href="#编程语言内置" class="headerlink" title="编程语言内置"></a>编程语言内置</h2><p>很多编程语言内置了一些缺省的编码方法：</p>
<ol>
<li>Java 有 <code>java.io.Serializable</code></li>
<li>Ruby 有 <code>Marshal</code></li>
<li>Python 有 <code>pickle</code></li>
</ol>
<p>如果你确定你的数据只会被某种特定的语言所读取，那么这种内置的编码方法很好用。比如深度学习研究员因为基本都用 Python，所以常会把数据以 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnB5dGhvbi5vcmcvemgtY24vMy9saWJyYXJ5L3BpY2tsZS5odG1s">pickle<i class="fa fa-external-link-alt"></i></span> 的格式传来传去。</p>
<p>但这些编程语言内置的编码格式有以下缺点：</p>
<ol>
<li>和特定语言绑定</li>
<li>安全问题</li>
<li>兼容性支持不够</li>
<li>效率不高</li>
</ol>
<h2 id="JSON、XML-及其二进制变体"><a href="#JSON、XML-及其二进制变体" class="headerlink" title="JSON、XML 及其二进制变体"></a>JSON、XML 及其二进制变体</h2><p>JSON，XML 和 CSV 属于常用的<strong>文本编码</strong>格式，其好处在于肉眼可读，坏处在于不够紧凑，占空间较多。</p>
<p>JSON 最初由 JavaScript 引入，因此在 Web Service 中用的较多，当然随着 web 的火热，现在成为了比较通用的编码格式，比如很多日志格式就是 JSON 的。</p>
<p>XML 比较古老了，比 JSON 冗余度还高，有时候配置文件中会用，但总体而言用的越来越少了。</p>
<p>CSV （以逗号\TAB、换行符分割）还算紧凑，但是表达能力有限。数据库表导出有时会用。</p>
<p>除了不够紧凑外，<strong>文本编码（text encoding）</strong>还有以下缺点：</p>
<ol>
<li>对<strong>数值类型支持不够</strong>。CSV 和 XML 直接不支持，万物皆字符串。JSON 虽区分字符串和数值，但是不进一步区分细分数值类型。可以理解，毕竟文本编码嘛，主要还是面向字符串。</li>
<li><strong>对二进制数据支持不够</strong>。支持 Unicode，但是对二进制串支持不够，可能会显示为乱码。虽然可以通过 Base64 编码来绕过，但有点做无用功的感觉。</li>
<li><strong>XML和 JSON 支持额外的模式</strong>。模式会描述数据的类型，告诉你如何理解数据。配合这些模式语言，虽然可以让 XML 和 JSON 变得强大，但是大大增加了复杂度。</li>
<li><strong>CSV 没有任何模式</strong>。</li>
</ol>
<p>凡事讲究够用，很多场景下需要数据可读，并且不关心编码效率，那么这几种编码格式就够用了。</p>
<h3 id="二进制编码"><a href="#二进制编码" class="headerlink" title="二进制编码"></a>二进制编码</h3><p>如果数据只被单一程序读取，不需要进行交换，不需要考虑易读性等问题。则可以用二进制编码，在数据量到达一定程度后，二进制编码所带来的空间节省、速度提高都很可观。</p>
<p>因此，JSON 有很多二进制变种：MessagePack、BSON、BJSON、UBJSON、BISON 和 Smile 等。</p>
<p>对于下面例子，</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;userName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Martin&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;favoriteNumber&quot;</span><span class="punctuation">:</span> <span class="number">1337</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;interests&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;daydreaming&quot;</span><span class="punctuation">,</span> <span class="string">&quot;hacking&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>如果用 MessagePack 来编码，则为：</p>
<p><img src="https://s2.loli.net/2022/04/16/VC1ckpB3fi7FPQ6.png" alt="ddia-4-messagepack-enc.png"></p>
<p>可以看出其基本编码策略为：使用类型，长度，bit 串，顺序编码，去掉无用的冒号、引号、花括号。</p>
<p>从而将 JSON 编码的 81 字节缩小到了 66 字节，微有提高。</p>
<h2 id="Thrift-和-Protocol-Buffers"><a href="#Thrift-和-Protocol-Buffers" class="headerlink" title="Thrift 和 Protocol Buffers"></a>Thrift 和 Protocol Buffers</h2><p>Thrift 最初由 Facebook，ProtoBuf 由 Google 在 07~08 年左右开源。他们都有对应的 RPC 框架和编解码工具。表达能力类似，语法也类似，在编码前都需要由接口定义语言（IDL）来描述模式：</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line">struct Person &#123;</span><br><span class="line">    <span class="number">1</span>: <span class="keyword">required</span> <span class="type">string</span>       userName,</span><br><span class="line">    <span class="number">2</span>: <span class="keyword">optional</span> i64          favoriteNumber,</span><br><span class="line">    <span class="number">3</span>: <span class="keyword">optional</span> list&lt;<span class="type">string</span>&gt; interests</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">Person</span> &#123;</span><br><span class="line">    <span class="keyword">required</span> <span class="type">string</span> user_name       = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">optional</span> <span class="type">int64</span>  favorite_number = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">repeated</span> <span class="type">string</span> interests       = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>IDL 是编程语言无关的，可以利用相关代码生成工具，可以将上述 IDL 翻译为指定语言的代码。即，集成这些生成的代码，无论什么样的语言，都可以使用同样的格式编解码。</p>
<p>这也是不同 service 可以使用不同编码语言，且能够互相通信的基础。</p>
<p>此外，Thrift 还支持多种不同的编码格式，常用的有：Binary、Compact、JSON。可以让用户自行在：编码速度、占用空间、可读性方便进行取舍。</p>
<p><img src="https://s2.loli.net/2022/04/16/IvwdYEu8ZqHJeCP.png" alt="ddia4-thrift-binary-enc.png"></p>
<p>可以看出其特点：</p>
<ol>
<li><strong>使用 field tag 编码</strong>。field tag 其实蕴含了字段<strong>类型</strong>和<strong>名字</strong>。</li>
<li>使用类型、tag、长度、bit 数组的顺序编码。</li>
</ol>
<p><img src="https://s2.loli.net/2022/04/16/8NZAFpMU4PRfGqa.png" alt="ddia4-thrift-compact-enc.png"></p>
<p>相比 Binary Protocol，Compact Protocol 由以下优化：</p>
<ol>
<li>filed tag 只记录 delta。</li>
<li>从而将 field tag 和 type 压缩到一个字节中。</li>
<li>对数字使用变长编码和<span class="exturl" data-url="aHR0cHM6Ly9penVhbHpoeS5jbi9wcm90b2J1Zi1lbmNvZGUtdmFyaW50LWFuZC16aWd6YWc=">Zigzag编码<i class="fa fa-external-link-alt"></i></span>。</li>
</ol>
<p>ProtoBuf 与 Thrift Compact Protocol 编码方式很类似，也用了变长编码和 Zigzag 编码。但 ProtoBuf 对于数组的处理与 Thrift 显著不同，使用了 repeated 前缀而非真数组，好处后面说。</p>
<p><img src="https://s2.loli.net/2022/04/16/amgw7pUeodGhisb.png" alt="ddia4-pb-enc.png"></p>
<h3 id="字段标号和模式演变"><a href="#字段标号和模式演变" class="headerlink" title="字段标号和模式演变"></a>字段标号和模式演变</h3><p><strong>模式</strong>，即有哪些字段，字段分别为什么类型。</p>
<p>随着时间的推移，业务总会发生变化，我们也不可避免的<strong>增删字段</strong>，<strong>修改字段类型</strong>，即<strong>模式演变</strong>。</p>
<p>在模式发生改变后，需要：</p>
<ol>
<li><strong>向后兼容</strong>：新的代码，在处理新的增量数据格式的同时，也得处理旧的存量数据。</li>
<li><strong>向前兼容</strong>：旧的代码，如果遇到新的数据格式，不能 crash。</li>
</ol>
<ul>
<li><p>ProtoBuf 和 Thrift 是怎么解决这两个问题的呢？</p>
<p>  <strong>字段标号</strong> + <strong>限定符</strong>（optional、required）</p>
<p>  向后兼容：新加的字段需为 optional。这样在解析旧数据时，才不会出现字段缺失的情况。</p>
<p>  向前兼容：字段标号不能修改，只能追加。这样旧代码在看到不认识的标号时，省略即可。</p>
</li>
</ul>
<h3 id="数据类型和模式演变"><a href="#数据类型和模式演变" class="headerlink" title="数据类型和模式演变"></a>数据类型和模式演变</h3><p>修改数据类型比较麻烦：只能够在相容类型中进行修改。</p>
<p>如不能将字符串修改为整形，但是可以在整形内修改： 32 bit 到 64 bit 整形。</p>
<p>ProtoBuf 没有列表类型，而有一个 repeated 类型。其好处在于<strong>兼容数组类型</strong>的同时，支持将可选（optional）<strong>单值字段</strong>，修改为<strong>多值字段</strong>。修改后，旧代码在看到新的多值字段时，只会使用最后一个元素。</p>
<p>Thrift 列表类型虽然没这个灵活性，但是可以<strong>嵌套</strong>呀。</p>
<h2 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h2><p>Apache Avro 是 Apache Hadoop 的一个子项目，专门为数据密集型场景设计，对模式演变支持的很好。支持 <strong>Avro IDL</strong> 和 <strong>JSON</strong> 两种模式语言，前者适合人工编辑，后者适合机器读取。</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line">record Person &#123;</span><br><span class="line">    <span class="type">string</span>                userName;</span><br><span class="line">    union &#123; null, long &#125;  favoriteNumber = null;</span><br><span class="line">    array&lt;<span class="type">string</span>&gt;         interests;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;record&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Person&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;userName&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;favoriteNumber&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span> <span class="string">&quot;long&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;interests&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;array&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;items&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>可以看到 Avro 没有使用字段标号。</p>
<ul>
<li><p>仍是编码之前例子，Avro 只用了 32 个字节，为什么呢？</p>
<p>  他没有编入类型。</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/16/2rfkGMa3dDWq7YZ.png" alt="ddia4-avro-enc.png"></p>
<p>因此，Avro 必须配合模式定义来解析，如 Client-Server 在通信的握手阶段会先交换数据模式。</p>
<h3 id="写入模式和读取模式"><a href="#写入模式和读取模式" class="headerlink" title="写入模式和读取模式"></a>写入模式和读取模式</h3><ul>
<li><p>没有字段标号，Avro 如何支持模式演进呢？</p>
<p>  答案是<strong>显式的</strong>使用两种模式。</p>
</li>
</ul>
<p>即，在对数据进行编码（写入文件或者进行传输）时，使用模式 A，称为<strong>写入模式</strong>（writer schema）；在对数据进行解码（从文件或者网络读取）时，使用模式 B，称为<strong>读取模式</strong>（reader schema），而两者不必相同，只需兼容。</p>
<p>也就是说，只要模式在演进时，是<strong>兼容</strong>的，那么 Avro 就能够处理向后兼容和向前兼容。</p>
<p><strong>向后兼容</strong>：新代码读取旧数据。即读取时首先得到旧数据的写入模式（即旧模式），然后将其与读取模式（即新模式）对比，得到转换映射，即可拿着此映射去解析旧数据。</p>
<p><strong>向前兼容</strong>：旧代码读取新数据。原理类似，只不过是需要得到一个逆向映射。</p>
<p>在由写入模式到读取模式建立映射时有一些规则：</p>
<ol>
<li><strong>使用字段名来进行匹配</strong>。因此写入模式和读取模式字段名顺序不一样无所谓。</li>
<li><strong>忽略多出的字段</strong>。</li>
<li><strong>对缺少字段填默认值</strong>。</li>
</ol>
<p><img src="https://s2.loli.net/2022/04/16/KZt8aSOpivxuJbB.png" alt="ddia-4avro-map.png"></p>
<h3 id="模式演化规则"><a href="#模式演化规则" class="headerlink" title="模式演化规则"></a>模式演化规则</h3><ul>
<li>那么如何保证写入模式的兼容呢？<ol>
<li>在增删字段时，只能添加或删除具有默认值的字段。</li>
<li>在更改字段类型时，需要 Avro 支持相应的类型转换。</li>
</ol>
</li>
</ul>
<p>Avro 没有像 ProtoBuf、Thrift 那样的 optional 和 required 限定符，是通过 union 的方式，里指定默认值，甚至多种类型：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">union</span> &#123;</span>null, <span class="type">long</span>, <span class="built_in">string</span>&#125; field;</span><br></pre></td></tr></table></figure>

<p><strong>注</strong>：默认值必须是联合的第一个分支的类型。</p>
<p>更改字段名和在 union 中添加类型，都是向后兼容，但是不能向前兼容的，想想为什么？</p>
<h3 id="如何从编码中获取写入模式"><a href="#如何从编码中获取写入模式" class="headerlink" title="如何从编码中获取写入模式"></a>如何从编码中获取写入模式</h3><p>对于一段给定的 Avro 编码数据，Reader 如何从其中获得其对应的写入模式？</p>
<p>这取决于不同的应用场景。</p>
<ul>
<li><p><strong>所有数据条目同构的大文件</strong></p>
<p>  典型的就是 Hadoop 生态中。如果一个大文件所有记录都使用相同模式编码，则在文件头包含一次写入模式即可。</p>
</li>
<li><p><strong>支持模式变更的数据库表</strong></p>
<p>  由于数据库表允许模式修改，其中的行可能写入于不同模式阶段。对于这种情况，可以在编码时额外记录一个模式版本号（比如自增），然后在某个地方存储所有的模式版本。</p>
<p>  解码时，通过版本去查询对应的写入模式即可。</p>
</li>
<li><p><strong>网络中发送数据</strong></p>
<p>  在两个进程通信的握手阶段，交换写入模式。比如在一个 session 开始时交换模式，然后在整个 session 生命周期内都用此模式。</p>
</li>
</ul>
<h3 id="动态生成数据中的模式"><a href="#动态生成数据中的模式" class="headerlink" title="动态生成数据中的模式"></a>动态生成数据中的模式</h3><p>Avro 没有使用字段标号的一个好处是，不需要手动维护字段标号到字段名的映射，这对于动态生成的数据模式很友好。</p>
<p>书中给的例子是对数据库做导出备份，注意和数据库本身使用 Avro 编码不是一个范畴，此处是指导出的数据使用 Avro 编码。</p>
<p>在数据库表模式发生改变前后，Avro 只需要在导出时依据当时的模式，做相应的转换，生成相应的模式数据即可。但如果使用 PB，则需要自己处理多个备份文件中，字段标号到字段名称的映射关系。其本质在于，Avro 的数据模式可以和数据存在一块，但是 ProtoBuf 的数据模式只能体现在生成的代码中，需要手动维护新旧版本备份数据与PB 生成的代码间的映射。</p>
<h3 id="代码生成和动态语言"><a href="#代码生成和动态语言" class="headerlink" title="代码生成和动态语言"></a>代码生成和动态语言</h3><p>Thrift 和 Protobuf 会依据语言无关的 IDL 定义的模式，生成给定语言的编解码的代码。这对静态语言很有用，因为它允许利用 IDE 和编译器进行类型检查，并且能够提高编解码效率。</p>
<p><strong>上述思路本质上在于，将模式内化到了生成的代码中。</strong></p>
<p>但对于动态语言，或者说解释型语言，如 JavaScript、Ruby 或 Python，由于没有了编译期检查，生成代码的意义没那么大，反而会有一定的冗余。这时 Avro 这种支持不生成代码的框架就节省一些，它可以将模式写入数据文件，读取时利用 Avro 进行动态解析即可。</p>
<h2 id="模式的优点"><a href="#模式的优点" class="headerlink" title="模式的优点"></a>模式的优点</h2><p><strong>模式的本质是显式类型约束，即，先有模式，才能有数据。</strong></p>
<p>相比于没有任何类型约束的文本编码 JSON，XML 和 CSV，Protocol Buffers，Thrift 和 Avro 这些基于显式定义二进制编码优点有：</p>
<ol>
<li>省去字段名，从而更加紧凑。</li>
<li>模式是数据的注释或者文档，并且总是最新的。</li>
<li>数据模式允许不读取数据，仅比对模式来做低成本的兼容性检查。</li>
<li>对于静态类型来说，可以利用代码生成做编译时的类型检查。</li>
</ol>
<p>模式演化 vs 读时模式</p>
<h1 id="几种数据流模型"><a href="#几种数据流模型" class="headerlink" title="几种数据流模型"></a>几种数据流模型</h1><p>数据可以以很多种形式从一个系统流向另一个系统，但不变的是，流动时都需要编码与解码。</p>
<p>在数据流动时，会涉及编解码双方模式匹配问题，上一小节已经讨论，本小节主要探讨几种进程间典型的数据流方式：</p>
<ol>
<li>通过数据库</li>
<li>通过服务调用</li>
<li>通过异步消息传递</li>
</ol>
<h2 id="经由数据库的数据流"><a href="#经由数据库的数据流" class="headerlink" title="经由数据库的数据流"></a>经由数据库的数据流</h2><p>访问数据库的程序，可能：</p>
<ol>
<li><strong>只由同一个进程访问</strong>。则数据库可以理解为该进程向将来发送数据的中介。</li>
<li><strong>由多个进程访问</strong>。则多个进程可能有的是旧版本，有的是新版本，此时数据库需要考虑向前和向后兼容的问题。</li>
</ol>
<p>还有一种比较棘手的情况：在某个时刻，你给一个表增加了一个字段，较新的代码写入带有该字段的行，之后又被较旧的代码覆盖成缺少该字段的行。这时候就会出现一个问题：我们更新了一个字段 A，更新完后，却发现字段 B 没了。</p>
<p><img src="https://s2.loli.net/2022/04/16/WTvpoenYzxJhqOB.png" alt="ddia-4-update-by-old.png"></p>
<h3 id="不同时间写入的数据"><a href="#不同时间写入的数据" class="headerlink" title="不同时间写入的数据"></a>不同时间写入的数据</h3><p>对于应用程序，可能很短时间就可以由旧版本替换为新版本。但是对于数据，旧版本的代码写入的数据量，经年累月，可能很大。在变更了模式之后，由于这些旧模式的数据量很大，全部更新对齐到新版本的代价很高。</p>
<p>这种情况我们称之为：<strong>数据的生命周期超过了其对应代码的生命周期</strong>。</p>
<p>在读取时，数据库一般会对缺少对应列的旧数据：</p>
<ol>
<li>填充新版本字段的<strong>默认值</strong>（default value）</li>
<li>如果没有默认值则填充<strong>空值</strong>（nullable）</li>
</ol>
<p>后返回给用户。一般来说，在更改模式时（比如 alter table），数据库不允许增加既没有默认值、也不允许为空的列。</p>
<h3 id="存储归档"><a href="#存储归档" class="headerlink" title="存储归档"></a>存储归档</h3><p>有时候需要对数据库做备份到外存。在做备份（或者说快照）时，虽然会有不同时间点生成的数据，但通常会将各种版本数据转化、对齐到最新版本。毕竟，总是要全盘拷贝数据，那就顺便做下转换好了。</p>
<p>之前也提到了，对于这种场景，生成的是一次性的不可变的备份或者快照数据，使用 Avro 比较合适。此时也是一个很好地契机，可以将数据按需要的格式输出，比如面向分析的按列存储格式：<span class="exturl" data-url="aHR0cHM6Ly9wYXJxdWV0LmFwYWNoZS5vcmcvZG9jcy9maWxlLWZvcm1hdC8=">Parquet<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="经由服务的数据流：REST-和-RPC"><a href="#经由服务的数据流：REST-和-RPC" class="headerlink" title="经由服务的数据流：REST 和 RPC"></a>经由服务的数据流：REST 和 RPC</h2><p>通过网络通信时，通常涉及两种角色：服务器（server）和客户端（client）。</p>
<p>通常来说，暴露于公网的多为 HTTP 服务，而 RPC 服务常在内部使用。</p>
<p>服务器也可以同时是客户端：</p>
<ol>
<li>作为客户端访问数据库。</li>
<li>作为客户端访问其他服务。</li>
</ol>
<p>对于后者，是因为我们常把一个大的服务拆成一组功能独立、相对解耦的服务，这就是 <strong>面向服务的架构（service-oriented architecture，SOA）</strong>，或者最近比较火的<strong>微服务架构（micro-services architecture）</strong>。这两者有一些不同，但这里不再展开。</p>
<p>服务在某种程度上和数据库类似：允许客户端以某种方式存储和查询数据。但不同的是，数据库通常提供某种灵活的查询语言，而服务只能提供相对死板的 API。</p>
<h3 id="web-服务"><a href="#web-服务" class="headerlink" title="web 服务"></a>web 服务</h3><p>当服务使用 HTTP 作为通信协议时，我们通常将其称为 <strong>web 服务</strong>。但其并不局限于 web，还包括：</p>
<ol>
<li>用户终端（如移动终端）通过 HTTP 向服务器请求。</li>
<li>同组织内的一个服务向另一个服务发送 HTTP 请求（微服务架构，其中的一些组件有时被称为中间件）。</li>
<li>不同组织的服务进行数据交换。一般要通过某种手段进行验证，比如 OAuth。</li>
</ol>
<p>有两种设计 HTTP API 的方法：REST 和 SOAP。</p>
<ol>
<li><strong>REST 并不是一种协议，而是一种设计哲学</strong>。它强调简单的 API 格式，使用 URL 来标识资源，使用 HTTP 的动作（GET、POST、PUT、DELETE ）来对资源进行增删改查。由于其简洁风格，越来越受欢迎。</li>
<li>SOAP 是基于 XML 的协议。虽然使用 HTTP，但目的在于独立于 HTTP。现在提的比较少了。</li>
</ol>
<h3 id="RPC-面临的问题"><a href="#RPC-面临的问题" class="headerlink" title="RPC 面临的问题"></a>RPC 面临的问题</h3><p>RPC 想让调用远端服务像调用本地（同进程中）函数一样自然，虽然设想比较好、现在用的也比较多，但也存在一些问题：</p>
<ol>
<li>本地函数调用要么成功、要么不成功。但是 RPC 由于经过网络，可能会有各种复杂情况，比如请求丢失、响应丢失、hang 住以至于超时等等。因此，可能需要重试。</li>
<li>如果重试，需要考虑<strong>幂等性</strong>问题。因为上一次的请求可能已经到达了服务端，只是请求没有成功返回。那么多次调用远端函数，就要保证不会造成额外副作用。</li>
<li>远端调用延迟不可用，受网络影响较大。</li>
<li>客户端与服务端使用的编程语言可能不同，但如果有些类型不是两种语言都有，就会出一些问题。</li>
</ol>
<p>REST 相比 RPC 的好处在于，它不试图隐去网络，更为显式，让使用者不易忽视网络的影响。</p>
<h3 id="RPC-当前方向"><a href="#RPC-当前方向" class="headerlink" title="RPC 当前方向"></a>RPC 当前方向</h3><p>尽管有上述问题，但其实在工程中，大部分情况下，上述情况都在容忍范围内：</p>
<ol>
<li>比如局域网的网络通常比较快速、可控。</li>
<li>多次调用，使用幂等性来解决。</li>
<li>跨语言，可以使用 RPC 框架的 IDL 来解决。</li>
</ol>
<p>但 RPC 程序需要考虑上面提到的极端情况，否则可能会偶然出一个很难预料的 BUG。</p>
<p>另外，基于二进制编码的 RPC 通常比基于 HTTP 服务效率更高。但 HTTP 服务，或者更具体一点，RESTful API 的好处在于，生态好、有大量的工具支持。而 RPC 的 API 通常和 RPC 框架生成的代码高度相关，因此很难在不同组织中无痛交换和升级。</p>
<p>因此，如本节开头所说：暴露于公网的多为 HTTP 服务，而 RPC 服务常在内部使用。</p>
<h3 id="数据编码和-RPC-的演化"><a href="#数据编码和-RPC-的演化" class="headerlink" title="数据编码和 RPC 的演化"></a>数据编码和 RPC 的演化</h3><p>通过服务的数据流通常可以假设：所有的服务器先更新，然后服务端再更新。因此，只需要在请求里考虑后向兼容性，在响应中考虑前向兼容性：</p>
<ol>
<li>Thrift、gRPC（Protobuf）和 Avro RPC 可以根据编码格式的兼容性规则进行演变。</li>
<li>RESTful API 通常使用 JSON 作为请求响应的格式，JSON 比较容易添加新的字段来进行演进和兼容。</li>
<li>SOAP 按下不表。</li>
</ol>
<p>对于 RPC，服务的兼容性比较困难，因为一旦 RPC 服务的 SDK 提供出去之后，你就无法对其生命周期进行控制：总有用户因为各种原因，不会进行主动升级。因此可能需要长期保持兼容性，或者提前通知和不断预告，或者维护多个版本 SDK 并逐渐对早期版本进行淘汰。</p>
<p>对于 RESTful API，常用的兼容方法是，将版本号做到 URL 或者 HTTP 请求头中。</p>
<h2 id="经由消息传递的数据流"><a href="#经由消息传递的数据流" class="headerlink" title="经由消息传递的数据流"></a>经由消息传递的数据流</h2><p>前面研究了编码解码的不同方式：</p>
<ol>
<li>数据库：一个进程写入（编码），将来一个进程读取（解码）</li>
<li>RPC 和 REST：一个进程通过网络（发送前会编码）向另一个进程发送请求（收到后会解码）并同步等待响应。</li>
</ol>
<p>本节研究介于数据库和 RPC 间的<strong>异步消息系统</strong>：一个存储（消息 broker、消息队列来临时存储消息）+ 两次 RPC（生产者一次，消费者一次）。</p>
<p>与 RPC 相比，使用消息队列的优点：</p>
<ol>
<li>如果消费者暂时不可用，可以充当暂存系统。</li>
<li>当消费者宕机重启后，自动地重新发送消息。</li>
<li>生产者不必知道消费者 IP 和端口。</li>
<li>能将一条消息发送给多个消费者。</li>
<li>将生产者和消费者解耦。</li>
</ol>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><p>书中用的是<strong>消息代理</strong>（Message Broker），但另一个名字，消息队列，可能更为大家熟知，因此，本小节之后行文都用消息队列。</p>
<p>过去，消息队列为大厂所垄断。但近年来，开源的消息队列越来越多，可以适应不同场景，如 RabbitMQ、ActiveMQ、HornetQ、NATS 和 Apache Kafka 等等。</p>
<p>消息队列的<strong>送达保证</strong>因实现和配置而异，包括：</p>
<ol>
<li><strong>最少一次 （at-least-once）</strong>：同一条数据可能会送达多次给消费者。</li>
<li><strong>最多一次（at-most-once）</strong>：同一条数据最多会送达一次给消费者，有可能丢失。</li>
<li><strong>严格一次（exactly-once）</strong>：同一条数据保证会送达一次，且最多一次给消费者。</li>
</ol>
<p>消息队列的逻辑抽象叫做 <strong>Queue</strong> 或者 <strong>Topic</strong>，常用的消费方式两种：</p>
<ol>
<li>多个消费者互斥消费一个 Topic</li>
<li>每个消费者独占一个 Topic</li>
</ol>
<p><strong>注</strong>：我们有时会区分这两个概念：将点对点的互斥消费称为 Queue，多点对多点的发布订阅称为 Topic，但这并不通用，或者说没有形成共识。</p>
<p>一个 Topic 提供一个单向数据流，但可以组合多个 Topic，形成复杂的数据流拓扑。</p>
<p>消息队列通常是面向<strong>字节数组</strong>的，因此你可以将消息按任意格式进行编码。如果编码是前后向兼容的，同一个主题的消息格式，便可以进行灵活演进。</p>
<h3 id="分布式的-Actor-框架"><a href="#分布式的-Actor-框架" class="headerlink" title="分布式的 Actor 框架"></a>分布式的 Actor 框架</h3><p><strong>Actor 模型</strong>是一种基于消息传递的并发编程模型。 Actor 通常是由状态（State）、行为（Behavior）和信箱（MailBox，可以认为是一个消息队列）三部分组成：</p>
<ol>
<li>状态：Actor 中包含的状态信息。</li>
<li>行为：Actor 中对状态的计算逻辑。</li>
<li>信箱：Actor 接受到的消息缓存地。</li>
</ol>
<p>由于  Actor 和外界交互都是通过消息，因此本身可以并行的，且不需要加锁。</p>
<p>分布式的 Actor 框架，本质上是将消息队列和 actor 编程模型集成到一块。自然，在 Actor 滚动升级是，也需要考虑前后向兼容问题。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>DDIA</category>
      </categories>
      <tags>
        <tag>DDIA</tag>
        <tag>读书笔记</tag>
        <tag>设计数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title>2022 年终总结 —— 充实和迷茫</title>
    <url>/2023/01/05/2022-summary/</url>
    <content><![CDATA[<p>不知道为何，今年朋友圈分享年终总结的朋友格外多。我挺喜欢这个形式，一来，我很爱看别人的年终总结，看故事之余还能看到一些不同路径；二来，每年定期回顾下，也确实能帮着梳理下思路，简单做下展望。</p>
<p>古代知识垄断的时代，只有帝王将相才能有纪传；而今信息爆炸的世代，人人皆可记之，为自己代言。于短期来说，年岁渐长，思虑日增，很多事不记下来，旬月便忘，通过年终回顾，日后回头追踪下自己思想变迁轨迹，也算三省吾身，冀有新得；于长期来说，我们终将作古，若借助互联网能留下个一鳞半爪，博后世一笑，也算雁过留声。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/01/05/2022-summary">https://www.qtmuniao.com/2023/01/05/2022-summary</a> 转载请注明出处</em></p>
<p><strong>今年绕不开的主题必有疫情</strong>。疫情已经进入第四个年头，仍不知道最后会以什么方式结束。这几年来，新冠病毒深刻的影响了这个星球上每一个人的生活。最初，病毒致死率高，真实的压迫着每一个人的神经；后来，病毒传染性变强，社会的混乱烦扰着我们每个人的生活；现在，对于大多数年轻人来说，病毒本身似乎没那么可怕，但经济承压对所带来的更为深层次的影响，可能才初现端倪。我们无从分辨，这到底是结束的开始，还仅仅是开始的结束。</p>
<p>虽然如此，还是着几个假期出去玩了几次。包括去年元旦的北海，九月初的双乌（乌兰布统和乌兰察布），十一的内蒙古阿尔山。毕了业之后我变的相当宅，嫌麻烦，不爱出去玩。虽然去前总是各种磨蹭，去了之后变都成了“真香”。读万卷书，行万里路，古人诚不欺我，祖国山河真是壮阔。很多风景历史，真是身临其境才能体会；很多风俗人情，只有身处其中才会理解；这种多个感官的综合输入刺激，要远比读书的单维输入要直接和绚丽的多。而且，脑子特会偷懒，如果天天两点一线，规律重复，它就会给你压缩记忆；但如果你时不时去新的地方，它就总给你清晰的留着，也算变相延展了生命的有效长度。下面约略说说每次的感受。</p>
<p><strong>北海涠洲岛</strong>。作为广西毗邻北部湾的一个滨海城市，北海给我的初印象是相当宜居。虽然调侃说是传销之都，但初步感觉并无特别之处，而且外地人非常多，光打的的时候就遇到两次东北大哥大姐。北海下属的离岸小岛——涠洲岛，给我们的感觉很奇特而深刻。在岛上盘桓了几日，永远不会忘记骑着小电驴，兜着海风，流连在高高低低的路上，穿梭在各种民宿、小村落、香蕉田、栈桥和神奇的火山岛中。那一抹沁蓝的海水，是 Lightroom 中调不出的色调，有一种特别抓人魔力。<br><img src="https://photo.tuchong.com/15470921/f/1202005935.jpg"><br><img src="https://photo.tuchong.com/15470921/f/801384041.jpg"></p>
<p><strong>双乌之行</strong>。之前夏天的时候就去过一次<strong>乌兰布统</strong>，当时记忆最深的是——缎子式的山间草场。这次秋天再去，恰好处于景色青黄不接时节——夏草已收，冬雪未至。但好处就是，游人极少，可以独占茫茫天地。自驾在起伏的山路上，天高云淡，青黄色的山脊光影流转，各色的骏马三三两两，实是涤荡人心的景色。行至半路，总觉意犹未尽，于是稍微纠结了一下后，便冲向了<strong>乌兰察布</strong>，去寻访下之前听过的察哈尔火山群。连夜赶了许久的路，翌日又爬了半天，在看到三号火山口的那一刹那，多少有点失望——火山口落差只有不到两米。以前一直以为火山口会很深，里面有树林天池什么的。但好在带了无人机，每个火山绕着飞过去，上帝视角让一切赶路都值了。说到这里突然想起，赶路时两侧的景色其实非常棒，尤其是太阳落山时分的云彩，搭配心型的高压输电铁塔，简直绝了。</p>
<p><img src="https://photo.tuchong.com/15470921/f/798044315.jpg"><br><img src="https://photo.tuchong.com/15470921/f/682504410.jpg"><br><img src="https://photo.tuchong.com/15470921/f/682373526.jpg"></p>
<p><strong>内蒙阿尔山</strong>。本来想要先飞到哈尔滨，然后再租车过去。出发前临时发现哈尔滨有疫情，便改成了从北京直接自驾过去。也多亏这个决定，让我们回程时虽然辗转很久，但总算一次进了京。从北京到阿尔山甚至再北边的呼伦贝尔，足足要开两三天，还好们三个人轮换，但也免不了要赶夜路。去阿尔山时，运气非常棒，第一天看到了秋末的盛景，第二天恰又赶上第一场雪，见识了天气轮转间两个天池的不同身姿。阿尔山的森林以樟子松和白桦树为主，伴以火山喷发形成的天池和堰塞湖，再配上清冷干净的高山气候，让回忆也变的清冽起来。次日的漫山银装，微风后的簌簌落雪，露出黄色的发髻，真是不得感叹造物主的神奇。之后虽有呼伦贝尔的千里大草原，根河湿地的分分合合的河路和丛丛朵朵的灌木，黑山头的风车和日落，莫尔道嘎的深山密林，但比起初雪前后的阿尔山，都算添头。照片辑录在这篇<span class="exturl" data-url="aHR0cHM6Ly93d3cuZG91YmFuLmNvbS9ub3RlLzgzOTY3OTUxNS8=">文章<i class="fa fa-external-link-alt"></i></span>。<br><img src="https://photo.tuchong.com/15470921/f/1263088263.jpg"><br><img src="https://photo.tuchong.com/15470921/f/1036530424.jpg"><br><img src="https://photo.tuchong.com/15470921/f/689189355.jpg"></p>
<p><strong>旅游之外，今年迷上了国漫，尤其是古风动漫</strong>。心情烦躁之时，找个架空背景的动漫来看，便总能跳脱当时思维桎梏，慢慢开朗起来。也不知为何动漫于我有这般魔力，但相比电视剧，动漫的画面表现更强、布景约束更少、剧情呈现更活。用来制作科幻和仙侠题材，尤为契合。好一点的，《少年歌行》的鲜衣怒马、意气风发；《画江湖不良人》的背负使命、家国情怀；《凡人修仙传》的谨小慎微、无利不起早；《灵笼》的末日抉择、物种延续、赛博修仙。坏一些的，《斗罗大陆》《斗破苍穹》《完美世界》，虽有一些高光，但制作水平飘忽，立意不高，细节欠佳，整体流于无脑爽文。但无论好坏，这种世界法则搭建、角色成长设定、背景打斗华丽，都让我很放空和解压。我常想，如果自己也有机会设计一个这样的体系，该从哪里获得灵感，山海经？历代政治得失？该如何补充细节，生活经验？百科全书？该如何推动故事发展、该如何制造冲突、该如何铺陈感情等等。就类似于一个代码项目，从头构建的掌控感总是令人心旷神怡。</p>
<p><strong>今年囫囵的读了一些书，也非常认真的读了一本书</strong>。囫囵的开的书里面，有兰小欢《置身事内》，梳理了我国政府机制的一些职能和经济发展的一些内在脉络，对于我们这代人亲身经历的中国特色经济发展的内在逻辑，可窥一斑；有李光耀的《李光耀观天下》，粗略的给出了一个在 2013 这个时间节点，他个人对于世界上几个主要国家和地区的扼要评述，比对他的预测和后来实际走向，十分有意思；有经典文集《古文观止》，古人在其时代下的一些际遇和思考，有的读来很偏颇、有的感觉很透彻，但不变的是，文字的凝练、语句的韵律和结构的精妙；有巴里·诺顿的《中国经济：适应与增长》，提供了不错的脉络和一些视角，但结合之前读过的温铁军的《八次危机》和林毅夫的《解读中国经济》，可以看出外国人书中对某几段特殊时期总有一些偏颇甚至刻板化的偏见。</p>
<p>认真读的一本书就是和工作相关的技术书 《Designing Data-Intensive Application》，今年在上班之余总共花了上百个小时在这本书上，说出这个数字我也有些惊讶。一开始想法很简单，就是建了一个分布式系统和数据库的群，然后想给群里找个可日常维系的事情，便选了分享这本书。对于每章，会先读一遍英文版，然后意译一遍，可能会结合我的经验塞一些私货，最后再在周末分享一遍。其中翻译文字稿最费时间，有些英语拿不准，得参考下其他人的翻译；有的含义拿不准，得去查一些资料。自己粗读时不觉得有什么，待写文字稿时，字斟句酌，颇为耗费精力。然即便如此，如果写完一遍不做校对，词句和含义，总会漏洞百出。当然，即便粗校一遍，仍然有诸多问题，所以索性放在了 github 上面，欢迎大家指正。这么一年下来，好处也相当明显：与很多同行朋友产生了不少连接、英语阅读水平提高了很多、繁杂的数据系统脉络变得清晰起来、即使准备的不充分分享时也不会太过怯场、B站和知乎都涨了好几千粉丝等等。虽然效率确实不高，但很多东西，就这么的慢慢的磨了出来。最后，附一下我将文字稿和往期录屏<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8jLw==">网站<i class="fa fa-external-link-alt"></i></span>，希望能帮到对分布式系统和数据库感兴趣的同学。</p>
<iframe src="//player.bilibili.com/player.html?aid=253924566&bvid=BV1bY411L7HA&cid=507228434&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p><strong>受 DDIA 分享的影响，这一年博客更新少了很多</strong>。但持续写东西所带来的好处是缓慢而悠长的。首先，输出能带动高效的输入。很多知识，只有用自己的话表述一遍，才能深深的嵌到我的知识树中。其次，写作能让迫使条理化的思考问题，并试图抓核心痛点。介绍概念时，总需要找一些关键切入点，这就势必让你层层剥开表面迷雾；组织段落时，也需要符合一些逻辑线索，这势必要求你将不同的信息点进行勾连，合理呈现。最后，持续的输出能让你和其他人产生更多的连结。作为一个程序员，一味扎进工作细节里很容易缺乏社交，而通过持续的输出，能让不同的人通过文字找到你，认识你，产生更多的交流，碰撞出更多的想法和发现更多机会。</p>
<p><strong>21 年入职了一家数据库创业公司，做存储层开发</strong>。相比以前纯存储架构，数据库的存储层侧重有诸多不同。比如对象存储更关注大数据量、高可用，但模型简单、一致性要求弱；而数据库的存储层，需要关心 schema，就要考虑编码、演化和兼容，需要考虑 DDL 和 DML 的并发，需要考虑分布式事务，需要考虑下推来的计算执行等等，复杂度上升了很多。此外，我们是做图数据库领域，又需要关注图数据模型的特殊性。需要考虑图查询中最常见的模式匹配和图遍历，需要考虑如何进行优化多跳查询，需要考虑如何进行异构数据的支持。传统关系型数据库的知识能拿来解决很多问题，但有一些痛点不进行创新难以高效解决，比如多跳查询。此外，图的引领者们，如 Neo4j、TigerGraph，已经开始在图计算和机器学习上发力，我们又怎么切入等等诸多问题。但总体来说，非常有意思，这一年算是慢慢切入了图数据库这个领域，也做的很开心。但国内数据库的商业化普遍很艰难，不独技术因素，还有市场因素、合规因素等等。而且就算开始商业化，也大概率会像旷视那样，能活下去，但很难维持像前些年互联网企业那样的市盈比。因为现在的商业化路子，人效比普遍不高，很难撑得起互联网逻辑的估值。</p>
<p>虽然喜欢这个领域，但日复一日上班的日子，总会感觉缺了点什么。时不时的还会生出黑客帝国中对 Matrix 产生排斥反应的一些人所具有不真实感——我是谁、我在哪里、我在干什么。中国人讲究三十而立，虽未必是三十，但总会自觉不自觉的对比，到了哪个阶段，该有什么成就。眼睛盯着优秀的同龄人，便总会生出难以名状的焦虑。当然，更多的迫切感是内生的，总感觉难以找到能够投入百分之百热情的东西，也难以生出古贤人“为万世开太平”的使命感，即，总是很难以预期的烈度来燃尽每日时光。倘若我满足现状，或许能更为豁达；倘若我在奔赴理想，或许能感觉十分充实；懂一点，又似懂非懂；踮起脚，打开窗户一角，透进来一点光，但总觉开的不够大；想开大，却又力不从心的迷茫。可能很多事情，只能再积累再发展再探索，才能事后串珠成链。</p>
<p>路漫漫其修远兮，吾将上下而求索。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>年终总结</tag>
      </tags>
  </entry>
  <entry>
    <title>步步为营 剖析事务中最难的——隔离性</title>
    <url>/2022/07/07/db-isolation/</url>
    <content><![CDATA[<blockquote>
<p>很久没有发文了，搞了一个月事务相关的资料和分享，今天用这篇文章做个小节。希望能给大家一些启发。</p>
<p>说起数据库的事务，大家第一反应多是 ACID，但这几个属性的重要性和复杂度并不等同。其中，最难理解的当属<strong>隔离性</strong>（I，Isolation）。造成这种理解困局的一个重要原因是，历史上对几种隔离级别的定义和实现耦合在了一块、不同厂商的的叫法和实现又常常挂羊头卖狗肉。本文试着从锁的角度来梳理下几种常见的隔离级别，用相对<strong>不精确</strong>的叙述给大家建立一个直观感性的认识。</p>
</blockquote>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2022/07/07/db-isolation">https://www.qtmuniao.com/2022/07/07/db-isolation</a> 转载请注明出处</em></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>数据库试图通过事务隔离（transaction isolation）来给用户提供一种隔离保证，从而降低应用侧的编程复杂度。最强的隔离性，可串行化（Serializability），可以对用户提供一种保证：任意时刻，可以认为只有一个事务在运行。</p>
<p>初学时对几种隔离级别的递进关系通常难以理解，是因为没有找到一个合适的角度（再次表明观点：没有理解不了的问题，只有不对的打开方式）。我的经验是，从实现的角度对几种隔离级别进行梳理，会建立一个一致性的认识。</p>
<p>ANSI SQL 定义的四种隔离级别，由弱到强分别是：<strong>读未提交</strong>（Read Uncommited）、<strong>读已提交</strong>（Read Commited）、<strong>可重复读</strong>（Repeatable Read）和<strong>可串行化</strong>（Serializability），可以从使用锁实现事务的角度来理解其递进关系。</p>
<h2 id="以锁为媒"><a href="#以锁为媒" class="headerlink" title="以锁为媒"></a>以锁为媒</h2><p>最强的隔离性——<strong>可串行化</strong>，可以理解为全局一把大互斥锁，每个事务在启动时获取锁，在结束（提交或者回滚）时释放锁。但这种隔离级别性能无疑最差。而其他几种弱隔离级别，可以理解为是为了提高性能，缩小了加锁的粒度（谓词锁-&gt;对象锁）、减短了加锁的时间（事务结束后释放-&gt;用完即释放）、降低了加锁的强度（互斥锁-&gt;共享锁），从而牺牲一致性换取性能。</p>
<p>换个角度来说，从上锁的强弱考虑，我们有<strong>互斥锁</strong>（Mutex Lock，又称写锁、独占锁、排它锁）和<strong>共享锁</strong>（Shared Lock，又称读锁）；从上锁的长短来考虑，我们有长时锁（Long Period Lock，事务开始获取锁，到事务结束时释放）和短时锁（Short Period Lock，访问数据时获取，用完旋即释放）；从上锁的粗细来考虑，我们有对象锁（关系型数据中的 Row Lock，锁一行）和<strong>谓词锁</strong>（Predicate Lock，锁一个数据集合）。</p>
<h2 id="KV-模型"><a href="#KV-模型" class="headerlink" title="KV 模型"></a>KV 模型</h2><p>说到数据集合，由于数据库在存储层实现时都是基于 KV 模型，如 B+ 树中 Page 和 LSM-Tree 中的 Block 都是一组 KV 条目。对应到关系型数据库中，如果按行存储，则单条 KV 的 Key 通常是主键， Value 通常是一行数据。因此，之后行文，事务修改数据都可以理解为：</p>
<ol>
<li><strong>单个对象</strong>。可以理解为一个 KV 条目。</li>
<li><strong>一组对象</strong>。如 <code>where x &gt; 5 and y &lt; 6</code> 表达式，会确定一个 KV 条目子集。</li>
</ol>
<p>因此，下面讨论数据的粒度，都是基于 KV 模型。</p>
<h2 id="弱隔离级别和相应问题"><a href="#弱隔离级别和相应问题" class="headerlink" title="弱隔离级别和相应问题"></a>弱隔离级别和相应问题</h2><p>性能最好的隔离级别就是不上任何锁。但会存在<strong>脏读</strong>（Dirty Read，一个事务读到另一个事务未提交的更改）和<strong>脏写</strong>（Dirty Write，一个事务覆盖了另外一个事务未提交的更改）的问题。这两种现象会造成什么后果呢？举个例子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">脏读：</span><br><span class="line">初始 x=4</span><br><span class="line">事务1：--W(x=5)---&gt;rollback</span><br><span class="line">事务2：-----&gt;R(x=5)---&gt;commit</span><br><span class="line"></span><br><span class="line">事务2 错误的读出了 x=5，但这个值不应该存在过。原因在于事务2读到了事务1未提交的值。</span><br><span class="line"></span><br><span class="line">脏写：</span><br><span class="line">初始 x=4, y=4</span><br><span class="line">事务1：--W(x=5)--------W(y=5)---&gt;commit</span><br><span class="line">事务2：----W(x=6)--W(y=6)-&gt;commit</span><br><span class="line">最后结果是 x=6, y=5。但如果两个事务先后执行的正确结果应该是 x 和 y 要么都为 5，要么都为 6。造成这种不一致的原因在于，事务1未提交的更改 x=5 被覆盖了，事务2未提交的更改 y=6 也被覆盖了。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>为了避免脏写，可以给要更改的对象加长时写锁，但读数据时并不加锁，此时的隔离级别称为<strong>读未提交</strong>（RU，Read Uncommitted）。<br>但此时仍然会有脏读：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">脏读：</span><br><span class="line">初始 x = 4</span><br><span class="line">事务1：----WL(x),W(x=5)--&gt;rollback, UL(x)</span><br><span class="line">事务2：----------------&gt;R(x=5)---&gt;commit</span><br><span class="line"></span><br><span class="line">注：RL:ReadLock; WL:WriteLock；UL:Unlock</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>为了避免脏读，可以对要读取的对象加短时读锁，此时的隔离级别是<strong>读已提交</strong>（RC，Read Committed）。<br>但由于加的是短时读锁，一个事务先后两次读 x，而在中间空挡，另一个修改 x 的事务提交，则会出现两次读取不一致的问题，此种问题称为<strong>不可重复读</strong>（non Repeatable Read）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">初始 x = 4</span><br><span class="line">事务1: -RL(x),R(x=4),UL(x)--------------------------&gt;RL(x),R(x=5),UL(x)---&gt;commit</span><br><span class="line">事务2：-------------------WL(x),W(x=5)--&gt;commit,UL(x)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>为了解决此问题，需要在读取数据的时候也加长时读锁。解决了不可重复读的隔离级别称为<strong>可重复读</strong>（RR，Repeatable Read）。</p>
<p>到可重复读级别，都是针对单条数据上锁。在此隔离级别下，如果一个事务两次进行范围查询，比如说执行两次 <code>select count(x) where x &gt; 5</code>；另一个事务在两次查询中间插入了一条 <code>x = 6</code>，这两次读到的结果并不一样，这种现象称为<strong>幻读</strong>（Phantom Read）。为了解决幻读问题，需要针对范围查询语句加长时谓词读锁。解决了幻读的隔离级别，我们称为<strong>可串行化</strong>（Serializability）。</p>
<p>可以看出，在可串行隔离级别，不管读锁还是写锁，都要拿到事务结束。这种用锁方式，我们称为<strong>两阶段锁</strong>（2PL，two Phase Lock）。</p>
<blockquote>
<p>两阶段锁，即分为两个阶段，在第一个阶段（事务执行时）只允许上锁，在第二个阶段（事务提交时）只允许释放锁。当然，这其实是严格两阶段锁，SS2PL，感兴趣同学可以自行去查阅下其与 2PL 区别。</p>
</blockquote>
<h2 id="泛化一下"><a href="#泛化一下" class="headerlink" title="泛化一下"></a>泛化一下</h2><p>从更抽象角度来说，每个事务在执行过程中都要去<strong>摸</strong>（touch）一个数据对象子集，针对该数据子集可能会读，可能会写；如果两个并发的事务，摸到的数据子集并不相交，则不用做任何处理，可以放心并发执行。</p>
<p>如果数据子集有相交之处，就会形成事务之间的依赖关系。将事务抽象成一个点，依赖关系根据时间先后抽象成一条有向边，则可构造出一个<strong>有向无环图</strong>。</p>
<p>事务对外提供的最理想抽象是：所有的事务在时间线上可以坍缩为一个点（瞬时完成，即 ACID 中的 A，<strong>原子性</strong>）。这样所有的事务即可在时间轴上将 DAG 进行拓扑排序，即可串行化。</p>
<p>但在实际执行过程中，事务都是要持续一段时间，即一个时间线段，执行时间有交叠的事务便有了各种并发问题和隔离性（或者说可见性）问题。那如何让物理上并发的事务，逻辑上看起来像顺序地、原子地执行呢？答曰：只需在事务执行前后维持某些不变性即可。</p>
<p>这些不变性，即为 ACID 中的 C，<strong>一致性</strong>。在应用层看来，也可以称为<strong>因果性</strong>。也即，前面所说的有数据交集的事务的依赖性能够被正确的处理。举个例子，事务一依赖某个读取内容进行决策后修改，其依赖的内容不能为并发的事务二所修改，不然做出的决策就有问题。更实际的例子可以参考 DDIA 第七章医生值班问题。</p>
<p>我们通常使用两种思想，来维护这种不变性：</p>
<ol>
<li><strong>悲观的方式</strong>。加锁，使通一个数据子集不能同时为多个事务所访问。</li>
<li><strong>乐观的方式</strong>。MVCC，每个数据对象存多个版本，每个版本都是不可变的，修改对象即追加一个新的版本。每个事务可以放心的读写，在提交时检测到冲突后进行重试即可。</li>
</ol>
<p>这部分隐去了很多细节，感兴趣的可以去看看我录的<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVFyNHkxTTdabQ==">视频<i class="fa fa-external-link-alt"></i></span>。</p>
<h2 id="The-Last-Thing"><a href="#The-Last-Thing" class="headerlink" title="The Last Thing"></a>The Last Thing</h2><p>上面说的四种隔离级别没有覆盖到另一个常见的隔离级别——<strong>快照隔离</strong>（Snapshot Isolation）。因为它引出了另上面提到的乐观派实现族——MVCC。由于属于不同的实现思想，快照隔离和可重复读在隔离级别强弱的光谱上属于一个偏序关系，不能说谁强于谁，有机会再展开讲。</p>
<p>本文源于本月分享 DDIA 第七章事务的一个小结。篇幅所限，很多概念没有太展开，感兴趣的可以看看我的<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8jL2NoMDc=">读书笔记<i class="fa fa-external-link-alt"></i></span>，也可以叫翻译，因为实在太长了，毕竟一共录了三期视频（阅读原文可达）。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>事务</tag>
        <tag>隔离性</tag>
      </tags>
  </entry>
  <entry>
    <title>Facebook Velox 运行机制全面解析</title>
    <url>/2023/03/22/velox-task-analysis/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><span class="exturl" data-url="aHR0cHM6Ly9yZXNlYXJjaC5mYWNlYm9vay5jb20vcHVibGljYXRpb25zL3ZlbG94LW1ldGFzLXVuaWZpZWQtZXhlY3V0aW9uLWVuZ2luZS8=">Facebook Velox<i class="fa fa-external-link-alt"></i></span> 是一个针对 SQL 运行时的 C++ 库，旨在统一 Facebook 各种计算流，包括 Spark 和 Presto，使用推的模式、支持向量计算。</p>
<p>Velox 接受一棵<strong>优化过的</strong> <code>PlanNode</code> Tree，然后将其切成一个个的线性的 <code>Pipeline</code>，<code>Task</code> 负责这个转变过程，每个 Task 针对一个 PlanTree Segment。大多数算子是一对一翻译的，但是有一些特殊的算子，通常出现在多个 Pipeline 的<strong>切口</strong>处，通常来说，这些切口对应计划树的<strong>分叉处</strong>，如 <code>HashJoinNode</code>，<code>CrossJoinNode</code>， <code>MergeJoinNode</code> ，通常会翻译成 XXProbe 和 XXBuild。但也有一些例外，比如 <code>LocalPartitionNode</code> 和 <code>LocalMergeNode</code> 。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/03/22/velox-task-analysis">https://www.qtmuniao.com/2023/03/22/velox-task-analysis</a> 转载请注明出处</em></p>
<p><img src="https://s2.loli.net/2024/02/21/sMokCUzYrGh7bA9.png" alt="velox-join-bridge.png"></p>
<p>为了提高执行的<strong>并行度</strong>，Velox 引入了 <code>LocalPartitionNode</code> 节点，可以将一个 <code>Pipeline</code> 进行多线程（每个线程一个实例）并行运行，并且互斥的消费数据。其中每个实例称为 <code>Driver</code>。该算子在输入计划树里并没有分叉（即没有多个 source），但在翻译成物理算子时，会在此节点处进行切开，并在切口前后改变执行的并行度，对应的物理算子是<code>LocalPartition</code>  和  <code>LocalExchange</code>。</p>
<p><img src="https://s2.loli.net/2024/02/21/tkGnw9h8gv3euly.png" alt="velox-local-partition.png"></p>
<p>还有一个特殊节点，称为 <code>LocalMergeNode</code>，该对输入有要求：必须有序，然后会进行<strong>单线程</strong>的归并排序，从而使输出全局有序。也因此，由其而切开的消费 Pipeline 一定是单 Driver 的。翻译成算子，对应两个 <code>CallbackSink</code> 和 <code>LocalMerge</code>。</p>
<p><img src="https://s2.loli.net/2024/02/21/ImbMJuV2sp9wc7Q.png" alt="velox-local-merge.png"></p>
<p>总结一下，上述五个 PlanNode，<code>HashJoinNode</code>，<code>CrossJoinNode</code>， <code>MergeJoinNode</code> ，<code>LocalPartitionNode</code> ，<code>LocalMergeNode</code> 在翻译时会造成切口，即将逻辑 PlanTree 切成多个物理 Pipeline，因此在切口处会将一个逻辑算子翻译成多个物理算子，分到不同 Pipeline 上。每个 Pipeline 会有一个从 0 开始的编号：<strong>Pipeline ID</strong>，是全局粒度的。</p>
<p>并且，可以由 <code>LocalPartitionNode</code> 来按需改变每个 Pipeline 并行度，其中 Pipeline 的每个线程由一个 Driver 来执行。每个 Driver 也有一个从 0 开始的编号：<strong>Driver ID</strong>，是 Pipeline 粒度的。</p>
<p>其他 PlanNode 到算子的翻译基本都是一对一的，感兴趣的可以看官方文档的这个页面：<span class="exturl" data-url="aHR0cHM6Ly9mYWNlYm9va2luY3ViYXRvci5naXRodWIuaW8vdmVsb3gvZGV2ZWxvcC9vcGVyYXRvcnMuaHRtbA==">Plan Nodes and Operators<i class="fa fa-external-link-alt"></i></span>。</p>
<p>下面展开一些细节。</p>
<h2 id="Splits"><a href="#Splits" class="headerlink" title="Splits"></a>Splits</h2><p>Velox 允许<strong>应用层</strong>（即 Velox 的使用方）以 Splits （每个算子的输入片段称为 Split）的方式给 Pipeline 喂数据，可以流式的喂，因此有两个 API：</p>
<ol>
<li><code>Task::addSplit(planNodeId, split)</code> ：喂一份数据给 Velox</li>
<li><code>Task::noMoreSplits()</code> ：通知 Velox 我喂完了。</li>
</ol>
<p>Velox 会使用一个队列在缓存这些 Splits 数据。在<strong>数据喂完之前</strong>的任意一个时刻，Pipeline 的叶子算子（对的，外部喂数据只能发生在叶子节点，如 TableScan，Exchange 和 MergeExchange）都可以从队列中取数据，对应 API 是 <code>Task::getSplitOrFuture(planNodeId)</code> ，返回值有两种：</p>
<ol>
<li>如果队列中有数据，则返回一个 Split</li>
<li>如果队列中无数据，但还没有收到喂完的信号，则返回一个 Future （类似于一个<strong>欠条</strong>，之后有数据之后，会凭该欠条兑付）。</li>
</ol>
<p><img src="https://s2.loli.net/2024/02/21/tQSKuMrjJw5BZEX.png" alt="velox-add-split.png"></p>
<h2 id="Join-Bridges-and-Barriers"><a href="#Join-Bridges-and-Barriers" class="headerlink" title="Join Bridges and Barriers"></a>Join Bridges and Barriers</h2><p>Join （HashJoinNode 和 CrossJoinNode）会翻译成 XXProbe 和 XXBuild 两个算子，并且通过一个共享的 <strong>Bridge</strong> 来沟通数据，两侧 Pipeline 都可以通过 <code>Task::getHashJoinBridge()</code> 函数来根据 PlanNodeId 获取该共享的 Bridge。</p>
<p>为了提高 build 速度，build 侧 Pipeline 通常使用多个 Driver 并发执行。但由于只有一个 Bridge，每个 Driver 在结束时可以调用 <code>Task::allPeersFinished()</code> （内部是使用一个 <code>BarrierState</code> 的结构来实现的）来判断自己是否为最后一个 Driver，如果是，则将所有 Driver 的输出进行合并后送到 Bridge。</p>
<p>当然，在 RIGHT and FULL OUTER join 情况下，Probe 侧也需要将没有 match 上的数据喂给 Bridge，此时也需要由最后一个 Driver 来负责这件事，于是同样需要调用  <code>Task::allPeersFinished()</code> 函数。</p>
<p><img src="https://s2.loli.net/2024/02/21/JUFEirQ41vCXxjg.png" alt="velox-hash-join.png"></p>
<p>下面来详细看下 Join 类算子的切分细节。以 HashJoin 为例，Task 在切分 PlanTree 时，会将逻辑上的一个 HashJoin 算子，转化成物理上的一对算子：HashProbe 和 HashJoin，并且使用异步机制进行通知：在 HashJoin 完成后，通知 HashProbe 所在 Pipeline 继续执行，在此之前，后者是阻塞等待的。</p>
<p><img src="https://s2.loli.net/2024/02/21/sMokCUzYrGh7bA9.png" alt="velox-join-bridge.png"></p>
<p>如上图，每个 Pipeline 在实例化（逻辑 PlanNode 转物理 Operator）的时候，可以生成多份，进行并行执行，互斥的消费数据。并且，每个 Pipeline 的<strong>并行粒度</strong>可以不一样，如上图 Probe Pipeline 实例化了两份，而 Build Pipeline 实例化了三份。并且，Build Pipeline 组中最后一个运行完的 Pipeline 负责将数据通过 Bridge 发送给 Probe Pipeline。</p>
<h2 id="Exchange-Clients"><a href="#Exchange-Clients" class="headerlink" title="Exchange Clients"></a>Exchange Clients</h2><p>Velox 使用 Exchange Clients 来获取远程 worker 的数据。分两个步骤：</p>
<p>第一步，Pipeline 中第一个 Driver （driverId &#x3D;&#x3D; 0） 的 Exchange 算子从 Task 中获取一个 Split，并且初始化一个共享 Exchange Client。</p>
<p>第二步，Exchange Client 会为上游每个 Task 构造一个 Exchange Source，并行的拉取每个上游 Task 同一个 Partition （图中是 Partition-15）数据，然后将其放在 Client 的队列 Queue 中。Exchange 的每个 Driver 都会去队列中拉取这些数据。</p>
<p>如何从上游 Task 拉取数据的逻辑，需要由用户自定义实现  <code>ExchangeSource</code> 和 <code>ExchangeSource::Factory</code>  。每个 <code>ExchangeSource</code> 接受一个上游 Task 的字符串 ID、Partition 编号和一个队列作为参数。然后会从上游 Task 中拉取该 Partition 的数据，并且放到队列中。</p>
<p><img src="https://s2.loli.net/2024/02/21/pCnU8ZB7gLKorhA.png" alt="velox-exchange-source.png"></p>
<blockquote>
<p>文章剩下还有一部分，欢迎订阅我的专栏看全文：</p>
<p>​<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2NhMDIwMjk3LTA5MDEtNDVkMS04YWNjLTFkODg0YmYxY2M4NA==">小报童-Facebook velox Task 解析<i class="fa fa-external-link-alt"></i></span></p>
<p>这是在小报童上面的一个付费订阅专栏，这是专栏地址：<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">https://xiaobot.net/p/system-thinking<i class="fa fa-external-link-alt"></i></span> </p>
<p>小报童是一个借鉴国外 newsletter 专注写作的付费订阅平台，只不过将邮箱换成了微信。 现在初步打算围绕“系统”开几个系列： 图数据库101系列 每天学点数据库系列 系统好文推荐系列 读书笔记系列 数据密集型论文导读系列 系统，既是数据库系统中的系统，也是分布式系统中的系统，也是人类组织系统中的系统，也可是一切有迹可循、有规律可考的系统。学习系统的架构，借鉴系统的组织，使我们的认知也系统起来。 会保证每周不低于两篇更新，现价一季度 32 块钱，作为给先订阅同学的福利，如果有同学通过你的分享订阅本专栏，你可以拿到该同学订阅费用的百分之三十的抽成~ 分享方式见专栏介绍。 如果有任何建议以及想看的系统文章，欢迎留言~</p>
</blockquote>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><span class="exturl" data-url="aHR0cHM6Ly9mYWNlYm9va2luY3ViYXRvci5naXRodWIuaW8vdmVsb3gvZGV2ZWxvcC90YXNrLmh0bWw=">https://facebookincubator.github.io/velox/develop/task.html<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>查询引擎</category>
      </categories>
      <tags>
        <tag>Runtime</tag>
        <tag>执行引擎</tag>
      </tags>
  </entry>
  <entry>
    <title>影响我写代码的三个 “Code”</title>
    <url>/2023/03/25/how-to-read-and-write-code/</url>
    <content><![CDATA[<p>国内很多大学的计算机专业，比较偏重基础和理论的“灌输”（就我当年上学的体验，现在可能会好一些），对于代码能力，虽然也有一些课程实验，但往往不太够用。于是，在进入正式工作前，很多同学就会对自己代码水平不太自信。下面我就根据我自身的写代码经历提供一些建议。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/03/25/how-to-read-and-write-code">https://www.qtmuniao.com/2023/03/25/how-to-read-and-write-code</a> 转载请注明出处</em></p>
<h2 id="一些经历"><a href="#一些经历" class="headerlink" title="一些经历"></a>一些经历</h2><p>我是 2010 年上的北邮，当时也是很迷糊的就进了计算机专业。自然的，在大学一开始也谈不上什么学习规划。只能是沿用着高中的学习方法，懵懂地跟着老师走——上课就听课，课余就自习做作业。结果便是，学习效率很低，上课听不太懂、题目做不通透。但总归，上完计算机导论后，编程作业都是自己啃出来的，跌跌撞撞的完成之后，慢慢地竟感受到了编程的乐趣。</p>
<p>我们当时大作业最多的几门课，C++ 程序设计、算法和数据结构、操作系统、计算机网络、微机原理等，现在想来，大部分都都跟玩具一样。后来做了国外一些知名大学公开课的实验才知道，要打造好一个实验项目，是非常难的事情：</p>
<ol>
<li>首先，得适配学生的水平，准备详尽的实验材料。</li>
<li>其次，得搭好代码框架，在合适的地方“留白”，给学生“填空”。</li>
<li>最后，还得构建足够好的自动化测试平台，进行打分。</li>
</ol>
<p>如果从头开发，这里面涉及到的复杂度、需要花的心思，并不比发一篇顶会论文简单。那作为教授来说，有这些时间，我为什么不去发一篇论文呢？毕竟国内高校都是科研第一、教学老末。</p>
<p>因此，我在本科课内，代码水平也并没有打下太好的基础。在后面在读研和工作中，不断摸索，代码水平才一点点提高。回头来看，对我代码能力提升有比较大影响的可以总结为 “Code”：<strong>LeetCode</strong>、<strong>Writing&#x2F;Review Code Loop</strong>、<strong>Clean Code</strong>。</p>
<h2 id="LeetCode"><a href="#LeetCode" class="headerlink" title="LeetCode"></a>LeetCode</h2><p>在说 LeetCode 前，想先说说工作后，见到的一类神奇的人——打过算法比赛（通称 ACM，其实是 ICPC 和 CCPC）的同学的印象。这类同学的一大突出特点，用最简单直接的语言来形容，就是：<strong>出活快</strong>。几年的竞赛经历，让他们只要在脑袋中对需求（题目）理解之后，就能在最短的时间内转化为代码。</p>
<p>由于太过懵懂，我自然是没有打过竞赛，等反应过来竞赛的诸般好处时，已经大三下了。当时，校队也不会招这么“大龄”的队员了，就算招，门槛也非常高。也是大学诸多憾事中的一件了。</p>
<p>后来读了研，在找工作前一年时，LeetCode 已经相当流行了，便也和同学组队，互相激励着刷了起来。当时题目还不是特别多，到研二暑假找实习时，大概把前两百多道刷了两遍。一开始，会不断思考题目是什么意思，该用什么算法解，有时半天想不出来，便去看高票答案。很多高票解真的是精妙而简练，这大概也是当时 LeetCode 最吸引人的地方之一。慢慢的对各种类型题目有些感觉之后，就开始练速度和通过率。也就是上文说的，在理解题目后，能够迅速转变为 bug free 的代码。</p>
<p>因此，虽然没有打过比赛，但是通过 LeetCode 的训练，确实也有了类似竞赛的收获。但自然，在深度、广度和速度上都远不及那些“身经百赛”的同学。不过于我已经是受益匪浅：</p>
<ol>
<li><strong>对常见数据结构和算法掌握纯熟</strong>。比如现在说起六种排序，特点、使用场景、背后原理，可以做到如数家珍；比如说起树的各种递归非递归遍历，脑动模拟递归执行过程，也是信手拈来；再比如链表、队列、图等特点，也能在脑中边模拟，边换成代码。</li>
<li><strong>学到了很多精巧的代码片段“构件”</strong>。比如如何二分、如何迭代、如何处理链表头尾节点、如何设计基本数据结构的接口等等。这些偏“原子”的构件，是我后来工作中写代码的血肉来源。</li>
</ol>
<p>但只有这些，是远远不够的，一到大项目里，写出的代码就很容易——“有佳句无佳章”。</p>
<h2 id="Writing-x2F-Review-Code-Loop"><a href="#Writing-x2F-Review-Code-Loop" class="headerlink" title="Writing&#x2F;Review Code Loop"></a>Writing&#x2F;Review Code Loop</h2><p>遇到上述窘境，往往是因为缺少中大型项目的磨练。表现在<strong>空间上</strong>，不知道如何组织上万行的代码，如何划分功能模块、构建层次体系；体现在<strong>时间上</strong>，没有经过项目“起高楼、宴宾客、楼塌了”的构建-腐烂-重构循环。</p>
<p>工程中在理解代码和组织代码时有个矛盾：</p>
<ol>
<li><strong>可理解性</strong>。作为维护人员，我们学习代码时，多喜欢顺着<strong>数据流</strong>和<strong>控制流</strong>来理解，所谓根据某个头，一路追查到底，是为<strong>纵向</strong>。</li>
<li><strong>可维护性</strong>。但作为架构人员，我们组织代码时，为了容易维护，多是按照围绕模块来组织代码——把关联紧密的代码聚合到一块，是为<strong>横向</strong>。</li>
</ol>
<p>所以我们在拿到一个大工程时，如果立即地毯式的看代码，肯定会昏昏欲睡、事倍功半。不幸的是，由于多年读书养成的强大习惯，这个毛病，跟了我很多年。正确的打开方式是，要像对待团在一起的多条线一样，找到“线头”，然后慢慢往外揪。在项目中，这些线头是：service 的 main 函数、各种单测入口。</p>
<p>但我们在构建一个大工程时，又得反着来：先搭建一个揉在一起的主流程，然后逐渐迭代。就像盘古开天辟地一样，随着时间而演化，让天慢慢的升高、地慢慢下降，让整体化为地上四极、山川河流、太阳月亮。如是迭代，将一个混沌的流程，慢慢地模块化。比如常用的工具模块（utils）、业务相关基础模块（common）、控制模块（controller、manager）、RPC HTTP 等回调处理模块（processor）等等。</p>
<p>但当然，如果你已经有了构建某种类型系统的经验，则并不需要在构建初期经历这个漫长过程，可以直接按经验分出一些模块。更进一步，你已经形成了自己的一个代码库，比如时钟、网络、多线程、流控等等，可以直接拿来就用。</p>
<p>那剩下的问题就是细节的微调，我们在进行分层时，边界处的功能，是往上升，还是往下沉；某个较完整的结构，是拍平到使用类里，还是单独拎出来；这些形形色色的决策，都没有一个定则，更多的还是根据场景的需求、工期的长短等诸多实际情况，便宜行事。而这种背后的决策，则是在长时间对中大型项目的学习、对别人修改的 Review、自己上手搭架子和修修补补中，一点点形成的直觉。</p>
<p>就像股票市场有周期一样，工程代码也是有其周期。不经历一个股市牛熊周期，我们不敢轻言<strong>空多</strong>；不经历过一个工程构建-成熟-腐烂的周期，我们也不敢轻言<strong>取舍</strong>。即，没办法在工程构建初期，预见到其最常用的打开方式，进而面向主要场景设计，牺牲次要场景的便利性。</p>
<p>单元测试的重要性，怎么强调都不为过。一方面，能不能写出的单元测试，意味着你代码的模块边界是否清楚；另一方面，通过设计好的输入和输出，测试能够保证某种“不变性”，之后无论你怎么微调、重构，只要能跑过之前的测试，那就可以放心一半。另一半，就要靠自己和别人不断 Review 、测试集群线上集群不断地迭代了。</p>
<p>所以，这个过程是一个无休止的 loop，不断的磨，尔后不断地提升。</p>
<h2 id="Clean-Code"><a href="#Clean-Code" class="headerlink" title="Clean Code"></a>Clean Code</h2><p>最后说说对代码的<strong>品味</strong>。小节标题是：Clean Code，是因为我对代码的品味，最初是从 <span class="exturl" data-url="aHR0cHM6Ly9ib29rLmRvdWJhbi5jb20vc3ViamVjdC80MTk5NzQxLw==">Clean Code: A Handbook of Agile Software Craftsmanship<i class="fa fa-external-link-alt"></i></span> 这本书建立起来的。其第二章对<strong>命名</strong>——这个工程中“最难”的事情——的阐述，给我印象很深。</p>
<p>举几个例子：</p>
<ol>
<li><strong>单一职责</strong>。如果你不能清晰的对你的类或者函数命名，说明你的类或者函数干的事情太多了。</li>
<li><strong>命名代替注释</strong>。比如不要直接使用字面值常量，最好给其一个名字；比如最好不要使用匿名函数，也要给其一个能看出含义的名字。</li>
</ol>
<p>工作中，我们常说，某某对代码有“洁癖”。我也多少有一些，但我并不以为这是洁癖，而是一种对美的欣赏和追求。代码的美体现在哪里呢？我这里稍微抛个砖（当然，我之前也写文章就代码命名问题啰嗦过，感兴趣的可以点<a href="https://www.qtmuniao.com/2021/12/12/how-to-write-code-scrutinize-names/">这里</a>可以去看看）：</p>
<ol>
<li><strong>一致性</strong>。比如具有相同含义的实体，使用相同的命名；而需要区分的实体，则要通过命名阈、前缀来进行甄别。从而给读者造成最小的心智负担。</li>
<li><strong>体系性</strong>。是指我们在做一组相关接口时，要考虑其体体系性。比如增删改查，比如生产消费，比如预处理、处理、处理后，比如读取写入等等。体系性又包括对称性和逻辑性，让人在拿到一组接口时，就能最小成本地理解其是如何相互联系、又是如何具有区别的。</li>
<li><strong>没有赘肉</strong>。写代码，不要啰嗦，不要啰嗦，不要啰嗦。如果不小心啰嗦了，说明你可能没有想清楚所解决问题的本质。复杂的表象，在不断地剥离杂质后，往往有很简单的关窍。抓住这些关窍，再往其上附着骨肉，同时理清楚一对一、一对多、多堆多等依赖关系，往往能化简为繁。</li>
</ol>
<p>不同概念（对应代码中的类）间的关系，在理解代码组织的时候至关重要，最好在名字上有所体现，比如一对一，一对多还是多对多。每个概念的内涵，以及多个概念之间的包含、连接关系，是在做模块设计的时候最需要考虑的事情之一。</p>
<p>在审美之外，还要说说<strong>建模</strong>（在某种程度上和<strong>隐喻</strong>是相通的）。毕竟，我们在说<strong>构建</strong>时，本身就是借助的建筑学中的隐喻。软件工程中，类似的隐喻随处可见。</p>
<p><strong>我们大脑在认知新事物时，多建立在基于旧的模型推演上</strong>。因此，如果在处理模块时，如果能从经典的模型库中，找到一个相对合适的抽象，往往能够极大降低用户理解门槛。比如经典的生产者消费者模型、树形组织模型、路由器模型、线程调度模型、内存模型等等。此外，也可以使用某种常见意像、隐喻来命名项目，往往也能在易理解性上收获奇效。比如监控系统，可以叫“鹰眼”；比如各种流水线管控，可以叫“富士康”（手动斜眼）；再比如更常见一些的数据采集，我们都知道他叫——“爬虫”。</p>
<h2 id="The-last-Thing"><a href="#The-last-Thing" class="headerlink" title="The last Thing"></a>The last Thing</h2><p>世间的事情往往是多方印证、互相补足的——<strong>如果你想写好代码，就不能只是低头写代码</strong>，你得去读读历史、学学美术、写写文字、见见河山，建立一套你自己的审美偏好，然后将其理念平移到写代码里来，才能写出符合直觉、具有美感的好代码。</p>
<blockquote>
<p>本篇文章来自我的小报童专栏，初步规划有以下几个系列：</p>
<ul>
<li>图数据库101系列</li>
<li>每天学点数据库系列</li>
<li>系统好文推荐系列</li>
<li>读书笔记系列</li>
<li>数据密集型论文导读系列</li>
</ul>
<p>订阅方式见<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">专栏介绍<i class="fa fa-external-link-alt"></i></span>，欢迎喜欢我文章的朋友们的订阅支持，激励我产出更多优质文章。</p>
</blockquote>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>素养</tag>
      </tags>
  </entry>
  <entry>
    <title>RocksDB 运行原理</title>
    <url>/2023/06/05/how-rocksdb-works/</url>
    <content><![CDATA[<blockquote>
<p>RocksDB 是很多分布式数据库的底层存储，如 TiKV、CRDB、NebulaGraph 等等。在 DataDog 工作的 <span class="exturl" data-url="aHR0cHM6Ly9hcnRlbS5rcnlseXNvdi5jb20v">Artem Krylysov<i class="fa fa-external-link-alt"></i></span> 写了一篇<span class="exturl" data-url="aHR0cHM6Ly9hcnRlbS5rcnlseXNvdi5jb20vYmxvZy8yMDIzLzA0LzE5L2hvdy1yb2Nrc2RiLXdvcmtzLw==">文章<i class="fa fa-external-link-alt"></i></span>来对 RocksDB 做了一个科普，通俗易懂，在这里翻译下分享给大家。</p>
</blockquote>
<h2 id="导语"><a href="#导语" class="headerlink" title="导语"></a>导语</h2><p>近几年，RocksDB 的采用率急速上升，俨然成为内嵌型键值存储（以下简称 kv 存储）的不二之选。</p>
<p>目前，RocksDB 在 Meta、<span class="exturl" data-url="aHR0cHM6Ly9ibG9ncy5iaW5nLmNvbS9FbmdpbmVlcmluZy1CbG9nL29jdG9iZXItMjAyMS9Sb2Nrc0RCLWluLU1pY3Jvc29mdC1CaW5n">Microsoft<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly9uZXRmbGl4dGVjaGJsb2cuY29tL2FwcGxpY2F0aW9uLWRhdGEtY2FjaGluZy11c2luZy1zc2RzLTViZjI1ZGY4NTFlZg==">Netflix<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly93d3cudWJlci5jb20vZW4tSlAvYmxvZy9jaGVyYW1pLW1lc3NhZ2UtcXVldWUtc3lzdGVtLw==">Uber<i class="fa fa-external-link-alt"></i></span> 等公司的生产环境上运行。在 <span class="exturl" data-url="aHR0cHM6Ly9lbmdpbmVlcmluZy5mYi5jb20vMjAyMS8wNy8yMi9kYXRhLWluZnJhc3RydWN0dXJlL215c3FsLw==">Meta<i class="fa fa-external-link-alt"></i></span>，RocksDB 作为 MySQL 部署的存储引擎，为分布式图数据库（<a href="https://www.qtmuniao.com/2021/10/07/facebook-tao/">TAO</a>）提供支持存储服务。</p>
<p>大型科技公司并非 RocksDB 的仅有用户，像是 CockroachDB、Yugabyte、PingCAP 和 Rockset 等多个初创企业都构建在 RocksDB 基础之上。</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9hcnRlbS5rcnlseXNvdi5jb20v">我<i class="fa fa-external-link-alt"></i></span>在 Datadog 工作了 4 年时间，在生产环境中构建和运行了一系列基于 RocksDB 的服务。本文将就 RocksDB 的工作原理进行概要式讲解。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/06/05/how-rocksdb-works">https://www.qtmuniao.com/2023/06/05/how-rocksdb-works</a> 转载请注明出处</em></p>
<h2 id="RocksDB-是什么"><a href="#RocksDB-是什么" class="headerlink" title="RocksDB 是什么"></a>RocksDB 是什么</h2><p>RocksDB 是一种可持久化的、内嵌型 kv 存储。它是为了存储大量的 key 及其对应 value 设计出来的数据库。可以基于这种简单 kv 数据模型来构建倒排索引、文档数据库、SQL 数据库、缓存系统和消息代理等复杂系统。</p>
<p>RocksDB 是 2012 年从 Google 的 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS9sZXZlbGRi">LevelDB<i class="fa fa-external-link-alt"></i></span> fork 出来的分支，并针对跑在 SSD 上的服务器进行了优化。目前，RocksDB 由 Meta <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rL3JvY2tzZGI=">开发<i class="fa fa-external-link-alt"></i></span>和维护。</p>
<p>RocksDB 使用 C++ 编写而成，因此除了支持 C 和 C++ 之外，还能通过 С binding 的形式嵌入到使用其他语言编写的应用中，例如 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3J1c3Qtcm9ja3NkYi9ydXN0LXJvY2tzZGI=">Rust<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpbnhHbnUvZ3JvY2tzZGI=">Go<i class="fa fa-external-link-alt"></i></span> 或 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29rL3JvY2tzZGIvdHJlZS9tYWluL2phdmE=">Java<i class="fa fa-external-link-alt"></i></span>。</p>
<p>如果你之前用过 SQLite，你肯定知道什么是内嵌式数据库。在数据库领域，特别是在 RocksDB 的上下文中，“内嵌”意味着：</p>
<ul>
<li>该数据库没有独立进程，而是被集成进应用中，和应用共享内存等资源，从而避免了跨进程通信的开销。</li>
<li>它没有内置服务器，无法通过网络进行远程访问。</li>
<li>它不是分布式的，这意味着它不提供容错性、冗余或分片（sharding）机制。</li>
</ul>
<p>如有必要，需依赖于应用层来实现上述功能。</p>
<p>RocksDB 以 kv 对集合的形式存储数据， key 和 value 是任意长度的字节数组（byte array），因此都是没有类型的。RocksDB 提供了很少的几个用于修改 kv 集合的函数底层接口：</p>
<ul>
<li><code>put(key, value)</code>：插入新的键值对或更新已有键值对</li>
<li><code>merge(key, value)</code>：将新值与给定键的原值进行合并</li>
<li><code>delete(key)</code>：从集合中删除键值对</li>
</ul>
<p>通过点查来获取 key 所关联的 value：</p>
<ul>
<li><code>get(key)</code></li>
</ul>
<p>通过迭代器可以进行范围扫描——找到特定的 key，并按顺序访问该 key 后续的键值对：</p>
<ul>
<li><code>iterator.seek(key_prefix); iterator.value(); iterator.next()</code></li>
</ul>
<h2 id="Log-structured-merge-tree"><a href="#Log-structured-merge-tree" class="headerlink" title="Log-structured merge-tree"></a><strong>Log-structured merge-tree</strong></h2><p>RocksDB 的核心数据结构被称为<strong>日志结构合并树</strong> （LSM-Tree）。它是一种树形的数据结构，由多个层级组成，每层的数据按 key 有序。LSM-Tree 主要设计用来应对写入密集型工作负载，并于 1996 年在同名论文 <span class="exturl" data-url="aHR0cDovL3BhcGVyaHViLnMzLmFtYXpvbmF3cy5jb20vMThlOTFlYjRkYjIxMTRhMDZlYTYxNGYwMzg0ZjI3ODQucGRm">The Log-Structured Merge-Tree (LSM-Tree)<i class="fa fa-external-link-alt"></i></span> 被大家所知。</p>
<p>LSM-Tree 的最高层保存在内存中，包含最近写入的数据。其他较低层级的数据存储在磁盘上，层数编号从 0 到 N 。第 0 层 L0 存储从内存移动到磁盘上的数据，第 1 层及以下层级则存储更老的数据。通常某层的下个层级在数据量上会比该层大一个数量级，当某层数据量变得过大时，会合并到下一层。</p>
<p><img src="https://s2.loli.net/2023/08/21/fgHoJOTvwmM1sjl.png" alt="blog_how-rocksdb-works_rocksdb-lsm.png"></p>
<p><em>注：虽然本文主要讨论 RocksDB，但涉及 LSM-Tree 的概念适用于大多数底层采用此技术实现的数据库（例如 Bigtable、HBase、Cassandra、ScyllaDB、LevelDB 和 MongoDB WiredTiger）</em>。</p>
<p>为了更好地理解 LSM-Tree 的工作原理，下面我们将着重剖析它的写 &#x2F; 读路径。</p>
<h2 id="写路径"><a href="#写路径" class="headerlink" title="写路径"></a>写路径</h2><h3 id="MemTable"><a href="#MemTable" class="headerlink" title="MemTable"></a><strong>MemTable</strong></h3><p>LSM-Tree 的顶层被称为 MemTable。MemTable 是一个内存缓冲区，在键值对写入磁盘之前，Memtable 会缓存住这些键值对。所有插入和更新操作都会过 MemTable。当然也包括删除操作：不过，在 RocksDB 中，并不会直接原地修改键值对，而是通过插入墓碑记录（tombstone ）来进行标记删除。</p>
<p>MemTable 具有可配置的字节数限制。当一个 MemTable 变满时，就会切到一个新的 MemTable，同时原 MemTable 变为不可修改状态。</p>
<p>注：MemTable 的默认大小为 64 MB。</p>
<p>现在，我们往数据库写入点 key 看看：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;chipmunk&quot;</span>, <span class="string">&quot;1&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;cat&quot;</span>, <span class="string">&quot;2&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;raccoon&quot;</span>, <span class="string">&quot;3&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;dog&quot;</span>, <span class="string">&quot;4&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2023/08/21/1lO8bVrwKx9Lsoa.png" alt="how-rocksdb-works-memtable.png"></p>
<p>如上图所示，MemTable 中的键值对是按 key 有序排列的。尽管 <code>chipmunk</code> 是最先插入的，但由于 MemTable 是按 key 有序的，因此 <code>chipmunk</code> 排在 <code>cat</code> 之后。这种排序对于范围扫描是必须的，此外，稍后我会详细介绍，它也会让某些操作更加高效。</p>
<h3 id="预写日志"><a href="#预写日志" class="headerlink" title="预写日志"></a><strong>预写日志</strong></h3><p>无论是在进程意外崩溃退出还是计划内重启时，其内存中的数据都会丢失。为了防止数据丢失，保证数据的持久化，除了 MemTable 之外，RocksDB 会将所有更新写入到磁盘上的预写日志（WAL，Write-ahead log）中。这样，在重启后，数据库可以回放日志，进而恢复 MemTable 的原始状态。</p>
<p>WAL 是一个只允许追加的文件，包含一组更改记录序列。每个记录包含键值对、记录类型（Put &#x2F; Merge &#x2F; Delete）和校验和（checksum）。与 MemTable 不同，在 WAL 中，记录不按 key 有序，而是按照请求到来的顺序被追加到 WAL 中。</p>
<p><img src="https://s2.loli.net/2023/08/21/oPHnCwyhDtX1jdF.png" alt="how-rocksdb-works-wal.png"></p>
<h2 id="Flush"><a href="#Flush" class="headerlink" title="Flush"></a>Flush</h2><p>RocksDB 使用一个专门的后台线程定期地把不可变的 MemTable 从内存持久化到磁盘。一旦刷盘（flush）完成，不可变的 MemTable 和相应的 WAL 就会被丢弃。RocksDB 开始写入新的 WAL、MemTable。每次刷盘都会在 L0 层上产生一个新的 SST 文件。该文件一旦写入磁盘后，就不再会修改。</p>
<p>RocksDB 的 MemTable 的默认基于<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvU2tpcF9saXN0">跳表<i class="fa fa-external-link-alt"></i></span>实现。该数据结构是一个具有额外采样层的链表，从而允许快速、有序地查询和插入数据。有序性使得 MemTable 刷盘时更高效，因为可以直接按顺序迭代键值对顺序写入磁盘。<strong>将随机写变为顺序写是 LSM-Tree 的核心设计之一</strong>。</p>
<p><img src="https://s2.loli.net/2023/08/21/VpTvmdt3oXIEKnU.png" alt="how-rocksdb-works-flush.png"></p>
<p><em>注：RocksDB 高度可配，因此你可以给 MemTable 配置其他的实现方案，RocksDB 中大部分组件都是如此。在其他的一些基于 LSM 实现的数据库中，使用自平衡二叉搜索树来实现 MemTable 并不鲜见</em>。</p>
<h3 id="SST"><a href="#SST" class="headerlink" title="SST"></a><strong>SST</strong></h3><p>SST 文件包括从 MemTable 刷盘而来的简直对，并且使用一种对查询友好的数据格式来存储。 SST 是 Static Sorted Table 的缩写（其他数据库中也称为 Sorted String Table）。它是一种基于块（ block） 的文件格式，会将数据切成固定大小的块（默认为 4KB）进行存储。RocksDB 支持各种压缩 SST 文件的压缩算法，例如 Zlib、BZ2、Snappy、LZ4 或 ZSTD 算法。与 WAL 的记录类似，每个数据块中都包含用于检测数据是否损坏的校验和。每次从磁盘读取数据时，RocksDB 都会使用这些校验和进行校验。</p>
<p>SST 文件由几个部分组成：首先是数据部分，包含一系列有序的键值对。key 的有序性可以让我们对 其进行增量编码，也即，对于相邻的 key ，我们可以只存其差值而非整个 key。</p>
<p>尽管 SST 中的 kv 对是有序的，我们也并非总能进行二分查找，尤其是数据块在压缩过后，会使得查找很低效。RocksDB 使用索引来优化查询，存储在紧邻数据块之后的索引块。Index 会把每个 block 数据中最后一个 key 映射到它在磁盘上的对应偏移量。同样地，index 中的 key 也是有序的，因此我们可以通过二分搜索快速找到某个 key。</p>
<p><img src="https://s2.loli.net/2023/08/21/R76i5ThCW9epxGk.png" alt="how-rocksdb-works-sstable.png"></p>
<p>例如，我们在查找 <code>lynx</code>，索引会告诉我们这个键值对可能在 block 2，因为按照字典序，<code>lynx</code> 在 <code>chipmunk</code> 之后，但在 <code>raccoon</code> 之前。</p>
<p>但其实 SST 文件中并没有 <code>lynx</code>，但我们仍然需要从磁盘加载 block 以进行搜索。RocksDB 支持启用<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQmxvb21fZmlsdGVy">布隆过滤器<i class="fa fa-external-link-alt"></i></span>，一种具有高效空间利用率的概率性数据结构，可以用来检测某个元素是否在集合中。布隆过滤器保存在 SST 文件中过滤器部分，以便能够快速确定某个 key 不在 SST 中（从而省去摸硬盘上的数据块的开销）。</p>
<p>此外，SST 还有其他几个不太有趣的部分，比如元数据部分。</p>
<h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><p>到现在为止，一个功能完备的键值存储引擎讲完了。但如果这样直接上生产环境，会有一些问题：空间放大（space amplifications）和读放大（read amplifications）。空间放大是存储数据所用实际空间与逻辑上数据大小的比值。假设一个数据库需要 2 MB 磁盘空间来存储逻辑上的 1 MB 大小的键值对是，那么它的空间放大率是 2。类似地，读放大用来衡量用户执行一次逻辑上的读操作，系统内所需进行的实际 IO 次数。作为一个小练习，你可以尝试推演下什么是写放大。</p>
<p>现在，让我们向数据库添加更多 key 并删除当中的一些 key：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">db.<span class="built_in">delete</span>(<span class="string">&quot;chipmunk&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;cat&quot;</span>, <span class="string">&quot;5&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;raccoon&quot;</span>, <span class="string">&quot;6&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;zebra&quot;</span>, <span class="string">&quot;7&quot;</span>)</span><br><span class="line"><span class="comment">// Flush triggers</span></span><br><span class="line">db.<span class="built_in">delete</span>(<span class="string">&quot;raccoon&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;cat&quot;</span>, <span class="string">&quot;8&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;zebra&quot;</span>, <span class="string">&quot;9&quot;</span>)</span><br><span class="line">db.<span class="built_in">put</span>(<span class="string">&quot;duck&quot;</span>, <span class="string">&quot;10&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2023/08/21/egTk2fHdES6WvAZ.png" alt="blog_how-rocksdb-works_rocksdb-compaction1.png"></p>
<p>随着我们的不断写入，MemTable 不断被刷到磁盘，L0 上的 SST 文件数量也在增长：</p>
<ul>
<li>删除或更新 key 所占用的空间永远不会被回收。例如，<code>cat</code> 这个 key 的三次更新记录分别在 SST1，SST2 和 SST3 中，而 <code>chipmunk</code> 在 SST1 中有一次更新记录，在 SST2 中有一次删除记录，这些无用的记录仍然占用额外磁盘空间。</li>
<li>随着 L0 上 SST 文件数量的增加，读取变得越来越慢。每次查找都要逐个检查所有 SST 文件。</li>
</ul>
<p>RocksDB 引入了压实（ Compaction ）机制，可以降低空间放大和读放大，但代价是更高的写放大。Compaction 会将某层的 SST 文件同下一层的 SST 文件合并，并在这个过程中丢弃已删除和被覆盖的无效 key。Compaction 会在后台专用的线程池中运行，从而保证了 RocksDB 可以在做 Compaction 时能够正常处理用户的读写请求。</p>
<p><img src="https://s2.loli.net/2023/08/21/iDsEe7N5x8HBbcv.png" alt="blog_how-rocksdb-works_rocksdb-compaction2.png"></p>
<p>Leveled Compaction 是 RocksDB 中的默认 Compaction 策略。使用 Leveled Compaction，L0 层中的不同 SST 文件键范围会重叠。L1 层及以下层会被组织为包含多个 SST 文件的序列，并保证同层级内的所有 SST 在键范围上没有交叠，且 SST 文件之间有序。Compaction 时，会选择性地将某层的 SST 文件与下一层的 key 范围有重叠 SST 文件进行合并。</p>
<p>举例来说，如下图所示，在 L0 到 L1 层进行 Compaction 时，如果 L0 上的输入文件覆盖整个键范围，此时就需要对所有 L0 和 L1 层的文件进行 Compaction。</p>
<p><img src="https://s2.loli.net/2023/08/21/7rV1EjIzk8G5HUq.png" alt="blog_how-rocksdb-works_rocksdb-compaction3.png"></p>
<p>而像是下面的这种 L1 和 L2 层的 Compaction，L1 层的输入文件只与 L2 层的两个 SST 文件重叠，因此，只需要对部分文件进行 Compaction 即可。</p>
<p><img src="https://s2.loli.net/2023/08/21/RBxDIzEFWdTn2Yy.png" alt="blog_how-rocksdb-works_rocksdb-compaction4.png"></p>
<p>当 L0 层上的 SST 文件数量达到一定阈值（默认为 4）时，将触发 Compaction。对于 L1 层及以下层级，当整个层级的 SST 文件总大小超过配置的目标大小时，会触发 Compaction 。当这种情况发生时，可能会触发 L1 到 L2 层的 Compaction。从而，从 L0 到 L1 层的 Compaction 可能会引发一直到最底层级联 Compaction。在 Compaction 完成之后，RocksDB 会更新元数据并从磁盘中删除 已经被 Compcated 过的文件。</p>
<p><em>注：RocksDB 提供了不同 Compaction 策略来在空间、读放大和写放大之间进行权衡</em>。</p>
<p>看到这里，你还记得上文提过 SST 文件中的 key 是有序的吗？有序性允许使用 K 路归并算法逐步合并多个 SST 文件。K 路归并是两路归并的泛化版本，其工作方式类似于归并排序的归并阶段。</p>
<h2 id="读路径"><a href="#读路径" class="headerlink" title="读路径"></a>读路径</h2><p>使用持久化在磁盘上不可变的 SST 文件，读路径要比写路径简单很多。要找寻某个 key，只需自顶而下遍历 LSM—Tree。从 MemTable 开始，下探到 L0，然后继续向更低层级查找，直到找到该 key 或者检查完所有 SST 文件为止。</p>
<p>以下是查找步骤：</p>
<ol>
<li>检索 MemTable。</li>
<li>检索不可变 MemTables。</li>
<li>搜索最近 flush 过的 L0 层中的所有 SST 文件。</li>
<li>对于 L1 层及以下层级，首先找到可能包含该 key 的单个 SST 文件，然后在文件内进行搜索。</li>
</ol>
<p>搜索 SST 文件涉及：</p>
<ol>
<li>（可选）探测布隆过滤器。</li>
<li>查找 index 来找到可能包含这个 key 的 block 所在位置。</li>
<li>读取 block 文件并尝试在其中找到 key。</li>
</ol>
<p>这就是全部所需步骤了！看看这个 LSM-Tree：</p>
<p><img src="https://s2.loli.net/2023/08/21/phNnzDGEsakAKml.png" alt="blog_how-rocksdb-works_rocksdb-lookup.png"></p>
<p>根据待查找的 key 的具体情况，查找过程可能在上面任意步骤提前终止。例如，在搜索 MemTable 后，key “cat” 或 “chipmunk” 的查找工作会立即结束。查找 “raccoon” 则需要搜索 L1 为止，而查找根本不存在的 “manul” 则需要搜索整个树。</p>
<h2 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h2><p>RocksDB 还提供了一个同时涉及读路径和写路径的功能：合并（merge）操作。假设，你在数据库中存了一个整数列表，偶尔需要扩展该列表。为了修改列表，你需要从数据库中读取其现有值，在内存中更新该列表，最后把更新后的值写回数据库。</p>
<p>上面整个操作序列被称为 “Read-Modify-Write” 循环：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">db = <span class="built_in">open_db</span>(path)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取 Read</span></span><br><span class="line">old_val = db.<span class="built_in">get</span>(key) <span class="comment">// RocksDB stores keys and values as byte arrays. We need to deserialize the value to turn it into a list.</span></span><br><span class="line">old_list = <span class="built_in">deserialize_list</span>(old_val) <span class="comment">// old_list: [1, 2, 3]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 修改 Modify</span></span><br><span class="line">new_list = old_list.<span class="built_in">extend</span>([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]) <span class="comment">// new_list: [1, 2, 3, 4, 5, 6]</span></span><br><span class="line">new_val = <span class="built_in">serialize_list</span>(new_list)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写回 Write</span></span><br><span class="line">db.<span class="built_in">put</span>(key, new_val)</span><br><span class="line"></span><br><span class="line">db.<span class="built_in">get</span>(key) <span class="comment">// deserialized value: [1, 2, 3, 4, 5, 6]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上面这种方式能达到目的，但存在一些缺陷：</p>
<ul>
<li>非线程安全——两个尝试更新相同的 key 的不同线程，交错执行，会出现更新丢失。</li>
<li>存在写放大——随着值变得越来越大，更新成本也会增加。例如，在含有 100 个数的列表中追加一个整数需要读取 100 个整数并将 101 个整数写回。</li>
</ul>
<p>除了 <code>Put</code> 和 <code>Delete</code> 写操作之外，RocksDB 还支持第三种写操作 <code>Merge</code>。<code>Merge</code> 操作需要提供 <code>**Merge Operator**</code>——一个用户定义函数，负责将增量更新组合成单个值：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">funcmerge_operator</span>(existing_val, updates) &#123;</span><br><span class="line">        combined_list = <span class="built_in">deserialize_list</span>(existing_val)</span><br><span class="line">        <span class="keyword">for</span> op in updates &#123;</span><br><span class="line">                combined_list.<span class="built_in">extend</span>(op)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">serialize_list</span>(combined_list)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">db = <span class="built_in">open_db</span>(path, &#123;merge_operator: merge_operator&#125;)</span><br><span class="line"><span class="comment">// key&#x27;s value is [1, 2, 3]</span></span><br><span class="line"></span><br><span class="line">list_update = <span class="built_in">serialize_list</span>([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">db.<span class="built_in">merge</span>(key, list_update)</span><br><span class="line"></span><br><span class="line">db.<span class="built_in">get</span>(key) <span class="comment">// deserialized value: [1, 2, 3, 4, 5, 6]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上面的 <code>merge_operator</code> 将传递给 Merge 调用的增量更新组合成一个单一值。当调用 Merge 时，RocksDB 仅将增量更新插入到 MemTable 和 WAL 中。之后，在 flush 和 compaction 时，RocksDB 调用 <code>merge_operator()</code> ，在条件允许时，将若干更新合并成单个更新或者单个值。在用户调用 <code>Get</code> 或扫描读取数据时，如果发现任何待 merge 的更新，也会调用 <code>merge_operator</code> 向用户返回一个经过 merge 而得到的值。</p>
<p>Merge 非常适合于需要持续对已有值进行少量更新的写入密集型场景。那么，代价是什么？读将变得更加昂贵——读时的合并值没有写回。对该 key 的查询需要一遍又一遍地执行相同的合并过程，直到触发 flush 和 compaction 为止。与 RocksDB 其他部分一样，我们可以通过限制 MemTable 中 merge 对象的数量、降低 L0 中 SST 文件数量来优化读行为。</p>
<h2 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h2><p>如果你的应用对性能非常敏感，那么使用 RocksDB 面临的最大挑战是需要针对特定工作负载来进行配置调优。RocksDB 提供了非常多的可配置项，但对其进行合理调整通常需要理解数据库内部原理并深入研究 RocksDB 源代码：</p>
<blockquote>
<p>“不幸的是，对 RocksDB 进行配置调优并不容易。即使作为 RocksDB 开发人员的我们，也不能完全理解每个配置更改的所造成的影响。如果你想针对你的工作负载充分调优，我们建议你进行实验和基准测试，并时刻注意三个放大因素。”</p>
<p>– RocksDB  官方调优指南</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从零开始写一个生产级别的 kv 存储是非困难的：</p>
<ul>
<li>硬件和操作系统随时都有可能丢失或损坏数据。</li>
<li>性能优化需要大量时间投入。</li>
</ul>
<p>RocksDB 解决了上述两个问题，从而让你可以专注于上层业务逻辑实现。这也使得 RocksDB 成为构建数据库的优秀模块。</p>
<blockquote>
<p>本篇文章来自我的小报童专栏，初步规划有以下几个系列：</p>
<ul>
<li>图数据库101系列</li>
<li>每天学点数据库系列</li>
<li>系统好文推荐系列</li>
<li>读书笔记系列</li>
<li>数据密集型论文导读系列</li>
</ul>
<p>会保证每周不低于两篇更新，订阅方式见<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">专栏介绍<i class="fa fa-external-link-alt"></i></span>，欢迎喜欢我文章的朋友们的订阅支持，激励我产出更多优质文章。</p>
</blockquote>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>rocksdb</tag>
        <tag>lsmtree</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库面试的几个常见误区</title>
    <url>/2023/08/21/database-interview-myth/</url>
    <content><![CDATA[<h1 id="数据库面试的几个常见误区"><a href="#数据库面试的几个常见误区" class="headerlink" title="数据库面试的几个常见误区"></a>数据库面试的几个常见误区</h1><p>由于业务的需要，最近面试了很多数据库候选人。发现很多候选人在面试准备时会有一些普遍的误区，借此机会展开聊聊我作为面试官的一些建议。这次主要讲四个误区：代码基础差、工程素养弱、沟通思维无、知识框架碎。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/08/21/database-interview-myth">https://www.qtmuniao.com/2023/08/21/database-interview-myth</a> 转载请注明出处</em></p>
<h2 id="误区一：代码基础差"><a href="#误区一：代码基础差" class="headerlink" title="误区一：代码基础差"></a><strong>误区一：代码基础差</strong></h2><p>数据库是一个工程性极强的领域，因此代码是面试考察中非常重要的一个环节，可以说代码写得好，即使背景稍弱，也可能会通过面试；但反之则不然，遇到过一些候选人，分布式事务的一些细节可以说的头头是道，但却连链表等基础数据结构都写不太明白，这个情况就是想给过也有心无力。</p>
<p>说到代码，我们并不期望候选人要能做出多么难的算法题。反而，会更针对偏基础、偏工程的方向考察。</p>
<ol>
<li><strong>基础数据结构</strong>。基础数据结构包括<strong>链表、哈希表、树</strong>等常见的数据结构和相关算法，最好都能快速地自己实现，并了解每种数据结构的特点。<strong>图</strong>偶尔会考察，但比较少，而且考察点很固定，通常就是最基本的遍历（BFS、DFS）、<strong>最短路</strong>、<strong>最小生成树</strong>和<strong>拓扑排序</strong>等三四个固定的算法。</li>
<li><strong>常见算法</strong>。最基本的就是几种常见的<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3F1ZXN0aW9uLzUxMzM3MjcyL2Fuc3dlci8xMjUzODUzNTU=">排序算法<i class="fa fa-external-link-alt"></i></span>，弄清楚其时间复杂度和空间复杂度以及基本的优缺点。另外一个初学者比较难理解的就是基于树的<strong>回溯算法</strong>，这个本质上是对<strong>递归思想</strong>了解的不透彻。当然，我当年也是花了很久才理解这种思想，但一般不会考很难的回溯。另外就是<strong>二分算法</strong>和<strong>分治算法</strong>，其核心思想是拆解问题域，去解决子问题：二分就是不断缩小问题规模，分治则是在缩小规模的基础上，还要将子问题的解进行组合，进而求解原问题。<strong>动态规划</strong>算法会比较难，通常不会考，即使考也只会考非常简单的，比如最基础版本的 01 背包问题。</li>
<li><strong>工程题目</strong>。我之前去面试其他公司，偏工程题目被考到最多的就是 <strong>LRU</strong>，因为他结合了哈希表、链表等多个数据结构，Corner case 也比较多，是很看代码功底的题，但是后来背的人多了，区分度也就不太高了。另外就是<strong>前缀树</strong>，也就是 <strong>Trie 树</strong>，这个相对少一些，代码写起来也会细节很多。我自己多会问一些基础数据结构的实现，比如实现一个哈希表，这个题可以有很多 follow up，比如扩缩容、线程安全等等；此外一些涉及文件读写、字节操作、多线程的题目偶尔也会问，由于这些 API 通常都很难记，这时候我通常让候选人可以随便查阅互联网，只需要让我看着就行。其实看候选人如何解决问题、如何搜索的过程本身也是一种考察。</li>
</ol>
<h2 id="误区二：工程素养弱"><a href="#误区二：工程素养弱" class="headerlink" title="误区二：工程素养弱"></a><strong>误区二：工程素养弱</strong></h2><p>现代的数据库代码，动辄数十万行，如果没有良好的<strong>代码规范</strong>，会在项目演进过程中很快变得不可维护。因此如果候选人在写代码时能够比较注意代码风格、体现出工程素养，会非常加分；反之如果胡乱命名、没有基本的抽象和复用，则会很减分。</p>
<p>另一个很能够体现工程素养的点是：<strong>解决实际问题的思路</strong>。比如当面试官考察一些工程代码时，题目可能比较模糊、宏大。这时候候选人如果能：</p>
<ol>
<li>用一些<strong>计算机常识</strong>，将模糊地带进行确定化。比如题目不要求基于内存还是文件，我们都先假设都在内存中，然后跟面试官说下利用 WAL 和 SnapShot 等方法应对宕机即可。</li>
<li>做一些<strong>简单假设</strong>，将问题域进行收束。比如数据类型不确定时，我们可以假设是最简单的整形；又如文件数据格式不确定时，我们可以假设一行一个数据。</li>
<li>抽象出基本模块，先走通<strong>宏观思路</strong>。也就是做项目时常用的<strong>最小可用原型</strong>思想，将每个子问题（比如读写文件、排序等）模块化，使用最简单实现、甚至暂时留白，从而专注主干逻辑搭建，迅速实现一个可用的原型，尔后再跟面试官讨论，对需要的模块进行优化。</li>
</ol>
<p>其中，最后一点非常重要，因为面试时间通常都很有限，如果你很快陷入某一块的工程细节中，比如如何读写文件、如何取舍 buffer 大小、如何处理 offset ，轻则时间到了还写不完、重则由于紧张陷进去根本出不来。这时候一定要注意使用最小可用模型、自顶向下逐步求精等思想，因为这也是我们在实际工作中完成任务常见的思想，是非常能够体现工程素养的一个侧面。</p>
<hr>
<p>本篇文章出自我的持续更新的数据库、分布式系统专栏：《系统日知录》，还剩下两小段，欢迎前往专栏<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">查看<i class="fa fa-external-link-alt"></i></span>。</p>
<p><img src="https://s2.loli.net/2023/08/21/ZGDQVIS7nWghXky.png" alt="database-interview-myth.png"></p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>生活工程学（一）：多轮次拆解</title>
    <url>/2023/08/21/life-engineering-many-passes/</url>
    <content><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><blockquote>
<p>我们在工程实践中，有些构建代码的小技巧，其背后所体现的思想，生活中也常常可见。本系列便是这样一组跨越生活和工程的奇怪联想。这是第一篇：多轮次拆解，也即，<strong>很多我们习惯一遍完成的事情，有时候拆成多个轮次完成，会简单、高效很多</strong>。</p>
</blockquote>
<p>我在进行 code review 时，常看到一些新手同学在一个 for 循环中干太多事情。常会引起多层嵌套，或者 for 循环内容巨大无比。此时，如果不损失太多性能，我通常建议同学将要干的事情拆成多少个步骤，每个步骤一个 for 循环。甚至，可以每个步骤一个函数。</p>
<p>当然，这些全是从维护角度着眼的。因为人一下总是记不了太多事情，一步步来，而不是揉在一块来，会让每个步骤逻辑清晰很多。后者，我通常称之为”<strong>摊大饼</strong>“式代码，这种代码的特点是写时很自然，但是维护起来很费劲——细节揉在一起总会让复杂度爆炸。软件工程中的最小可用原型，也是类似的理念。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/08/21/life-engineering-many-passes">https://www.qtmuniao.com/2023/08/21/life-engineering-many-passes</a> 转载请注明出处</em></p>
<p>这种理念，其实在”函数式“编程中也随处可见，即对一个数据集操作时，我们会链式的应用一系列变换函数，从而让数据流清晰的展示出来。在大数据处理中，这种范式就更常见了，比如 spark 论文中提到的：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">errors.<span class="built_in">filter</span>(_.<span class="built_in">contains</span>(<span class="string">&quot;HDFS&quot;</span>))</span><br><span class="line">      .<span class="built_in">map</span>(_.<span class="built_in">split</span>(’\t’)(<span class="number">3</span>))</span><br><span class="line">      .<span class="built_in">collect</span>()</span><br></pre></td></tr></table></figure>

<p> SQL 查询引擎在实现时也是用的类似机制，即将一个查询语句，转换成对一个行列组成的二维数据集，施加<strong>多轮次的算子变换</strong>。如下图所示。</p>
<p><img src="https://pic.imgdb.cn/item/64e31ef4661c6c8e54aa6e71.png"></p>
<p>图源：CMU15445，<span class="exturl" data-url="aHR0cHM6Ly8xNTQ0NS5jb3Vyc2VzLmNzLmNtdS5lZHUvZmFsbDIwMjIvbm90ZXMvMTItcXVlcnlleGVjdXRpb24xLnBkZg==">查询引擎讲义<i class="fa fa-external-link-alt"></i></span>。</p>
<p>我高中时学过一点点素描，虽然没有入门，但其多轮次的做图技法给我印象很深：先勾轮廓，再逐层完善。打线的时候也是一层层的打，而非一个地方画完再画另一个地方。我最近常常翻译文章，开始时，我总是务求一遍翻译好。但结果就是非常慢，且很容易放弃。后面开始使用多轮次、逐层打磨法。一开始用 ChatGPT 帮忙翻译一遍，然后自己再对照原文订正语义，最后扫一遍调换语序理顺词句等等。常言道，好文章是改出来的，应该也是这个道理。</p>
<p>滑铁卢大学教授 Srinivasan Keshav 在其 ”<span class="exturl" data-url="aHR0cDovL2Njci5zaWdjb21tLm9yZy9vbmxpbmUvZmlsZXMvcDgzLWtlc2hhdkEucGRm">How to Read a Paper<i class="fa fa-external-link-alt"></i></span>“ 中阐述了经典的”三遍（three-pas approach）读论文“方法，也是类似的思想：</p>
<ol>
<li>The first pass：鸟瞰式略读，抓摘要、章节标题、结论等重点内容。</li>
<li>The second pass：稍微细一些，但不要陷入细节。</li>
<li>The third pass：细读，完全理解。</li>
</ol>
<p>其中任何一步都可以及时停止：这可能不是你需要的论文。但我之前读论文就长陷入一个误区，我愿称之为”地毯式读法“——逐字句过每一个细节。包括我刚开始进行 code review 时，也常常陷入这个误区。</p>
<p>一次性的、按顺序把事情做完，是大部分人的天性，但这种天性往往是低效的，我们要通过不断地训练来克服。说起来，下馆子点菜的时候，也常用两遍法——第一遍把想吃的都加上，第二遍考虑各种约束（偏好强弱、价格高低、吃过与否等等）来将菜品去到一个合理的范围内。</p>
<p>我想背后的原因是：</p>
<ol>
<li>人的注意力是有限的，因此只擅长一次专注的做好一件事情。</li>
<li>人的认知也是一个由浅入深的过程，一层层细化便是利用了这个特点。</li>
</ol>
<hr>
<p>本文来自我的小报童付费专栏《系统日知录》，专注分布式系统、存储和数据库，有图数据库、代码解读、优质英文播客翻译、数据库学习、论文解读等等系列，欢迎喜欢我文章的朋友订阅👉<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">专栏<i class="fa fa-external-link-alt"></i></span>支持，你的支持对我持续创作优质文章非常重要。下面是当前文章列表：</p>
<p><strong>图数据库系列</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2ZiNGNhNzQ4LTUzZDktNDk1Yy05OWNhLTQwNDkzMzJhZDY5NQ==">图数据库资料汇总<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY5MTRhOGY2LWI1MDYtNGEzNy04YjU1LTg0OTE4NTQzOWQxNQ==">译： Factorization &amp; Great Ideas from Database Theory<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY1NmQ4ZDczLWY4ZWQtNDYwNC05ZjE0LWY3Nzc5N2U4NzdiMA==">Memgraph 系列（二）：可串行化实现<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzJlODA5MWEwLTgzNjMtNDk4Zi1iNjA5LWNlOGUyMzExMGM5ZQ==">Memgraph 系列（一）：数据多版本管理<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2I0MGZkYzIzLTEyYTktNGE4NS04ZDNhLWUzNWY2ZDFiMWIwYw==">【图数据库系列四】与关系模型的“缘”与“争”<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY2MDc1Y2U5LWZjNzYtNGUzNS1hOTFjLTkwY2Q2MTFmYzczMg==">【图数据库系列三】图的表示与存储<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzc3NTcyZWQ0LTcyM2QtNGRmZC1iYTE2LTViMTM2ZmY5YTdhMw==">【图数据库系列二】 Cypher 初探<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzZjBiZjExLWUxNjctNGY4MC04NDE1LTJlYjRhYjE3OTdiNQ==">【图数据库系列一】属性图模型是啥、有啥不足<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>数据库</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2FmM2RjM2E3LThkMmUtNDJhOC05NWMxLTNmY2MzZTZlNzA0NQ==">译：数据库五十年来研究趋势<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzk4MjRjYjlmLTIyODktNDg5NS1hOTM4LTQzMGQ1NWJhMWViYQ==">译：数据库中的代码生成（Codegen in Databas…<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2NhMDIwMjk3LTA5MDEtNDVkMS04YWNjLTFkODg0YmYxY2M4NA==">Facebook Velox 运行机制解析<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzE3NDdkNjQ4LTBiMGQtNDNmMy1iNDg0LWM5OTJhZDlmNmUyNQ==">分布式系统架构（二）—— Replica Placement<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzMzMjcxMDdiLTA5MTItNGQ3ZC05ZDk0LTM0Mzk1NGY1NmQ1ZA==">【好文荐读】DuckDB 中的流水线构建<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIwMzc5YzlkLTBiMDctNDFkNy05OWFhLTNiMzkwMDYzMmY1Mw==">译：时下大火的向量数据库，你了解多少？<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzMyZDgwYWVhLTM0NjYtNDU5Ni1iMDY4LWE3MTE1YmI3Y2JhYQ==">数据处理的大一统——从 Shell 脚本到 SQL 引擎<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIyZmZjYjUzLTFjZDItNDFhNS04MzA3LWEyOGEwZDZkNmZhNg==">Firebolt：如何在十八个月内组装一个商业数据库<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzhjZjk0ZDQzLWE5MWMtNGZlMy1iODMxLTYxNWVhYzhjOWUzYQ==">论文：NUMA-Aware Query Evaluation Framework 赏析<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzI4ZTAzMDMyLWUwOWYtNDkwNS04ZGJhLTU1OTE4MGIxNmMwMA==">优质信息源：分布式系统、存储、数据库<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Y3NzhjOWRiLTFiOWUtNDQ0YS05ZDY3LWQ0MGI3YWYzNDllNA==">向量数据库 Milvus 架构解析（一）<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzYTQ5MWRhLTE3ZjgtNGRmNy05ZThhLTI5YTc4ODk1NmI0MQ==">ER 模型背后的建模哲学<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzI5ZmY2MWZkLTI1ZTItNDEwNC05NDQ2LTZjY2I3MDJiY2Y1YQ==">什么是云原生数据库？<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>存储</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Y3NGUzNmIyLTE5MWEtNDcyZi1iMDczLTFiY2QxNDA0ZmMzOA==">存储引擎概述和资料汇总<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzcxY2Y5NzMzLWVlNzQtNGViYi1hYTI3LWY2M2Q3MmFmNjcxNg==">译：RocksDB 是如何工作的<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzZmZGQ5NTllLTk2MjktNGY3YS1hYjk3LWMxYTVjNDJmNWVkMg==">RocksDB 优化小解（二）：Prefix Seek 优化<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2UwNjk2YzRjLTdmYWYtNDQ0YS1iZTQwLWJhMjI4MDFjOTdmZg==">RocksDB 优化小解（三）：Async IO<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzdjY2MzYTcxLTBjNTktNGVmMy1hNTRiLTExMjZiMzIxY2ZkMQ==">大规模系统中使用 RocksDB 的一些经验<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>代码&amp;编程</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzc1MGUwOGY5LWY2NjctNDQ1OS05ZDk0LTUzZjM4YzA1MjlkYw==">影响我写代码的三个 “Code”<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzZjMmNmMzdjLWI3ZTMtNDliYy04ODFlLWJmNDRlYmE2YmNhZQ==">Folly 异步编程之 futures<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzQ2YzExOGVmLTkwY2ItNDg2OC1iYTEwLTU2MDQ1OWM2ZmEyYQ==">关于接口和实现<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2RmNTZjZDMyLTI3ZTgtNGNjOS1iYjQyLTJmZjM2MzUxMzQ5OQ==">C++ 私有函数的 override<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzlkOGY0OTNkLThlZmYtNDJjZS04NzNjLTFlODFlZDZlMWNjNA==">ErrorCode 还是 Exception ？<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzg0ODYwNTYxLWJhNTYtNGRlNC1hZGU4LWI3MzIwZDE1ODU4Ng==">Infra 面试之数据结构（一）：阻塞队列<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2VkZmRiYjE4LTJiYjEtNDlkMy1iMDdmLWRkMmEyZjU2MjkyOQ==">数据结构与算法（四）：递归和迭代<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>每天学点数据库系列</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2E0OTIyOTllLWRkMGUtNDY5ZS04NzA2LTI4MzZlMjBmODFmMA==">【每天学点数据库】Lecture #06：内存管理<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzgxOWMwMjk0LTBlZDQtNDE2MS1iM2M2LThhNjIzMTM2ZmE2Mg==">【每天学点数据库】Lecture #05：数据压缩<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzA1ZWEyY2Y2LTRiM2QtNDE2YS05MjRhLTNjMWY3YWQzN2ExZQ==">【每天学点数据库】Lecture #05：负载类型和存储模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzdlNjk1N2Q2LTRmZWUtNDJkYi1hNTFkLWQ3MmYyODRlMjczMw==">【每天学点数据库】Lecture #04：数据编码<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzVlMzRlZTBmLThmYTMtNGM3ZS05YjA5LTIxMjg3ZTBkYTYzOQ==">【每天学点数据库】Lecture #04：日志构型存储<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzZDZmNDk5LWVlZTctNDFiMi1iOGRlLTU1ZmIwMDAwN2NkNA==">【每天学点数据库】Lecture #03：Data Layout<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2IzYWQ4MTU0LTJlMjktNGVjMS1hNjI3LWZkMzI4OGI1ZDJhOQ==">【每天学点数据库】Lecture #03: Database and OS<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2FlMmUxZTM1LTNkY2MtNGZiZC05ZjZiLTM5ZTY0NWU5OTA2NQ==">【每天学点数据库】Lecture #03：存储层次体系<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2E2ZTVmOTc2LTBlOTktNDExMS1hMWU5LWMwZWE4NTNiMjJiYg==">【每天学点数据库】Lecture #01：关系代数<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzFkM2U5OGE4LTBkZWUtNGI3OS05M2Q0LWE5NjQwOTQxMzI1Mw==">【每天学点数据库】Lecture #01：关系模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2M0NDE2OGNmLTljM2ItNGM1My1iNDllLWEzZTUxZTg1NzZhZA==">【每天学点数据库】Lecture #01：数据模型<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>杂谈</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">数据库面试的几个常见误区 🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzJlNzgzNWE1LTRhZDUtNDViMC05ZWJjLWQxMjk0NWU4NjZmMQ==">生活工程学（一）：多轮次拆解<i class="fa fa-external-link-alt"></i></span><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Q1OGViMmZhLWZjM2QtNGE2ZS1hOWZkLWI4NTQxZGZhNTFiZQ==">系统中一些有趣的概念对<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2VmZTZjNzRkLWY2ZGMtNDk0Yy04NDdiLTVmZDIxMzhjMGYwNQ==">系统设计时的简洁和完备<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzM0ZGMzYzRiLWRkM2QtNGNhMi04ZWNjLTFlZmFiNWVjZjcwOQ==">工程经验的周期<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2RlMmNjNTI5LTBhN2UtNDE4Ni05N2UxLWFiNTE0ZWM5MTZjYg==">关于“名字”拿来<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY2NDcyMGE1LWI5NDMtNDU2OC1hODEwLWUyNzhiYzZjMTczYw==">Cache 和 Buffer 都是缓存有什么区别？<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>多轮次</tag>
        <tag>multi-passes</tag>
      </tags>
  </entry>
  <entry>
    <title>知新的关键——类比</title>
    <url>/2023/08/21/use-analogy-to-know-more/</url>
    <content><![CDATA[<p>这一年来，由于各种原因，需要不断地学新东西。于是如何高效地学习，就成了一个随之而来的问题。最近看了一些书和公开课，包括 Scott H Young 的 <span class="exturl" data-url="aHR0cHM6Ly9ib29rLmRvdWJhbi5jb20vc3ViamVjdC8xMTYwMzI5OC8=">Learn More, Study Less<i class="fa fa-external-link-alt"></i></span>（以下简称 LMSL），和 Coursera 上的公开课<span class="exturl" data-url="aHR0cHM6Ly93d3cuY291cnNlcmEub3JnL2xlYXJuL3J1aGUteHVleGk=">学会如何学习<i class="fa fa-external-link-alt"></i></span>（Learning How to Learn，以下简称 LHL），发现了一些有意思的观点，趁着热乎（虽然都还没看完），记下来梳理一下，也希望能对大家有所启发。</p>
<p>这两个资源在进行讲解时，都使用了<strong>类比</strong>（analogy）。</p>
<p>LMSL 中提出了<strong>整体学习法</strong>（Holistic learning），其基本思想是：你不可能孤立地学会一个概念，而只能将其融入已有的概念体系中，从不同角度对其进行刻画来弄懂其内涵和外延。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/08/21/use-analogy-to-know-more">https://www.qtmuniao.com/2023/08/21/use-analogy-to-know-more</a> 转载请注明出处</em></p>
<p>并且书中使用三个类比对整体学习法进行拆解：</p>
<ol>
<li><strong>构件（Constructs）</strong>：一组紧密相关的知识。如学习 C++ 时，构件就是 C++ 所涉及到的各种知识。</li>
<li><strong>模具（Models）</strong>：对构件抽象出的可以进行移植和复用的主要特点。所谓“举一隅不以三隅反，则不复也”。</li>
<li><strong>高速路（Highways）</strong>：看似毫不相干的概念间的连接。如跨领域、交叉学科间的某些概念的相似性。</li>
</ol>
<p><img src="https://s2.loli.net/2023/08/21/64DBnd3amuYpZHk.png" alt="highway-in-brain.png"></p>
<p>即，你在做了足够多的<strong>构件</strong>之后，就可以抽象出某些可复用的<strong>模具</strong>，以快速的造新构件。而由于复杂构件的组合性，不同领域的构件可能在某些角度具有相似性，这些相似性便是不同概念团之间的<strong>高速路</strong>。这个模型很像求 K 临近的 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE2MDMuMDkzMjA=">HNSW<i class="fa fa-external-link-alt"></i></span> 算法中所涉及到的<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvU21hbGwtd29ybGRfbmV0d29yaw==">小世界<i class="fa fa-external-link-alt"></i></span>模型思想。实践多了（构件）大家都会有一些总结（模型），但真正让你与众不同的是，这些跨领域、多维度的连接（高速路）。</p>
<p>LHL 中提出了<strong>专注模式</strong>（ Focused Mode）和<strong>发散模式</strong>（Diffuse Mode）的两种思维方式。前者我们常常提起，就是指我们一心一意扑在某个东西上；而后者，我们可能不太熟悉，是指我们处于相对放松的状态，原本不太相干的知识团发生了连接。为了进行说明，课程使用我们小时候玩的<strong>弹珠游戏</strong>来进行类比。</p>
<p><img src="https://s2.loli.net/2023/08/21/OLpdc4oIKZErNqB.png" alt="brain-two-models.png"></p>
<p>在专注模式下，缓冲器（图中蓝色的点）很密集，已经学到的知识就像是在小范围内形成的一些固定通路（图中橙色通路）。我们在对熟悉的事务相关联的注思考时，可以思路顺畅的进行推理和思考。但是对于一些从未接触过的新的概念（图中绿色通路），则不知道这个模式在哪里、看起来如何。对应到图中，我们不知道如何让弹珠抵达这个区域。</p>
<p>这时，要开启一种新的思维模式，我们需要一个不同的思路——发散模式。在发散模式下，橡胶缓冲器很稀疏，想法（弹珠）蹦出来后，由于阻碍较少，可以在大范围内跳来跳去。在这种模式下，我们可以从更高的维度、全局鸟瞰的视角来在不同的概念间进行穿梭，从而建立新的连接、打开新思路的入口。这两种模式是互斥的，比如你在进行全景式思考时，势必就不能让思维陷入到某个细节问题的详细解决办法中。</p>
<p>从上面两个例子，我们可以看出：<strong>虽然用来类比的意像并非百分之百贴切，但确实抓住了所阐述道理的一些核心特点</strong>。这便是类比的威力所在，通过大家熟知的意像来对新概念体系进行“速写”，然后再展开细节，对这些意像进行适当地裁剪，从而达到对真实的逼近。总的来说，类比既是我们进行学习的重要倚靠，也是我们进行阐释的强力手段。</p>
<p>类比，或者隐喻（metaphor）在软件工程中也非常重要。<span class="exturl" data-url="aHR0cHM6Ly9tLmRvdWJhbi5jb20vYm9vay9zdWJqZWN0LzE0MzIwNDIv">代码大全<i class="fa fa-external-link-alt"></i></span>（code complete）在第二章中提到了这一点。我自己的感受是，通过隐喻选取合适的概念体系对你的代码进行组织，可以大大降低代码编写和维护的成本。随便举个例子，在构造分布式任务调度系统时，我们通常会涉及以下概念：</p>
<ol>
<li>Job：逻辑上的一个任务</li>
<li>Tasks：物理上调度到不同节点上的、属于同一个任务的一组子任务。</li>
<li>Hint：用以任务调度的约束，如容错域、资源余量。</li>
<li>Scheduler：组织调度策略的任务调度方。</li>
</ol>
<p>这些概念最初取材于现实的工业生产，我们将其拿来，通过合理地定义这些概念的含义和联系，可以轻松地构造复杂的任务调度系统。</p>
<p>最后，希望类比成为你打开新世界大门的钥匙。</p>
<hr>
<p>本文来自我的小报童付费专栏《系统日知录》，专注分布式系统、存储和数据库，有图数据库、代码解读、优质英文播客翻译、数据库学习、论文解读等等系列，欢迎喜欢我文章的朋友订阅👉<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">专栏<i class="fa fa-external-link-alt"></i></span>支持，你的支持对我持续创作优质文章非常重要。下面是当前文章列表：</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>类比</tag>
      </tags>
  </entry>
  <entry>
    <title>数据处理的大一统——从 Shell 脚本到 SQL 引擎</title>
    <url>/2023/08/21/unify-data-processing/</url>
    <content><![CDATA[<p>“工业流水线”的鼻祖，<span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj1BczBscXNkMi1OSQ==">福特 T 型汽车<i class="fa fa-external-link-alt"></i></span>的电机装配，将组装过程拆成 29 道工序，将装备时间由平均二十分钟降到五分钟，效率提升四倍 ，下图<span class="exturl" data-url="aHR0cHM6Ly93d3cubW90b3IxLmNvbS9mZWF0dXJlcy8xNzgyNjQvZm9yZC1tb2RlbC10LWZhY3RvcnktY3V0YXdheS1raW1ibGUv">图源<i class="fa fa-external-link-alt"></i></span>。</p>
<p><img src="https://s2.loli.net/2023/08/21/BrMe3j9oapmX8f2.png" alt="T-model-car.png"></p>
<p>这种流水线的思想在数据处理过程中也随处可见。其核心概念是：</p>
<ol>
<li><strong>标准化的数据集合</strong>：对应待组装对象，是对数据处理中各个环节输入输出的一种<strong>一致性抽象</strong>。所谓一致，就是一个任意处理环节的输出，都可以作为任意处理环节的输入。</li>
<li><strong>可组合的数据变换</strong>：对应单道组装工序，定义了对数据进行变换的一个<strong>原子</strong>操作。通过组合各种原子操作，可以具有强大的表达力。</li>
</ol>
<p>则，数据处理的本质是：<strong>针对不同需求，读取并标准化数据集后，施加不同的变换组合</strong>。</p>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/08/21/unify-data-processing">https://www.qtmuniao.com/2023/08/21/unify-data-processing</a> 转载请注明出处</em></p>
<h2 id="Unix-管道"><a href="#Unix-管道" class="headerlink" title="Unix 管道"></a>Unix 管道</h2><p>Unix 管道是一项非常伟大的发明，体现了 Unix 的一贯哲学：</p>
<blockquote>
<p>程序应该只关注一个目标，并尽可能把它做好。让程序能够互相协同工作。应该让程序处理文本数据流，因为这是一个通用的接口。</p>
</blockquote>
<blockquote>
<p>— Unix Pipe 机制发明者 Malcolm Douglas McIlroy</p>
</blockquote>
<p>上述三句话哲学正体现了我们提到的两点，标准化的数据集合——来自<strong>标准输入输出</strong>的<strong>文本</strong>数据流，可组合的数据变换——能够协同工作的程序（如像 sort, head, tail 这种 Unix 自带的工具，和用户自己编写的符合管道要求的程序）。</p>
<p>让我们来看一个使用 Unix tools 和管道来解决实际问题的例子。假设我们有一些关于服务访问的日志文件（<code>var/log/nginx/access.log</code> ，例子来自 <span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">DDIA<i class="fa fa-external-link-alt"></i></span> 第十章），日志的每一行格式如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// $remote_addr - $remote_user [$time_local] &quot;$request&quot;</span></span><br><span class="line"><span class="comment">// $status $body_bytes_sent &quot;$http_referer&quot; &quot;$http_user_agent&quot;</span></span><br><span class="line"><span class="number">216.58</span><span class="number">.210</span><span class="number">.78</span> - - [<span class="number">27</span>/Feb/<span class="number">2015</span>:<span class="number">17</span>:<span class="number">55</span>:<span class="number">11</span> +<span class="number">0000</span>] <span class="string">&quot;GET /css/typography.css HTTP/1.1&quot;</span> </span><br><span class="line"><span class="number">200</span> <span class="number">3377</span> <span class="string">&quot;http://martin.kleppmann.com/&quot;</span> <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) </span></span><br><span class="line"><span class="string">AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.115 Safari/537.36&quot;</span></span><br></pre></td></tr></table></figure>

<p>我们的需求是，统计出日志文件中最受欢迎的五个网页。使用 Unix Shell ，我们会写出类似的命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /var/log/nginx/access.log | <span class="comment"># 读取文件，打入标准输出</span></span><br><span class="line">    awk <span class="string">&#x27;&#123;print $7&#125;&#x27;</span> | <span class="comment"># 取出每行按空格分割的第七个字段</span></span><br><span class="line">    <span class="built_in">sort</span>             | <span class="comment"># 对每行按字面值进行排序</span></span><br><span class="line">    <span class="built_in">uniq</span> -c          | <span class="comment"># 归并重复行，并给出重复次数</span></span><br><span class="line">    <span class="built_in">sort</span> -r -n       | <span class="comment"># 按重复次数降序进行排序</span></span><br><span class="line">    <span class="built_in">head</span> -n 5          <span class="comment"># 输出前五行</span></span><br></pre></td></tr></table></figure>

<p>可以看出上述 Shell 命令有以下几个特点：</p>
<ol>
<li>每个命令实现的功能都很简单（高内聚）</li>
<li>所有命令通过<strong>管道</strong>进行组合（低耦合），当然这也要求可组合的程序只面向标准输入、标准输出进行编程，无其他副作用（比如输出到文件）</li>
<li>输入输出面向文本而非二进制</li>
</ol>
<p>此外，Unix 的管道的另一大优点是——流式的处理数据。也即所有程序中间结果并非都计算完成之后，才送入下一个命令，而是边算边送，从而达到多个程序并行执行的效果，这就是流水线的精髓了。</p>
<p>当然，管道也有缺点——只能进行<strong>线性</strong>的流水线排布，这也限制了他的表达能力。</p>
<h2 id="GFS-和-MapReduce"><a href="#GFS-和-MapReduce" class="headerlink" title="GFS 和 MapReduce"></a>GFS 和 MapReduce</h2><p>MapReduce 是谷歌 2004 年的论文 <span class="exturl" data-url="aHR0cHM6Ly9yZXNlYXJjaC5nb29nbGUuY29tL2FyY2hpdmUvbWFwcmVkdWNlLW9zZGkwNC5wZGY=">MapReduce: Simplified Data Processing on Large Clusters<i class="fa fa-external-link-alt"></i></span> 提出的，用以解决大规模集群、并行数据处理的一种算法。GFS 是与 MapReduce 配套使用的基于磁盘的分布式文件系统。</p>
<p>MapReduce 算法主要分为三个阶段：</p>
<ol>
<li><strong>Map</strong>：在不同机器上并行的对每个数据分区执行用户定义的 <code>map() → List&lt;Key, Value&gt;</code> 函数。</li>
<li><strong>Shuffle</strong>：将 map 的输出结果（KV 对）按 key 进行重新分区，按 key 聚集送到不同机器上， <code>Key→ List&lt;Value&gt;</code>。</li>
<li><strong>Reduce</strong>：在不同机器上并行地对 map 输出的每个 key 对应的<code>List&lt;Value&gt;</code> 调用 reduce 函数。</li>
</ol>
<p>（下图源 DDIA 第十章）</p>
<p><img src="https://s2.loli.net/2023/08/21/vWfR7J5pUTub89i.png" alt="mapreduce.png"></p>
<p>每个 MapReduce 程序就是对存储在 GFS 上的数据集（标准化的数据集）的一次变换。理论上，我们可以通过组合多个 MapReduce 程序（可组合的变换），来满足任意复杂的数据处理需求。</p>
<p>但与管道不同的是，每次 MapReduce 的输出都要进行“<strong>物化</strong>”，即完全落到分布式文件系统 GFS 上，才会执行下一个 MapReduce 程序。好处是可以进行任意的、非线性的 MapReduce 程序排布。坏处是代价非常高，尤其考虑到 GFS 上的文件是多机多副本的数据集，这意味着大量的跨机器数据传输、额外的数据拷贝开销。</p>
<p>但要考虑到历史上开创式的创新，纵然一开始缺点多多，但会随着时间迭代而慢慢克服。GFS + MapReduce 正是这样一种在工业界开创了在大规模集群尺度上处理海量数据的先河。</p>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><p>Spark 便是为了解决 MapReduce 中每次数据集都要落盘的一种演进。</p>
<p>首先，Spark 提出了标准的数据集抽象——<a href="https://www.qtmuniao.com/2019/11/14/rdd/">RDD</a>，这是一种通过<strong>分片</strong>的形式分散在<strong>多机</strong>上、<strong>基于内存</strong>的数据集。基于内存可以使得每次处理结果不用落盘，从而处理延迟更低。基于分片可以使得在机器宕机时，只用恢复少量分片，而非整个数据集。逻辑上，我们可以将其当做一个整体来进行变换，物理上，我们使用多机内存承载其每个分片。</p>
<p>其次，基于 RDD，Spark 提供了多种可灵活组合的算子集，这相当于对一些常用的变换逻辑进行“<strong>构件化</strong>”，可以让用户开箱即用。（下面图源 <span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9zeXN0ZW0vZmlsZXMvY29uZmVyZW5jZS9uc2RpMTIvbnNkaTEyLWZpbmFsMTM4LnBkZg==">RDD 论文<i class="fa fa-external-link-alt"></i></span>）</p>
<p><img src="https://s2.loli.net/2023/08/21/wTIi7SbOnRmMpZX.png" alt="rdd-operators.png"></p>
<p>基于此，用户可以进行任意复杂数据处理，在物理上多个数据集（点）和算子（边）会构成一个复杂的 DAG （有向无环图）执行拓扑：</p>
<p><img src="https://s2.loli.net/2023/08/21/xuYijZW6GoqSMFd.png" alt="rdd-dag.png"></p>
<h2 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h2><p>关系型数据库是数据处理系统的集大成者。一方面，它对外提供强大的声明式查询语言——SQL，兼顾了灵活性和易用性。另一方面，他对内使用紧凑、索引友好的存储方式，可以支撑高效的数据查询需求。关系型数据库系统同时集计算和存储于一身，又会充分利用硬盘，甚至网络（分布式数据库）特点，是对计算机各种资源全方位使用的一个典范。本文不去过分展开关系型数据库实现的各个环节，而是聚焦本文重点——标准的数据集和可组合的算子。</p>
<p>关系型数据库对用户提供的数据基本组织单位是——关系，或者说表。在 SQL 模型中，这是一种由行列组成的、强模式的二维表。所谓强模式，可以在逻辑上理解为表格中每个单元所存储的数据必须要符合该列“表头”的类型定义。针对这种标准的二维表，用户可以施加各种关系代数算子（选择、投影、笛卡尔乘积）。</p>
<p>一条 SQL 语句，在进入 RDBMS 之后，经过解析、校验、优化，最后转化成算子树进行执行。对应的 RDBMS 中的逻辑单元，我们通常称之为——<strong>执行引擎</strong>，<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29raW5jdWJhdG9yL3ZlbG94">Facebook Velox<i class="fa fa-external-link-alt"></i></span> 就是专门针对该生态位的一个 C++ 库。</p>
<p>传统的执行引擎多使用火山模型，一种属于拉（ pull-based ）流派的执行方式。其基本概念就是以树形的方式组织算子，并从根节点开始，自上而下的进行递归调用，算子间自下而上的以行（row）或者批（batch）的粒度返回数据。</p>
<p><img src="https://pic.imgdb.cn/item/64e31c15661c6c8e549fa073.png"></p>
<p>近些年来，基于推（push-based）的流派渐渐火起来了，DuckDB、Velox 都属于此流派。类似于将递归转化为迭代，自下而上，从叶子节点进行计算，然后推给父亲节点，直到根节点。每个算子树都可以拆解为多个可以并行执行的算子流水线（下图源，<span class="exturl" data-url="aHR0cHM6Ly9mYWNlYm9va2luY3ViYXRvci5naXRodWIuaW8vdmVsb3gvZGV2ZWxvcC90YXNrLmh0bWw=">Facebook Velox 文档<i class="fa fa-external-link-alt"></i></span>）</p>
<p><img src="https://s2.loli.net/2023/08/21/RUnOCV2wEtHxFW4.png" alt="pipeline-break.png"></p>
<p>我们把上图顺时针旋转九十度，可以发现他和 Spark 的执行方式如出一辙，更多关于 velox 机制的解析，可以参考我写的<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82MTQ5MTgyODk=">这篇文章<i class="fa fa-external-link-alt"></i></span>。</p>
<p>但无论推还是拉，其对数据集和算子的抽象都符合本文一开始提出的理论。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>考察完上述四种系统之后，可以看出，数据处理在某种角度上是大一统的——<strong>首先抽象出归一化的数据集，然后提供施加于该数据集之上的运算集，最终通过组合的形式表达用户的各种数据处理需求</strong>。</p>
<hr>
<p>本文来自我的小报童付费专栏《系统日知录》，专注分布式系统、存储和数据库，有图数据库、代码解读、优质英文播客翻译、数据库学习、论文解读等等系列，欢迎喜欢我文章的朋友订阅👉<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">专栏<i class="fa fa-external-link-alt"></i></span>支持，你的支持对我持续创作优质文章非常重要。下面是当前文章列表：</p>
<p><strong>图数据库系列</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2ZiNGNhNzQ4LTUzZDktNDk1Yy05OWNhLTQwNDkzMzJhZDY5NQ==">图数据库资料汇总<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY5MTRhOGY2LWI1MDYtNGEzNy04YjU1LTg0OTE4NTQzOWQxNQ==">译： Factorization &amp; Great Ideas from Database Theory<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY1NmQ4ZDczLWY4ZWQtNDYwNC05ZjE0LWY3Nzc5N2U4NzdiMA==">Memgraph 系列（二）：可串行化实现<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzJlODA5MWEwLTgzNjMtNDk4Zi1iNjA5LWNlOGUyMzExMGM5ZQ==">Memgraph 系列（一）：数据多版本管理<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2I0MGZkYzIzLTEyYTktNGE4NS04ZDNhLWUzNWY2ZDFiMWIwYw==">【图数据库系列四】与关系模型的“缘”与“争”<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY2MDc1Y2U5LWZjNzYtNGUzNS1hOTFjLTkwY2Q2MTFmYzczMg==">【图数据库系列三】图的表示与存储<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzc3NTcyZWQ0LTcyM2QtNGRmZC1iYTE2LTViMTM2ZmY5YTdhMw==">【图数据库系列二】 Cypher 初探<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzZjBiZjExLWUxNjctNGY4MC04NDE1LTJlYjRhYjE3OTdiNQ==">【图数据库系列一】属性图模型是啥、有啥不足<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>数据库</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2FmM2RjM2E3LThkMmUtNDJhOC05NWMxLTNmY2MzZTZlNzA0NQ==">译：数据库五十年来研究趋势<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzk4MjRjYjlmLTIyODktNDg5NS1hOTM4LTQzMGQ1NWJhMWViYQ==">译：数据库中的代码生成（Codegen in Databas…<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2NhMDIwMjk3LTA5MDEtNDVkMS04YWNjLTFkODg0YmYxY2M4NA==">Facebook Velox 运行机制解析<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzE3NDdkNjQ4LTBiMGQtNDNmMy1iNDg0LWM5OTJhZDlmNmUyNQ==">分布式系统架构（二）—— Replica Placement<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzMzMjcxMDdiLTA5MTItNGQ3ZC05ZDk0LTM0Mzk1NGY1NmQ1ZA==">【好文荐读】DuckDB 中的流水线构建<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIwMzc5YzlkLTBiMDctNDFkNy05OWFhLTNiMzkwMDYzMmY1Mw==">译：时下大火的向量数据库，你了解多少？<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzMyZDgwYWVhLTM0NjYtNDU5Ni1iMDY4LWE3MTE1YmI3Y2JhYQ==">数据处理的大一统——从 Shell 脚本到 SQL 引擎<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIyZmZjYjUzLTFjZDItNDFhNS04MzA3LWEyOGEwZDZkNmZhNg==">Firebolt：如何在十八个月内组装一个商业数据库<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzhjZjk0ZDQzLWE5MWMtNGZlMy1iODMxLTYxNWVhYzhjOWUzYQ==">论文：NUMA-Aware Query Evaluation Framework 赏析<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzI4ZTAzMDMyLWUwOWYtNDkwNS04ZGJhLTU1OTE4MGIxNmMwMA==">优质信息源：分布式系统、存储、数据库<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Y3NzhjOWRiLTFiOWUtNDQ0YS05ZDY3LWQ0MGI3YWYzNDllNA==">向量数据库 Milvus 架构解析（一）<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzYTQ5MWRhLTE3ZjgtNGRmNy05ZThhLTI5YTc4ODk1NmI0MQ==">ER 模型背后的建模哲学<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzI5ZmY2MWZkLTI1ZTItNDEwNC05NDQ2LTZjY2I3MDJiY2Y1YQ==">什么是云原生数据库？<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>存储</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Y3NGUzNmIyLTE5MWEtNDcyZi1iMDczLTFiY2QxNDA0ZmMzOA==">存储引擎概述和资料汇总<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzcxY2Y5NzMzLWVlNzQtNGViYi1hYTI3LWY2M2Q3MmFmNjcxNg==">译：RocksDB 是如何工作的<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzZmZGQ5NTllLTk2MjktNGY3YS1hYjk3LWMxYTVjNDJmNWVkMg==">RocksDB 优化小解（二）：Prefix Seek 优化<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2UwNjk2YzRjLTdmYWYtNDQ0YS1iZTQwLWJhMjI4MDFjOTdmZg==">RocksDB 优化小解（三）：Async IO<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzdjY2MzYTcxLTBjNTktNGVmMy1hNTRiLTExMjZiMzIxY2ZkMQ==">大规模系统中使用 RocksDB 的一些经验<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>代码&amp;编程</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzc1MGUwOGY5LWY2NjctNDQ1OS05ZDk0LTUzZjM4YzA1MjlkYw==">影响我写代码的三个 “Code”<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzZjMmNmMzdjLWI3ZTMtNDliYy04ODFlLWJmNDRlYmE2YmNhZQ==">Folly 异步编程之 futures<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzQ2YzExOGVmLTkwY2ItNDg2OC1iYTEwLTU2MDQ1OWM2ZmEyYQ==">关于接口和实现<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2RmNTZjZDMyLTI3ZTgtNGNjOS1iYjQyLTJmZjM2MzUxMzQ5OQ==">C++ 私有函数的 override<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzlkOGY0OTNkLThlZmYtNDJjZS04NzNjLTFlODFlZDZlMWNjNA==">ErrorCode 还是 Exception ？<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzg0ODYwNTYxLWJhNTYtNGRlNC1hZGU4LWI3MzIwZDE1ODU4Ng==">Infra 面试之数据结构（一）：阻塞队列<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2VkZmRiYjE4LTJiYjEtNDlkMy1iMDdmLWRkMmEyZjU2MjkyOQ==">数据结构与算法（四）：递归和迭代<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>每天学点数据库系列</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2E0OTIyOTllLWRkMGUtNDY5ZS04NzA2LTI4MzZlMjBmODFmMA==">【每天学点数据库】Lecture #06：内存管理<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzgxOWMwMjk0LTBlZDQtNDE2MS1iM2M2LThhNjIzMTM2ZmE2Mg==">【每天学点数据库】Lecture #05：数据压缩<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzA1ZWEyY2Y2LTRiM2QtNDE2YS05MjRhLTNjMWY3YWQzN2ExZQ==">【每天学点数据库】Lecture #05：负载类型和存储模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzdlNjk1N2Q2LTRmZWUtNDJkYi1hNTFkLWQ3MmYyODRlMjczMw==">【每天学点数据库】Lecture #04：数据编码<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzVlMzRlZTBmLThmYTMtNGM3ZS05YjA5LTIxMjg3ZTBkYTYzOQ==">【每天学点数据库】Lecture #04：日志构型存储<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzZDZmNDk5LWVlZTctNDFiMi1iOGRlLTU1ZmIwMDAwN2NkNA==">【每天学点数据库】Lecture #03：Data Layout<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2IzYWQ4MTU0LTJlMjktNGVjMS1hNjI3LWZkMzI4OGI1ZDJhOQ==">【每天学点数据库】Lecture #03: Database and OS<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2FlMmUxZTM1LTNkY2MtNGZiZC05ZjZiLTM5ZTY0NWU5OTA2NQ==">【每天学点数据库】Lecture #03：存储层次体系<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2E2ZTVmOTc2LTBlOTktNDExMS1hMWU5LWMwZWE4NTNiMjJiYg==">【每天学点数据库】Lecture #01：关系代数<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzFkM2U5OGE4LTBkZWUtNGI3OS05M2Q0LWE5NjQwOTQxMzI1Mw==">【每天学点数据库】Lecture #01：关系模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2M0NDE2OGNmLTljM2ItNGM1My1iNDllLWEzZTUxZTg1NzZhZA==">【每天学点数据库】Lecture #01：数据模型<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>杂谈</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">数据库面试的几个常见误区 🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzJlNzgzNWE1LTRhZDUtNDViMC05ZWJjLWQxMjk0NWU4NjZmMQ==">生活工程学（一）：多轮次拆解<i class="fa fa-external-link-alt"></i></span><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Q1OGViMmZhLWZjM2QtNGE2ZS1hOWZkLWI4NTQxZGZhNTFiZQ==">系统中一些有趣的概念对<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2VmZTZjNzRkLWY2ZGMtNDk0Yy04NDdiLTVmZDIxMzhjMGYwNQ==">系统设计时的简洁和完备<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzM0ZGMzYzRiLWRkM2QtNGNhMi04ZWNjLTFlZmFiNWVjZjcwOQ==">工程经验的周期<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2RlMmNjNTI5LTBhN2UtNDE4Ni05N2UxLWFiNTE0ZWM5MTZjYg==">关于“名字”拿来<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY2NDcyMGE1LWI5NDMtNDU2OC1hODEwLWUyNzhiYzZjMTczYw==">Cache 和 Buffer 都是缓存有什么区别？<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>data processing</tag>
      </tags>
  </entry>
  <entry>
    <title>20230819 B 站求职面试直播</title>
    <url>/2023/08/19/live-show-infra-interview/</url>
    <content><![CDATA[<p>这是我第一次在 b 站直播分享，录屏地址 <span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMUZ6NHkxdTc5dg==">https://www.bilibili.com/video/BV1Fz4y1u79v<i class="fa fa-external-link-alt"></i></span> ，主要是从我的求职经历以及面试经历角度聊了一些关于 infra 找工作的注意点，并回答了同学一些现场问题。</p>
<h1 id="🐎-求职准备"><a href="#🐎-求职准备" class="headerlink" title="🐎 求职准备"></a>🐎 求职准备</h1><h2 id="软素质"><a href="#软素质" class="headerlink" title="软素质"></a>软素质</h2><p>💁‍♂️ <strong>沟通</strong>。面试时无论是经历描述，系统设计甚至写代码，沟通都是第一位的，这是面试各个环节顺利展开的前提。</p>
<p>把一件事说清楚：</p>
<ol>
<li>上下文：先和面试官对齐上下文，不要默认他比你知道的多。</li>
<li>条理性：背景 → 需求 → 方案 → 挑战点 → 结果</li>
<li>简洁性：就跟写文章一样，多过几遍就好了。</li>
</ol>
<p>🧠 <strong>思维</strong>。主要是<strong>抽象</strong>和<strong>联想</strong>。</p>
<ol>
<li><strong>抽象</strong>。也可以说是归纳，或者叫<strong>知识聚簇</strong>。以树来做类比，就是遍历几个子节点，抽象出其共通的父节点的特质，然后进而推演出新的子节点。比如调度问题（CPU 调度、分布式任务调度）。</li>
<li><strong>联想</strong>。也可以说是关联，或者叫<strong>跨域跳联</strong>。以图来做类比，就是对于几个连通子图，在新的维度上给其建立通路。比如文字是思想的一种序列化。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/08/19/live-show-infra-interview">https://www.qtmuniao.com/2023/08/19/live-show-infra-interview</a> 转载请注明出处</em></p>
<h2 id="硬素质"><a href="#硬素质" class="headerlink" title="硬素质"></a>硬素质</h2><p>🧑‍💻 <strong>代码功底</strong>。初级的就是<strong>数据结构</strong>和<strong>基本算法</strong>；中级的包括<strong>代码组织</strong>和<strong>工程经验</strong>。</p>
<ol>
<li>数据结构：数组、链表、栈、堆、二叉树、哈希表、图</li>
<li>基本算法：六种排序算法、分治算法、贪心算法、回溯算法、图算法、背包问题；LeetCode</li>
<li>代码组织：接口、封装、开闭原则</li>
<li>工程经验：降低复杂度、理解上下文；最小可用原型、CDCI、单测、Review</li>
</ol>
<p>🏬 <strong>知识体系</strong>。以点带面的拎出计算机的知识体系。</p>
<ol>
<li><strong>操作系统</strong>。主要围绕计算和存储。计算就是围绕 CPU 而来，进程线程协程，调度策略和算法；存储就是计算机的存储层次体系，依离 CPU 由近到远有寄存器、Cache、Memory、SSD&#x2F;HDD、Network。</li>
<li><strong>计算机网络</strong>。TCP&#x2F;IP 五层协议模型。离用户由近到远，应用层（你用的各种 APP、网页）、传输层（TCP，Socket）、网络层（IP，路由算法）、数据链路层、物理层。分层思想、拥塞控制算法、滑动窗口思想等等。浏览器中输入一条 URL 的到返回网页的基本过程。</li>
<li><strong>数据库</strong>。不同建模方式：关系、KV、图、时序等等。数据库常见组件：Parser、Binder、Planner、Optimizer、Execution、Storage。</li>
<li><strong>分布式系统</strong>。核心问题将数据或者计算摊到多机，并解决多机带来的延迟和容错问题。多机 → 数据集分片→ 多副本 → 一致性（主从、共识协议）。跨分片 → 分布式事务。</li>
</ol>
<p>📺 <strong>编程语言</strong>。每个语言都有自己独特的特点，但是有一些思想和模块是共性的：生命周期（时间）和作用域（空间）、一等公民（基本类型、类和函数？）、并发编程、标准库、字符串和文件等等。</p>
<ul>
<li>C++</li>
<li>Rust</li>
<li>Golang</li>
<li>Java</li>
</ul>
<p>📝 <strong>过往项目</strong>。对于应届同学来说，就是如何找到合适的项目（实习、公开课、开源）；对于社招同学来说，就是如何筛选呈现。</p>
<h1 id="📜简历打磨"><a href="#📜简历打磨" class="headerlink" title="📜简历打磨"></a>📜简历打磨</h1><h2 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h2><p>格式是对简历的第一印象，也是最容易提升的地方，因此要花一些时间，多过几遍：</p>
<ol>
<li><strong>对齐</strong>。各种经历、项目上的标题、日期、公司等模块一定要对齐。</li>
<li><strong>一致</strong>。比如所有模块标题都用四个字、列表中多个项目句式相同、经历的叙述方式相同。</li>
</ol>
<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>如何对过往经历和个人亮点进行呈现。</p>
<ol>
<li><strong>取舍</strong>。根据面试公司的方向对经历进行有计划的裁剪。</li>
<li><strong>简洁</strong>。经历叙述不要啰嗦，保持一致性。</li>
<li><strong>逻辑</strong>。所有信息的罗列一定要讲究内在逻辑。</li>
</ol>
<h1 id="➕-其他资料"><a href="#➕-其他资料" class="headerlink" title="➕ 其他资料"></a>➕ 其他资料</h1><p>我之前的一些面试相关文章：</p>
<ol>
<li><a href="https://www.qtmuniao.com/2021/04/17/storage-interview/">分布式存储面试经验</a></li>
<li><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82Mzc5OTQ4ODA=">数据库面试的几个常见误区<i class="fa fa-external-link-alt"></i></span></li>
<li><a href="https://www.qtmuniao.com/2023/03/25/how-to-read-and-write-code/">影响我写代码的三个 “Code”</a></li>
</ol>
]]></content>
      <categories>
        <category>职场</category>
        <category>工作</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>infra</tag>
      </tags>
  </entry>
  <entry>
    <title>NUMA-Aware 执行引擎论文解读</title>
    <url>/2023/08/21/numa-aware-execution-engine/</url>
    <content><![CDATA[<blockquote>
<p>最近翻 DuckDB 的执行引擎相关的 PPT(<span class="exturl" data-url="aHR0cHM6Ly9kc2RzZC5kYS5jd2kubmwvc2xpZGVzL2RzZHNkLWR1Y2tkYi1wdXNoLWJhc2VkLWV4ZWN1dGlvbi5wZGY=">Push-Based-Execution<i class="fa fa-external-link-alt"></i></span>) 时，发现了这篇论文：<span class="exturl" data-url="aHR0cHM6Ly8xNTcyMS5jb3Vyc2VzLmNzLmNtdS5lZHUvc3ByaW5nMjAxNi9wYXBlcnMvcDc0My1sZWlzLnBkZg==">Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age<i class="fa fa-external-link-alt"></i></span>。印象中在执行引擎相关的文章中看到他好几次；且 NUMA 架构对于现代数据库架构设计非常重要，但我对此了解尚浅，因此便找来读一读。</p>
</blockquote>
<p>从题目中也可以看到，论文最主要关键词有两个：</p>
<ol>
<li>NUMA-Aware</li>
<li>Morsel-Driven</li>
</ol>
<p>据此，大致总结下论文的中心思想：</p>
<ol>
<li>多核时代，由于部分 CPU 和部分内存的绑定关系，CPU 访问内存是不均匀（NUMA）的。也即，对于某一个 CPU 核来说，本机上一部分内存访问延迟较低，另一部分内存延迟要高。</li>
<li>传统火山模型，使用 Exchange 算子来进行并发。其他算子并不感知多线程，因此也就没办法就近内存调度计算（硬件亲和性）。也即，非 NUMA-local。</li>
<li>为了解决此问题，论文在数据维度：对数据集进行水平分片，一个 NUMA-node 处理一个数据分片；对每个分片进行垂直分段（Morsel），在 Morsel 粒度上进行并发调度和抢占执行。</li>
<li>在计算维度：为每个 CPU 预分配一个线程，在调度时，每个线程只接受数据块（Morsel）分配到本 NUMA-node 上的任务；当线程间子任务的执行进度不均衡时，快线程会”窃取“本应调度到其他线程的任务，从而保证一个 Query 的多个子任务大约同时完成，而不会出现”长尾“分片。</li>
</ol>
<span id="more"></span>

<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/08/21/numa-aware-execution-engine">https://www.qtmuniao.com/2023/08/21/numa-aware-execution-engine</a> 转载请注明出处</em></p>
<h2 id="背景铺垫"><a href="#背景铺垫" class="headerlink" title="背景铺垫"></a>背景铺垫</h2><p>论文中出现了一些名词，如果不了解其内涵，可能很对论文的一些关键设计点理解到位，因此这里对相关概念和背景做了一些铺垫。</p>
<h3 id="NUMA"><a href="#NUMA" class="headerlink" title="NUMA"></a>NUMA</h3><p>NUMA，是 <strong>Non-Uniform Memory Access</strong> 的缩写，即<strong>非一致性内存访问</strong>架构。传统 UMA （一致性访存）架构比较好理解，它也是我们通常以为的内存访问模型——所有 CPU core 访问本机所有内存的延迟是一致的（下<span class="exturl" data-url="aHR0cHM6Ly9mcmFua2Rlbm5lbWFuLm5sLzIwMTYvMDcvMDcvbnVtYS1kZWVwLWRpdmUtcGFydC0xLXVtYS1udW1hLw==">图源<i class="fa fa-external-link-alt"></i></span>）：</p>
<p><img src="https://s2.loli.net/2023/08/21/RXsBYITQUmroxHC.png" alt="uma-architecture.png"></p>
<p>但在多核（现在常用的服务器动不动就是 50+ core）时代，内存访问总线会”争用“非常严重，从而造成内存延迟迅速增高。于是，便有了 NUMA 架构——将单机内存切分成几块，分别和一些 CPU 进行绑定。一组绑定的 CPU 和内存通常称为一个 <strong>NUMA-node</strong> 或者 <strong>NUMA socket。</strong></p>
<p><img src="https://s2.loli.net/2023/08/21/TM2P1REhOFJjtvG.png" alt="numa-architecture.png"></p>
<p>上图只是一个示意图，通常一个 NUMA-node 会有很多个 CPU core，而非上图中的一个。那么，本 NUMA-node 的访问就是 Local Access，对其他 NUMA-node 的内存访问就是 Remote Access，后者通常要比前者慢几倍。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">~ numactl --hardware</span><br><span class="line">available: 2 nodes (0-1)</span><br><span class="line">node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 28 29 30 31 32 33 34 35 36 37 38 39 40 41</span><br><span class="line">node 0 size: 128840 MB</span><br><span class="line">node 0 free: 56030 MB</span><br><span class="line">node 1 cpus: 14 15 16 17 18 19 20 21 22 23 24 25 26 27 42 43 44 45 46 47 48 49 50 51 52 53 54 55</span><br><span class="line">node 1 size: 128987 MB</span><br><span class="line">node 1 free: 65212 MB</span><br><span class="line">node distances:</span><br><span class="line">node   0   1</span><br><span class="line">  0:  10  21</span><br><span class="line">  1:  21  10</span><br></pre></td></tr></table></figure>

<p>上面代码是通过 <code>numactl</code> 命令查看的一个物理机的 NUMA 情况。可以看出该物理机一共有 56 核，分为两个 NUMA-node，每个 28 核，每个 NUMA-node 有 128G 内存，local access 和 remote access 访问延迟比大概是 10: 21。</p>
<p>通常来说，操作系统尽量将线程和其使用的内存分配到同一个 NUMA-node 中，尤其是只需要小内存的线程。但对于数据库这种遇到大内存（buffer pool）的系统来说，内存分配很容易跨  NUMA-node，因此需要专门设计。</p>
<p>在分布式环境下，一个机器节点本质上就是一组CPU + 一块内存的资源容器；而在单机上，一个 NUMA-node 也是如此。因此，以看待分布式调度算法的思想（将计算调度到存储旁）看待本论文，很多地方或可更易理解。</p>
<h3 id="火山模型"><a href="#火山模型" class="headerlink" title="火山模型"></a>火山模型</h3><p><strong>火山模型</strong>是最传统、经典的一种数据库执行引擎模型。在火山模型中，SQL 语句会转化成一棵算子树，其中每个算子都实现了 open-next-close 接口；通过自上而下的（对 next）树形递归调用，完成数据的处理。</p>
<p>火山模型中的算子有个特点，就是不感知其所处理的数据在哪块内存、也不感知自己运行在哪个 CPU 上，甚至不感知是否为并行执行。当然，为了利用多核性能，可以扩展火山模型，通过 Exchange 算子来实现类似 partition→parallel processing→merge 的 shuffle 操作，从而将算子树进行并发执行。Exchange 算子可以插入算子树的任何一个位置，从而改变局部并发。除此之外，其他算子都不会感知并行运行细节。这种模型的优点在于，简洁优雅、表达能力强。但在多核时代，这种模型显然没有照顾到 NUMA 架构特点。</p>
<p>对于上述火山模型，我们通常将其执行模式称为<strong>基于拉</strong>（”pull-based“）的。因为我们都问从算子树的根节点要数据，而根节点会递归的向孩子节点要数据，直到叶子节点（通常是各种 scan 节点）。整体，就像从根节点往外”拉“数据一样。</p>
<p>与基于拉的模式相对，我们还有<strong>基于推</strong>（”push-based“）的执行模式。就像在代码中将递归转化为迭代一样，push-base 就是直接从叶子节点开始执行，在算子执行完生成新的数据后，会往数据下游算子（算子树中的父节点）推数据。</p>
<p>这两者最大的不同在于，pull-based 是不需要进行算子级别的调度的，所有数据都是”需求倒逼生产“，下游一步步问上游要；而 push-based 则需要一个全局调度器来协调上下游的数据生产消费关系——在下游能够接受数据时，将上游吐出来的数据推给下游。</p>
<h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>在 push-based 的模式下，我们通常会将算子树切分成多个线性的流水线（ <strong>Pipeline</strong>），并以 Pipeline （下图中虚线部分）的粒度进行执行调度。每个 pipeline 也可称为 <strong>pipeline segment</strong>，即整个算子树的一部分。</p>
<p><img src="https://s2.loli.net/2023/08/21/zRHvM5FsQpwK7W9.png" alt="pipeline-split.png"></p>
<p>Pipeline 的切口处，我们通常称之为 <strong>Pipeline Breaker</strong>——即 Pipeline 进行不下去，要进行切分了。如果你恰好对 Spark 的执行 Stage 划分有所了解，就会发现他们原理是一样的——在 Shuffle 处进行切分。而 Join 处通常会发生 shuffle。</p>
<p><img src="https://s2.loli.net/2023/08/21/PLi7ZA9q1C8H2cV.png" alt="stage-split.png"></p>
<h3 id="morsel"><a href="#morsel" class="headerlink" title="morsel"></a>morsel</h3><p>morsel 是本论文提出的一个类似”数据块“的概念，可以理解为关系数据库中的多个行（row）或者多个元组（tuple），这是本论文的最小调度和单元，对应下文中相同颜色标出的部分。</p>
<p><img src="https://s2.loli.net/2023/08/21/aoruy5UCKpQNzvX.png" alt="data-parallelism-morsel.png"></p>
<p>若想理解 morsel，可以对比 CPU 的时间片。只有将 CPU 切换成一块块大小合适的时间片段，我们才能更加方便的设计利用率高（更容易做均衡调度）、可抢占（单块时间片完成后而不必等待整个任务完成，便可调入其他任务占用时间片）、带优先级（执行新的时间片时，按优先级选择任务）的各种调度算法。</p>
<h2 id="内容概要"><a href="#内容概要" class="headerlink" title="内容概要"></a>内容概要</h2><h3 id="morsel-驱动执行"><a href="#morsel-驱动执行" class="headerlink" title="morsel 驱动执行"></a>morsel 驱动执行</h3><p>论文首先举了 <code>σ...(R) &gt;&lt; A σ...(S) &gt;&lt; B σ...(T)</code> 的三张表进行 inner join 的例子，其中 S 和 T 是小表。则在 Join 时对其 scan 后进行 Build 构建 HashTable；R 是大表，则在 S 和 T 的 HashTable 构建完成后，扫描以 Probe。将 HashJoin 切成 HashBuild（构建 HashTable）和 HashProbe（利用 HashTable 进行匹配），是经典的 HashJoin 的执行过程。</p>
<p><img src="https://s2.loli.net/2023/08/21/CidGuceUXAB6rpM.png" alt="3-pipelines-parallelism.png"></p>
<p>结合之前 Pipeline 的背景知识，可以推断出该执行计划会被划分为三个 Pipeline，分别是 HashTable(T) 的构建 、HashTable(S) 的构建 Pipeline 和 R 的探测。下面分别来说：</p>
<p><strong>HashTable 的构建</strong>。两个 HashTable 的构建过程是类似的，以 HashTable(T) 为例，构建过程又会分为两个阶段：</p>
<ol>
<li><strong>阶段一（Phase 1）</strong>：将 T 的 scan 输出按 morsel 粒度均匀分发给几个 CPU core 的 storage area，本质上是 Partition 的过程。</li>
<li><strong>阶段二（Phase 2）</strong>：每个 CPU core 对应的线程去扫描被分派的数据分片（包含很多 morsel），构建一个全局（跨线程）HashTable，本质上是 Merge 的过程。</li>
</ol>
<p><img src="https://s2.loli.net/2023/08/21/HZQ4jx9B8CPGSMu.png" alt="numa-aware-build-phase.png"></p>
<p>为了并行的对数据进行处理，通常都会有个数据分片阶段——按某种方式将一个输入流变成多个输入流。正如在 MapReduce 之前有个 split 的过程。</p>
<p>第二个阶段会涉及跨线程的数据写入，因此需要对 HashTable 这个跨线程的全局数据结构的实现做一些优化：</p>
<ol>
<li>在阶段一确定 HashTable 的大小，一次性预分配 HashTable，避免 HashTable 动态增长造成的</li>
<li>只将数据的指针插入 HashTable，避免跨线程的数据拷贝。</li>
<li>HashTable 使用无锁结构，降低多线程插入时争用造成的性能下降。</li>
</ol>
<p><strong>HashTable 的探测</strong>。在 HashTable(T) 和 HashTable(S) 构建完成后，就会开始对 R 表的探测。R 表在扫描后，其数据也会被分派到多个 NUMA-node 上去，进行并行的探测，探测完成后也会输出到线程所在的 NUMA-local。</p>
<p><img src="https://s2.loli.net/2023/08/21/Skaes8YijWRpglT.png" alt="numa-aware-proble-phase.png"></p>
<p>如果探测之后还有其他的算子，比如 Top、Filter、Limit 等等，也会被调度到 Probe 输出所在 NUMA-node 上进行执行。</p>
<p>不同于火山模型，这些算子（比如上图中的 HashJoin）要感知并行，并需要进行同步。</p>
<p>关于 Dispatcher 的实现和一些具体算子的实现，可以去我的<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">系统专栏<i class="fa fa-external-link-alt"></i></span>里看。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li>Viktor Leis等人论文，<span class="exturl" data-url="aHR0cHM6Ly8xNTcyMS5jb3Vyc2VzLmNzLmNtdS5lZHUvc3ByaW5nMjAxNi9wYXBlcnMvcDc0My1sZWlzLnBkZg==">https://15721.courses.cs.cmu.edu/spring2016/papers/p743-leis.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li>draveness，NUMA 架构设计：<span class="exturl" data-url="aHR0cHM6Ly9kcmF2ZW5lc3MubWUvd2h5cy10aGUtZGVzaWduLW51bWEtcGVyZm9ybWFuY2Uv">https://draveness.me/whys-the-design-numa-performance/<i class="fa fa-external-link-alt"></i></span></li>
<li>dirtysalt，Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age： <span class="exturl" data-url="aHR0cHM6Ly9kaXJ0eXNhbHQuZ2l0aHViLmlvL2h0bWwvbW9yc2VsLWRyaXZlbi1wYXJhbGxlbGlzbS1mcmFtZXdvcmsuaHRtbA==">https://dirtysalt.github.io/html/morsel-driven-parallelism-framework.html<i class="fa fa-external-link-alt"></i></span></li>
<li>张茄子，OLAP 任务的并发执行与调度： <span class="exturl" data-url="aHR0cHM6Ly9pby1tZXRlci5jb20vMjAyMC8wMS8wNC9vbGFwLWRpc3RyaWJ1dGVkLw==">https://io-meter.com/2020/01/04/olap-distributed/<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<hr>
<p>本文来自我的小报童付费专栏<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">《系统日知录》<i class="fa fa-external-link-alt"></i></span>，专注分布式系统、存储和数据库，有图数据库、代码解读、优质英文播客翻译、数据库学习、论文解读等等系列，欢迎喜欢我文章的朋友订阅 专栏支持，你的支持对我持续创作优质文章非常重要。下面是当前文章列表：</p>
<p><strong>图数据库系列</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2ZiNGNhNzQ4LTUzZDktNDk1Yy05OWNhLTQwNDkzMzJhZDY5NQ==">图数据库资料汇总<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY5MTRhOGY2LWI1MDYtNGEzNy04YjU1LTg0OTE4NTQzOWQxNQ==">译： Factorization &amp; Great Ideas from Database Theory<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY1NmQ4ZDczLWY4ZWQtNDYwNC05ZjE0LWY3Nzc5N2U4NzdiMA==">Memgraph 系列（二）：可串行化实现<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzJlODA5MWEwLTgzNjMtNDk4Zi1iNjA5LWNlOGUyMzExMGM5ZQ==">Memgraph 系列（一）：数据多版本管理<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2I0MGZkYzIzLTEyYTktNGE4NS04ZDNhLWUzNWY2ZDFiMWIwYw==">【图数据库系列四】与关系模型的“缘”与“争”<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY2MDc1Y2U5LWZjNzYtNGUzNS1hOTFjLTkwY2Q2MTFmYzczMg==">【图数据库系列三】图的表示与存储<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzc3NTcyZWQ0LTcyM2QtNGRmZC1iYTE2LTViMTM2ZmY5YTdhMw==">【图数据库系列二】 Cypher 初探<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzZjBiZjExLWUxNjctNGY4MC04NDE1LTJlYjRhYjE3OTdiNQ==">【图数据库系列一】属性图模型是啥、有啥不足<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>数据库</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2FmM2RjM2E3LThkMmUtNDJhOC05NWMxLTNmY2MzZTZlNzA0NQ==">译：数据库五十年来研究趋势<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzk4MjRjYjlmLTIyODktNDg5NS1hOTM4LTQzMGQ1NWJhMWViYQ==">译：数据库中的代码生成（Codegen in Databas…<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2NhMDIwMjk3LTA5MDEtNDVkMS04YWNjLTFkODg0YmYxY2M4NA==">Facebook Velox 运行机制解析<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzE3NDdkNjQ4LTBiMGQtNDNmMy1iNDg0LWM5OTJhZDlmNmUyNQ==">分布式系统架构（二）—— Replica Placement<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzMzMjcxMDdiLTA5MTItNGQ3ZC05ZDk0LTM0Mzk1NGY1NmQ1ZA==">【好文荐读】DuckDB 中的流水线构建<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIwMzc5YzlkLTBiMDctNDFkNy05OWFhLTNiMzkwMDYzMmY1Mw==">译：时下大火的向量数据库，你了解多少？<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzMyZDgwYWVhLTM0NjYtNDU5Ni1iMDY4LWE3MTE1YmI3Y2JhYQ==">数据处理的大一统——从 Shell 脚本到 SQL 引擎<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIyZmZjYjUzLTFjZDItNDFhNS04MzA3LWEyOGEwZDZkNmZhNg==">Firebolt：如何在十八个月内组装一个商业数据库<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzhjZjk0ZDQzLWE5MWMtNGZlMy1iODMxLTYxNWVhYzhjOWUzYQ==">论文：NUMA-Aware Query Evaluation Framework 赏析<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzI4ZTAzMDMyLWUwOWYtNDkwNS04ZGJhLTU1OTE4MGIxNmMwMA==">优质信息源：分布式系统、存储、数据库<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Y3NzhjOWRiLTFiOWUtNDQ0YS05ZDY3LWQ0MGI3YWYzNDllNA==">向量数据库 Milvus 架构解析（一）<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzYTQ5MWRhLTE3ZjgtNGRmNy05ZThhLTI5YTc4ODk1NmI0MQ==">ER 模型背后的建模哲学<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzI5ZmY2MWZkLTI1ZTItNDEwNC05NDQ2LTZjY2I3MDJiY2Y1YQ==">什么是云原生数据库？<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>存储</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Y3NGUzNmIyLTE5MWEtNDcyZi1iMDczLTFiY2QxNDA0ZmMzOA==">存储引擎概述和资料汇总<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzcxY2Y5NzMzLWVlNzQtNGViYi1hYTI3LWY2M2Q3MmFmNjcxNg==">译：RocksDB 是如何工作的<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzZmZGQ5NTllLTk2MjktNGY3YS1hYjk3LWMxYTVjNDJmNWVkMg==">RocksDB 优化小解（二）：Prefix Seek 优化<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2UwNjk2YzRjLTdmYWYtNDQ0YS1iZTQwLWJhMjI4MDFjOTdmZg==">RocksDB 优化小解（三）：Async IO<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzdjY2MzYTcxLTBjNTktNGVmMy1hNTRiLTExMjZiMzIxY2ZkMQ==">大规模系统中使用 RocksDB 的一些经验<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>代码&amp;编程</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzc1MGUwOGY5LWY2NjctNDQ1OS05ZDk0LTUzZjM4YzA1MjlkYw==">影响我写代码的三个 “Code”<i class="fa fa-external-link-alt"></i></span> <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzZjMmNmMzdjLWI3ZTMtNDliYy04ODFlLWJmNDRlYmE2YmNhZQ==">Folly 异步编程之 futures<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzQ2YzExOGVmLTkwY2ItNDg2OC1iYTEwLTU2MDQ1OWM2ZmEyYQ==">关于接口和实现<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2RmNTZjZDMyLTI3ZTgtNGNjOS1iYjQyLTJmZjM2MzUxMzQ5OQ==">C++ 私有函数的 override<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzlkOGY0OTNkLThlZmYtNDJjZS04NzNjLTFlODFlZDZlMWNjNA==">ErrorCode 还是 Exception ？<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0Lzg0ODYwNTYxLWJhNTYtNGRlNC1hZGU4LWI3MzIwZDE1ODU4Ng==">Infra 面试之数据结构（一）：阻塞队列<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2VkZmRiYjE4LTJiYjEtNDlkMy1iMDdmLWRkMmEyZjU2MjkyOQ==">数据结构与算法（四）：递归和迭代<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>每天学点数据库系列</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2E0OTIyOTllLWRkMGUtNDY5ZS04NzA2LTI4MzZlMjBmODFmMA==">【每天学点数据库】Lecture #06：内存管理<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzgxOWMwMjk0LTBlZDQtNDE2MS1iM2M2LThhNjIzMTM2ZmE2Mg==">【每天学点数据库】Lecture #05：数据压缩<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzA1ZWEyY2Y2LTRiM2QtNDE2YS05MjRhLTNjMWY3YWQzN2ExZQ==">【每天学点数据库】Lecture #05：负载类型和存储模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzdlNjk1N2Q2LTRmZWUtNDJkYi1hNTFkLWQ3MmYyODRlMjczMw==">【每天学点数据库】Lecture #04：数据编码<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzVlMzRlZTBmLThmYTMtNGM3ZS05YjA5LTIxMjg3ZTBkYTYzOQ==">【每天学点数据库】Lecture #04：日志构型存储<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzIzZDZmNDk5LWVlZTctNDFiMi1iOGRlLTU1ZmIwMDAwN2NkNA==">【每天学点数据库】Lecture #03：Data Layout<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2IzYWQ4MTU0LTJlMjktNGVjMS1hNjI3LWZkMzI4OGI1ZDJhOQ==">【每天学点数据库】Lecture #03: Database and OS<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2FlMmUxZTM1LTNkY2MtNGZiZC05ZjZiLTM5ZTY0NWU5OTA2NQ==">【每天学点数据库】Lecture #03：存储层次体系<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2E2ZTVmOTc2LTBlOTktNDExMS1hMWU5LWMwZWE4NTNiMjJiYg==">【每天学点数据库】Lecture #01：关系代数<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzFkM2U5OGE4LTBkZWUtNGI3OS05M2Q0LWE5NjQwOTQxMzI1Mw==">【每天学点数据库】Lecture #01：关系模型<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2M0NDE2OGNmLTljM2ItNGM1My1iNDllLWEzZTUxZTg1NzZhZA==">【每天学点数据库】Lecture #01：数据模型<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p><strong>杂谈</strong></p>
<ul>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">数据库面试的几个常见误区 🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzJlNzgzNWE1LTRhZDUtNDViMC05ZWJjLWQxMjk0NWU4NjZmMQ==">生活工程学（一）：多轮次拆解<i class="fa fa-external-link-alt"></i></span><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzEwZjRmNzg0LThiYjEtNGNhMy1hNjM1LWVlOWZiMTRlM2IxZA==">🔥<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2Q1OGViMmZhLWZjM2QtNGE2ZS1hOWZkLWI4NTQxZGZhNTFiZQ==">系统中一些有趣的概念对<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2VmZTZjNzRkLWY2ZGMtNDk0Yy04NDdiLTVmZDIxMzhjMGYwNQ==">系统设计时的简洁和完备<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzM0ZGMzYzRiLWRkM2QtNGNhMi04ZWNjLTFlZmFiNWVjZjcwOQ==">工程经验的周期<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2RlMmNjNTI5LTBhN2UtNDE4Ni05N2UxLWFiNTE0ZWM5MTZjYg==">关于“名字”拿来<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY2NDcyMGE1LWI5NDMtNDU2OC1hODEwLWUyNzhiYzZjMTczYw==">Cache 和 Buffer 都是缓存有什么区别？<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>dadtabase</tag>
        <tag>NUMA</tag>
      </tags>
  </entry>
  <entry>
    <title>Firebolt：如何在十八个月内组装一个商业数据库</title>
    <url>/2023/10/05/firebolt-paper/</url>
    <content><![CDATA[<p>假如你是一个初创公司的 CTO，想迅速推出一款面向 AP 市场可用的数据库产品，还得有差异化的功能（不然谁会用一个新产品），你会怎么做呢？</p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuZmlyZWJvbHQuaW8v">Firebolt<i class="fa fa-external-link-alt"></i></span> 在 2022 年专门发了一篇论文：<span class="exturl" data-url="aHR0cHM6Ly93d3cuZmlyZWJvbHQuaW8vY29udGVudC9maXJlYm9sdC12bGRiLWNkbXMtMjAyMg==">Assembling a Query Engine From Spare Parts<i class="fa fa-external-link-alt"></i></span> 来讲这个事情。核心思想就是，<strong>利用开源组件，像攒台式机一样攒出一个数据库</strong>。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/10/05/firebolt-paper">https://www.qtmuniao.com/2023/10/05/firebolt-paper</a> 转载请注明出处</em></p>
<p>让我们看下“装机清单”：</p>
<p><img src="https://s2.loli.net/2023/10/06/BbUWk8Q7oFrVi5h.png" alt="firebolt.png"></p>
<p>了解数据库内核开发的同学都知道，一个数据库包含非常多的组件。就我所做的存储层来说，就可以列一个长长的清单，可以参考我之前写的<a href="https://www.qtmuniao.com/2022/05/04/distributed-database-storage-components/">这篇文章</a>。更遑论数据库的大头——查询引擎了。就算化简再化简，也需要解析器——Parser，计划生成——Planner，计划执行——Runtime。</p>
<p>当然，对于一个数据库来说，最重要的还有对外提供的接口—— SQL 。虽然有 ANSI SQL 这个标准在，但工业上真正使用的却是一个个的“方言”（dialect）。虽然说接口需要独立于实现，但不同的实现总会不可避免的冒出头来，影响到接口。而且，分布式数据库不可避免的会进行站队，选择某个方言。比如 TiDB 选择兼容 MySQL，而 Firebolt 选择兼容 Posgres。</p>
<h2 id="组件选择"><a href="#组件选择" class="headerlink" title="组件选择"></a>组件选择</h2><p>选定了兼容的 SQL 方言，下一步就是上面提到的几个重要组件的选择：Parser，Plannner，Runtime。让我们一块来看看 Firebolt 是怎么选的。</p>
<h3 id="Parser-amp-Planner"><a href="#Parser-amp-Planner" class="headerlink" title="Parser &amp; Planner"></a>Parser &amp; Planner</h3><p>Parser 就是进行语法解析，将 SQL 语句进行分词，组织成语法树——AST。Planner 就是将 AST 基于规则和代价等进行优化成一个可以执行的算子树。</p>
<p>由于 Parser 和 Planner 的接口是 AST，而 AST 通常来说没有一个统一的标准——也即很难将从属于不同项目的 Parser 和 Planner 组合到一块。因此 Firebolt 倾向于寻找一个同时包括两个模块的项目。</p>
<p>Firebolt 对这两个模块的需求是：</p>
<ol>
<li>Parser 需要支持大部分 Postgres SQL 方言，包括 DDL、DML、DCL 和 DQL</li>
<li>LogicPlanner 需要支持现代数仓的重要规则，如谓词下推、子查询去关联</li>
<li>LogicPlanner 需要支持对规则变换（rule-based transformation）的扩展</li>
<li>PhysicalPlanner 需要支持对基于代价的连接调序（cost-based join reordering）</li>
<li>PhysicalPlanner 需要支持自定义的统计信息收集和代价模型</li>
<li>Planner 需要支持复合数据类型，如数组、结构体</li>
</ol>
<p>市面上当时针对这两个模块的开源项目还是挺多的，下面来逐一列举下其优劣：</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>简介</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>Postgres Parser</td>
<td></td>
<td>1. 天然兼容 Postgres SQL 方言</td>
<td></td>
</tr>
<tr>
<td><br>2. libpg_query 已经将 Parser 和 Postgres 其他模块隔离了开来</td>
<td>1. 将  Planner 从 Postgres 项目中剥离出来工作量很大。</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Google ZetaSQL</td>
<td>谷歌出品的一个 C++ 项目，包含 Parser 和 Analyzer</td>
<td>1. 在谷歌诸多产品 BigQuery、Spanner、Dataflow、Dremel、F1 和 Procella 中被验证过<br>2. 项目简洁、充分测试、工业可用</td>
<td>1. 不支持 Postgres SQL 的很多功能<br>2. 只支持简单的算子树变换<br>3. Planner 功能也很简单</td>
</tr>
<tr>
<td>Apache Calcite</td>
<td>一个开源供数据处理领域使用的查询处理和优化的 Java 项目</td>
<td>1. 支持多种 SQL 方言<br>2. 模块化良好，Planner 支持自定义 rule<br>3. 代码良好、测试充分、使用广泛（Hive，Storm，Flink，Druid 和 MapD）</td>
<td>1. 不是用 C++ 写的，很难和其他组件进行代码集成</td>
</tr>
<tr>
<td>CWI Duckdb</td>
<td>基于内存的、嵌入型的分析型数据库，C++ 编写</td>
<td>1. 测试充分，在交互式数据分析场景广泛使用<br>2. 同时支持基于规则和基于代价的计划改写<br>3. 使用 libpg_query 作为 Parser 的基准，因此对 Postgres SQL 方言兼容的很好</td>
<td>1. Firebolt 选型时还很不成熟</td>
</tr>
<tr>
<td>Hyrise</td>
<td>HPI 开发的一个内存型数据库</td>
<td>1. 简单的代码库<br>2. 同时支持基于规则和基于代价的计划改写</td>
<td>1. 是一个学术型项目<br>2. 测试不够充分、SQL 语法覆盖也不够</td>
</tr>
</tbody></table>
<p>最后 Firebolt 基于种种考虑，选择了 Hyrise ：</p>
<ol>
<li>使用 C++ 开发</li>
<li>同时支持基于规则和基于代价的计划改写</li>
<li>代码库简单易于重构</li>
</ol>
<p>Firebolt 参考 Calcite 的设计和概念体系对 Firebolt 做了深度改写，比如增加了复合类型支持、修改了逻辑执行计划的表示等等。</p>
<h3 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h3><p>Runtime 是对优化过后的查询计划进行执行的组件，对数据库的性能有至关重要的影响。当时作为一个小创，Firebolt 依然选择了使用开源项目。</p>
<p>Runtime 有两种实现流派——<strong>向量化</strong>（vectorization）和<strong>代码生成</strong>（code generation），后者效率可能会高一些，但实现复杂度较高，需要投入的研发资源太多。</p>
<p>总结下，Firebolt 对 Runtime 项目的要求有：</p>
<ol>
<li>支持向量化执行</li>
<li>有一定的扩展性，可进行分布式的数据处理改造</li>
<li>由于 Runtime 和存储引擎耦合性较高，因此项目最好同时实现了高效的<strong>列存</strong>引擎</li>
</ol>
<p>相对 Parser 和 Planner 的多样性选择，Runtime 可供选择的项目相对较少（当时 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2ZhY2Vib29raW5jdWJhdG9yL3ZlbG94">Facebook Velox<i class="fa fa-external-link-alt"></i></span> 也没有开源）。最终 Firebolt 选择了 ClickHouse：</p>
<ol>
<li>是一个向量化的执行引擎</li>
<li>经过充分的测试</li>
<li>有自己的列存格式——MergeTree，支持高效的数据裁剪</li>
</ol>
<h3 id="缝合-Planner-和-Runtime"><a href="#缝合-Planner-和-Runtime" class="headerlink" title="缝合 Planner 和 Runtime"></a>缝合 Planner 和 Runtime</h3><p>由于 ClickHouse 的执行引擎要求的格式和 Hyrise 的产出格式并不一致，即后者生成的执行计划树（LQP）并不能被前者直接执行。为此，Firebolt 做了一个骚操作——将 LQP 逆向翻译（backtranslate）回 ClickHouse SQL。</p>
<p>这种方式可以 work，但并不高效，且会丢失一些优化信息。后来，Firebolt 将其进行了替换，将 LQP 直接翻译成了<strong>多阶段的分布式执行计划</strong>（类似 Spark 执行时的多阶段划分），并借助 protobuf 进行序列化和反序列化，传到每个执行节点上进行执行。当然，也要求对 ClickHouse 进行一定的改造。</p>
<h3 id="分布式执行"><a href="#分布式执行" class="headerlink" title="分布式执行"></a>分布式执行</h3><p>尽管 ClickHouse 自己支持对某些 Query 的分布式执行，比如选择性的 table scan，分布式聚合、基于广播的 Join 等等。但数仓中更为普遍的一些 SQL 模式，ClickHouse 并不能对其进行很好的分布式执行。比如两个大表 Join、高基数分组聚合、分布式排序等等。</p>
<p>为此，Firebolt 实现了自己的分布式执行框架，将执行计划按 shuffle 算子切开划分成不同阶段。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>以上就是 Firebolt 初期作为一个人很少的小创，如何用十八个月迅速攒出一个商业可用的数仓项目，从而为后来<span class="exturl" data-url="aHR0cHM6Ly93d3cuc29odS5jb20vYS81MTk0MTUxODhfMTIxMTE4NzEw">获得大量融资<i class="fa fa-external-link-alt"></i></span>打下了基础。这也从另一个侧面反映了当前数据库开源生态的繁荣。</p>
<p>当然，为了商业可用，还有很多方面的需要打磨，其中最重要的就是对测试用例的覆盖，这里就不展开了，感兴趣的可以去读读<span class="exturl" data-url="aHR0cHM6Ly93d3cuZmlyZWJvbHQuaW8vY29udGVudC9maXJlYm9sdC12bGRiLWNkbXMtMjAyMg==">论文原文<i class="fa fa-external-link-alt"></i></span>。</p>
<hr>
<p>本文出自我的小报童付费专栏《系统日知录》，专注互联网最基础的方向——<strong>大规模数据系统</strong>，有图数据库、代码解读、优质英文播客翻译、数据库学习、论文解读等等系列，欢迎喜欢我文章的朋友订阅👉<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">专栏<i class="fa fa-external-link-alt"></i></span>支持，你的支持对我持续创作优质文章非常重要。</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>firebolt</tag>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>【图解面试基础】三种基本排序算法</title>
    <url>/2023/09/18/three-basic-sort/</url>
    <content><![CDATA[<blockquote>
<p>这是使用 <span class="exturl" data-url="aHR0cHM6Ly9wcm9jcmVhdGUuY29tLw==">Procreate<i class="fa fa-external-link-alt"></i></span> 画图之余，心血来潮开的一个<span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMzA5MzM4MTIvY2hhbm5lbC9jb2xsZWN0aW9uZGV0YWlsP3NpZD0xNjU1MDY5">面试基础系列<i class="fa fa-external-link-alt"></i></span>，力求图文并茂、代码视频兼顾，做成最好看的面试系列。欢迎喜欢的小伙伴点赞、转发和打赏，如果支持的同学多，我就继续更下去。</p>
</blockquote>
<p><img src="https://s2.loli.net/2023/09/18/g78B3XunFliWv6a.png" alt="3-basic-sort.png"></p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/09/18/three-basic-sort">https://www.qtmuniao.com/2023/09/18/three-basic-sort</a> 转载请注明出处</em></p>
<p>{[order-list], [unorder-list]}</p>
<p>冒泡排序、选择排序和插入排序是三种最基本的排序算法。其原理是相通的：</p>
<ol>
<li>将数组划分成前后两个子集：前面是有序集，后面是无序集</li>
<li>三种方法都是线性的一次从无序集中搬一个元素到有序集中，只不过搬法不同：<ul>
<li>冒泡：从无序集最后逐个比较冒一个到有序集<strong>最后</strong>。</li>
<li>选择：遍历无序集，选一个放到有序集<strong>最后</strong>。</li>
<li>插入：从边界处选一个，插入到有序集中<strong>合适位置</strong>。</li>
</ul>
</li>
</ol>
<p>三种排序的复杂度都是 O(n^2)。</p>
<h2 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h2><p>S-order &lt;–bubble– S-unorder</p>
<p>像冒泡一样，每次让最小的数<strong>冒出</strong>剩余数据集（无序）“水面”，抵达有序集。</p>
<p>口诀：</p>
<ol>
<li>数组分两块，初始前空置；</li>
<li><strong>后面交换往前挤</strong>，前满后空则终止。</li>
</ol>
<h2 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h2><p>S-order &lt;–selection– S-unorder</p>
<p>从剩余数据集（无序）中<strong>选择</strong>最值，放到有序集中。</p>
<p>口诀：</p>
<ol>
<li>数组分两块，初始前空置；</li>
<li><strong>后面选极前追加</strong>，前满后空则终止。</li>
</ol>
<h2 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h2><p>S-order &lt;–insertion– S-unorder</p>
<p>从剩余数据集（无序）中随意取一个值，然后通过比较“插入”（也可以理解为往前冒泡）到有序集中。</p>
<p>口诀：</p>
<ol>
<li>数组分两块，初始前空置；</li>
<li><strong>边界选值前插入</strong>，前满后空则终止。</li>
</ol>
<hr>
<p>代码仓库在<a href="%EF%BC%9Ahttps://github.com/DistSysCorp/infra-interview" title="infra 面试基础 repo">这里</a>，欢迎通过提 issue 来告诉我你想看图解的常见面试题目，如果发现有疏漏，也欢迎提 PR 来贡献。</p>
<p>b 站视频在这里：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWR1NDExNzdpdQ==">https://www.bilibili.com/video/BV1du41177iu<i class="fa fa-external-link-alt"></i></span><br>Youtube 视频：<span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vcGxheWxpc3Q/bGlzdD1QTFNJU1J1MmIyTjU1SHRwXzN0VVFvcU1QUDRFc1RMR3h2">https://www.youtube.com/playlist?list=PLSISRu2b2N55Htp_3tUQoqMPP4EsTLGxv<i class="fa fa-external-link-alt"></i></span></p>
<hr>
<p>最后，如果喜欢我的文章，可以订阅我的小报童付费专栏《系统日知录》，专注互联网最基础的方向——<strong>大规模数据系统</strong>，有图数据库、代码解读、优质英文播客翻译、数据库学习、论文解读等等系列，欢迎喜欢我文章的朋友订阅👉<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">专栏<i class="fa fa-external-link-alt"></i></span>支持，你的支持对我持续创作优质文章非常重要。</p>
]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>使用“隐喻”的方式帮你建立对 Raft 的直觉</title>
    <url>/2023/11/15/raft-explain/</url>
    <content><![CDATA[<p>相比 Paxos，Raft 的一大特色就是算法拆成了相对正交的几个部分——领导者选举、日志同步、状态持久化、日志压缩和配置变更。你如果对课程照目录看下就能看出来，除却最后一部分，这些模块就是我们课程 PartA ~ PartD 要分别实现的内容。将算法正交化拆分的好处是，让每个模块相对内聚，使得整体更易理解和实现——这也是 Raft 算法设计的初衷。</p>
<p>下面我不打算采用<strong>精确</strong>的方式来讲解每个模块——那是<strong>论文正文</strong>和<strong>代码实现</strong>要做的事情。相反，本章我将带领大家在<strong>感性</strong>上建立一个对 Raft 基本概念（任期、选举）和两大流程（领导选举、日志同步）的认识。带着这个感性认识，大家可以再去仔细研读<span class="exturl" data-url="aHR0cHM6Ly9yYWZ0LmdpdGh1Yi5pby9yYWZ0LnBkZg==">论文<i class="fa fa-external-link-alt"></i></span>，想必能事半功倍地梳理出 Raft 算法中海量的细节。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/11/15/raft-explain">https://www.qtmuniao.com/2023/11/15/raft-explain</a> 转载请注明出处</em></p>
<h1 id="任期"><a href="#任期" class="headerlink" title="任期"></a>任期</h1><p><strong>任期</strong>（term）在任何共识协议中都很重要。Raft 中所有关键事件的展开，都是基于任期的，任期最直观的理解就是领导者任期，如“总统任期”。</p>
<p>但其本质上是一种关于时间隐喻，可以理解为“纪元”——如桃花源中的村民“不知有汉，无论魏晋”的那种朝代纪元。与桃花源村民相似，在 Raft 中，如果出现网络分区，某些 Peer 被隔绝，也很容易不知道其他 Peer 到了哪个 Term。一段时间后，被隔绝分区中的 Peer 与其他 Peer 重新建立通信（武陵人发现了他们）时，首先要做的就是对齐 Term，这是之后一切沟通展开的基础。</p>
<p>从另外一个角度讲，任期还是一种<strong>优先级</strong>或者<strong>权力</strong>的隐喻：</p>
<ol>
<li>低任期的 Peer 收到高任期的 Peer 任何信息后，会自动“跟上”（Follow）任期变成<strong>跟随者</strong>（Follower）。</li>
<li>高任期的 Peer 收到低任期 Peer 的任何<strong>请求</strong>时，会直接拒绝。</li>
</ol>
<p>在所有 Peer 进行“交流”（RPC 通信）时，任期都是第一优先级的，只有对齐了任期，才有谈其他的基础。</p>
<h1 id="领导选举"><a href="#领导选举" class="headerlink" title="领导选举"></a>领导选举</h1><p>Raft 使用的是“强人模式”，即只要 Leader 当选，他就对其任期内日志长啥样有说一不二的权力。Raft 中也采取“一山不容二虎”策略——一个任期内最多有一个 Leader（也可以没有选出）。但在同一时刻，可能会存在多个 Leader，但，他们一定处于不同任期中。</p>
<p>由于采用强人策略，则在选举时就要慎之又慎——以期能选出能“顾全大局”的人（具备所有已提交日志的候选者）。为此，每个 Peer 在投票时，都要比比谁的日志“更新更全”。一旦跟随者投出其票，就表示对该候选者心悦诚服——“承诺”一段时间内不会再发起选举（重置选举时钟）。</p>
<p>Leader 在当选后，要做的第一件事就是“昭告天下”（心跳）以“压制”其他“试图挑战权威”的人——“迫使”每个 Follower 承诺一段时间内不得再发起选举。Follower 在收到心跳后，只要任期不比人家大，就要乖乖给出“承诺”（重置选举时钟）。</p>
<p>之后，Leader 便会周期性的发送“政令”，直到收到来自高“任期”的消息，便要乖乖“交权”，让出领导权。从这里也可以看出，任期是第一优先级，这是“时间法则”的攻击，Leader 也不能免疫。当然，还有一种优化，就是 Leader 发现自己成为“孤家寡人”（发现大部分人不应答“政令”了，通常出现在 Leader 与多数 Follower 发生了网络隔离时）后，也自动交权。</p>
<h1 id="日志同步"><a href="#日志同步" class="headerlink" title="日志同步"></a>日志同步</h1><p>Leader 在接收到“甲方”（客户端）的“请求”后，会将其包装为“政令”（日志），然后“附带”到周期性的广播（心跳）上，将“政令灌输”给每个 Follower。最简单粗暴的方式，就是将本地所有日志一股脑的附带到心跳上，Follower 收到后，直接替换本地日志即可。但如果 Leader 日志量很大，通信代价将会非常高。因此 Leader 采用一种“乐观+回撤”的方式进行同步：</p>
<ol>
<li><strong>乐观</strong>：一开始心跳不附带任何日志，只带一些“暗号”过去。假如 Follower 的通过“暗号”发现自己日志跟 Leader 完全一致，就直接回：一致，之后的心跳不需附加任何日志。</li>
<li><strong>回撤</strong>：如果 Follower 通过“暗号”发现自己和 Leader 日志并不一致，也会告诉 Leader——下次得附带日志。则 Leader 就附加一些末尾的日志，如果发现还是不一致，就要继续回撤，多向前附加一些日志，同时更新“暗号”，直到收到 Follower 肯定回复，则继续恢复不附加任何日志的心跳。</li>
</ol>
<p>这个“暗号”，就是 Leader 所附带日志的的前一条日志信息的二元组：<code>&lt;下标，任期&gt;</code>。如果心跳没有附加任何日志，则暗号就是 Leader 最后一条日志的相关信息。为了保证 Leader 附带日志总有前一条日志，我们在对日志进行初始化的时候，会在开头放一条“空日志”，从而避免一些边界判断（这个做法类似带头结点的链表）。</p>
<p>那为什么只要“暗号”对的上，就能保证两方日志前缀一致呢？</p>
<p>简单来说，对“暗号”的过程，就是一个<strong>递推</strong>的过程。根据<strong>数学归纳法</strong>，每次附加新日志，都要对齐前序日志。而由任期单调递增、单任期最多一个 Leader，则同任期的日志前缀一定对得上。这样一来，同任期前缀对的上，跨任期同步前都会对齐前任日志，则“政令畅通”的情况下，所有日志最终都会收敛为 Leader 日志。</p>
<p>在“政令”（日志）同步到大多数节点后，Leader 就会宣布该政令“生效”（提交）。但论文特别强调了，Leader 不能直接宣布前任的“政令”生效，而要在本任期内发布“政令”后，通过“生效”本任期“政令”来间接“追认”前序任期的相关“政令”。这是为什么呢？（下图是 Raft 中大名鼎鼎的一张图“Figure 8”，很多实现 Raft 的同学应该都被该图虐过。）</p>
<p><img src="https://s2.loli.net/2023/11/16/5ct82NClLY6UBsO.png" alt="raft-fig8.png"></p>
<p>这是由于我们选举时会通过比最后一条日志的“大小”来决定是否 Leader 当选，因此前任的日志，如果没有通过本任期“盖棺定论”，是有可能被其他在相同下标具有更新日志的 Peer 当选 Leader 后“冲掉的”，也就是上图 c、d、e 的情况——没有 4 日志的“压一道”， S5 是可以当选 Leader 的，之后 S1~S3 的 2 日志是有可能被 S5 的 3 的日志冲掉。</p>
<hr>
<blockquote>
<p>本文来自我和 roseduan 合作的《<span class="exturl" data-url="aHR0cHM6Ly9hdjZodWYyZTFrLmZlaXNodS5jbi9kb2N4L0pDc3NkbGdGNG9SQURjeHhMcW5jUHBSQ241Yg==">从零实现分布式 KV<i class="fa fa-external-link-alt"></i></span>》的课程。该课程会手把手教你如何弄懂一个共识协议，以及基于共识协议的分布式 KV 的方方面面、各种细节；也会教你如何组织和写出漂亮的工程代码。分布式系统是当今主流互联网系统的基础架构，而共识协议又是其中的典型代表和基石中的基石。学习本课程，能让你对分布式系统所面临的问题、所使用的技能有一个全面和深入的认识。<br>感兴趣的同学，欢迎戳《<span class="exturl" data-url="aHR0cHM6Ly9hdjZodWYyZTFrLmZlaXNodS5jbi9kb2N4L0pDc3NkbGdGNG9SQURjeHhMcW5jUHBSQ241Yg==">从零实现分布式 KV<i class="fa fa-external-link-alt"></i></span>》了解详情。</p>
</blockquote>
<p><img src="https://s2.loli.net/2023/11/14/RcyutnXh35ZovBT.jpg" alt="cover1.jpeg"></p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title>构建和维护星球最强对象存储系统的一点微小经验</title>
    <url>/2023/11/15/s3-experience/</url>
    <content><![CDATA[<blockquote>
<p>本文来自 Amazon S3 VP  <span class="exturl" data-url="aHR0cHM6Ly93d3cubGlua2VkaW4uY29tL2luL2FuZHl3YXJmaWVsZA==">Andy Warfield<i class="fa fa-external-link-alt"></i></span> 在 FAST 23 上的主旨演讲的<span class="exturl" data-url="aHR0cHM6Ly93d3cuYWxsdGhpbmdzZGlzdHJpYnV0ZWQuY29tLzIwMjMvMDcvYnVpbGRpbmctYW5kLW9wZXJhdGluZy1hLXByZXR0eS1iaWctc3RvcmFnZS1zeXN0ZW0uaHRtbA==">文字稿<i class="fa fa-external-link-alt"></i></span>，总结了他们在构架和维护如此量级的对象存储 —— S3 的一些经验。我们知道，Amazon S3 是云时代最重要的存储基础设施之一，现在各家云厂商的对象存储基本都兼容 S3 接口，所有云原生的基础设施，比如云原生数据库，其最终存储都要落到对象存储上。</p>
</blockquote>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2023/11/15/s3-experience">https://www.qtmuniao.com/2023/11/15/s3-experience</a> 转载请注明出处</em></p>
<p>截至 2023 年，Amazon S3 自 2006 年上线以来，已经 17 岁了。在开始之前，我们首先看下Andy Warfield 给出的一组数据，来感受下星球最强的对象存储已经到了什么量级：</p>
<p><img src="https://s2.loli.net/2023/11/16/rgiQNFkLyhPqpZJ.png" alt="S3-metrics.png"></p>
<p>即，</p>
<ul>
<li><strong>容量和吞吐</strong>：超过 280 万亿个对象，QPS 平均超过 1 亿 &#x2F; s</li>
<li><strong>事件</strong>：<strong>每天</strong> S3 会向 serverless 应用发送超过 <strong>1250 亿个事件</strong></li>
<li><strong>冗余</strong>：<strong>每周</strong>超过 <strong>100 PB</strong> 的数据冗余</li>
<li><strong>冷存储检索</strong>：<strong>每天</strong>都要至少从 S3 归档存储中回复 <strong>1 PB 数据</strong></li>
<li><strong>数据完整性校验</strong>：<strong>每秒</strong>进行 <strong>40 亿次</strong>完整性校验计算</li>
</ul>
<p>对这个量级有了直观的感受之后，我们来看看 Andy Warfield 分享的经验。为了方便叙述，下面都用第一人称——我们，意指 S3 团队。</p>
<h1 id="HDD-对-S3-设计的影响"><a href="#HDD-对-S3-设计的影响" class="headerlink" title="HDD 对 S3 设计的影响"></a>HDD 对 S3 设计的影响</h1><p>虽然 SSD 在价格上已经越来越便宜，但对于 S3 如此量级的存储来说，仍然大量采用 HDD。其中一个重要原因仍然是成本优势（存储密度和寿命都很棒）。相对其最初诞生时期，HDD 体积缩小了 5k+ 倍、单字节成本更是便宜了 60亿倍！然而，受制于机械特性，其随机访问延迟只降低了 150+ 倍左右。</p>
<p>S3 刚上线时，HDD 的满载 IOPS 大概是 120，这个数值在这么多年间基本没有变过。HDD 这种存储密度越来越高，但访问延迟却一直停滞的特点，给 S3 的设计带来了很大影响—— 必须想方设法将流量均摊到不同硬盘上去，避免单块盘的 IO 过载。</p>
<h1 id="热度管控：数据放置和性能"><a href="#热度管控：数据放置和性能" class="headerlink" title="热度管控：数据放置和性能"></a>热度管控：数据放置和性能</h1><p>基于上述原因，S3 在不断 scale 的同时，所面临的最主要和有意思的问题之一就是：<strong>如何在如此多的 HDD 上管理和均衡 IO 流量</strong>。我们称该问题为——<strong>热度管控</strong>（heat management）。</p>
<p>所谓<strong>热度</strong>（heat）：就是任意时间点，某个磁盘承受的 IO 请求。如果管控不当，造成不同磁盘间流量的严重倾斜，就会造成数据局部访问<strong>热点</strong>（hotspot），从而造成<strong>长尾效应</strong>（“stragglers”）。这些长尾请求通过 S3 的<strong>存储软件栈</strong>（software storage stack）层层放大之后，可能大范围影响请求性能。为了解决这个问题，我们需要仔细考虑<strong>数据放置</strong>策略（data placement）。</p>
<p>通常来说，由于无法在数据<strong>写入时</strong>（即进行放置决策时）预知其之后的访问模式，我们很难用一个策略消除所有用户的访问热点。但由于 S3 的量级以及多租户机制，我们可以进行完全不同的设计。</p>
<p>我们发现一个特点：在 S3 上运行的工作负载越多，不同对象请求间的<strong>去相关性</strong>（decorrelated）就越强。对于用户的单个存储单元来说（比如一组 Object，或者一个 Bucket），其通常的访问模式是：长时间沉寂后，突然一个远高于平均值访问高峰。但是当我们<strong>聚合了百万计</strong>的请求之后，非常有趣的事情发生了：聚合请求总量的变化曲线变的非常平缓，且出现了某种内在可预测的规律。可以看<span class="exturl" data-url="aHR0cHM6Ly93d3cuYWxsdGhpbmdzZGlzdHJpYnV0ZWQuY29tL3ZpZGVvcy9mYXN0LWFnZy1ncmFwaC1jb21wcmVzc2VkLXNtYWxsLm1wNA==">这个视频<i class="fa fa-external-link-alt"></i></span>直观感受下。</p>
<p><img src="https://s2.loli.net/2023/11/16/brs62GiUCyt5acA.png" alt="S3-aggreate.png"></p>
<p>这其实也符合直觉，在成千上万的<strong>不相干</strong>访问流汇聚成海后，单个流的突发很难影响整体趋势。因此我们的问题就变成了：<strong>如何将这种聚合后总体上相对平坦的请求速率均摊到所有磁盘上，变成每个磁盘上相对平滑的 IO 访问速率</strong>。</p>
<h1 id="数据复制：数据放置和持久性"><a href="#数据复制：数据放置和持久性" class="headerlink" title="数据复制：数据放置和持久性"></a>数据复制：数据放置和持久性</h1><p>在存储系统里，总是会用数据冗余来保护数据免于硬件故障。但冗余，同样可以用来管控热度。在多机上有多个副本，给了我们在流量过来时选择机器的自由度。从存储容量（capacity）的视角来看，数据冗余推高了成本；但从 IO （至少是读取）的角度来看，数据冗余提升了性能。</p>
<p>除了多副本冗余外，S3 自然也是用了 EC （erasure coding）方式来降低冗余。其具体原理我们在 <a href="https://www.qtmuniao.com/2019/03/30/f4/">Facebook F4</a> 中介绍过，这里不再赘述。</p>
<h1 id="数据尺度对放置策略的影响"><a href="#数据尺度对放置策略的影响" class="headerlink" title="数据尺度对放置策略的影响"></a>数据尺度对放置策略的影响</h1><p>除了使用数据冗余来均摊流量外，我们下一步可做的是：<strong>将新写入的对象数据尽可能大范围地摊到硬盘池中</strong>。将同一个桶的对象摊到不同的硬盘后，同一个用户的访问流量便也随之打到了不同硬盘集合。这样做有两个好处：</p>
<ol>
<li><strong>负载隔离</strong>：如果每个用户的数据在单块磁盘上都只会占一小块地方，因此很难靠单个用户的访问来“掀起波浪”，造成该盘的访问热点。</li>
<li><strong>热点摊平</strong>：对于任意的突发流量，我们可以利用超常规尺度的磁盘池来将其摊平。这对于小存储集群来说是非常昂贵且难以想象的。</li>
</ol>
<p><img src="https://s2.loli.net/2023/11/16/6yuNbMjU4IZXzcP.png" alt="S3-flow-avg.png"></p>
<p>如上图，可能是基因研究用户在使用 lambda 函数计算进行大规模的并行数据分析，IOPS 一度达到 2.3M IOPS，但我们使用数百万张磁盘可以轻松满足这种需求（上面计算可以看出 2w 张盘满载可以满足，那么有百万张盘，每个只用百分之一就可以满足）。</p>
<p>这种尺度的请求处理在 S3 中并不算夸张，当下 S3 集群至少有<strong>上万用户</strong>的存储桶的数据横跨超过<strong>百万张盘</strong>。正是 S3 如此体量的用户和用户数据，让这种构建方式成为可能。</p>
<h1 id="人的因素对-S3-的影响"><a href="#人的因素对-S3-的影响" class="headerlink" title="人的因素对 S3 的影响"></a>人的因素对 S3 的影响</h1><p>本文来自我的专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">系统日知录 2023<i class="fa fa-external-link-alt"></i></span>》，还有一部分在专栏文章中。你的订阅是我持续创作优质文章的最大动力，目前专栏有 82 篇文章，涵盖数据库、存储、系统等主题，如果你对大规模数据系统内容感兴趣，目前处于完结前的打折期，不容错过。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>s3</tag>
      </tags>
  </entry>
  <entry>
    <title>Y Combinator 2024 年关注 20 个创业领域</title>
    <url>/2024/01/03/yc-2024-rfs/</url>
    <content><![CDATA[<blockquote>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cueWNvbWJpbmF0b3IuY29tLw==">Y Combinator<i class="fa fa-external-link-alt"></i></span>（YC）是一家知名的美国创业加速器，自2005年成立以来致力于推动初创企业成功。作为初创企业界的领军人物，YC 的特点是，不仅提供资金，还提供指导、资源和网络，以帮助初创企业在竞争激烈的市场中脱颖而出。YC 的成功案例包括 Airbnb、Dropbox 和 Reddit 等，这些公司现在都是各自领域的巨头。<br>YC 发布的“创业公司征集请求”（<span class="exturl" data-url="aHR0cHM6Ly93d3cueWNvbWJpbmF0b3IuY29tL3Jmcw==">RFS<i class="fa fa-external-link-alt"></i></span>）是其基于对市场趋势、技术进步和全球挑战的深入理解，对全球创业社区的发出的一种前瞻性呼吁，相信能够对创业者和想选择创业公司的小伙伴们有诸多启发。2024 年的 RFS 一共有 20 个方向，这是上篇，包括前十个。如果看的人多，我再继续翻译后面 10 条。以下是正文。</p>
</blockquote>
<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a><strong>引言</strong></h1><p>虽然，我们投资过的最棒创业 idea，往往并不是一开始我们想找的，反而是那些无心插柳的。</p>
<p>但仍然，我们对几类创业公司非常期待。以下是我们最新的 2024 版本的<strong>创业公司征集请求</strong>（Requests for Startups，RFS），简述了下我们关注一些创业方向。</p>
<blockquote>
<p>但并非说创业只有选择这些方向，才能够申请 Y Combinator。其实我们的多数投资仍然集中在过于一直关注的互联网和移动端。所以如果在阅读本文前，你已经有相关方向的创业想法，请继续做下去。<br>同样的，也不是说我们列了这些方向，你就要据此创立一家公司。RFS 的目的在于，如果你正好已经有一个类似的想法，那欢迎向我们申请。<br>另外，如果你想知道我们在寻求投资哪些类型的非盈利组织，可以看<span class="exturl" data-url="aHR0cHM6Ly93d3cueWNvbWJpbmF0b3IuY29tL2Jsb2cvd2hhdC15LWNvbWJpbmF0b3ItbG9va3MtZm9yLWluLW5vbnByb2ZpdHMv">这篇文章<i class="fa fa-external-link-alt"></i></span>。</p>
</blockquote>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/01/03/yc-2024-rfs">https://www.qtmuniao.com/2024/01/03/yc-2024-rfs</a> 转载请注明出处</em></p>
<h1 id="1-人工智能（A-I-）"><a href="#1-人工智能（A-I-）" class="headerlink" title="1. 人工智能（A.I.）"></a>1. <strong>人工智能（A.I.）</strong></h1><p><strong>人工智能将对社会产生<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLnNhbWFsdG1hbi5jb20vYWk=">重大影响<i class="fa fa-external-link-alt"></i></span>。</strong></p>
<p>AI 很可能是技术史上的分水岭，其出现之前和之后世界看起来完全不同。我们对将 AI 应用于任何细分领域（药物发现、编程助手、法律咨询、欺诈检测等）的人感兴趣，特别是专注于 AI 和机器人交叉领域的人（制造业、自动驾驶汽车等）。</p>
<h1 id="2-生物科技（BIO）"><a href="#2-生物科技（BIO）" class="headerlink" title="2. 生物科技（BIO）"></a>2. <strong>生物科技（BIO）</strong></h1><p><strong>尽管尚处早期，但终于，我们正在生物科技领域中取得一些真正的进展。</strong></p>
<p>我们确信，该领域将在接下来几十年内持续是一个令人惊叹、强大且充满争议的领域。有点像肇始于 1970 年代的微型计算机技术。</p>
<p>工程原则现在被常态化地应用于合成生物学，且生物科技正在触达我们日常生活的各个方面，从医疗保健到制造业，甚至是食品和农业。</p>
<p>这里有很多细分方向——对抗疾病、延缓衰老、人机结合、上载记忆、遗传编程等。</p>
<p>DNA 读取技术已变得非常快和低成本，有了很多有趣的应用。随着 DNA 编辑技术更加成熟，可能会催生更多更为有趣的应用。</p>
<p>我们也对防止生物技术被滥用的领域感兴趣。举个例子，如果坏人能快速创造新的传染病，那么好人也能快速找到新的治疗方法和疫苗。</p>
<h1 id="3-实体店2-0"><a href="#3-实体店2-0" class="headerlink" title="3. 实体店2.0"></a>3. <strong>实体店2.0</strong></h1><p><strong>我们对于以有趣和高效的方式使用实体商业或零售空间（brick-and-mortar）的创业公司感兴趣。</strong></p>
<p>亚马逊正在让实体商场和大型连锁店破产。实体品牌与其和亚马逊进行无望的竞争，不如重新思考如何以能够充分发挥自身优势的方式使用零售空间。例如，特斯拉、沃比·帕克和佩洛顿利用实体店作为展厅，与他们的在线销售渠道互为补充。砍掉库存的需求，零售空间可以更有效地利用。</p>
<p>实体空间一些有意思的使用方向并不仅限于零售店——餐馆、娱乐场所、本地服务提供商和办公楼等领域也正在发生类似的巨变。新的商业模式将转向服务那些习惯于在线订购、与其他服务深度整合和即时交付等功能的客户。这其中，<strong>灵活性</strong>是关键。例如，与其提供为期数年的长租约，未来的商业模式更可能提供数天甚至几小时的“微租约”。</p>
<p>此外，消费者从市中心转向由停车场环绕郊区大卖场的偏好趋势（译者注：应该主要指美国购物的逆城市化趋势），可能会随着自动驾驶时代的到来而改变。一旦自动驾驶技术广泛落地，<strong>我们与物理空间的关系</strong>将出现难以预料的变革。我们希望看到创业公司能够思考这种变革，进而构建新的物理空间的使用方式。</p>
<h1 id="4-除碳技术"><a href="#4-除碳技术" class="headerlink" title="4. 除碳技术"></a>4. 除碳技术</h1><p><strong>巴黎气候协定设定了一个全球目标，即限制本世纪地球温度至多升高 1.5°C。仅通过转向可再生能源等调整能源结构的努力，并不足以实现该目标。因此，我们还必须大力发展大气除碳技术。</strong></p>
<p><strong>碳移除</strong>和<strong>封存技术</strong>仍处于初期阶段。目前的解决方案可以分为两类：<strong>依靠自然</strong>（如重新造林和生物炭）和<strong>倚重技术</strong>（如直接空气捕获）。包括美国在内的几个国家最近加大了对从大气中移除碳的财政刺激力度，但以目前的技术能力而言，还不具成本效益。</p>
<p>一些其他抑制气候变化的地球工程方法也很有潜力。</p>
<p>可以在 <span class="exturl" data-url="aHR0cDovL2NhcmJvbi55Y29tYmluYXRvci5jb20v">carbon.ycombinator.com<i class="fa fa-external-link-alt"></i></span> 页面上查看更多相关内容。</p>
<h1 id="5-细胞农业和清洁肉类"><a href="#5-细胞农业和清洁肉类" class="headerlink" title="5. 细胞农业和清洁肉类"></a>5. <strong>细胞农业和清洁肉类</strong></h1><p><strong>近期的科学发展改变了我们对蛋白质生产的看法。</strong></p>
<p>我们首次能够仅使用其细胞而不至伤害动物，生产在科学成分上与动物制品（如肉类和奶制品）无异的食物。</p>
<p>如今，人类主要依靠农场饲养动物来获取肉类和乳品。这种做法是否残忍和浪费且先放一边，起码它是不可持续的。每年有更多的人吃更多肉，但世界上已几无新的农田可用于肉类生产。农业领域是仅次于能源领域的世界第二大温室气体排放源，且农业中广泛使用的抗生素对我们自己的健康系统造成了真正的危害。</p>
<p><strong>直接从细胞培养真正的动物肉</strong>是一种革命性的科学。我们非常乐意投资更多的将这一技术推向市场的创业公司、我们也想投资专注于细胞农业规模化的创业公司。世界将从这种更可持续、更便宜、更健康的肉类生产方式中得益巨大。</p>
<h1 id="6-多元化"><a href="#6-多元化" class="headerlink" title="6. 多元化"></a>6. 多元化</h1><p><strong>多元化的劳动力对于商业和世界都有益。</strong></p>
<p>如果缺少不同的视角，我们创造的产品和服务将错失一大部分人的巨大机会。 我们希望投资这一类非营利组织和初创公司，帮助他们将技术服务于更多的人群，无关年龄、不分种族、无论文化，不论性取向。</p>
<h1 id="7-教育"><a href="#7-教育" class="headerlink" title="7. 教育"></a>7. <strong>教育</strong></h1><p><strong>如果我们能在当前解决教育问题，我们就最终能够解决该清单上的所有其他问题。</strong></p>
<p>由于大多数人缺乏良好的教育，这个星球上人类整体的大脑潜力被极大地低估了。强大的教育体系将带来更大的社会流动性、更强的工人、更好的公民，以及更多、更先进的创业公司。全球教育体系的智力成果的微小增长都将对人类生产力和经济增长产生巨大影响。</p>
<p>我们对能够大规模培养批判性思维、创造能力、公民意识和职业技能的新型学校模式感兴趣。我们正在寻找能够将技术与人际互动结合在一起、提供高度个性化教育体验的创业想法。</p>
<p>我们知道，人脑 90% 的发育在5岁之前完成，成就差距在幼儿园之前就已经拉开。我们对能够极大改善出生到五岁儿童的能力、降低不平等、并能够提高这些儿童及其家庭未来生活质量的创业项目感兴趣。得益于脑科学的逐渐发展和智能家居、可穿戴、移动互联等技术的进步，在现在的时间节点上，上述领域的可扩展解决方案应该是可行的。</p>
<h1 id="8-能源"><a href="#8-能源" class="headerlink" title="8. 能源"></a>8. <strong>能源</strong></h1><p><strong>能源成本与生活质量之间有着显著的相关性。</strong></p>
<p>历史上，每当能源成本大幅下降时（例如，蒸汽机革命），人们的生活质量都会大幅提高。</p>
<p>廉价的能源将极大地减少贫困。增加能源的新来源渠道还可以帮助保护环境、促进经济、减少战争、确保稳定的未来、增加食物和饮用水的供给等等。</p>
<p>我们相信经济因素将占主导地位——即使没有补贴，新能源也必须比旧能源便宜，并能满足全球需求。核能源可能满足这些要求，可再生能源可能也行。但定价是首要问题。</p>
<p>除了发电外，我们还对<strong>储能</strong>和<strong>传输</strong>感兴趣。如果电池能力提高10倍，将能够催生伟大新事物；如果能源能够便捷传输，相信也将有同样效果。</p>
<h1 id="9-企业软件"><a href="#9-企业软件" class="headerlink" title="9. 企业软件"></a>9. <strong>企业软件</strong></h1><p><strong>大公司使用的软件仍然很糟糕，使得该市场仍然非常有利可图。</strong></p>
<p>具有行业定义能力的企业软件公司将涌现出来，以解决不同行业、不同企业规模和不同工作职能的问题。以下是三个非常有趣的具体领域：</p>
<ol>
<li><strong>降低软件成本</strong>：由于传统企业软件的高昂成本，对于中小型企业来说，之前的许多的解决方案是不划算的。</li>
<li><strong>新增十亿工作者</strong>：传统上，企业软件的用户一直是坐办公室的脑力劳动者。 但手机和平板电脑等移动设备的普及会将各种其他类型的员工（从零售店员工到现场服务团队）转变为脑力工作者。</li>
<li><strong>各行业数字化</strong>：每个行业都在经历某种形式的信息化冲击；这会促使企业将他们的实践现代化，利用新数据、加速关键流程、并在流程中提供数字化的便捷体验。</li>
</ol>
<h1 id="10-金融服务"><a href="#10-金融服务" class="headerlink" title="10. 金融服务"></a>10. <strong>金融服务</strong></h1><p><strong>世界的金融系统越来越无法满足消费者和企业的需求。</strong></p>
<p>这有一定道理，因为旨在保护客户的立法速度，没能跟上被技术催生的客户新需求的速度。这种速度的不匹配，使得金融系统在几乎每个层面都是低效的。这会影响人们如何对他们的储蓄进行投资、如何帮助企业获得增长所需的资本、如何对风险进行定价和保险以及金融公司如何相互开展业务等诸多方面。</p>
<p>我们认为软件将加速金融服务的变革速度，并最终改变相关的法规。我们希望投资那些有创新想法来实现这一点的公司。</p>
]]></content>
      <categories>
        <category>创业</category>
      </categories>
      <tags>
        <tag>YC</tag>
        <tag>创业</tag>
      </tags>
  </entry>
  <entry>
    <title>2023 年终总结——穷则思变</title>
    <url>/2024/01/04/2023-summary/</url>
    <content><![CDATA[<p><img src="https://s2.loli.net/2024/01/04/YQDIuMkiNGJmdtx.jpg" alt="IMG_8879.JPG"></p>
<p>2023 年倏忽而过，事后来看，要用一个词来形容的话，就是——<strong>穷则思变</strong>。</p>
<p>穷倒并非是物理上穷的吃不下饭，而是更接近穷则独善其身”中困顿的穷。思想上原先很多赖以生存的观念维持不下去了，因此经历了一个痛苦地重塑过程。这倒并非坏事，只不过其间被动的思想拉扯，现在想来仍然倍感折磨。当然，正是这些逆境逼迫我们跳出“群体思维”进行求索（think different），纵一时痛苦，却能有所得——每个人毕竟要走出属于自己的路。</p>
<p>那这一年到底发生了哪些改变呢？</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/01/04/2023-summary">https://www.qtmuniao.com/2024/01/04/2023-summary</a> 转载请注明出处</em></p>
<p><strong>首先是生活上的，由于家庭原因，年中搬来英国生活</strong>。继而引起工作上的变动，辞了工作，计划到英国再找，仗着积累，初时甚为乐观，继而被现实来了一记闷棍——完全摸不着头脑的那种。最后我痛苦的发现，找一个我原来方向（存储、分布式和数据库等大规模数据系统方向）的工作并不容易，甚至我放低匹配度，投了一些数据和后端的工作，也杳无音信。当然我可以拉出来很多因素：</p>
<ol>
<li>英国偏 infra 的工作并不多</li>
<li>我需要公司 sponsor 工作签</li>
<li>我没有英国学习工作经历</li>
<li>我的口语不是很够用</li>
<li>我对英国面试流程不熟</li>
<li>…</li>
</ol>
<p>但我自己也知道，尽管我准备了不少，也投了很多，但终是没有放下全部“身段”，背水一战——死磕英语、充分备面、全方向投等等。终归心底仍不愿废掉之前 infra 的职业路径。当然，这也可能是一个借口，来掩盖我对这种落差的不适、对融入新环境的抵触。但无论如何，我低估了融入这边的难度，并且没有为此做好准备。</p>
<p>更何况，我所在的小镇好吃的实在是太少了（手动斜眼）！还有，英国的他就没多少天亮的时候（纬度高日照短就不说了，还成天阴天下雨）。久了，是真的容易致郁。久无工作、天天小黑屋、再加上每天独自买菜做饭的日子，使得下半年心情格外艰难。想象中的可以到处转转，至此，是根本没有心力。不多的亮色是通过羽毛球（国外发小红书真的可以聚拢一些同好）在这边认识了一些很棒的华人朋友，一块打打吃吃，勉为坚持。</p>
<p><strong>上半年在公司的时候，做了几个重要的功能，还是挺开心的</strong>。印象最深的有执行计划下推和分布式事务调研。执行计划下推是沟通计算层和存储层的桥梁，算是很重要的一个模块，感谢四王的信任。以此为契机，上下延伸、左右博引，点亮了数据库中以前模糊的一些脉络，补充了相关的一些论文和项目，成长良多。分布式事务虽然我出力不多，但是跟着一块调研和讨论，同时对照阅读分享 DDIA 的<span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8jL2NoMDk=">相关章节<i class="fa fa-external-link-alt"></i></span>，想算是弄懂了各种烂七八糟奇怪的一致性，明白了为什么“时钟”是分布式系统中“最重要”的事。</p>
<p><strong>下半年在英国的时候，无业，焦虑如影随形，但多少也做了些事情。</strong><span class="exturl" data-url="aHR0cHM6Ly9kZGlhLnF0bXVuaWFvLmNvbS8=">DDIA<i class="fa fa-external-link-alt"></i></span> 超级超级长的两章（对，说的就是批处理和流处理），文字稿写完了，不过流处理那一章还没有在 b 站分享。粗略用 <code>wc -m</code> 统计下前十一章的文字量，也快有三十万字了。鉴于字字手打，也算殊为可观了。很多地方需要理解、斟酌后等价变化（做过翻译的同学应该知道我在说啥），中间也难免挣扎。而且最后三章是真的冗长，因此 <span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vMzA5MzM4MTIvY2hhbm5lbC9jb2xsZWN0aW9uZGV0YWlsP3NpZD0yNDA1NTE=">b 站<i class="fa fa-external-link-alt"></i></span>上常有同学问最后的章节还更不更，虽然我一直嘴硬，说更。但内心知道其实一直处于“结尾”与“烂尾”之间。</p>
<blockquote>
<p>小尾巴：如果对 DDIA 感兴趣，但是又感觉像猫看到鸡蛋一样——无从下嘴，可以订阅我的专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL2xhcmdlLXNjYWxlLXN5cw==">DDIA 学习会<i class="fa fa-external-link-alt"></i></span>》，我会每周对书中细节进行答疑。由于大规模数据系统 infra 的从业经历，让我可以对书中一些晦涩难懂的细节提供一些工业上的实例和视角。当然，说是答疑，主要还是和大家交流，互相促进。</p>
</blockquote>
<p>其他的，就是<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC82NjcwMDE5OTE=">重新做了下 MIT 6.824<i class="fa fa-external-link-alt"></i></span>（现在已经改名了）的 lab，这已经是第三遍了，顺畅了很多，也因此生出了更多经验、感悟和心得，和 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3Jvc2VkdWFu">roseduan<i class="fa fa-external-link-alt"></i></span> 大佬合作，放到了一门“<span class="exturl" data-url="aHR0cHM6Ly9hdjZodWYyZTFrLmZlaXNodS5jbi9kb2N4L0pDc3NkbGdGNG9SQURjeHhMcW5jUHBSQ241Yg==">课程<i class="fa fa-external-link-alt"></i></span>”（带引号是因为可能叫心得更为合适）里。对 Raft 和 Go 感兴趣的同学可以关注下。</p>
<p>还有，就是更新我的大规模数据系统专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">系统日知录<i class="fa fa-external-link-alt"></i></span>》了，这是今年开的一个小报童专栏，现在有不到九十篇文章、一百多个同学订阅支持。刚开始时，方向也不是很明确，所以起了一个这样不太明白的名字。但后来随着我对之前工作经历的梳理、对 DDIA 的持续分享、对将来想要干的事情的思考，我把定位固化为“大规模数据系统”。当今任何数字化的<strong>系统</strong>都离不开数据，而且是海量<strong>数据</strong>，于是就要诉诸分布式系统，即<strong>大规模</strong>。在这个领域内，我试图通过工作、阅读和分享一点点拼图，慢慢扎下一些根，占下小小的一席之地。 以下是从专栏里遴选的，发在公众号的一些文章：</p>
<ul>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg2MDI5JmlkeD0xJnNuPTEzMWFlM2I4N2Q0YTk3NmU4ZTAzMDA5ODExNTgwMDE1JmNoa3NtPWMwMGQ1MjA3Zjc3YWRiMTE5OTI2NjJjMjMwMmNmY2VjODM4MjE4M2I4OWZmZWU4OWYxZTVkNTE1Y2MwZDRlMDNjNmI0MTllM2ZhMTEmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">构建和维护星球最强对象存储系统的一点微小经验<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1OTUxJmlkeD0xJnNuPTczMjMyZjdiZDU1MzE1YzdkZTlmZTQ5NzM4NzY4NjA1JmNoa3NtPWMwMGQ1MWI1Zjc3YWQ4YTM1MWYwNDcwZTEzYjc0MmQ5MzMxOTdlNTk0YjMzNDA1NGE4MjkyN2M3NjBjMjFkMjk2NmVlODk5ZmU4MDAmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">Firebolt：如何在十八个月内组装一个商业数据库<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1OTE4JmlkeD0xJnNuPTI1NWU3YWY3MDk0NzM3ZWRlMjdhOGNlMGY5ZTk1OTg3JmNoa3NtPWMwMGQ1MTk0Zjc3YWQ4ODI5NDYxNDNjMDliNjBkNjViMDcwNzM4YjQ1NWU2YTFmODMyMjI5NmM2MGE2YWQ3N2JhOTQ2ZWRjOWI4NDcmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">ER 模型背后的建模哲学<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1ODgwJmlkeD0xJnNuPTMwMDdmNDkzZjU2NmMxM2RmZmRlYWEwMmRlOWViOTliJmNoa3NtPWMwMGQ1MWYyZjc3YWQ4ZTQ0MmI1MWNjOGEzZTA3NmNiZTFjNTM4ZGE5MzdiMDNhODk4YTM1YWUwNWFlZGRlNWZkZjVkZGQwODJhYWYmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">NUMA-Aware 执行引擎论文解读<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1ODY2JmlkeD0xJnNuPTBjYWFmZjA4NzBjMWJiM2ExMjUwZDkwNTQyOWM4MzZjJmNoa3NtPWMwMGQ1MWUwZjc3YWQ4ZjZjYjc1ZDJiYzgyYTFlZWU5NTlmYmIyYzk2Nzg3NzNhZDAwZTM2YzU4ZjBjZjJkMTIxZWU5NGUzNTczNTcmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">数据处理的大一统——从 Shell 脚本到 SQL 引擎<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1ODU0JmlkeD0xJnNuPTAwMjBkYTNhYWJkMmE0YzU5MWRjMWZmYzE5ZDJjMjc0JmNoa3NtPWMwMGQ1MWQ0Zjc3YWQ4YzI1MGI2ZDUxYzVmMjhkZTg0NWE1MzQ0ZmQ2YjAzMTE5MDc1NjgxNjI5ZThiY2M1M2VmM2M0OWU3Mzc4NDcmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">生活工程学（一）：多轮次拆解<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1ODM1JmlkeD0xJnNuPTJlY2E4YjEyZjkxYzdhMDY2MTFjM2Q2MzMxMDVmNjZkJmNoa3NtPWMwMGQ1MWMxZjc3YWQ4ZDc0NTUwY2QyMTBkZTYzZTBkODY5NjE2OTJiNjYwNThlZGYxMmFmZmQxMTc3MTJiMjE2NTdhZTFmZTIyZmEmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">数据库面试的几个常见误区<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1NzQ4JmlkeD0xJnNuPTZhZDM5YzFmYmFhZjdhNDEzYzA1NTM0ZmY0NzYzNDk5JmNoa3NtPWMwMGQ1MTdlZjc3YWQ4NjhhNmI1NjMwN2VlNWE2ZmUwOTY4Y2M5ZjY5NzNjMWI1ZTRhNGRiMGYyNjAzMWZiOTEzNTYzNjJjOWM3MTImc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">Facebook Velox 运行机制全面解析<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1NzE3JmlkeD0xJnNuPWEwNGEwMjQ0OWQwMDc1ZTIxNzgwYzhkMGQ3OGM2YTNmJmNoa3NtPWMwMGQ1MTVmZjc3YWQ4NDlhNmQzMjY0NWU5MTY0ZDQxMGVmZDI2M2JkZDg2ODNhNzMxZTJjZjk3NTBlZjNlMjBkNTI1ZTQ1NTFiMjQmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">写好代码，我的三个 Code<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1NzA2JmlkeD0yJnNuPWNmMDNjMmJlZTViYjkyMjc0ZmY2YTE5Y2I5ODQwNjRhJmNoa3NtPWMwMGQ1MTQwZjc3YWQ4NTYwYjEyZTc4YzA1NzJmYmQzMTcyMDdiMzM0NGE3NDRiMjcxMGNlNDRjMGFkNGUzYTNkOTUxODg5NGNmMzImc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">图数据库系列（三）：图的表示<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cDovL21wLndlaXhpbi5xcS5jb20vcz9fX2Jpej1Nemc1TlRjeE56WTJPUT09Jm1pZD0yMjQ3NDg1NjcyJmlkeD0xJnNuPWM2MTA3Njc4MzI4OTkyYmM2NTEwYjRjNDFjYzVmZDdjJmNoa3NtPWMwMGQ1MGEyZjc3YWQ5YjQ1NzdiZTA3ZjI4MDA5ZTdkNGQyYWI2YzU5NjliOTYwZGQ5NmVkZTU2ZWRjYTZjMzk1NzNkMjc5YWQ1MWMmc2NlbmU9MjEjd2VjaGF0X3JlZGlyZWN0">分布式图库系列—— 图模型和 Cypher<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<p>纵然如今大模型大行其道，其背后生态所需海量数据的采、存、算、用等数据流，仍尚无规约，也将是本专栏今后的一个主要关注方向。</p>
<p><img src="https://s2.loli.net/2024/01/04/uC3GBcqUtHlExbd.png" alt="小报童专栏.png"></p>
<p>作为程序员，我今年写文字甚至要比写代码多不少，毕竟下半年无业，只能靠文字为生。虽然最后收入并不多，但收获却不少。文字输出本质上是一种锤炼思维的过程，虽然很缓慢，但在时间维度上积分过后，总量倒也可观。</p>
<p><strong>年末的时候，发现一个 up 主：</strong> <span class="exturl" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNDkxMzA2OTAy">课代表立正<i class="fa fa-external-link-alt"></i></span>。他采访了很多有意思的嘉宾，创业的、海归的、财富自由的、退休两年的、技术转投资的，聊天节奏把握的很好，我受到不少启发。看完一些视频后，对亮点印象很深：</p>
<ol>
<li><strong>框架性思维</strong>。比如知识树，举一反三。</li>
<li><strong>工具和目标混淆</strong>。比如赚钱和自由。</li>
</ol>
<p>虽然这两点老生常谈了，我也听过无数遍了，甚至第一点我在文章中也说过很多遍了，但为什么还会有启发？且听我慢慢铺垫。</p>
<p>人脑在理解东西的有趣之处在于，得积累够足够多的经历后，才能抽象出一些一阶规律；在积攒够了足够多的一阶规律后才能进而堆叠出二阶规律；循环往复，达到至深层的“万法归一”的通透。这种抽象的树形组织很像我们数据库领域中一种常用的数据结构——B+ 树。我们知道 B+ 树有个性质——所有的插入都发生在叶子节点上。这些视频也是，各个嘉宾的经历，给我的思维树凑了一些叶子结点，到达某种临界，引起了我的思维树（B+ 树中常见）的“级联分裂”，从而触到了一些之前苦苦思索却不得要领的深层问题的答案。</p>
<p>虽然知道了这些道理，我之后可能仍然会反复、可能仍然会掉到“文人相轻”（peer pressure）的怪圈中，但我相信收敛速度会越来越快。</p>
<p><strong>今年去的地方少，新鲜的地方也就南疆大环线和英国了</strong>。且，由于思维上的紧绷，后者就很囫囵的吞了一些景色，没有心思细品。在南疆有两个地方印象很深——高昌古城和喀什古城。</p>
<p><img src="https://s2.loli.net/2024/01/04/fEW6lxmVTsSoj5p.jpg" alt="高昌故城.jpg"></p>
<p>与其他西域古国不同，高昌是一个汉族政权——汉朝屯兵的后代，最终城毁于蒙古铁骑，可怜宫阙万间，都做了土。我们的幸运之处在于，蹭到了一个旅游团请的资深解说。随着摆渡车在不同区域停靠，解说大叔信手拈来，曰某某处，昔为某所，有何掌故。其口气云淡风轻，但对这方土地、这段历史的热爱却难以抑制的流露。</p>
<p>如果说高昌古城是“死”的古城，那喀什老城便是“活”着的老城，老而不朽，活色生香。我以此名上传到图虫，顺手投稿了中国日报新媒体中心主办的一个比赛，竟然第一次在摄影比赛中得奖。<br><img src="https://s2.loli.net/2024/01/04/te6JBH7pQqYNR4G.jpg" alt="图虫获奖.png"></p>
<p>世上之事难言难传，无心插柳的喜讶，反而更胜于，有心栽花的梦成。所以我还是希望自己能慢慢“松弛”下来，多做一些“心怀善念”的无用之事，多结一些“无用”之善缘。说到这里，我又想起之前一次对加我微信的一个同学，由于一直讲不到我想要的“重点”，被当时忙着的我略显粗暴的打断，实是追悔。</p>
<p>英国的小镇，兼具国内乡村的景色与闲适、城市的便捷与审美，确实宜居。但彼时，我总被没有工作的隐忧淡淡环绕，不能自轻，自然也没法充分品尝这份安宁，愿他日再得赐良机。</p>
<p><img src="https://s2.loli.net/2024/01/04/RpqPwedKs56jhAf.jpg" alt="IMG_8516.JPG"></p>
<p>最后，人类总是矛盾。譬如，我们需要社交来锚定自己、却又不能从众来拘囿自己。因此凡事总需要拿捏一个度，老祖宗说“中庸”，今人说“松弛”，愿 2024 大家能忠于内心所愿！</p>
<blockquote>
<p>去年年终总结：<a href="https://www.qtmuniao.com/2023/01/05/2022-summary">2022 年终总结 —— 充实和迷茫</a></p>
</blockquote>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>年终总结</tag>
      </tags>
  </entry>
  <entry>
    <title>MemGraph 背后论文《基于内存和MVCC 的高速可串行化》详细解析（一）</title>
    <url>/2024/02/06/memory-mvcc-serial/</url>
    <content><![CDATA[<blockquote>
<p><span class="exturl" data-url="aHR0cHM6Ly9tZW1ncmFwaC5jb20v">Memgraph<i class="fa fa-external-link-alt"></i></span> 是一个内存型图数据库，使用 OpenCypher 作为查询语言，主打小数据量、低延迟的图场景。由于 Memgraph 是开源的（repo 在<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL21lbWdyYXBoL21lbWdyYXBo">这<i class="fa fa-external-link-alt"></i></span>，使用 C++ 实现）我们可以一窥其实现。根据<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL21lbWdyYXBoL21lbWdyYXBoL2Jsb2IvbWFzdGVyL3NyYy9zdG9yYWdlL3YyL3N0b3JhZ2UuaHBwI0w1Nw==">这行注释<i class="fa fa-external-link-alt"></i></span>，我们可以看出，其内存结构实现灵感主要来自论文：<span class="exturl" data-url="aHR0cHM6Ly9kYi5pbi50dW0uZGUvfm11ZWhsYmF1L3BhcGVycy9tdmNjLnBkZg==">Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems<i class="fa fa-external-link-alt"></i></span>。</p>
<p>本系列主要分为两大部分，<strong>论文解读</strong>和<strong>代码串讲</strong>，每一部分会根据情况拆成几篇。本篇，是论文解读（一），主要讲论文概述以及如何使用链表巧妙的存储了多版本、控制了可见性。论文解析（二）和（三），会讲如何实现可串行化以及回收多版本数据。</p>
</blockquote>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>从论文题目可以看出，本论文旨在实现一种针对<strong>内存型</strong>数据库的、基于<strong>多版本</strong>（MVCC）实现的、支持可<strong>串行化</strong>隔离级别的高性能数据结构。其基本思想是：</p>
<ol>
<li>使用列存</li>
<li>复用 Undo Buffer 数据结构</li>
<li>使用双向链表来串起数据的多版本</li>
<li>巧妙设计时间戳来实现数据的可见性</li>
<li>通过谓词树（PT）来判事务读集合（Read Set）是否被更改</li>
</ol>
<p>与一般的多版本不同的是，本论文会在<strong>原地更新</strong>数据，然后将旧版本数据“压”到链表中去，使用 “压”是因为链表采用头插法：表头一侧数据较新、表尾一侧数据较旧。所有数据的链表头由一个叫 <code>VersionVector</code> 的数据结构维护，如果某一行没有旧数据，对应的位置就是 <code>null</code>。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/02/06/memory-mvcc-serial">https://www.qtmuniao.com/2024/02/06/memory-mvcc-serial</a> 转载请注明出处</em></p>
<p><img src="https://s2.loli.net/2024/02/06/SdeBuqCJnvPTt6m.png" alt="MVCC-memory.png"></p>
<p>之后，我们之后会一直使用上图例子来辅助理解原理。这是一个 Sally 持续向别人转账的例子。开局时（T0）每人十块钱，然后 Sally 每次转给别人 1 块钱，一共转了三笔，当前时刻前两笔已经完成：</p>
<ol>
<li>Sally → Wendy，提交时间戳为 T3</li>
<li>Sally → Henry，提交时间戳为 T5</li>
</ol>
<p>正在进行第三笔：</p>
<ol>
<li>Sally → Mike，事务 ID 是 Ty，起始时间戳为 T6</li>
</ol>
<p>中间穿插着两次全表扫描（求所有账户总额）事务 Tx 和 Tz，起始时间戳分别为 T4 和 T7 ，都已经开始，但还没结束。</p>
<h2 id="版本管理"><a href="#版本管理" class="headerlink" title="版本管理"></a>版本管理</h2><p>每个事务在进入系统时会获取两个时间戳（uint64）：</p>
<ol>
<li><strong>transactionID</strong>：事务 ID 也是一个时间戳（从 2^63 开始自增），上图中的 Tx, Ty, Tz。</li>
<li><strong>startTime-stamp</strong>：一个自增的时间戳（从 0 开始自增），上图中的 T4, T6, T7。</li>
</ol>
<p>如前所述，所有的更新是原地的（in-place），但会在 undo buffer 中保存旧值。旧版本的数据有两个作用：</p>
<ol>
<li>before-image value，作为事务 undo log 的一部分。</li>
<li>作为该字段多版本的一个旧值。</li>
</ol>
<p>对于快照隔离和可串行化隔离级别来说，原地更新的值，是不为其他事务所见的，下一小节我们会讲如何控制可见性。</p>
<p>在事务提交时，会获取另外一个时间戳：<strong>commitTime-stamp</strong>，该时间戳和 startTime-stamp 共用一个自增计数器。</p>
<p><strong>在事务进行中</strong>，所有的 Undo Buffer 中的旧值会被打上 transactionID 的时间戳（图中第三笔转账：Ty）；<strong>在事务提交时</strong>，会统一替换为 commitTime-stamp （图中前两笔转账： T3 和 T5）。</p>
<h2 id="版本可见性"><a href="#版本可见性" class="headerlink" title="版本可见性"></a>版本可见性</h2><p>某个事务在访问一个字段的值时，会首先进行原地访问，然后沿着该值对应的 VersionVector 指向链表进行访问，直到满足以下条件后停止：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pred 表示下一个链节</span></span><br><span class="line"><span class="comment">// TS 表示对应链节的关联时间戳</span></span><br><span class="line"><span class="comment">// T 表示当前事务以及当前事务 ID</span></span><br><span class="line">v.pred == null || v.pred.TS == T || v.pred.TS &lt; T.startTime</span><br></pre></td></tr></table></figure>

<p>下面我们逐一看下三个子条件各自适用情况：</p>
<ol>
<li><code>v.pred == null</code> ：当该值没有多版本，或者链表到头时成立。</li>
<li><code>v.pred.TS == T</code>：正在进行的事务访问自己更新的数据。</li>
<li><code>v.pred.TS &lt; T.startTime</code>：通过事务起始时间戳，访问已经提交的老版本数据。</li>
</ol>
<p>上述条件比较抽象，我们结合例子来看。Sally 的多次转账会形成以下链表：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="number">7</span>(in-place) -pred-&gt; (Ty, Bal, <span class="number">8</span>) -pred-&gt; (T5, Bal, <span class="number">9</span>) </span><br><span class="line">            -pred-&gt; (T3, Bal, <span class="number">10</span>) -pred-&gt; null</span><br></pre></td></tr></table></figure>

<p>然后来看不同事务访问 Sally 的 Bal（Balance）数据的可见性：</p>
<ol>
<li><strong>事务 Ty</strong>：（Ty 是一个 &gt; 2^63 的值），所以会在后继节点满足： <code>pred == (Ty, Bal, 8)</code> （条件2，Ty &#x3D;&#x3D; Ty）时停住，此时访问到的值为 7 ，也即事务 Ty 更新到的值。</li>
<li><strong>事务 Tx</strong>：起始时间戳为 T4，所以会在后继节点满足 <code>pred == (T3, Bal, 10)</code> （条件3，T3 &lt; T4）时停住，此时访问到的 Sally 账户的值为 9，也即此时刚转过一次账，即提交时间戳为 T3 的那次转账。</li>
<li><strong>事务 Tz</strong>：起始时间戳为 T7，所以会在后继节点满足 <code>pred == (T5, Bal, 9)</code> （条件 3，T5 &lt; T7）时停住，此时访问到 Sally 的账户值为 8，也即此时完成了两次转账，第三次转账尚未完成，对 Tz 不可见。</li>
</ol>
<p>可以看出，上述链表把时间轴分成了四段：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">临时值（<span class="number">7</span>）----Ty--(<span class="number">8</span>)---T5---(<span class="number">9</span>)---T3---(<span class="number">10</span>)---T0</span><br></pre></td></tr></table></figure>

<p>比较事务起始时间戳和后继链节时间戳，是为条件 1：</p>
<ol>
<li>T0 ~ T3：见到的值是 10</li>
<li>T3 ~ T5：见到的值是 9</li>
<li>T5 ~ ∞：见到的值是 8</li>
</ol>
<p>其中，Ty （事务 ID）<strong>相对起始时间戳来说就是无穷大</strong>，这就是我们在前一小节提到的将 uint64 对半劈开的妙用之处：</p>
<ol>
<li>起始和提交时间戳：0 ~ 2^63 -1 </li>
<li>事务ID：2^63 ~ 2^64 - 1</li>
</ol>
<p>另外，null 就相当于 T0 ，是为条件 1 。</p>
<p>最后，为了让事务能够看到自己的更新，于是额外加了条件 2 。</p>
<p>下篇，我们会详细讲如何基于上述数据结构来实现可串行化隔离级别的。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li>开源项目：<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL21lbWdyYXBoL21lbWdyYXBo">https://github.com/memgraph/memgraph<i class="fa fa-external-link-alt"></i></span></li>
<li>相关论文：<span class="exturl" data-url="aHR0cHM6Ly9kYi5pbi50dW0uZGUvfm11ZWhsYmF1L3BhcGVycy9tdmNjLnBkZg==">https://db.in.tum.de/~muehlbau/papers/mvcc.pdf<i class="fa fa-external-link-alt"></i></span></li>
<li>解析博文：<span class="exturl" data-url="aHR0cHM6Ly93YW5nemlxaTIwMTMuZ2l0aHViLmlvL3BhcGVyLzIwMTgvMDcvMTAvRmFzdC1TZXJpYWxpemFibGUtTXVsdGktVmVyc2lvbi1Db25jdXJyZW5jeS1Db250cm9sLWZvci1NYWluLU1lbW9yeS1EYXRhYmFzZS1TeXN0ZW1zLmh0bWw=">https://wangziqi2013.github.io/paper/2018/07/10/Fast-Serializable-Multi-Version-Concurrency-Control-for-Main-Memory-Database-Systems.html<i class="fa fa-external-link-alt"></i></span></li>
</ol>
<blockquote>
<p>本篇文章来自我的小报童专栏，<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzY1NmQ4ZDczLWY4ZWQtNDYwNC05ZjE0LWY3Nzc5N2U4NzdiMA==">第二篇解读<i class="fa fa-external-link-alt"></i></span>也已经在专栏更新，欢迎喜欢我文章的朋友订阅支持，激励我产出更多优质文章。订阅方式见<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">这里<i class="fa fa-external-link-alt"></i></span>。</p>
</blockquote>
]]></content>
      <categories>
        <category>数据库</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>memgraph</tag>
        <tag>mvcc</tag>
      </tags>
  </entry>
  <entry>
    <title>螺蛳壳里做道场：实现一个256KB的迷你文件系统</title>
    <url>/2024/02/28/mini-filesystem/</url>
    <content><![CDATA[<blockquote>
<p>本文主要“编译”自书籍《<span class="exturl" data-url="aHR0cHM6Ly9wYWdlcy5jcy53aXNjLmVkdS9+cmVtemkvT1NURVAv">Operating Systems: Three Easy Pieces<i class="fa fa-external-link-alt"></i></span>》第 40 章，这是一本非常深入浅出的书，推荐给所有对操作系统感到迷茫的同学。本文件系统基于一个非常小的硬盘空间，以<strong>数据结构</strong>和<strong>读写流程</strong>为主线，从零到一的推导出各个基本环节，可以帮你快速建立起对文件系统的直觉。</p>
</blockquote>
<p>文件系统基本都是构建于块存储之上的。但当然，现在的一些分布式文件系统，如 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2p1aWNlZGF0YS9qdWljZWZz">JuiceFS<i class="fa fa-external-link-alt"></i></span>，底层是基于对象存储的。但无论块存储还是对象存储，其本质都是按 “数据块” 进行<strong>寻址</strong>和<strong>数据交换</strong>的。</p>
<p>我们首先会探讨一个完整的文件系统在硬盘上的数据结构，也即布局；然后再通过打开关闭、读写流程将各个子模块串起来，从而完成对一个文件系统要点的覆盖。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/02/28/mini-filesystem">https://www.qtmuniao.com/2024/02/28/mini-filesystem</a> 转载请注明出处</em></p>
<blockquote>
<p>本文来自我的大规模数据系统专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">系统日知录<i class="fa fa-external-link-alt"></i></span>》，专注存储、数据库、分布式系统、AI Infra 和计算机基础知识。欢迎订阅支持，解锁更多文章。你的支持，是我前行的最大动力。<br><img src="https://s2.loli.net/2024/02/28/GrZPSV15EXOAhbQ.png" alt="海报.png"></p>
</blockquote>
<h1 id="总体布局"><a href="#总体布局" class="headerlink" title="总体布局"></a>总体布局</h1><p>假设我们的块大小是 4KB，然后有一块非常小的硬盘，只有 64 个块（则总大小为 64 * 4KB &#x3D; 256KB），且该硬盘只给文件系统用。由于硬盘是按块进行寻址的，则地址空间为 0~63 。</p>
<p><img src="https://s2.loli.net/2024/02/28/bywIskmS9r4aAgt.png" alt="filesystem-empty.png"></p>
<p>基于此迷你硬盘，我们一起来逐步推导下这个极简文件系统。</p>
<p>文件系统的首要目的肯定是存储用户数据，为此我们在磁盘留出一块<strong>数据区</strong>（Data Region）。假设我们使用后面 56 个块作为数据区。为什么是 56 个呢？从后面就可以知道，其实是可以算出来的——我们可以大致算出元信息和真正数据的比例，进而可以确定两部分大小。</p>
<p><img src="https://s2.loli.net/2024/02/28/jSclXgo3GHEnPb4.png" alt="filesystem-data-region.png"></p>
<p>接下来，我们需要为系统中的<strong>每个文件</strong>保存一些元信息，比如：</p>
<ol>
<li>文件名</li>
<li>文件大小</li>
<li>文件归属者</li>
<li>访问权限</li>
<li>创建、修改时间</li>
</ol>
<p>等等。保存这些元信息的数据块，我们通常称为 <strong>inode</strong> （index node）。如下，我们给 inode 分配 5 个 block。</p>
<p><img src="https://s2.loli.net/2024/02/28/D4N1Jh8qSVlb5yz.png" alt="filesystem-inodes.png"></p>
<p>元信息所占空间相对较小，比如 128B 或者 256B，我们这里假设每个 inode 占用 256B。则每个 4KB 块能容纳 16 个 inode，则我们的文件系统最多可以支持 5 * 16 &#x3D; 80 个 inode，也即我们的迷你文件系统最多可以支持 80 个文件，但由于目录也要占 inode，所以实际可用文件数要少于 80。</p>
<p>现在我们有了数据区，有了文件元信息区，但在一个正常使用的文件系统中，还需要追踪哪些数据块被用了，哪些还没有被使用。这种数据结构我们称之为<strong>分配结构</strong>（allocation structures）。业界常用的方法有<strong>空闲链表</strong>（free list），即把所有空闲块按链表的方式串起来。但为了简单，这里使用一种更简单的数据结构：<strong>位图</strong>（bitmap），数据区用一个，称<strong>数据位图</strong>（data bitmap）；inode 表用一个，称 <strong>inode 位图</strong>（inode bitmap）。</p>
<p>位图的思想很简单，即为每一个 inode 或者数据块使用一个数据位，来标记是否空闲：0 表示空闲，1 表示有数据。一个 4KB 的 bitmap 最多能追踪 32K 的对象。为了方便，我们给 inode 表和数据池各分配一个完整的块（虽然用不完），于是便有了下图。</p>
<p><img src="https://s2.loli.net/2024/02/28/Nea5XHfkJdBcqCh.png" alt="filesystem-bitmap.png"></p>
<p>可以看出，我们的基本思路是从后往前进行数据布局，最后还剩一个块。该块我们是故意留的，用以充当文件系统的<strong>超级块</strong>（superblock）。超级块作为一个文件系统的<strong>入口</strong>，通常会保存一些文件系统级别的元信息，比如本文件系统中有多少个 inode 和数据块（80 和 56），inode 表的起始块偏移量（3），等等。</p>
<p><img src="https://s2.loli.net/2024/02/28/tnqOKpyTjroDfMG.png" alt="filesystem-superblock.png"></p>
<p>则当文件系统被<strong>装载</strong>（ mount ）时，操作系统会首先读取超级块（所以放最前面），并据此初始化一系列参数，并将其作为数据卷挂载到文件系统树中。有了这些基本信息，当该卷中的文件被访问到时，就能逐步找出其位置，也就是我们之后要讲的读写流程。</p>
<p>但在讲读写流程之前，需要先放大一些关键数据结构看看其内在布局。</p>
<h2 id="索引节点（Inode）"><a href="#索引节点（Inode）" class="headerlink" title="索引节点（Inode）"></a>索引节点（Inode）</h2><p>inode 是<strong>索引节点</strong>（index node）的简称，是对文件和文件夹的索引节点。为了简单，我们使用<strong>数组</strong>来组织索引节点，每个 inode 会关联一个<strong>编号</strong>（inumber），也即其在数组中的<strong>下标</strong>（偏移量）。</p>
<p><img src="https://s2.loli.net/2024/02/28/lMaDRH9oNuj8wFr.png" alt="filesystem-inode-table.png"></p>
<p>上面提到过一嘴，每个 inode 占 256B。则给定一个 inumber，我们就可以计算出其在硬盘中的偏移量（<code>12KB + inumber * 256</code>），但由于内外存交换是按块来的，我们可以据此进而计算出其所在磁盘块。</p>
<p>inode 主要保存文件名、一些元信息（权限控制、各种事件、一些标记位）和<strong>数据块索引</strong>。数据块索引其实也是元信息，单拎出来说是因为它很重要。</p>
<p>我们使用一种比较简单的索引方式：<strong>间接指针</strong>（<strong>indirect pointer</strong>）。即 inode 中保存的不是直接指向数据块的指针，而是指向一个指针块（也在数据区分配，但保存的都是二级指针）。如果文件足够大，可能还会引出三级指针（至于我们这个小系统是否用的着，大家可以估算下）。</p>
<p>但我们统计发现，在大多数文件系统中，小文件占多数。小到什么地步呢？一个数据块就可以存下。</p>
<p><img src="https://s2.loli.net/2024/02/28/l83ZrTzLtAOXcD5.png" alt="filesystem-statistic.png"></p>
<p>因此实践中，我们在 inode 中使用一种<strong>直接指针</strong>和<strong>间接指针</strong>混合的方式进行表示。在我们的文件系统中，就是使用 12 个直接指针和 1 个间接指针。所以只要文件尺寸不超过 12 个数据块，就可以直接用直接指针。只有过大时，才使用间接指针，并且在数据区新分配数据块，来存间接指针。</p>
<p>我们的数据区很小，只有 56 个 block，假设使用 4byte 进行索引。则二级指针最多可支持 (12 + 1024) · 4K ，也就是 4144KB 大小的文件。</p>
<blockquote>
<p>另一种实践中常用的方式是<strong>数据段</strong>（extents）。即将每个<strong>连续数据区</strong>用起始指针和大小来表示，然后将一个文件的所有数据段串起来。但多段数据时，如果想访问最后一个数据段或者随机访问，性能会很差（下一个数据段的指针都保存在上一个数据段中）。为了优化访问速度，常将该数据段的索引链表存在内存中。Windows 的早期文件系统 FAT 就是这么干的。</p>
</blockquote>
<h2 id="目录组织"><a href="#目录组织" class="headerlink" title="目录组织"></a>目录组织</h2><p>在我们的文件系统中，目录组织得很简单——即和文件一样，每个目录也占用一个 inode，但在 inode 指向的数据块不是存文件内容，而是存储该目录中所包含的所有文件和文件夹的信息，通常是用 <code>List&lt;entry name, inode number&gt;</code>  表示。当然要转为实际编码，还要存文件名长度等信息（因为文件名是变长的）。</p>
<p>看一个简单例子，设我们有一个文件夹 dir （inode 编号是 5），里面有三个文件（foor，bar 和 foobar），其对应的 inode 编号分别是 12，13 和 24 。则在该文件夹的数据块中存储的信息如下：</p>
<p><img src="https://s2.loli.net/2024/02/28/MDqE2O5X3FaKwRs.png" alt="filesystem-dir-content.png"></p>
<p>其中 <code>reclen</code> （record length）是文件名所占空间大小，<code>strlen</code> 是实际长度。点和点点是指向本文件夹和上级文件夹的两个指针。记录<code>reclen</code> 看着有点多此一举，但要考虑到文件删除问题（可以用特殊的 inum，比如 0 来标记删除）。如果文件夹下的某个文件或者目录被删除，存储就会出现空洞。<code>reclen</code> 的存在，可以让删除留下的空洞为之后新增的文件复用。</p>
<p>需要说明的是，线性的组织一个目录中的文件是最简单的方式。实践中，还有其他方式。比如说在 XFS 中，如果目录中文件或者子文件夹特别多，会使用 B+ 树进行组织。从而在插入时，可以很快地知道是否有同名文件。</p>
<h2 id="空闲空间管理"><a href="#空闲空间管理" class="headerlink" title="空闲空间管理"></a>空闲空间管理</h2><p>当我们需要新建文件或者目录项时，就需要从文件系统中获取一块可用空间。因此，如何高效的管理空闲空间，是个很重要的问题。我们使用两个 bitmap 进行管理，优点是简单，缺点是每次都得线性的扫描查找所有空闲 bit 位，且只能做到块粒度，块内如果有剩余空间，就管不到了。</p>
<h1 id="读写路径"><a href="#读写路径" class="headerlink" title="读写路径"></a>读写路径</h1><p>有了对磁盘上的数据结构的把握之后，我们再来通过读写流程将不同的数据结构串一下。我们假设文件系统已经被挂载：即<strong>超级块</strong>（superblock）已经在内存中。</p>
<h2 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h2><p>我们的操作很简单，就是打开一个文件（如 <code>/foo/bar</code>），进行读取，然后关闭。简化起见，假设我们文件大小占一个 block，即 4k。</p>
<p>当发起一个系统调用 <code>open(&quot;/foo/bar&quot;, O RDONLY)</code>时，文件系统需要首先找到文件 bar 对应的 inode，以获取其元信息和数据位置信息。但现在我们只有文件路径，那怎么办呢？</p>
<p>答曰：<strong>从根目录往下遍历</strong>。根目录的 inode 编号，我们要么保存在超级块中，要么就写死（比如 2，大部分 Unix 文件系统都是从 2 开始的）。也即，必须能事先知道（well known）。</p>
<p>于是文件系统将该根目录的 inode 从硬盘调入内存，进而再通过 inode 中的指针找到其指向数据块，进而从其包含所有子目录和文件夹中找到 <code>foo</code> 文件夹和其对应 inode。递归的重复上述过程，open 系统调用的最后一步是将 bar 的 inode 载入内存，进行权限检查（比对进程用户权限和 inode 访问权限控制），分配<strong>文件描述符</strong>放到进程打开文件表中，并将其返回给用户。</p>
<p>一旦文件被打开后，就可以继而发起 <code>read()</code> 的系统调用 ，真正的去读取数据。读取时，首先会根据文件的 inode 信息，找到第一个 block（除非读前实现用 <code>lseek()</code> 修改过偏移量），然后读取。同时，可能会更改 inode 的一些元信息，比如说访问时间。继而，更新进程中该文件描述符的偏移量，继续往下读，直到某个时刻，调用 <code>close()</code> 关闭该文件描述符。</p>
<p>进程关闭文件时，所需工作要少得多，只需要释放文件描述符即可，并不会有真正的磁盘 IO。</p>
<p>最后，我们再捋一下这个读文件过程。从根目录的 inode 编号开始，我们交替的读取 inode 和相应数据块，直到最终找到待查找文件。然后要进行数据读取，还要更新其 inode 的访问时间等元信息，进行写回。下表简单地总结了下这个过程，可以看出，读取路径全程不会涉及分配结构—— data bitmap 和 inode bitmap。</p>
<p><img src="https://s2.loli.net/2024/02/28/7wE8cDb4BUkPYOX.png" alt="filesystem-read-timeline.png"></p>
<p>从<strong>深度上</strong>来说，如果我们的待查找路径层级非常多，这个过程会线性增长；从<strong>广度上</strong>来说，如果中间查找时涉及到的文件夹，其包含的目录子项特别多，即文件树“很宽”，则每次在目录中进行查找时，可能需要读取不止一个数据块。</p>
<h2 id="写入硬盘"><a href="#写入硬盘" class="headerlink" title="写入硬盘"></a>写入硬盘</h2><p>写文件和读取文件的流程很类似，也是打开文件（从根目录一路找到对应文件）；然后开始写入，最后关闭。但与读取文件不同的是，写入需要分配新的数据块，这就需要涉及我们之前的 bitmap 了，通常来说，一次写入至少需要五次 IO：</p>
<ol>
<li>读取 data bitmap（以找到空闲块，并在内存中标记使用）</li>
<li>写回 data bitmap（以对其他进程可见）</li>
<li>读取 inode（增加新的数据位置指针）</li>
<li>写回 inode</li>
<li>在找到的空闲块中写入数据</li>
</ol>
<p>这还只是对已经存在的文件进行写入。如果是尚未存在的文件进行创建并写入，那流程还要更为复杂：还要创建 inode，这就会引入一系列新的 IO：</p>
<ol>
<li>一次对 inode bitmap 的读取（找到空闲 inode）</li>
<li>一次对 inode bitmap 的写回（标记某个 inode 被占用）</li>
<li>一次对 inode 本身的写入（初始化）</li>
<li>一次对父文件夹所对应目录子项数据块的读写（增加新建的文件和 inode 对）</li>
<li>一次对父文件夹 inode 的读写（更新修改日期）</li>
</ol>
<p>如果父文件夹的数据块不够用，还得需要新分配空间，就又得读 data bitmap，和 data block。下图是创建 <code>/foo/bar</code> 文件的时间线上涉及到的 IO：</p>
<p><img src="https://s2.loli.net/2024/02/28/1lmRPWpMtF8qaeC.png" alt="filesystem-write-timeline.png"></p>
<h2 id="缓存和缓冲"><a href="#缓存和缓冲" class="headerlink" title="缓存和缓冲"></a>缓存和缓冲</h2><p>从上面对读写流程的分析可以看出，即便如此简单的读写操作，都会涉及大量 IO，这在实践中是不可接受的。为了解决这个问题，大部分工业上的文件系统，会充分利用内存，将重要的（也就是频繁访问的）数据块缓存（cache）在内存中；与此同时，为了避免频繁刷盘，会将修改先应用到内存缓冲区（buffer）里，然后积攒后一块落盘。</p>
<p>早期的文件系统引入了<strong>固定尺寸缓存</strong>（fixed-size cache），如果满了，会利用 LRU 等替换算法进行页面淘汰。其缺点在于当缓存不满的时候浪费空间，满了又可能频繁换页。我们称这种风格为<strong>静态分区</strong>（static partitioning）。大部分现代文件系统，都是用<strong>动态分区</strong>（dynamic partitioning）技术。比如，将虚拟内存页和文件系统页放到一个池子中，称为<strong>统一页面缓存</strong>（unified page cache），从而上两者分配和更加弹性。上了缓存之后，对于同一个目录中多个文件的读取，后面的读取就可以省下很多 IO。</p>
<p>写流程由于前半程根据路径查找数据块时牵扯到读，所以也会从缓存中受益。但对于写的部分，我们可以通过缓冲区（writing buffering），来延迟刷盘。延迟刷盘有很多好处，比如说可以多次修改 bitmap 可能只需要刷一次；积攒一批更改，可以提高 IO 带宽利用率；如果文件先增后删，可能就直接省了刷盘。</p>
<p>但这些性能的提升是有代价的——意外宕机可能会造成数据丢失。所以，虽然现代文件系统大部分开启了读写缓冲，但也通过 direct I&#x2F;O 的方式，来允许用户绕过缓存，直接写磁盘。对丢失数据很敏感的应用，可以利用其对应的系统调用 <code>fsync()</code> 来即时刷盘。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>至此，我们完成了一个至简的文件系统的实现。其“麻雀虽小，五脏俱全”，我们从中可以看出文件系统设计一些基本的理念：</p>
<ol>
<li>使用 inode 存储文件粒度的元信息；使用数据块存真正的文件数据</li>
<li>目录是一种特殊的文件，只不过存的不是文件内容，而是文件夹子目录项</li>
<li>除了 inode 和数据块外，还需要一些其他的数据结构，比如 bitmap 来追踪空闲块</li>
</ol>
<p>从这个基本的文件系统出发，我们其实可以看到特别多的可以取舍和优化的点，如果感兴趣，大家可以在本文基础上，去看看一些工业上的文件系统的设计。</p>
]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>文件系统</tag>
        <tag>文件</tag>
      </tags>
  </entry>
  <entry>
    <title>关于如何在晴天卖出 250 把雨伞这件事</title>
    <url>/2024/04/08/paywall-one-year/</url>
    <content><![CDATA[<p>说的就是我的大规模数据系统专栏《系统日知录》—— 有人问，在读了你的专栏文章后，可能很久之后<del>才可能会用到</del>都不会用到，那为啥要买呢？何况，雨伞在雨天可是刚需，这专栏在面试的时候可不是。所以这实在不是一门好“生意”——<strong>受众狭窄、场景低频</strong>，两者乘数，便是我这惨淡销量了。</p>
<p>这也是为什么成功的专栏动辄上万次购买，而我只卖了个二百五，也敢把经历拿出来说一说了。万一你有类似的危险想法，也可以参考一二。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/04/08/paywall-one-year">https://www.qtmuniao.com/2024/04/08/paywall-one-year</a> 转载请注明出处</em></p>
<p><img src="https://s2.loli.net/2024/04/08/rt3ngjZfsohwUW9.png" alt="IMG_8300.PNG"></p>
<h2 id="为什么这件事难？"><a href="#为什么这件事难？" class="headerlink" title="为什么这件事难？"></a>为什么这件事难？</h2><p>这既有外在的条件，也有内在的因素。</p>
<p>从客观条件来说，技术专栏受众群太小了。想卖给最崇尚开源、最喜欢分享、最有学习动手能力的一群人“二手的知识”？痴人说梦。何况，相比付费专栏（或者 news letter），大家更喜欢一个全须全尾的课程。</p>
<p>从主观因素来说，这个专栏内容太散了。我内心自然是振振有词：泛数据系统，或者说大规模数据系统，本来就是包罗万千；前期散一点是为了试探用户的反馈来找方向，云云。所以那你有反馈吗？有吗？只能说聊胜于无，并不能形成<strong>统计价值</strong>，自然也就不能指导输出方向。不聚焦，就没法解决痛点。半边遮阳、半边防水、还有卡哇伊的伞坠，你说，这把伞谁会买？</p>
<h2 id="那是怎么卖了二百五？"><a href="#那是怎么卖了二百五？" class="headerlink" title="那是怎么卖了二百五？"></a>那是怎么卖了二百五？</h2><p>卖的最多的渠道，竟然是发推。某天我发现，把写的文章提要下发个推，竟然在转化之余还能涨粉。总体来说，推上用户付费意愿还是比较强。当然，推特账号能度过最初的冷启动阶段达到 1k 关注（这在自媒体圈实在算不上什么成绩），离不开朋友的热心转发。相形之下，知乎上的 12k 粉丝，基本上就没有多少转化。说到知乎，感觉它的类似推文的短消息板块——“想法”，就没做起来，不知道是因为长文起家基因不合的拧巴，还是觉得不是亲生的不给流量。</p>
<p>说到流量，知乎起家靠的是关注人的瀑布流，起来后却果断用算法劫持搞推荐。平台为了赚钱我也理解，可你倒是赚点钱呀，我买的那点股票还在手里<strong>砸着呢</strong>！说起来，我最开始写文章时，也从知乎上挣得了不少正反馈。当时在知乎写文章这件事是有确定性的——只要你用心写，平台就会给你用心推，大家就会给你用心赞。但现在确定性没有了，流量随机、用户佛系。而且知乎这算法的“调性”也相当难猜——或者说没人花心思去猜——毕竟是最难商业化的平台，没有之一。而其内容把控的初心也早已不再，可谓进退失据。所以我在知乎的输出也越来越少了，说到知乎就容易怒其不争，扯远了。</p>
<p>转化第二多的渠道，是朋友圈。这大部分要归功于做 DDIA 的分享（这真是一本好书，从好几种意义上来说都是）。很多同学通过分享加到我的微信，我每次在专栏写完文章后都会发到朋友圈遛一遛，经年累月，可能大家感念我对 DDIA 的分享，也让我也慢慢化缘来一些订阅。还是忍不住感叹，DDIA 是本好书，<strong>虽短于细节、但胜在框架</strong>，勾连印证、汪洋恣肆，再次推荐给所有想建立数据系统的知识体系的人。当然，配合我的 “<strong>DDIA 逐章精读</strong>”（去谷歌搜该关键词第一条就是）食用，风味更加。</p>
<p>剩下的一些零散的渠道，包括公众号、b站、知乎、小红书、v2ex ，就是三三两两，不成规模了。</p>
<p>说完渠道，再聊聊一些其他的增长策略。一个是在平台推出打折券后，在特定的时间点发一些打折券，这时一些平时关注，但没有下手的同学就会产生不少转化。另一个是将专栏从订阅制改成买断制，这样就会降低一些同学的心里购买门槛。另外，在选题上偶尔也能发现一些点——比如大家对面试比较感兴趣，那就多写一些。</p>
<p>点点滴滴，一年时间，汇总成了这将近二百五十个种子用户。</p>
<h2 id="为什么会有这个专栏？"><a href="#为什么会有这个专栏？" class="headerlink" title="为什么会有这个专栏？"></a>为什么会有这个专栏？</h2><p>说了半天，回顾下初心——当初为什么会开这个专栏。去年年初偶然一个契机，了解到“小报童”这个平台，又了解到其提倡的 news letter 文化，当时感觉它这配色好赞（但是代码格式好丑呀！而且当初还是我给平台反馈后才加上的，也侧面反映了当时程序员用这个平台的好少），用文字可以赚一些钱好酷。</p>
<p>就跟消息队列一样，通过这么一个专栏，可以解耦生产者（我）和消费者（读者）—— 我只顾创作，就可以不用担心读者。。。么？怎么可能——你得自己推广！因为平台设计是去中心化的，它甚至没有一个官方的专栏的 hub 页（但确实有第三方做这个事情）。但这种克制的调性，确实也有一种森系美。</p>
<p>于是，就慢慢的将创作重心从知乎转到小报童。那写什么呢？自然是费曼学习法——学什么写什么了。就跟 build in public 的实践一样，这本质上是 learning in public —— 吗？付费的专栏好像是 private，虽然我偶尔会随缘把一些文章分享到各个公共平台。</p>
<p>有这么个小皮鞭抽着，我这一年多（翻了下 2023 年 2 月末发了第一篇文章）竟然也写满了 100 篇文章。掐指一算，竟然周更近乎二（篇）？确实超乎想象，我这样懒散之人竟然有这等“自律”？所以呀，知道脸皮薄的人怎么坚持做一件事了吗？卖空气，啊不对，卖承诺呀。收了费，你就会被推着走。虽然，在由订阅制变成买断制之后，我也就心安理得、长出一口气地不承诺周更了。毕竟我已经试出了我的能力边界，而周更两篇显然在这个边界之外。</p>
<h1 id="将来怎么搞？"><a href="#将来怎么搞？" class="headerlink" title="将来怎么搞？"></a>将来怎么搞？</h1><p>经过这一年不着调的探索，之后应该——还是不会收敛。毕竟人生的意思就在于寻找增量嘛，怎么能收敛到一个区间内呢。接下来由于工作和兴趣的原因，可能会多写一些 AI System 相关的东西。但老的板块：存储和数据库应该也不会落下；此外，面试专题——毕竟流量密码——也会常更。至于其他还有写什么，就看读者大大们的“反馈”了。</p>
<p>奥，对了，基础知识应该也会发力一些。因为我发现前几天想了一个 slogan —— <strong>技术不止 CRUD，开发需要底层逻辑</strong>，效果还不错。经过工作多年的磨砺，很多大学时觉得庞杂的概念，现在也慢慢体会出其和谐与简洁。所以也会结合这些年的工作体悟，返璞归真，再去重塑下大学时基础知识体系，为想摆脱“工作良久，却感觉一直原地踏步”的焦虑的同学，提供一些弹药和食粮。</p>
<p>絮叨良久，十米大刀压不住了，也是时图穷匕见——100 篇啦，要涨价啦，各位大爷，走过路过莫要错过，求个订阅吧。正好现在“可刀”——关注我的公众号：木鸟杂记，回复“优惠券”，获得八折订阅链接，数量有限，说没就没。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>付费专栏</tag>
      </tags>
  </entry>
  <entry>
    <title>Infra 面试之数据结构五：顺序组装</title>
    <url>/2024/05/05/infra-interview-tcp/</url>
    <content><![CDATA[<p>这是我在很早之前遇到的一个题，很有意思，所以到现在仍然记得。题意借用了 TCP 的上下文，要求实现 TCP 中一个“顺序组装”的关键逻辑：</p>
<ol>
<li>对于 TCP 层来说，IP 层的 packet 是乱序的收到。</li>
<li>对于应用层来说，TCP 层交付的是顺序的数据。</li>
</ol>
<p>这个题有意思的点在于，借用了 TCP 的上下文之后，就可以先和候选人讨论一些 TCP 的基础知识，然后话锋一转，引出这道题。这样既可以考察一些基础知识，也可以考察工程代码能力。</p>
<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Packet</span> &#123;</span><br><span class="line">    <span class="type">size_t</span> offset;</span><br><span class="line">    <span class="type">size_t</span> length;</span><br><span class="line">    <span class="type">uint8_t</span> *data;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现一个“顺序交付”语义</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TCP</span> &#123;</span><br><span class="line">  <span class="comment">// 应用层调用：按顺序读取不超过 count 的字节数到 buf 中，并返回实际读到的字节数</span></span><br><span class="line">  <span class="function"><span class="type">size_t</span> <span class="title">read</span><span class="params">(<span class="type">void</span> *buf, <span class="type">size_t</span> count)</span></span>;</span><br><span class="line">  <span class="comment">// TCP 层回调：得到一些随机顺序的 IP 层封包</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">receive</span><span class="params">(Packet* p)</span></span>;</span><br><span class="line">  <span class="comment">// TCP 层回调：数据发完，连接关闭</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">finish</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/05/05/infra-interview-tcp">https://www.qtmuniao.com/2024/05/05/infra-interview-tcp</a> 转载请注明出处</em></p>
<h1 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h1><p>由于多少和“实际”有些关联，所以本题目中有相当多的可以讨论的点，反过来说，如果你不进行合适的建模和简化，实现起来复杂度会非常高——四十五分钟是写不完的。</p>
<p>对于 Packet 结构体：</p>
<ol>
<li>offset 是否会有交叠？（只要发送数据足够多，耗尽 size_t 的范围就有可能发生）</li>
<li>length 的长度是固定的还是变长的？</li>
</ol>
<p>对于 read 调用：</p>
<ol>
<li><code>TCP:read()</code> 是否阻塞？如果是阻塞的，是否要阻塞到凑齐要求大小（count）的数据才能返回，还是只要有一部分数据就立即返回？</li>
<li>如果<code>TCP::finish()</code> 后，<code>TCP:read()</code> 的返回值是什么？</li>
</ol>
<p>对于内存问题：</p>
<ol>
<li><code>TCP::read</code>  中给应用层中 buf 填充数据时，是否要进行拷贝？</li>
<li><code>TCP::receive</code> 中 <code>Packet::data</code> 的内存是否要在 TCP 类中释放？</li>
</ol>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>这本质上是一个生产者消费者问题。我们需要维护一个线程安全的有序数据结构，生产者（<code>TCP::receive</code>）往里面放数据，消费者（<code>TCP::read</code>）从里面取数据。要求是：乱序放、顺序取、可切分。</p>
<p>为了简化实现，可以和面试官做如下设定。</p>
<p>对于 Packet 结构体：</p>
<ol>
<li>offset 没有交叠</li>
<li>length 变长</li>
</ol>
<p>对于 read 是否阻塞问题，可以设定：</p>
<ol>
<li>read 函数是阻塞的</li>
<li>read 只要收到一部分数据，即使没达到 count，也可以立即返回</li>
</ol>
<p>对于内存问题，可以设定：</p>
<ol>
<li>TCP 类不负责收到的数据的生命周期，但要求调用者保证 TCP 整个生命周期中 packet 中的数据都是有效（不能被释放）的。</li>
<li>给应用层的数据会拷贝到用户提供的 buf 中。</li>
</ol>
<p>以下是代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Packet</span>&#123;</span><br><span class="line">    <span class="built_in">Packet</span>(<span class="type">size_t</span> off, <span class="type">size_t</span> len, <span class="type">uint8_t</span> *data):</span><br><span class="line">        <span class="built_in">offset</span>(off), <span class="built_in">length</span>(len), <span class="built_in">data</span>(data) &#123;&#125;</span><br><span class="line">    <span class="type">size_t</span> offset;</span><br><span class="line">    <span class="type">size_t</span> length;</span><br><span class="line">    <span class="type">uint8_t</span> *data;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TCP</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">TCP</span>() &#123;</span><br><span class="line">        nextOffset_ = <span class="number">0</span>;</span><br><span class="line">        finished_ = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">read</span><span class="params">(<span class="type">void</span> *buf, <span class="type">size_t</span> count)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mu_)</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">size_t</span> leftBytes = count;</span><br><span class="line">        <span class="keyword">while</span> (leftBytes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!packets_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                <span class="type">size_t</span> offset = packets_.<span class="built_in">begin</span>()-&gt;first;</span><br><span class="line">                <span class="keyword">auto</span>* p = packets_.<span class="built_in">begin</span>()-&gt;second;</span><br><span class="line">                <span class="keyword">if</span> (offset == nextOffset_) &#123;</span><br><span class="line">                    <span class="comment">// fetch the packet</span></span><br><span class="line">                    packets_.<span class="built_in">erase</span>(offset);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// copy to the user buf</span></span><br><span class="line">                    <span class="type">size_t</span> len = std::<span class="built_in">min</span>(p-&gt;length, leftBytes);</span><br><span class="line">                    std::<span class="built_in">memcpy</span>(buf, p-&gt;data, len);</span><br><span class="line">                    leftBytes -= len;</span><br><span class="line">                    nextOffset_ += len;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// put back the left data</span></span><br><span class="line">                    p-&gt;length -= len;</span><br><span class="line">                    <span class="keyword">if</span> (p-&gt;length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        p-&gt;data += len;</span><br><span class="line">                        p-&gt;offset += len;</span><br><span class="line">                        packets_[p-&gt;offset] = p;</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> count-leftBytes;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (finished_) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            cv_.<span class="built_in">wait</span>(lock);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// finished</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">receive</span><span class="params">(Packet* p)</span> </span>&#123;</span><br><span class="line">        <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mu_)</span></span>;</span><br><span class="line">        packets_[p-&gt;offset] = p;</span><br><span class="line">        cv_.<span class="built_in">notify_one</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">finish</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mu_)</span></span>;</span><br><span class="line">        finished_ = <span class="literal">true</span>;</span><br><span class="line">        cv_.<span class="built_in">notify_one</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::mutex mu_;</span><br><span class="line">    std::condition_variable cv_;</span><br><span class="line">    <span class="type">size_t</span> nextOffset_;</span><br><span class="line">    <span class="type">bool</span> finished_;</span><br><span class="line">    std::map&lt;<span class="type">uint64_t</span>, Packet*&gt; packets_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>核心实现点包括：</p>
<ol>
<li>使用 <code>std::map</code> 组织所有 IP 层封包</li>
<li>使用 <code>nextOffset_</code> 来记录需要交付给应用层下一个偏移量</li>
<li>如果包被切分了，剩余的包记得放回去</li>
</ol>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>本题目的测试也有些意思：</p>
<ol>
<li>如何模拟乱序</li>
<li>如何控制所有 IP 封包中的 data 生命周期</li>
<li>如何对应用层收到的数据进行校验</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">TCP tcp;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">producer</span><span class="params">(<span class="type">uint8_t</span>* data)</span> </span>&#123;</span><br><span class="line">    std::random_device rd;</span><br><span class="line">    <span class="function">std::mt19937 <span class="title">gen</span><span class="params">(rd())</span></span>;</span><br><span class="line">    std::uniform_int_distribution&lt;&gt; <span class="built_in">dis</span>(<span class="number">50</span>, <span class="number">99</span>);</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;construct data...&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="function">std::vector&lt;Packet*&gt; <span class="title">packets</span><span class="params">(<span class="number">100</span>)</span></span>;</span><br><span class="line">    <span class="type">size_t</span> offset = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">        <span class="type">size_t</span> randLen = <span class="built_in">dis</span>(gen);</span><br><span class="line">        packets[i] = <span class="keyword">new</span> <span class="built_in">Packet</span>(offset, randLen, data);</span><br><span class="line">        data += randLen;</span><br><span class="line">        offset += randLen;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;total &quot;</span> &lt;&lt; offset &lt;&lt; <span class="string">&quot; bytes&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;make the data unordered...&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    std::<span class="built_in">shuffle</span>(packets.<span class="built_in">begin</span>(), packets.<span class="built_in">end</span>(), gen);</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;give it to tcp...&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">        tcp.<span class="built_in">receive</span>(packets[i]);</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;receive data [&quot;</span> &lt;&lt; packets[i]-&gt;offset &lt;&lt; <span class="string">&quot; ,&quot;</span></span><br><span class="line">            &lt;&lt; packets[i]-&gt;offset+packets[i]-&gt;length&lt;&lt; <span class="string">&quot;): &quot;</span></span><br><span class="line">            &lt;&lt; packets[i]-&gt;length &lt;&lt; <span class="string">&quot; bytes&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        std::this_thread::<span class="built_in">sleep_for</span>(std::chrono::<span class="built_in">milliseconds</span>(<span class="number">100</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    tcp.<span class="built_in">finish</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">consumer</span><span class="params">(<span class="type">uint8_t</span>* data)</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> nBytes = <span class="number">0</span>;</span><br><span class="line">    <span class="type">uint8_t</span> buf[<span class="number">100</span>];</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> offset = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> ((nBytes = tcp.<span class="built_in">read</span>(buf, <span class="number">50</span>)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">auto</span> diff = std::<span class="built_in">memcmp</span>(data+offset, buf, nBytes);</span><br><span class="line">        std::stringstream ss;</span><br><span class="line">        ss &lt;&lt; <span class="string">&quot;read data [&quot;</span> &lt;&lt; offset &lt;&lt; <span class="string">&quot; ,&quot;</span> &lt;&lt; offset+nBytes &lt;&lt; <span class="string">&quot;): &quot;</span></span><br><span class="line">            &lt;&lt; nBytes &lt;&lt; <span class="string">&quot; bytes&quot;</span>;</span><br><span class="line">        <span class="keyword">if</span> (!diff) &#123;</span><br><span class="line">            ss &lt;&lt; <span class="string">&quot;; verify ok&quot;</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ss &lt;&lt; <span class="string">&quot;; verify bad&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        std::cout &lt;&lt; ss.<span class="built_in">str</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">        offset += nBytes;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;read finish&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">uint8_t</span> buffer[<span class="number">10000</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; ++i) &#123;</span><br><span class="line">        buffer[i] = i &amp; <span class="number">0xff</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">std::thread <span class="title">c</span><span class="params">(consumer, buffer)</span></span>;</span><br><span class="line">    <span class="function">std::thread <span class="title">p</span><span class="params">(producer, buffer)</span></span>;</span><br><span class="line"></span><br><span class="line">    p.<span class="built_in">join</span>();</span><br><span class="line">    c.<span class="built_in">join</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果你想自己跑下代码，可以在<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0Rpc3RTeXNDb3JwL2ludGVydmlldy1kYXRhLXN0cnVjdHVyZXMvYmxvYi9tYWluL1BhY2tldHMuY2M=">这里<i class="fa fa-external-link-alt"></i></span>自取。</p>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>如果还有时间，面试官可能会跟你讨论些，如果取消你做的那些假设，需要怎么样实现，不过只要能做过基础版，剩下的就都是加分项了。</p>
<blockquote>
<p>本文出自我的专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0L2RiOTAxNDgwLTBlNTgtNDE5Yi1hZTAxLWY2NDEwZDM4Y2UxZg==">系统日知录<i class="fa fa-external-link-alt"></i></span>》的 infra 程序员面试题系列，本系列集合了我多年来面试和被面试遇到的一些精华题目。当下一共更新了七篇：阻塞队列、无锁队列、事件队列、哈希表、顺序组装、堆、前缀树。如果大家感兴趣，之后还会继续更新。</p>
</blockquote>
<blockquote>
<p>专栏目前有一百多篇文章。如果大家觉得我的文章写的不错，欢迎大家留言、订阅支持我，你们的支持是我持续创作的最大动力。</p>
</blockquote>
]]></content>
      <categories>
        <category>职场</category>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>TCP</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title>有趣的线性代数（一）：矩阵乘法</title>
    <url>/2024/06/29/interesting-linear-algebra-1/</url>
    <content><![CDATA[<blockquote>
<p>由于对各种矩阵运算物理意义的理解总是跟不上，因此尽管多年多次尝试入门机器学习，却总是被拒之门外。偶然间同事推荐了 <span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMTZaNHkxVTdvVQ==">MIT 那门经典的线性代数公开课<i class="fa fa-external-link-alt"></i></span>，听了几节，煞是过瘾，之前紧闭的大门竟有打开一丝的感觉。</p>
</blockquote>
<blockquote>
<p>因此，本系列会在每篇文章分享一些课程中有意思的点。为了避免晦涩，每章会尽可能去上下文、保持简短，请放心食用。也因此，本系列会牺牲一些精确性，且并无体系化，仅仅旨在唤起你一丢丢兴趣。注：例子都由 <span class="exturl" data-url="aHR0cHM6Ly9raW1pLm1vb25zaG90LmNuLw==">KimiChat<i class="fa fa-external-link-alt"></i></span> 生成。</p>
</blockquote>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/06/29/interesting-linear-algebra-1/">https://www.qtmuniao.com/2024/06/29/interesting-linear-algebra-1/</a> 转载请注明出处</em></p>
<h1 id="右乘列向量"><a href="#右乘列向量" class="headerlink" title="右乘列向量"></a>右乘列向量</h1><p><img src="https://s2.loli.net/2024/06/29/3VfiNFpBJvujwTY.png" alt="la-Ax-b.png"></p>
<p>对于一个方阵 A 来说，右乘一个列向量 x，可以理解为：<strong>使用 x 中的值作为权重，对 A 中列向量进行线性组合，得到一个新的列向量 b</strong>。</p>
<p>利用该理解对上图拆开一下就是：</p>
<p><img src="https://s2.loli.net/2024/06/29/EnspgASVmhKGWdI.png" alt="la-b-A.png"></p>
<p>注：这其中会要求一些性质，比如 A 是可逆矩阵（invertible matrix），或者是非奇异（non singular matrix），但这些名词我们就不在此深究了，感兴趣的可以去看<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMTZaNHkxVTdvVS8=">视频<i class="fa fa-external-link-alt"></i></span>。</p>
<h1 id="左乘行向量"><a href="#左乘行向量" class="headerlink" title="左乘行向量"></a>左乘行向量</h1><p><img src="https://s2.loli.net/2024/06/29/FeSJoWkqdKE3jp9.png" alt="la-matrix-vector.png"></p>
<p>对于一个方阵 A 来说，左乘一个行向量 x，可以理解为：<strong>使用 x 中的值作为权重，对 A 中行向量进行线性组合，得到一个新的行向量 b</strong>。</p>
<p>拆解下过程，就是：</p>
<p><img src="https://s2.loli.net/2024/06/29/2YXwILy89n4BORo.png" alt="la-b-linear.png"></p>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><p>有了上述直觉，我们就可以扩展一下，拆解矩阵乘法了。</p>
<p>比如利用右乘行向量拆解。</p>
<p><code>A * X = B</code></p>
<p>可以拆解为：</p>
<p><img src="https://s2.loli.net/2024/06/29/YlrKaLfZzkuyBxo.png" alt="la-B-as-A.png"></p>
<p>即，利用 X 中三列分别对 A 进行线性组合，得到结果 B 中的三列。</p>
<p>同样，也可以利用左乘行向量对上述乘法进行拆解，可以自己试试。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>当然，有时候，这种思想有时候可能会使得简单的运算变复杂。但学多了就会发现，对于线代中同一个公式会有多种“物理理解”，每种理解方法都会有其特定适用场景，多在工具箱里积累一些工具方法，会使得我们对矩阵运算这种高维思维更加得心应手。</p>
]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>线性代数</tag>
        <tag>矩阵乘法</tag>
      </tags>
  </entry>
  <entry>
    <title>人生是旷野 —— 罗素《幸福之路》</title>
    <url>/2024/07/28/listening-conquest-of-happiness/</url>
    <content><![CDATA[<blockquote>
<p>缘于某个播客提了一嘴，便找来书在通勤时听了。这版是傅雷翻在 1939 年译的版本，有一股淡淡的老式白话风。小书不长，几天便听完。我喜欢在走路的时候听东西，所听入耳、所观入眼，哲人的凝言练语、街头的风物百态，总能在心里发生奇妙的化学反应，偶在三伏天都一激灵。</p>
<p>最近心绪颇为起伏，在上下班踱步听这本书时，数次给我宽慰平和，书中指出的快乐和不快乐之因，都命中了我的某些缺点和特点，因此听完觉得还是要写点东西。</p>
</blockquote>
<h1 id="罗素《幸福之路》"><a href="#罗素《幸福之路》" class="headerlink" title="罗素《幸福之路》"></a>罗素《幸福之路》</h1><p>人类从狩猎时代进入农耕时代后，虽获得了生活的相对安稳，却也失掉了向外的探索和冒险。到工业时代，城市化加剧，进一步脱离了自然的“蓝领白领”亦是如此。只有少数的企业家才仍然保持着丛林式的生活方式。</p>
<p>选择安稳意味着有大量的“烦闷”（Boredom）需要排遣。但多数人过度的将注意力集中在自己的身上，比如畏罪狂（纠结于行为不符合少时的成见或社会的规训）、自溺狂（过度期待外界称许的虚荣）、自大狂（过度的权力欲望），则使得这种烦闷愈加在幻想中野蛮式的生长，直至占满人们的内心。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/07/28/listening-conquest-of-happiness/">https://www.qtmuniao.com/2024/07/28/listening-conquest-of-happiness/</a> 转载请注明出处</em></p>
<p>罗素认为不应该向内地过度关注自己，而应该更多的去向外培养各种志趣、兴致，放下自己的各种刻板印象（ ego） 去体味生活，去发现自然和科学的美妙，以期达到某种多姿、真诚、自然的生活。罗素自己作为获得了诺贝尔文学奖的哲学家和数学家，持此种理念，倒也算知行合一。</p>
<p>从投资的角度来看人生，也不应该把我们所有的“资金”（时间）投入到单一的品类上，而应去尽量多样化所持的观点和爱好。否则一旦旧有信念坍塌，新的信念无从生发，便容易被彻底打倒，陷于一蹶不振。因此，我们最好能拥有一项和工作完全不相干的志趣，来对冲人生的无常。因之我们确切知道，虽然人类大势总是有迹可循，但具体到个体人生，总是被无常的偶然填满——这也许就是“波粒二象性”规律在社会领域的投射吧。</p>
<p>于我自己而言，不自觉关注在各种“体系”中的位置和评价总给我带来诸多烦恼和内耗。我们在定义一个概念时，总有两种选择——从内在性质推演、从外界观察逼近。而过度关注外界，就会让我们人生定义倒向后者——你只是你周围社会关系“围出”的一个洋葱，层层剥开后，内里什么都没有。</p>
<p>持这种心境让我很难自然、真诚地对待自己，也很难沉浸地去做事，总会分出一缕甚至大部心神来想：旁人怎么看我这个做法？溺于此，也就很难真正的去探寻自己的兴致所在。这固然有农耕社会遗留的“君君臣臣父父子子”的血液规训因素，但更多的还是自己的天性以及后天各种偶然的契机所强化的妄念。若想祛除，需得勇敢回溯，层层剥开，重塑自身，这何其难也。</p>
<p>本书给出了另外一条路，转移精力，去找寻对世界的各种兴致。恰好，这倒也契合了我为数不多的优点——尚对世界有各种好奇、尚对美好事物有感知。这个动漫情节为何做此设计、这种小花是什么名字、这种纪念银币有什么故事、西方古典建筑为什么都长这样、此地为何能激发古人登临情志、矩阵运算如何记忆本质是什么，等等。在做这些时，我没在想旁人怎么看我，而只想和朋友分享我的乐趣。此时，我由需要别人能量喂养的人，变成了对外散发能量的人。说起来，这也应与小学时在乡间长大有关，当时野外总对我有各种的吸引力，一有机会便去探索和“演绎”——瞎玩以及在瞎玩的基础上天马行空地瞎想。</p>
<p><strong>人生确是旷野，你远比你想象的自由。</strong></p>
<h1 id="题图故事"><a href="#题图故事" class="headerlink" title="题图故事"></a>题图故事</h1><p><img src="https://s2.loli.net/2024/07/28/mi5PIbxJZK2EySM.jpg" alt="beijing-chaoyang.jpg"><br>盛夏傍晚国贸漫步接头所见</p>
]]></content>
      <categories>
        <category>生活</category>
        <category>读书</category>
      </categories>
      <tags>
        <tag>读书</tag>
        <tag>人生</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 ray.data 进行大规模数据处理（二）：全局视角</title>
    <url>/2024/07/07/ray-data-2/</url>
    <content><![CDATA[<blockquote>
<p><span class="exturl" data-url="aHR0cDovL3JheS5kYXRhLw==">ray.data<i class="fa fa-external-link-alt"></i></span> 是基于 ray core 的一层封装。依赖 ray.data，用户用简单的代码，就可以实现数据大规模的异构处理（主要指同时使用 CPU 和 GPU）。一句话总结：很简单好用，同时也有很多坑。<br>在 <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzU1YzJkNDU1LTMzMTktNGM3Zi05ZTVlLTRlYjExOGE0ODJkNw==">上一篇<i class="fa fa-external-link-alt"></i></span>中，我们从用户接口出发，浅浅地梳理了一下 <span class="exturl" data-url="aHR0cDovL3JheS5kYXRhLw==">ray.data<i class="fa fa-external-link-alt"></i></span> 的主要接口。本篇，我们从宏观的角度，大概串一下 ray.data 的基本原理。之后，我们再用几篇，结合代码细节和使用经验，探讨下比较重要的几块内容：执行调度、数据格式和避坑指南。<br> 本文来自我的专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">系统日知录<i class="fa fa-external-link-alt"></i></span>》，如果你觉得文章还不错，欢迎订阅支持我。</p>
</blockquote>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>从高层来理解，ray.data 的一次数据处理任务大致可以分成前后相继的三阶段：</p>
<ol>
<li><strong>数据加载</strong>：将数据从系统外部读到 ray 的 Object Store 中 （如 read_parquet）</li>
<li><strong>数据变换</strong>：利用各种算子在 Object Store 中对数据进行变换（如 map&#x2F;filter&#x2F;repartition）</li>
<li><strong>数据写回</strong>：将 Object Store 中的数据写回外部存储（如 write_parquet）</li>
</ol>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/07/07/ray-data-2/">https://www.qtmuniao.com/2024/07/07/ray-data-2/</a> 转载请注明出处</em></p>
<p><img src="https://s2.loli.net/2024/07/07/gN5jaVGmOWTJoKb.webp" alt="ray-object-store.png"></p>
<p>如上图，解释下提到的名词：</p>
<ul>
<li><strong>Object Store</strong> 是由各个节点受控内存组成，用于存储上一个子任务的中间结果，供其他节点上的下一个子任务拉取使用。</li>
<li><strong>Raylet</strong> 是 ray 在集群中各节点的 daemon，负责本节点上各种 ray 任务的调度和执行。</li>
</ul>
<h1 id="数据抽象"><a href="#数据抽象" class="headerlink" title="数据抽象"></a>数据抽象</h1><p>ray.data 对使用三级粒度来组织一个数据集：<strong>数据集（Dataset）、数据块（Block）、数据条目（Row）</strong>。每个数据集在逻辑上是一张二维表，读入系统后，会按行切成多块分散到多个机器的 Object Store 中。</p>
<p>其中，数据块是不可变的（Immutable），是 <span class="exturl" data-url="aHR0cDovL3JheS5kYXRhLw==">ray.data<i class="fa fa-external-link-alt"></i></span> 对数据进行存储和传输的基本单元，也是最基本的并行粒度。数据块在 Object Store 中以 <span class="exturl" data-url="aHR0cHM6Ly9hcnJvdy5hcGFjaGUub3JnLw==">Apache Arrow<i class="fa fa-external-link-alt"></i></span> 的格式进行存储，其特点是按列存储、编程语言无关、支持零拷贝。</p>
<h2 id="batch-非-block"><a href="#batch-非-block" class="headerlink" title="batch 非 block"></a>batch 非 block</h2><p>ray data 中有一个很重要的向量化（batch 是按列组织传给算子的）处理算子 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnJheS5pby9lbi9sYXRlc3QvZGF0YS9hcGkvZG9jL3JheS5kYXRhLkRhdGFzZXQubWFwX2JhdGNoZXMuaHRtbA==">map_batches<i class="fa fa-external-link-alt"></i></span>。可以通过一个例子来大致感受下其使用方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_dog_years</span>(<span class="params">batch: <span class="type">Dict</span>[<span class="built_in">str</span>, np.ndarray]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, np.ndarray]:</span><br><span class="line">    batch[<span class="string">&quot;age_in_dog_years&quot;</span>] = <span class="number">7</span> * batch[<span class="string">&quot;age&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> batch</span><br><span class="line"></span><br><span class="line">ds = (</span><br><span class="line">    ray.data.from_items([</span><br><span class="line">        &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Luna&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">4</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Rory&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">14</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Scout&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">9</span>&#125;,</span><br><span class="line">    ])</span><br><span class="line">    .map_batches(add_dog_years, batch_size=<span class="number">32</span>)</span><br><span class="line">)</span><br><span class="line">ds.show()</span><br></pre></td></tr></table></figure>

<p>该算子涉及到了一个 batch 参数，这个 batch 和 block 是解耦的，其区别和联系是：</p>
<ol>
<li>block 是物理上的静态存储实体；而 batch 是将数据送给算子前动态生成的。</li>
<li>ray.data 会将一个或者多个 block 组合成 <code>batch_size</code> 大小，送给用户算子。</li>
<li>每个 batch 在经过算子处理后，会变成新的 block 写回 Object Store 。</li>
</ol>
<p>注意最后一步，一个 batch 的经过处理后的输出不一定是一个 block，因为 ray data 对 block 的大小有控制：[1M, 128M] （可以通过 <a href="https://docs.ray.io/en/latest/data/api/data_context.html#ray.data.DataContext"><code>DataContext.target_min_block_size</code></a> 和 <a href="https://docs.ray.io/en/latest/data/api/data_context.html#ray.data.DataContext"><code>DataContext.target_max_block_size</code></a> 修改），过大了会切，但过小了好像不会合。</p>
<h2 id="初始-block-数"><a href="#初始-block-数" class="headerlink" title="初始 block 数"></a>初始 block 数</h2><p>说完 block 和 batch 的关系后，我们很容易联想到一个问题：数据集加载到内存后，会分成多少个 block？</p>
<p>首先，我们可以在读取类算子中<strong>显式地</strong>指定其数量：<code>override_num_blocks</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"><span class="comment"># Pretend there are two CPUs.</span></span><br><span class="line">ray.init(num_cpus=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">ds = ray.data.read_csv(<span class="string">&quot;example://iris.csv&quot;</span>, **override_num_blocks**=<span class="number">1</span>).<span class="built_in">map</span>(<span class="keyword">lambda</span> row: row)</span><br><span class="line"><span class="built_in">print</span>(ds.materialize().stats())</span><br></pre></td></tr></table></figure>

<p>其次，如果我们不指定，ray data 就会根据一系列规则进行估算。大致估算步骤是：</p>
<ol>
<li><strong>初始大小</strong>：初始 block 数量为 200</li>
<li><strong>尺寸约束调整</strong>：采样大致估算总大小，以选择合适 block 数量，保证单个 block 大小落在 [1M, 128M]  区间</li>
<li><strong>并行度约束调整</strong>：考虑可用 cpu 数量，使数据加载时尽量充分利用 cpu —— 保证 block 数量至少是 cpu 核数的两倍</li>
</ol>
<p>最后一条涉及一个实现细节：ray.data 会为每一个 block 调度一个 read task，也即我们之前提到的 block 是基本的并行单位。</p>
<h2 id="block-写出文件数"><a href="#block-写出文件数" class="headerlink" title="block 写出文件数"></a>block 写出文件数</h2><p>如果不加任何控制，将数据集落到系统外时，每个 block 会默认写成一个文件。如果想改变文件数量，比如，避免过多小文件，可以使用 Repartition 算子，对 block 数进行改变：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Dataset.repartition(num_blocks: <span class="built_in">int</span>, *, shuffle: <span class="built_in">bool</span> = <span class="literal">False</span>) → Dataset[source]</span><br></pre></td></tr></table></figure>

<h1 id="弱模式"><a href="#弱模式" class="headerlink" title="弱模式"></a>弱模式</h1><p>我们前面提到，在逻辑上可以将数据集（Dataset）理解为一张大的二维表，但和关系型数据库中对每列类型进行强约束不同，ray data 对数据集中的列只进行了弱约束。毕竟，这是 Python 呀…</p>
<p>这个设计确实给了用户很大的灵活性，但也带来了非常多的坑，就跟 Python 这门语言一样——实现的怎么样，全靠用户水平。</p>
<p>但吊诡的是，ray.data 的数据集是有 schema 接口的，只不过是读第一行测算出来的。如下面代码中的年龄列，在同时有字符串类型和整形的情况下，ray.data 并不会报错，且将第一行的数据类型作为了该列的类型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_dog_years</span>(<span class="params">batch: <span class="type">Dict</span>[<span class="built_in">str</span>, np.ndarray]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, np.ndarray]:</span><br><span class="line">    batch[<span class="string">&quot;age_in_dog_years&quot;</span>] = <span class="number">7</span> * batch[<span class="string">&quot;age&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> batch</span><br><span class="line"></span><br><span class="line">ds = (</span><br><span class="line">    ray.data.from_items([</span><br><span class="line">        &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Luna&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="string">&quot;3&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Rory&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">14</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Scout&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">12</span>&#125;,</span><br><span class="line">    ])</span><br><span class="line">    .map_batches(add_dog_years)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ds.schema())</span><br><span class="line"></span><br><span class="line"><span class="comment"># schema 输出：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Column            Type</span></span><br><span class="line"><span class="comment"># ------            ----</span></span><br><span class="line"><span class="comment"># name              string</span></span><br><span class="line"><span class="comment"># age               **string**</span></span><br><span class="line"><span class="comment"># age_in_dog_years  **string**</span></span><br><span class="line"></span><br><span class="line">ds.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果输出：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;&#x27;name&#x27;: &#x27;Luna&#x27;, &#x27;age&#x27;: &#x27;3&#x27;, &#x27;age_in_dog_years&#x27;: &#x27;3333333&#x27;&#125;</span></span><br><span class="line"><span class="comment"># &#123;&#x27;name&#x27;: &#x27;Rory&#x27;, &#x27;age&#x27;: 14, &#x27;age_in_dog_years&#x27;: 98&#125;</span></span><br><span class="line"><span class="comment"># &#123;&#x27;name&#x27;: &#x27;Scout&#x27;, &#x27;age&#x27;: 12, &#x27;age_in_dog_years&#x27;: 84&#125;</span></span><br></pre></td></tr></table></figure>

<p>batch 是按列来组织数据的，即 batch 的类型是 Dict[str, np.ndarray]，每一列是使用 numpy 来组织的。但如果 np.ndarray 中每个值是None、嵌套的、不定长的，ray 也不会做任何检查，只能由用户自己来保证。</p>
<p>这在实践中会有非常多的坑，包括：</p>
<ol>
<li>numpy 是不支持 Python 中 None 类型的，因此如果处理后生成的新数据中混入了 None 后，在转换为 block 存入 object store 前，会先绕个远——先转换成 Pandas，再转换为 arrow 后写入 Object Store。</li>
<li>如果 batch 中一列的输出结果是一个高维的 numpy，那 ray 会将包装成一个自定义的 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JheS1wcm9qZWN0L3JheS9ibG9iL2RmYWIwZjQ4OTUxZGRkNmQ3NWQ2N2RiNjljYTdkOWE3N2RiZWJjZTMvcHl0aG9uL3JheS9haXIvdXRpbC90ZW5zb3JfZXh0ZW5zaW9ucy9hcnJvdy5weSNMMzA5">ArrowTensorArray<i class="fa fa-external-link-alt"></i></span>，假装它是多行的 numpy，但内存还是按高维 numpy 组织的。</li>
</ol>
<p>这里各种隐式的转换会给新用户带来非常多的麻烦。</p>
<p>本质上在于，ray.data 没有做一套自己的类型系统，而是利用 numpy、pandas、pyarrow 来构造了一套类型系统及其序列化和反序列化方法，但是配合使用时又有诸多龃龉，从而引出很多非预期行为的 bug ，为此，ray.data 在不断迭代和疯狂 patch，经常几周就更新一个小版本。</p>
<h1 id="任务执行"><a href="#任务执行" class="headerlink" title="任务执行"></a>任务执行</h1><p>那么 ray.data 是如何对 pipeline 进行大规模的并行执行的呢？可以用两个词来简要概括：</p>
<ol>
<li>微批模式（micro-batch）</li>
<li>算子并行（operator-pool）</li>
</ol>
<h2 id="任务类型"><a href="#任务类型" class="headerlink" title="任务类型"></a>任务类型</h2><p>展开来说，ray.data 根据用户的定义，构建出一个由算子组成的 pipeline。对于 pipeline 中的每个算子，会根据用户配置的并行度，启动相应数量的 Task 或者 Actor：</p>
<ol>
<li><strong>Task</strong>：针对用户传入的无状态函数，调用完即销毁。比如非常简单的增加计数的 map </li>
<li><strong>Actor</strong>：针对用户传入的有状态类，是常驻的。比如 map 中要进行推理，需要预先加载模型。使用 Actor 模式，就可以只在构造函数中加载一次，之后便可以进行多个 batch 的推理，直到整个任务结束。</li>
</ol>
<h2 id="调度逻辑"><a href="#调度逻辑" class="headerlink" title="调度逻辑"></a>调度逻辑</h2><p>将所有算子的执行单元（Task 或者 Actor ）启动起来之后，ray.data 的基本调度逻辑是：</p>
<ol>
<li>为每个算子维护一个 input buffer 和一个 output buffer，存放 block 的引用（block 本尊在 object store 中）</li>
<li>对于所有算子，当其 input buffer 中有数据时，会调度一个任务（task 或者 actor）对其进行消费后放到 output buffer 中</li>
<li>下游算子的 input offer 就是上游的 output buffer</li>
</ol>
<p>即通过阻塞队列（input&#x2F;output buffer）将所有算子逻辑上桥接起来，根据用户给算子指定的并行粒度，调度任务驱动数据整体往前流动。</p>
<p>并且在数据快处理完时，会将 pipeline 中前面那些算子用不到的 Actor 释放掉（Task 是无状态的，调用完即释放，而 Actor 是常驻的）。</p>
<p>在新的版本中，Task 和 Actor 还支持配置动态的并行度区间，ray data 可以根据资源和需求进行伸缩式的调度，但是实现的还非常粗糙，实际体验并不理想。</p>
<p>此外，ray.data 还会根据下游 Object Store 的内存使用，对上游算子的执行做一定的背压。但如果你的下游算子使用的内存没落在 Object Store 中，而在进程的堆内，那 ray 就无能为力了。</p>
<h1 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h1><p>ray.data 不适合做大规模的 shuffle。这里说一个 shuffle 的粗略定义：<strong>需要在多个节点间进行多对多的数据交换</strong>。比如 sort、rand_shuffle 等算子。</p>
<p>和 Spark 不同，<span class="exturl" data-url="aHR0cDovL3JheS5kYXRhLw==">ray.data<i class="fa fa-external-link-alt"></i></span> 需要把所有的数据加载到内存中才能进行 shuffle，因此如果数据量比较大，在内存中装不下时，就会发生大量的 spill。但 ray.data 对于 spill 到外存的数据管理的很不好，shuffle 中各种优化（比如预排序、小文件合并）也做的非常不好。因此，大部分的 shuffle 场景，Ray 都不如 Spark 快。</p>
<p>更不用说，Ray 在接口层面就不支持 Join 算子（也是一种非常常见的 shuffle 算子）。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>本文从宏观上描述了下 ray.data 对于 block 的组织和变换、对于数据模式的处理以及基本的执行调度逻辑。之后，我们将深入代码细节，讲一下 ray.data 的执行引擎。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Ray</tag>
        <tag>数据处理</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Snowflake：云原生数仓的开创者</title>
    <url>/2024/08/25/snowflake-paper/</url>
    <content><![CDATA[<blockquote>
<p>Snowflake 由甲骨文的两位员工在 2012 年出来创办，一开始就瞄准云原生数仓，因此架构设计（在当时看来）非常“激进”。超前的视野带来超额的回报，Snowflake 在 2020 年正式上市，市值一度高达 700 亿美金，创造了史上规模最大的软件 IPO 记录。</p>
<p>本文我们综合两篇论文：<span class="exturl" data-url="aHR0cHM6Ly9kbC5hY20ub3JnL2RvaS9wZGYvMTAuMTE0NS8yODgyOTAzLjI5MDM3NDE=">The Snowflake Elastic Data Warehouse<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9zeXN0ZW0vZmlsZXMvbnNkaTIwLXBhcGVyLXZ1cHBhbGFwYXRpLnBkZg==">Building An Elastic Query Engine on Disaggregated Storage<i class="fa fa-external-link-alt"></i></span>  来大致聊聊其架构设计。</p>
<p> 本文来自我的专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">系统日知录<i class="fa fa-external-link-alt"></i></span>》，如果你觉得文章还不错，欢迎订阅支持我。</p>
</blockquote>
<p>这篇文章我早就想写了，但上次在看论文时卡住了——论文信息太多，地毯式的阅读，很快就淹没在细节中，当时也只看了三分之二，就搁置了。上周（20240707）在文章 <span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wb3N0LzkzZDNlOWFkLTkwZjItNDdlYy1hOTQyLWZmOTVjMzUxY2JhMQ==">Spark：如何在云上做缩容<i class="fa fa-external-link-alt"></i></span>时提到了存算分离的 snowflake ，有读者要求写下，于是便重新捡起来。</p>
<p>相比上次 push 的方式，本次采用 pull 的方式：即不是被动的读论文，而是先思考，如果让我设计这么一个云原生数仓，我要怎么设计，会有哪些问题等等。带着这些问题，我再去从论文中找答案，发现效率一下高了很多，也便让这篇文章没有再次难产。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/08/25/snowflake-paper/">https://www.qtmuniao.com/2024/08/25/snowflake-paper/</a> 转载请注明出处</em></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Snowflake 主要设计目标如下：</p>
<ol>
<li><strong>存算分离</strong>：因此存储和计算都能做到弹性伸缩，按实际用量计费</li>
<li><strong>多租户</strong>：保证多租户之间的隔离性</li>
<li><strong>高性能</strong>：在1,2 前提下尽可能的提升性能</li>
</ol>
<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>为了实现上述设计目标，让我们首先看看 snowflake 的整体架构：</p>
<p><img src="https://s2.loli.net/2024/08/25/5ejpN3sDxutzdEb.png" alt="snow-architecture.png"></p>
<p>可以看出，snowflake 整体分为三层。除了我们常说的存算两层外，还有一个元信息层。</p>
<blockquote>
<p>这也是分布式数据系统经典的分法，我在<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMXAxNDIxQzdTRg==">这个视频<i class="fa fa-external-link-alt"></i></span>中也按照这种分类方法梳理了分布式系统的一些脉络，感兴趣的同学可以去看看。</p>
</blockquote>
<h2 id="数据库存储层（Database-Storage）"><a href="#数据库存储层（Database-Storage）" class="headerlink" title="数据库存储层（Database Storage）"></a>数据库存储层（Database Storage）</h2><p>这一层是数据的最终持久化层，最开始时（论文发表时）通常存在各个云厂商的对象存储上。后来也开始支持第三方存储，比如 <span class="exturl" data-url="aHR0cHM6Ly9pY2ViZXJnLmFwYWNoZS5vcmcv">Apache Iceberg<i class="fa fa-external-link-alt"></i></span>。</p>
<p>当数据写入 snowflake 后，snowflake 会将数据组织成<strong>微分区（micro partition）</strong>的方式，写入对象存储，具体如何做优化、压缩，如何确定大小、管理元信息，我们稍后会讲。</p>
<h2 id="查询处理层（Query-Processing）"><a href="#查询处理层（Query-Processing）" class="headerlink" title="查询处理层（Query Processing）"></a>查询处理层（Query Processing）</h2><p>也就是计算层。Snowflake 使用 <strong>虚拟数仓（virtual warehouse，VM）</strong>来组织计算单元，每个 VM 包含一组计算节点，可以有不同尺寸。不同 VM 之间是隔离的，不会互相影响。</p>
<p>查询处理层里有一个非常重要的缓存层，该层通常以 VM 为单位，以一致性哈希组织（避免节点增删后的数据 shuffle），来缓存对象存储捞上来的数据和算子运算的中间结果。</p>
<h2 id="云服务（Cloud-Services）"><a href="#云服务（Cloud-Services）" class="headerlink" title="云服务（Cloud Services）"></a>云服务（Cloud Services）</h2><p>该层是整个 Snowflake 集群的“大脑”，由一组运行在云上的计算实例构成。包含以下组件：</p>
<ol>
<li><strong>鉴权认证（authentication）</strong>：多租户</li>
<li><strong>基础设施管理（infra management）</strong>：也就是集群内物理信息管理管理</li>
<li><strong>元信息管理（metadata management）</strong>：主要是数据库、表等 schema 信息的管理</li>
<li><strong>查询解析和优化（query parsing and optimization）</strong>：SQL 解析到执行几个阶段中，除最后执行外都在这里，毕竟这里有全局元信息，便于优化</li>
<li><strong>准入控制（ access control）</strong></li>
</ol>
<p>接下来我们重点说说存储层和计算层。</p>
<h1 id="存储层"><a href="#存储层" class="headerlink" title="存储层"></a>存储层</h1><p>各家云上<strong>最便宜、容错性最好</strong>的，无疑就是对象存储了。云上的系统，如果有大规模的数据存储需求，一般都会用对象存储。对象存储也即 blob 存储（不管你存的是啥，人家都当做一段不理解的二进制块来存储），以桶（bucket，也就是 namespace）、对象（object）两级来进行逻辑组织。每个对象都是 path → object 的 kv 对，是拍平的，<strong>没有</strong>类似文件系统的目录树结构。</p>
<p>对于 Snowflake 的存储系统来说，对象存储需要考虑的特点有：</p>
<ol>
<li><strong>自容错</strong>：因此不用再上层进行 replication</li>
<li><strong>不可变</strong>：因此不能进行原地更新</li>
</ol>
<p>对象存储本身容错，从而使 Snowflake 无需担心可用性问题，也就不用像传统 share-nothing 的 TiDB 架构，得自己在多机搞多副本，然后还要用 raft 来维持一致性。</p>
<h2 id="微分区（micro-partition）"><a href="#微分区（micro-partition）" class="headerlink" title="微分区（micro-partition）"></a>微分区（micro-partition）</h2><p>在表和实际存储中间，数据库通常都会按 block（叫 partition 也行）对数据进行组织，传统的数仓的 block 多为静态的。而 Snowflake 管每块数据叫 micro-partition，其特点是：</p>
<ol>
<li><strong>不太大</strong>：几十兆到几百兆间，便于拆分、合并和迁移，也即<strong>动态</strong>分区。</li>
<li><strong>列存</strong>：每个 micro-partition 包含一些行，但是内部为了压缩和应对数仓场景，是按列存储的。</li>
<li><strong>元信息</strong>：会保存每列 min-max 等元信息，以便进行快速过滤。</li>
</ol>
<p>大致示意图如下，左边是逻辑上的一张表，右边是物理上的数据组织，一张表“横切”为多个 micro-partition，每个  micro-partition 内“纵切”后按列存储。</p>
<p><img src="https://s2.loli.net/2024/08/25/ek9EWqxnJAtD17M.png" alt="snowflake-storage-layout.png"></p>
<p>每个 micro-partition 作为一个 object 存在对象存储中。</p>
<h2 id="DML-操作"><a href="#DML-操作" class="headerlink" title="DML 操作"></a>DML 操作</h2><p>由于每个 micro-partition 是不可变的，那我们往表中插入、更新和删除行数据时该怎么办呢？</p>
<p><strong>插入</strong>：插入最简单，将新插入的数据生成新的  micro-partition  即可。</p>
<p><strong>更新</strong>：首先找到被更新的行对应的 micro-partition ，读到 VM 中，修改，然后整体写回对象存储中。这里为了区分新旧 micro-partition，会给每个 micro-partition 文件关联一个版本号。</p>
<p><strong>删除</strong>：和更新类似，读取→删除→ 写回，此间也要更新版本号。</p>
<p>基于每个文件版本号，Snowflake 可以做 MVCC 的并发控制，进一步提供 SI 级别的隔离性和<strong>时间回溯</strong>（time travel）的功能。</p>
<p>整体来看，就是每次一个写事务，就会将系统的版本号推高，并且圈出一个文件集合，构成当前版本号下的一个 snapshot。基于这些 snapshot，我们可以访问任意时间的快照，即时间回溯。</p>
<h1 id="计算层"><a href="#计算层" class="headerlink" title="计算层"></a>计算层</h1><p>计算层也就是查询执行层（之前的解析、优化都在云服务层完成了），Snowflake 引入了 VM（Virtual Warehouse）的概念。下面我们梳理下几个概念间的关系：</p>
<ol>
<li><strong>用户</strong>：每个用户可以起多个 VM，比如有的 VM 用来做 ETL，有的 VM 用来做查询。</li>
<li><strong>VM</strong>：每个 VM 可以有 XS → XXL 不同的尺寸，表示其包含不同数量、尺寸的计算资源。VM 和 VM 之间是完全隔离的。</li>
<li><strong>节点</strong>：云上的计算节点，会包含一定的内存和外存（HDD 或者 SSD）</li>
</ol>
<p>在设计执行层时，一个很重要的点是，是否支持 MPP ？可以粗略的理解为，一个查询语句是否能在多个节点上进行类似 spark 的分布式执行；还是只能局限在一个节点中进行单机执行。后者实现简单，但是吞吐上不去。而数仓通常是大数据量场景，因此多采用前者，当然实现会更负载，因为会在执行时，会涉及多机的的通信，以进行数据的 shuffle（可以参考 spark 中的 shuffle）。</p>
<p>回到 Snowflake 中，也就是一个查询语句是否可以在 VM 中的多个节点执行，从论文中的蛛丝马迹来看，应该是可以的。</p>
<p>除此之外，Snowflake 的计算引擎主要有以下几个特点：</p>
<ol>
<li><strong>列式（columnar）</strong>：由于数仓场景通常都是“宽表窄查”，因此采用列式执行引擎效率会更高，而且可以充分利用单机缓存和 SIMD 指令加速计算。</li>
<li><strong>向量化执行（Vectorized）</strong>：这里感觉和列式稍微有点混淆，主要是想表达算子间是“流水线”地执行，而非每个算子的输出都物化。</li>
<li><strong>推模型（push-based）</strong>：也即不是用的经典的基于拉的火山模型，将控制和数据解耦，能够充分利用缓存，效率也更高。当然，实现会更复杂一些。</li>
</ol>
<h2 id="伸缩"><a href="#伸缩" class="headerlink" title="伸缩"></a>伸缩</h2><p>每个 VM 的大小可以按用户的需求进行动态的伸缩。比如一个任务比较着急，就可以多加计算节点，用较短时间跑出来。由于 Snowflake 是按照 <code>机器*时间</code> 计费的，因此对于同一个 query 来说：多机器快速跑和少量机器慢慢跑，费用是差不多的，但前者无疑更快，利好用户。</p>
<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>执行引擎用到的数据主要包括两块：</p>
<ol>
<li><strong>输入数据</strong>：即执行计划各个叶子节点需要加载的数据，需要从远端（对象存储）中拉取。</li>
<li><strong>中间数据</strong>：执行计划就是由算子组成的 DAG，每个算子会读入数据，进行“变换”后，产生输出，为下一个算子所用。</li>
</ol>
<p>上述两种数据都有被复用的可能，尤其是输入数据，即某个 table 的微分区被访问后，后续一段时间内很有可能被再次访问（<span class="exturl" data-url="aHR0cHM6Ly9iYWlrZS5iYWlkdS5jb20vaXRlbS8lRTUlQjElODAlRTklODMlQTglRTYlODAlQTclRTUlOEUlOUYlRTclOTAlODYvMzMzNDU1Ng==">局部性原理<i class="fa fa-external-link-alt"></i></span>）。因此，可以将其缓存在 VM 节点中的内存或者外存（HDD，SDD）中。单机容量有限，因此 Snowflake 会将 VM 内所有节点的内外存组成一个缓存池，并以<strong>一致性哈希算法</strong>（可以参考<a href="https://www.qtmuniao.com/2020/06/13/dynamo/">这篇文章</a>）来维护缓存，并且是 lazy 的一致性哈希，可以避免在 VM 中有节点变更时，数据频繁的迁移的。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly9kbC5hY20ub3JnL2RvaS9wZGYvMTAuMTE0NS8yODgyOTAzLjI5MDM3NDE=">The Snowflake Elastic Data Warehouse<i class="fa fa-external-link-alt"></i></span> </li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cudXNlbml4Lm9yZy9zeXN0ZW0vZmlsZXMvbnNkaTIwLXBhcGVyLXZ1cHBhbGFwYXRpLnBkZg==">Building An Elastic Query Engine on Disaggregated Storage<i class="fa fa-external-link-alt"></i></span>  </li>
<li><span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnNub3dmbGFrZS5jb20v">snowflake 官方文档<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cubGlua2VkaW4uY29tL3B1bHNlL2ltcGFjdC1kbWwtb3BlcmF0aW9ucy1taWNyby1wYXJ0aXRpb25zLXNub3dmbGFrZS1taW56aGVuLXlhbmcv">The Impact of DML Operations with micro-partitions in Snowflake<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
        <category>论文解读</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>云原生</tag>
        <tag>snowflake</tag>
      </tags>
  </entry>
  <entry>
    <title>从“丰巢”快递柜看 Jemalloc 的内存管理</title>
    <url>/2024/10/27/jemalloc/</url>
    <content><![CDATA[<h1 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h1><p>在某些工作负载中，随着时间的推移，内存的使用会逐渐增长，直到 OOM。后面发现是内存碎片问题，而将系统默认的内存分配器（<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xhdHRlcmEvZ2xpYmMvYmxvYi9tYXN0ZXIvbWFsbG9jL21hbGxvYy5j">glibc malloc<i class="fa fa-external-link-alt"></i></span>）换成 <span class="exturl" data-url="aHR0cHM6Ly9qZW1hbGxvYy5uZXQv">jemalloc<i class="fa fa-external-link-alt"></i></span> ，能有效控制内存的增长上界。</p>
<p>为了解其背后原理，便找来 jemalloc 最初的论文：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYnNkY2FuLm9yZy8yMDA2L3BhcGVycy9qZW1hbGxvYy5wZGY=">A Scalable Concurrent malloc(3) Implementation for FreeBSD<i class="fa fa-external-link-alt"></i></span> 来一探究竟。当然，相比 2006 年论文发表时，当前的 jemalloc 可能已经发生了很大改变，因此本文只对当时论文内容负责。更多 jemalloc 机制，大家可以去其 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2plbWFsbG9jL2plbWFsbG9j">github 仓库<i class="fa fa-external-link-alt"></i></span>查看文档和源码。</p>
<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在探讨论文的主要思路之前，我们先简单回顾下<strong>内存分配器</strong>（memory allocator）的<em>作用</em>和<em>边界</em>。简言之：</p>
<ol>
<li>对下，向操作系统申请<strong>大块</strong>内存（使用 <code>sbrk</code>、<code>mmap</code> 等系统调用）</li>
<li>对上，处理应用层的各种尺寸的内存申请请求（<code>malloc(size)</code>），并在应用层“表示”不用（<code>free</code>）后进行释放</li>
</ol>
<p>往小了说，分配器的功能非常简单：<strong>分配</strong>和<strong>释放</strong>（malloc 和 free）。想象中，实现也应该很简单，只需利用一个表来记录所有已使用内存和未分配内存（ a bit of bookkeeping），然后：</p>
<ol>
<li>malloc 请求来了，先去空闲表中找，不够的话就问操作系统要</li>
<li>free 请求来了，还回空闲表中，如果空的多了，就还给操作系统</li>
</ol>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2024/10/27/jemalloc/">https://www.qtmuniao.com/2024/10/27/jemalloc/</a> 转载请注明出处</em></p>
<p>但为了实现内存的高效分配和回收、控制内存的利用率，其间的学问就大了去了，CPU 缓存、 RAM 特性和虚拟内存都会对其造成影响。其中最核心的点，就是如何进行内存组织排布，以便在用户<strong>高并发</strong>、<strong>多尺寸</strong>、<strong>不定时</strong>的申请和释放后，仍然能保证<strong>较低的调用延迟</strong>和<strong>较高的使用率</strong>。当然，对于本论文来说，还要加上一条：越多的核数能够支持越高的并发，谓之<strong>可扩展</strong>（scale）。</p>
<p>需要说明的是，不要将本文的内存分配器和各种具有自动 GC 功能的编程语言运行时（比如 Java 的 JVM、Golang 的 Runtime）所混淆。后者是在 malloc&#x2F;free 的基础上，往上继续封装了一层，通过<strong>对象间的引用关系来追踪每个对象的生命周期，以自动地回收空间</strong>。</p>
<p>可以这么理解，C++&#x2F;C 等编程语言要用户自己通过 malloc&#x2F;free 来管理内存；而使用 Java&#x2F;Golang&#x2F;Python，用户无脑新建对象就可以了，什么时候回收是语言“运行时”的工作。而我们本文只讨论前者。</p>
<p>但从另外角度来看，存储引擎中也实现了类似的功能。因为存储引擎本质上也是要面对用户 put&#x2F;delete 的的请求，来进行存储的的分配和释放。只不过这里的存储，就不局限于内存（存储引擎多是 disk-based）。但其主要思想非常相似，比如使用<strong>空闲列表</strong>（free list）对可分配内存进行追踪。</p>
<h1 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h1><p>从论文标题可以看出，jemalloc 在提出时，主要为了解决在多核时代下内存分配器性能随核数而 scale 问题，但其实论文花了相当多的篇幅来阐释如何进行内存排布来解决碎片问题。下面，我们就围绕这两个方向来大致窥探下其原理。</p>
<h2 id="多核并发"><a href="#多核并发" class="headerlink" title="多核并发"></a>多核并发</h2><p>在多核时代进行内存分配时，主要面对的问题有：</p>
<ol>
<li>抢锁竞争</li>
<li>缓存震荡</li>
</ol>
<p>为了保证全局数据结构的一致性的问题，就必须引入某种手段（比如锁）来进行协调。但如果多线程抢锁过于频繁，就会造成严重的性能下降。为了降低对锁的竞争，自然的想法就是，对主要的全局数据结构粒度拆分（比如 Java 的 ConcurrentHashMap 就是将哈希桶分成了多个段进行上锁）。</p>
<p>分配器中最重要的数据结构就是空闲列表，我们可以将空闲列表拆分成多个，每个空闲列表使用单独的锁。这样可以缓解多线程的竞争问题，但却解决不了多核架构的另外一个问题——<strong>缓存震荡</strong>（cache sloshing）。</p>
<p>在多核架构中，如果两个线程没有正确的共享缓存。比如线程 A 和线程 B 共享了一个缓存行（Cache Line），且两线程分别会反复修改缓存行的不同部分。如果 A 和 B 调度到了不同的 CPU 上，就会造成 Cache Line 所有权的反复竞争。</p>
<p><img src="https://s2.loli.net/2024/10/27/ZHUtIgPlTpeqEOm.png" alt="cache-sloshing.png"></p>
<p>为了解决此问题，jemalloc 会将所管理的内存分为几个（通常是 CPU 核数的四倍）区域（ 称为 Arena，“竞技场”）。在不同线程的 client 到来时，会均匀地（round robin）绑定到某个 Arena，之后该 client 所有内存的申请和释放都发生在该 Arena。论文还提及了 <span class="exturl" data-url="aHR0cHM6Ly9kbC5hY20ub3JnL2RvaS9wZGYvMTAuMTE0NS8zMDE1ODkuMjg2ODgw">Larson and Krishnan<i class="fa fa-external-link-alt"></i></span> (1998) 之前使用 hash 的方法进行绑定，但由于哈希过程是<strong>伪随机</strong>的（pseudo-random），因此很难保证线程到 Arena 的均匀。</p>
<p>下面我们来讨论如何在每个 Arena 内排布内存来应对用户对象的申请和释放。</p>
<h2 id="内存排布"><a href="#内存排布" class="headerlink" title="内存排布"></a>内存排布</h2><p>在开始讨论前，我们首先引入一个衡量内存利用率的指标——内存碎片（fragments），分为<strong>内部碎片</strong>和<strong>外部碎片</strong>。为了理解这个概念，我们可以思考下平日中“丰巢寄存柜”的工作原理，借此意象来比对理解分配器如何进行内存排布的。</p>
<p>“丰巢”一般是问物业要一块地方，来建立一个快递柜（对应一个 Arena），就近服务小区居民。对于每个快递柜，会进一步将其划分成一个个格子，但如何划分就是讲究之处。</p>
<p>由于快递通常大小不一，如果将快递柜等分，会有什么问题？</p>
<ol>
<li>对于小快递，每个格子会浪费很多空间（内部碎片）</li>
<li>对于大快递，所有格子都放不下（明明总空间够，但却放不下，此时整个格子就是外部碎片）</li>
</ol>
<p>为了解决这个问题，我们日常中所见的快递柜多会分成大大小小尺寸不等的格子。但仍然可能有快递员，选一个大格子却放一个小快递。对于真实世界来说，这无解，因为所有格子是在快递柜出厂时就分好的，也即“静态分配”的；但在计算机世界，我们对内存的划分都是“逻辑上的”，因此可以做到“动态分配”。</p>
<blockquote>
<p>如果有人往大格子中放了一个小对象，可以将剩下的空间切出来形成一个新格子，给后面的对象用。且，在后面该小对象被取走后，可以将两个格子重新合并成一个大格子，以应对更大的对象。</p>
</blockquote>
<p>这就是“伙伴分配算法”的基本思想，当然，这并非 jemalloc 原创。但 jemalloc 在“二分伙伴算法”基础上，通过统计用户负载，进一步精细化管理内存，从而控制了碎片的无节制增长。</p>
<p>比如 jemalloc 发现，大部分的对象不超过 512 B，因此引入了“量子间距”（quantum-spaced）。对这个尺寸附近及以下的格子并不使用伙伴算法，而是在一个页内进行静态分配，让其全是同样大小的格子——这样有什么好处呢？由于每个格子大小固定，就可以使用 bitmap 来充当空闲列表，从而加快了空闲列表的查找。</p>
<p><img src="https://s2.loli.net/2024/10/27/ZyhwJDaf5rLiPlv.png" alt="memory-layout.png"></p>
<p>这种精细化管理虽然会带来比较多的外部碎片（很多格子用不了），但却能更多地减少内部碎片（大部分格子能用满），得可偿失。</p>
<h1 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h1><p>由于实践中不同应用程序内存负载的千变万化，如何衡量分配器好坏本身就是一个非常复杂的问题。很可能一个分配器设计出来后，在某些用户负载中表现良好、但在另外负载中却表现极差，此时我们很难说其是一个好的分配器。好的分配器应该是<strong>多数方面表现均衡、某些方面表现突出</strong>——因为面对如此复杂的现实世界，不可能所有方面都好，总会有取舍。</p>
<p>因此作者花了很大功夫来设计了一套分配器性能评价工具，来证明 jemalloc 的优势，但这部分就不是本文重点了，感兴趣的同学可以去查论文原文。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>我们首先铺垫了内存分配器的一些背景，说明了分配器是什么（malloc&#x2F;free），不是什么（auto gc），和什么相似（存储引擎 put&#x2F;get）；然后分析了论文中实现 jemalloc 的主要目标——多核扩展；继而讨论了其主要实现思路——为了避免竞争和缓存震荡问题，引入均匀的内存分区；为了减少碎片问题，基于伙伴算法对分区内存精细化管理，并以“丰巢快递柜”比对来帮助理解。</p>
<p>最后提了一嘴如何评估分配器的好坏。需要强调的是，本文旨在帮你建立直觉，有想要展开查证之处，强烈推荐大家去读论文原文。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol>
<li><span class="exturl" data-url="aHR0cHM6Ly93d3cuYnNkY2FuLm9yZy8yMDA2L3BhcGVycy9qZW1hbGxvYy5wZGY=">A Scalable Concurrent malloc(3) Implementation for FreeBSD<i class="fa fa-external-link-alt"></i></span></li>
<li><span class="exturl" data-url="aHR0cHM6Ly9kbC5hY20ub3JnL2RvaS9wZGYvMTAuMTE0NS8zMDE1ODkuMjg2ODgw">Memory Allocation for Long-Running Server Applications<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>jemalloc</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title>数据可视化利器—— Streamlit 的有趣哲学</title>
    <url>/2025/03/18/streamlit/</url>
    <content><![CDATA[<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3N0cmVhbWxpdC9zdHJlYW1saXQ=">streamlit<i class="fa fa-external-link-alt"></i></span> 是一款可以快速进行简单网页开发的 Python 库，其 slogan 是：</p>
<blockquote>
<p><strong>A faster way to build and share data apps</strong></p>
</blockquote>
<p>即“一种快速构建、分享数据应用的方法”。其在机器学习、数据科学，甚至当今大模型领域非常流行。其优点非常突出：</p>
<ol>
<li>使用上述领域开发者最喜欢的语言：Python。不用写前端，pip 安装就能用。</li>
<li>简单几行代码就能快速攒出一个数据可视化、打标等小工具的网页。</li>
<li>还支持丰富的第三方组件扩展，比如社区开发的 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2JvdXppZGFuYXMvc3RyZWFtbGl0LWNvZGUtZWRpdG9y">code_editor<i class="fa fa-external-link-alt"></i></span> 。</li>
</ol>
<p>当然，如果你还想要低延迟、高并发、深度定制等需求，那对不起，这是 streamlit 被 tradeoff 出去的那一部分。但对于面向内部少数人使用的小工具来说，streamlit 简直是利器。可以说这个小生态位被它卡的太好了，所以能在 2022 年以 8 亿美金卖给 Snowflake。</p>
<p>本文我们就一块来看看其基本设计哲学和一些简单实践。</p>
<h1 id="设计哲学"><a href="#设计哲学" class="headerlink" title="设计哲学"></a>设计哲学</h1><p>其基本设计哲学可以概括为：</p>
<ol>
<li>用后端语言写前端</li>
<li>收到新事件会重新构建</li>
<li>支持会话级别的缓存</li>
</ol>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2025/03/18/streamlit/">https://www.qtmuniao.com/2025/03/18/streamlit/</a> 转载请注明出处</em></p>
<p>上面三点是依次递进的设计：由于是用后端语言写前端，因此每次响应用户请求都会全部重新执行一遍代码，当然也就不支持局部刷新；为了避免每次全部执行带来的不必要的数据加载，引入了细粒度（每次用户主动刷新页面会丢失）的缓存，从而达到了类似局部刷新的目标——不需要刷新的部分缓存起来复用就好了。</p>
<p>总结成一句话就是：<strong>顺序执行以保持简洁，按需缓存来提高效率。</strong></p>
<h1 id="看个例子"><a href="#看个例子" class="headerlink" title="看个例子"></a>看个例子</h1><p>我们把功能搞简单一点：用户输入一个 parquet 格式本地路径，我们将其读出展示可视化。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># app.py</span></span><br><span class="line"></span><br><span class="line">import streamlit as st</span><br><span class="line">import pandas as pd</span><br><span class="line">import pyarrow.parquet as pq</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Parquet 文件</span></span><br><span class="line">def load_parquet(file_path):</span><br><span class="line">    <span class="built_in">return</span> pq.read_table(file_path).to_pandas()</span><br><span class="line"></span><br><span class="line">st.title(<span class="string">&quot;学生绩点可视化&quot;</span>)</span><br><span class="line"></span><br><span class="line">file_path = st.text_input(<span class="string">&quot;请输入 Parquet 文件的地址:&quot;</span>, value=<span class="string">&quot;students.parquet&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查文件是否存在</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">    <span class="comment"># 加载数据</span></span><br><span class="line">    data = load_parquet(file_path)</span><br><span class="line">    st.write(<span class="string">&quot;数据预览:&quot;</span>)</span><br><span class="line">    st.dataframe(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可选项1：显示统计信息</span></span><br><span class="line">    <span class="keyword">if</span> st.checkbox(<span class="string">&quot;统计信息&quot;</span>):</span><br><span class="line">        st.write(data.describe())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可选项2：绘制直方图</span></span><br><span class="line">    <span class="keyword">if</span> st.checkbox(<span class="string">&quot;直方图&quot;</span>):</span><br><span class="line">        st.bar_chart(data.set_index(<span class="string">&#x27;姓名&#x27;</span>)[<span class="string">&#x27;绩点&#x27;</span>]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    st.error(<span class="string">&quot;输入的文件路径不存在，请检查后再试。&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>简单构造了包括学生名和绩点两列的数据，存在 parquet 文件中（构造代码会放在附录中）。运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">streamlit run app.py</span><br></pre></td></tr></table></figure>

<p>然后访问 <a href="http://localhost:8501/"><code>http://localhost:8501</code></a> 即可看到页面：</p>
<p><img src="https://s2.loli.net/2025/03/18/HZcuFpMVKLYRNTb.png" alt="streamlit-example.png"></p>
<p>从该例子可以大致看出 streamlit 的语法相当简洁：</p>
<ol>
<li><strong>组件构造</strong>：通过 <code>st.title，st.dataframe，st.checkbox</code> 等接口就可以快速构造很多标准组件，而不用在意其样式。</li>
<li><strong>顺序执行</strong>：和 js 事件驱动不同，streamlit 的代码就是自上而下顺序执行的，非常容易理解和调试。每次重新输入路径、重新点击复选框后整个页面都会重新渲染。</li>
</ol>
<h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>那么问题来了，如果学生表的数据量很大，每次重新输入路径后都会全部重新执行、重新加载，岂不是冗余且很慢？为此，我们可以通过 streamlit 的缓存机制，将<strong>数据</strong>缓存下来。</p>
<p>可以使用  <code>st.session_state</code> 显式的进行缓存：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">st.session_state[file_path] = data</span><br></pre></td></tr></table></figure>

<p>也可以通过在加载数据上的函数增加注解 <code>st.cache_data</code>进行缓存，此时缓存的 key 就是函数的输入参数，本例中也是 <code>file_path</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@st.cache_data</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_parquet</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="keyword">return</span> pq.read_table(file_path).to_pandas()</span><br></pre></td></tr></table></figure>

<p>但其实，在 streamlit 中，我们不仅可以缓存数据，也可以缓存组件（widget）。比如说 <code>st.dataframe</code>，如果我们不想其每次都重新渲染怎么办？给其一个 key！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">st.dataframe(data, key=<span class="string">f&quot;df-<span class="subst">&#123;file_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>这样，只要 key 不变，该 dataframe 就不会重新渲染。</p>
<p>至此，我们大概从感性上明白了 streamlit 的哲学：<strong>通过顺序执行来保持简洁、通过按需缓存来保持效率</strong>。下面用一张图来概括下：</p>
<p><img src="https://s2.loli.net/2025/03/18/3xBRWoC8IZEFdXj.png" alt="streamlit-architecture.png"></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>本文非常浅显的通过一个小例子来分析了下 streamlit 的设计哲学，帮助大家建立一个感性的认识，如果有类似面向团队内部的可 GUI 需求，不妨一试。</p>
<p>但囿于篇幅，并没有剖析其背后是如何实现的，也没有讲更多的进阶使用，如果大家对这些东西感兴趣，欢迎留言告诉我。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>官方文档：<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnN0cmVhbWxpdC5pby9nZXQtc3RhcnRlZC9mdW5kYW1lbnRhbHMvYWR2YW5jZWQtY29uY2VwdHM=">https://docs.streamlit.io/get-started/fundamentals/advanced-concepts<i class="fa fa-external-link-alt"></i></span></p>
<h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p>需要安装的库：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install streamlit pyarrow pandas</span><br></pre></td></tr></table></figure>

<p>构造数据的代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建学生数据</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;姓名&#x27;</span>: [<span class="string">&#x27;Alice&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Charlie&#x27;</span>, <span class="string">&#x27;David&#x27;</span>, <span class="string">&#x27;Eva&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;绩点&#x27;</span>: [3.5, 3.8, 2.9, 3.2, 3.9]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 DataFrame</span></span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入 Parquet 文件</span></span><br><span class="line">df.to_parquet(<span class="string">&#x27;students.parquet&#x27;</span>, index=False)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;学生数据已写入 students.parquet 文件。&quot;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>streamlit</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解大模型 1：Transformer，大模型的基石</title>
    <url>/2025/09/10/llm-1-transformer/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://princeton-cos597r.github.io/"><strong>Princeton COS 597R “Deep Dive into Large Language Models”</strong></a> 是普林斯顿大学的一门研究生课程，系统探讨了大语言模型原理、准备和训练、架构演进及其在多模态、对齐、工具使用等前沿方向中的应用与一些问题。注意，该课程侧重概念的理解上，而非工程的实现上。<br>我之前是在分布式系统和数据库内核方向，但这两年转到一家大模型公司做数据。本笔记主要是我对课程论文的梳理和精要。不同的是，我会结合在工作中解决实际问题的一些体感，给出一点转行人不同视角的思考，希望能对同样想从工程入门算法的同学一点帮助。</p>
<p>本文来自我的付费专栏《<span class="exturl" data-url="aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZw==">系统日知录<i class="fa fa-external-link-alt"></i></span>》，欢迎订阅查看更多大模型解析文章，文末有优惠券信息。</p>
</blockquote>
<p>本篇主要关注大模型的奠基之作——Transformer。</p>
<p>首先要明确问题域，Transformer 试图解决的是序列建问题，最主要的代表就是语言建模和机器翻译。其次，需要知道前驱方法—— RNN（循环神经网络）和 CNN（卷积神经网络）存在的一些问题，才能知道 Transformer 的创新之处。最后，Transformer 的解决要点的在于“多头注意力机制”和“位置编码”。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2025/09/10/llm-1-transformer/">https://www.qtmuniao.com/2025/09/10/llm-1-transformer/</a> 转载请注明出处</em></p>
<h1 id="序列建模"><a href="#序列建模" class="headerlink" title="序列建模"></a>序列建模</h1><p><strong>序列建模</strong>是对一个<strong>有顺序的元素序列</strong>进行建模，以捕捉元素间的<strong>依赖关系</strong>（因果性，万物的法则），从而可以：</p>
<ol>
<li>预测序列中下一个元素（语言建模）</li>
<li>判断序列的合法性（语法检查）</li>
<li>将一个序列转化为另一个序列（机器翻译）</li>
</ol>
<p>序列建模是一个相当泛化的概念，很多 NLP 任务本质上都是序列建模问题。更进一步，现实中的很多问题自动化，都可以转化为序列建模问题。</p>
<p>再看一些序列建模的例子感受下：</p>
<table>
<thead>
<tr>
<th>领域</th>
<th>输入&#x2F;输出序列的形式</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>编程语言</td>
<td>代码 token 序列</td>
<td>代码自动补全、代码翻译、代码生成</td>
</tr>
<tr>
<td>分子结构</td>
<td>化学式序列（SMILES）</td>
<td>药物生成</td>
</tr>
<tr>
<td>图像描述</td>
<td>图像 → 描述序列</td>
<td>对图片内容进行总结</td>
</tr>
<tr>
<td>多模态理解</td>
<td>图像序列 + 文字序列</td>
<td>对图片内容进行问答、定位</td>
</tr>
<tr>
<td>操作轨迹</td>
<td>GUI 操作序列</td>
<td>自动执行任务的 Agent</td>
</tr>
</tbody></table>
<p>因此，随着大模型的成功，这个方法也是现在被看做最有希望通向 AGI 的路径之一。</p>
<h1 id="前序方案"><a href="#前序方案" class="headerlink" title="前序方案"></a>前序方案</h1><p>下面我们来看看传统的 <strong>递归结构（RNN&#x2F;LSTM）</strong> 和 <strong>卷积结构（CNN）</strong> 在进行序列建模时存在的主要问题。</p>
<h2 id="递归结构"><a href="#递归结构" class="headerlink" title="递归结构"></a>递归结构</h2><p>递归结构如 RNN &#x2F; LSTM &#x2F; GRU 曾长期主导序列建模，其公式是：</p>
<p>$$<br>h_{t}&#x3D;f(h_{t−1},x_{t})<br>$$</p>
<p>可以用图片来辅助理解：</p>
<p><img src="https://s2.loli.net/2025/09/10/86a1tymDIdAU2Ok.png" alt="transformer-rnn.png"></p>
<p>其中 $h_{t}$ 是 t 位置（或者说“时刻”）的隐藏状态， $x_{t}$ 是 t 位置的输入。直观上很好理解，就是将之前的输入序列压缩到一个隐藏状态 $h_{t}$ （hidden state）中，然后不断向后传递。从图中的圈，可以更好理解为什么叫递归结构。</p>
<p>这种结构主要有两个问题：</p>
<ol>
<li>无法进行并行计算</li>
<li>长路径信息稀释</li>
</ol>
<p>可以看出，这个结构中每一个隐藏状态的计算（ $h_{t}$ ），都依赖上一个结果（ $h_{t-1}$ ），这种前后相继的依赖关系导致我们想得到最后的状态时，只能一步步地进行串行计算。从而没有办法充分利用 GPU 的并行能力，网络稍微一大训练起来就非常慢。</p>
<p>另外，不同元素间的状态传递都依赖这样一步步的计算，可想而知，当距离足够远之后，序列前面元素的信息将会被稀释到什么地步。因此，RNN 结构很难捕捉过长距离的两个词之间的依赖。</p>
<h2 id="卷积结构"><a href="#卷积结构" class="headerlink" title="卷积结构"></a>卷积结构</h2><p>卷积神经网络（CNN）在上一波以 CV 为主要应用领域的人工智能浪潮中大放异彩，核心特点就在于其并行性，以及可深层堆叠性（当然主要依赖同时期创造的残差网络等技巧），从而构建出足够复杂的网络结构以容纳足够多信息。</p>
<p>因此 CNN 被引入序列建模，代表如 <strong>ByteNet、ConvS2S</strong>，试图通过局部感受野+多层堆叠来并行化建模。但 CNN 也有其问题：</p>
<ol>
<li>单层卷积视野有限</li>
<li>不能捕捉绝对位置信息</li>
</ol>
<p>由于单个卷积核通常不会太大（比如图像中的卷积核通常是 3<em>3 or 5</em>5，太大效果不太好），因此为了捕捉长距离依赖，通常会进行多层堆叠，以扩大感受野。但网络过深，不仅会让训练更难，也会大大推高训练成本。本质在于，卷积方式对长距离建模效率较低。</p>
<p>不同于图像，对于序列来说，我们通常在<strong>位置</strong>或者<strong>时间</strong>维度上进行一维卷积。由于卷积核本质上是位置无关的（没有位置信息，只是一个权重，左边和右边参数一样），因此只能捕捉卷积核视野内的相对位置信息。另外，卷积在图像领域很好用的一大原因是：<strong>平移不变性</strong>。举个例子，一个猫出现在左上角和右下角，都是一个猫。但在语言序列中，一个词的含义是非常依赖上下文的。因此，卷积对序列来说，并非一个原生的结构。</p>
<h1 id="核心架构"><a href="#核心架构" class="headerlink" title="核心架构"></a>核心架构</h1><p>在分析了问题域和前序方案的短板之后，我们来看看 <span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE3MDYuMDM3NjI=">Transformer<i class="fa fa-external-link-alt"></i></span> 是如何设计网络结构来解决这两个问题的。但在详解之前，我们再铺垫一些相关的概念。</p>
<h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><p><strong>编码器-解码器结构（encoder-decoder structure）</strong>。是为了解决我们之前提到的序列建模中的 seq2seq 的一类问题而提出的，主要应用于基于神经网络的机器翻译领域。最早被提出时（2014）是基于 RNN 的。</p>
<p>其基本工作原理是：</p>
<ol>
<li><strong>编码器</strong>将输入序列编码为固定长度的<strong>上下文向量</strong>（context vector）。从直觉上理解，该向量类似于输入句子的”摘要“。</li>
<li><strong>解码器</strong>利用该上下文向量作为起始的隐藏状态，通过”自回归“的方式逐步生成输出序列。</li>
</ol>
<p>因此，最初的编码器解码器结构，是通过一个<strong>固定长度</strong>的中间向量来“桥接”输入和输出序列的。可想而知，当输入序列的信息量变大（比如序列变长），这个固定长度的”桥“会成为瓶颈。</p>
<p><strong>自回归（auto-regressive）</strong>。自回归最开始是统计学和时间序列分析中的一个概念，其基本含义是一个变量当前的值等于过去值的线性组合，再叠加一个随机扰动项。在大模型中，就是输出下一个 token 时，模型会将已经输出的 token 作为上下文一起送入模型。</p>
<p>举个例子，当 GPT 生成“天空是蓝色的”这句话时：</p>
<ul>
<li>首先生成“天空”。</li>
<li>然后利用“天空”作为上下文，生成“是”。</li>
<li>再利用“天空是”作为上下文，生成“蓝色”。</li>
<li>最后利用“天空是蓝色”作为上下文，生成“的”。</li>
</ul>
<p>这中间会有一些冗余信息，也是推理 infra 的着重发力的一个方向：KVCache。当然，这里的 KV 概念会涉及到 Attention 一些概念了，之后会展开讲。</p>
<p><strong>自注意力（self-attention）</strong>。注意力机制的最开始引入是为了解决编码器解码器结构中间桥接向量“信息瓶颈”的问题。其基本做法是：</p>
<ol>
<li>编码时：（粒度作细）不再将整个输入序列编码成一个固定长度向量，而是为每个词生成一个“关系”向量，该向量包含了该词和序列中其他词的“亲疏”关系，当然，该词的位置信息也被以某种方式编码了进去。</li>
<li>解码时：（分亲疏）生成每个词时，也不再仅依赖固定长度的上下文向量，而是动态的<strong>关注</strong>输入序列不同部分。实现上，就是利用之前得到的每个词的“关系”向量，来对输入序列按”注意力“（亲疏性）进行加权，得到下一个词。</li>
</ol>
<p>形象来说，注意力机制：</p>
<ol>
<li><strong>粒度作细</strong>：不再为整个输入序列生成做”摘要“，而为每个词逐词做摘要。</li>
<li><strong>分亲疏</strong>：不是粗暴利用一个固定长度上下文做解码，而是每次解码时，动态的获取当前最应该关注的输入序列的部分词，来做加权。</li>
</ol>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="https://s2.loli.net/2025/09/10/JcZmz7SLADCKrho.png" alt="transformer-architecture.png"></p>
<p>有了上面铺垫，我们再来看论文中这张 Transformer 经典的架构图。</p>
<p>主干的左右两侧遵循了经典的编码器-解码器结构。</p>
<p>在编码器一侧，堆叠了 N&#x3D;6 个<strong>基本层</strong>，堆叠的时候通过残差和归一化（Add &amp; Norm）方式来规避深层神经网络的梯度消失和爆炸问题。每个基本层包含两个基本单元，多头注意力（Multi-Head Attention）和前馈网络（Feed Forward）。前馈网络其实就是有一个隐藏层的三层全连接网络，后面会详细解析这两个基本构件。</p>
<p>右侧的解码器结构和编码器基本结构大体相同，层数也相同，变化有二。第一，加了一层交叉注意力模块，以将编码器抽取的<strong>“上下文”</strong>桥接过来。第二，注意力计算时是要先做掩码的，使得每个词只能关注到其以前的词，而看不到其之后的词。</p>
<p>最后就是通过一个线性层，然后利用 softmax 进行概率归一化。</p>
<p>另外，输入时也可以分成两块：</p>
<ol>
<li>token 到向量转换：tokenizer 这里没画。token 到向量的转换函数也是可以学的。</li>
<li>叠加位置信息：给每个 token 的向量叠加一个其所在句子中的位置信息。</li>
</ol>
<h3 id="注意力"><a href="#注意力" class="headerlink" title="注意力"></a>注意力</h3><p>在计算注意力的时候，我们会为每个 token 的向量引入三个额外表征：Q（query），K（key），V（value）。即从 token 原向量（设为 x）中通过“投影”（矩阵变换）的方式在另外空间抽取（或者说衍生）三种不同用途的表征。下面我们通过一个“去图书馆查资料”的例子来理解下。</p>
<p>想象一下，你要写一篇关于“人工智能对经济的影响”的论文，需要去图书馆查找一些相关文献。</p>
<ul>
<li>**原始输入向量 (x)**：就像你脑海中模糊的想法或一个高度抽象的词，比如“经济”。这个想法本身包含了很多维度的含义。</li>
<li><strong>查询 (Query - Q)<strong>：为了查找资料，你不能只抱着“经济”这个模糊的想法。你需要把它具化成一个</strong>问题或查询</strong>，比如“寻找关于AI技术如何改变就业市场的书籍”。这个具体的查询就是<strong>Q</strong>。它是从你的原始想法“经济”派生出来的，但更具方向性。</li>
<li><strong>键 (Key - K)<strong>：在图书馆里，为了让每一本书能被快速检索到，都会有自己的</strong>标签或关键词</strong>，比如“AI”、“就业”、“自动化”、“市场分析”等。这些标签就是<strong>K</strong>。它们代表了这本书的摘要，是用来和“查询”进行相关性匹配的。</li>
<li><strong>值 (Value - V)<strong>：书本的</strong>实际内容</strong>就是<strong>V</strong>。一旦你的查询（Q）和某本书的标签（K）高度匹配，你就可以去阅读这本书的详细内容（V）来获取更多信息。</li>
</ul>
<p>那为啥不直接用原始向量 x 与其他 token 的向量做乘积就好了？原因有多方面：</p>
<ol>
<li><strong>角色解耦</strong>：如果将 QKV 都使用 x，则需要该向量同时“分饰三角”，其实是做了一种“先验”的强约束关系。交叉注意力时更能明显体现这一点。</li>
<li><strong>表达能力</strong>：将原始向量投影到不同空间中，本质上是一种更内聚的抽取，而且这个抽取方式也是可以进行参数化学习的，从而极大提升了灵活性和表达能力。</li>
<li><strong>支持多头</strong>：正因为同一个 x 可以有不同的“抽取”方式，Transformer 的多头并行地进行不同维度的 feature 抽取才有意义。</li>
</ol>
<p>Transformer 中用到了两种注意力方式：</p>
<ol>
<li><strong>自注意力（self-attention）</strong>：编码器部分中的注意力层，捕捉序列中 token 的的内在依赖关系。此时，QKV 都来自同一个序列的不同投影。</li>
<li><strong>交叉注意力（cross-attention）</strong>：编码器和解码器间的桥接部分，利用编码器捕捉到的内在依赖关系，进行下一个 token 的预测，此时 Q 来自解码器，KV 来自于编码器。</li>
</ol>
<p>在给定窗口内，注意力模块会为每个 token 计算和其他 token 的关联性，从而为每个 token 得到一个对其他所有 token 的<strong>关系向量</strong>。计算相关性时，可以用加法注意力或点积（乘积）注意力，两者效果类似，但因为 GPU 对点乘进行了高度优化，所以选择了后者。最后为了保持输出的分布稳定性（点乘后均值会放大 $\sqrt{d_k}$，搜下点积公式就可以看出），因此要加一个缩放（除以 $\sqrt{d_k}$）将均值搞回去，以避免将 <code>softmax</code> 函数推入梯度极小的区域。</p>
<p><img src="https://s2.loli.net/2025/09/10/lXUeD1bHjWJthzC.png" alt="transformer-vqa.png"></p>
<p>那为什么用多头呢？这点其是借鉴了卷积神经网络（CNN）中的多头抽取、深层堆叠的特点，分别抽取不同维度的特征，最后利用线性层重新组合到一块，效果更佳。</p>
<p>论文中采用了 h&#x3D;8 个并行注意力层，或称为<strong>头</strong>（head）。对于每一个头，使用 $d_{k} &#x3D; d_{v} &#x3D; d_{model} &#x2F; h &#x3D; 64$，即增加数量的同时，减小每个头的维度。从而在保持计算量差不多的同时，可以并行抽取多个特征。</p>
<h3 id="前馈神经网络层（FNN）"><a href="#前馈神经网络层（FNN）" class="headerlink" title="前馈神经网络层（FNN）"></a><strong>前馈神经网络</strong>层（FNN）</h3><p>是一个三层的全连接神经网络（输入层，隐藏层，输出层）。类似于 CNN 中多头后面的卷积核 &#x3D; 1 的组合层，提供了额外的非线性（主要是通过<strong>激活函数</strong>）。直观上理解，自注意力层是“横向”地（在窗口内跨 token）整合信息，它将所有相关词的上下文信息聚合到每个 token 的表示中。而 FFN 层是“纵向”地（词间不互相影响，在每个词内的特征维度上）深化和提炼这些聚合后的信息。它在每个位置上独立地进行特征学习和重塑，使其能够更好地捕捉该位置上更抽象、更高层次的特征。</p>
<h3 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h3><p>由于注意力模块是计算的序列中不同 token 的相对关系，是没有位置信息的。为了让网络学到 token 间的位置信息，也即我们之前提到的因果关系，Transformer 额外引入了位置编码。为了让位置编码能够简便地叠加到 token 的 embeding 上，让其保持了和 embeding 同样的维度 512 。从而可以利用简单的加法方式进行叠加。</p>
<p>这个编码可以通过参数学出来，也可以事先固定。Transformer 选择了后者，因为发现和学出来的差不多（但当然，后面不同工作进行了大量改良）。Transformer 采用了一种正弦波的编码方式，特点在于可以捕捉位置的可加性。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>本文从首先明确了问题领域——序列建模，讨论了为什么序列建模可以成为解决一大类通用问题的基础；然后简单分析了之前 RNN 和 CNN 存在的一些问题：难以并行和长距离依赖捕获；最后剖析了 Transformer 的解决方案和主要架构——多头自注意力机制。</p>
<p>此外，我们可以追踪一个 token 对应的 embedding 的变换过程（变换过程中维度是保持 512 不变的），来更深的理解 Transformer。</p>
<p>编码器部分：</p>
<ol>
<li>位置编码：加法，叠加位置信息</li>
<li>自注意力层：捕捉<strong>输入序列</strong>中 token 向量间关系压缩到表征向量中（两头看）</li>
<li>FNN 线性层：增加一些非线性性，锤炼每个 token 的表征向量</li>
</ol>
<p>解码器部分：</p>
<ol>
<li>掩码自注意力层：捕获输出序列中的 token 和其前序 token 的间依赖，压缩到表征向量中（只向前看）</li>
<li>交叉注意力：将编码学到输入序列的 token 在句子中的相关性表征送给解码器，从而让新的表征向量既带有输入序列的信息、也带有输出前序 token 的信息。从而准备好了预测下一个 token 的所有信息。</li>
<li>FNN 线性层：锤炼每个 token 的表征向量，增加一些非线性性</li>
</ol>
<p>多层堆叠：通过残差和正则，以在保持训练稳定性的前提下加深网络。从而进行反复抽取提炼，以更多参数容纳更多信息量。</p>
]]></content>
      <categories>
        <category>大模型</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>LLM</tag>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>在云上进行大规模数据处理的一些实践</title>
    <url>/2025/06/04/data-processing-on-cloud/</url>
    <content><![CDATA[<p>随着云基础设施的不断成熟，新兴的公司为了快速实现业务目标，一般都会让基础设施上云。而在云上进行开发与传统上直接使用物理机开发其实有很大不同。云上更强调<strong>共享</strong>和<strong>弹性</strong>，此外，规模变大又会带来<strong>隔离性</strong>。这些改变也倒逼我们在进行开发时做出一些改变。在云上进行大规模数据处理，我主要有一些 spark 和 ray 的经验，使用的语言主要是 python；从这些技术栈出发，谈谈一些还算行之有效开发实践。</p>
<p>使用 ray 在云上进行大规模数据处理，一个基本的思路是：构建最小可并行单元，进行功能测试和性能测试，然后再利用 <span class="exturl" data-url="aHR0cDovL3JheS5kYXRhLw==">ray.data<i class="fa fa-external-link-alt"></i></span> （比如 <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnJheS5pby9lbi9sYXRlc3QvZGF0YS9hcGkvZG9jL3JheS5kYXRhLkRhdGFzZXQubWFwLmh0bWw=">map<i class="fa fa-external-link-alt"></i></span>，<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLnJheS5pby9lbi9sYXRlc3QvZGF0YS9hcGkvZG9jL3JheS5kYXRhLkRhdGFzZXQubWFwX2JhdGNoZXMuaHRtbA==">map_batches<i class="fa fa-external-link-alt"></i></span> ）进行 scale。使用 spark 时，会稍有不同；相比 ray，spark 虽然灵活性稍差一些，但抽象封装更好，可以从数据集整体的角度来考虑数据处理，spark 会通过你设置的分区数和并行度，自动地扩展和容错。</p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2025/06/14/data-processing-on-cloud/">https://www.qtmuniao.com/2025/06/14/data-processing-on-cloud/</a> 转载请注明出处</em></p>
<h1 id="共享性"><a href="#共享性" class="headerlink" title="共享性"></a>共享性</h1><p>共享性可以大致分为两方面：一方面是多个开发机的环境共享，另一方面是开发环境和生产环境的共享。那为什么会有多个开发机共享的需求呢？一来，我们总会因为各种原因，有开发机迁移的需求；二来，可能会有 CPU 机器和 GPU 机器的区分；三来，同事间、开发机和生产机偶尔也想通过文件系统来共享一些东西。</p>
<p>如果换机器进行开发，大家多少都会遇到过一些痛点：辛辛苦苦的在一台机器配好的环境，换个环境又要再来一次。当然，有的同学可能会把这个过程固化成一个脚本，每次启动时执行一遍。但即使这个过程能够被标准化和自动化，但每次装机也是需要花一些时间的，不能做到开箱即用。</p>
<p>就像 Java 的 slogan 所谓“一次编译、到处运行”一样，我们在配置开发机环境是，能不能达到“一次配置，随便换机”的效果呢？下面分享一种很粗糙的实践。</p>
<p>为了实现多机共享，可以向云厂商申请一块很大的支持 POSIX 语义、多点读写的共享云盘。然后将所有用户目录放到该云盘上，等有新的开发机时直接挂载该盘，然后将你的用户目录软连到本机用户根目录（&#x2F;home ）下即可。这样解决了<strong>数据共享</strong>问题。那么进一步，<strong>账号系统</strong>能不能也共享呢？如果多机的账号不通，则意味着需要给同样的数据目录给多机的多个账号进行不同授权。授权其实还好，但 owner 只能有一个，给了这个机器的，就不能给另外机器的账号。当然，这个问题的本质在于不同机器的账号 id （uid 和 gid）可能会产生冲突。于是为了真正丝滑的进行多机用户目录共享，我们还得配套地进行账号系统共享。</p>
<p>研究下 Linux 下用户系统可以发现，所有用户信息的最小集落在两个文件中：</p>
<ol>
<li>用户基本信息：<code>/etc/passwd</code></li>
<li>用户组信息：<code>/etc/group</code></li>
</ol>
<p>只要让所有机器共享这两个文件，即可让所有机器共享账号系统。但问题又来了：这个信息在哪里生成？如果有用户恶意改动其内容怎么办？</p>
<p>第一个问题，参考分布式系统中的常见操作，可以让一个开发机充当 “master”，所有用户都由该机器来创建，其他机器称为 “follower”，来挂载这两个文件，替换系统原用户信息文件。由唯一的 master 生成的 uid&#x2F;gid 从而避免账号体系的冲突。</p>
<p>第二个问题，由组内管理员来控制账号的统一创建。但又不能不给其他用户 sudo 权限（不然在本机安装东西会很麻烦），所以随意修改这两个文件权限还是控不住，这个就只能大家口头约定了。</p>
<p>这样，就初步达成了我们“一次配置，随意换机”的目标。</p>
<p>但在这个体系下，还有一些实际问题需要解决，比如尽量使用类似 conda 的工具，将所有的环境和依赖安装到自己的用户目录下，而非每台机器的系统盘。这个我们在隔离性的一小节再详细展开。</p>
<h1 id="弹性"><a href="#弹性" class="headerlink" title="弹性"></a>弹性</h1><p>这也是云最大的卖点之一：按需弹量、按量付费，但现实总没有这么美好。</p>
<h2 id="成本"><a href="#成本" class="headerlink" title="成本"></a>成本</h2><p>从成本上说，<strong>弹性资源</strong>的总会比<strong>包年包月</strong>的贵很多。因此作为云厂商用户的我们，通常会买一些包年包月的机器来满足大部分场景需求，然后在偶尔不够用时临时使用弹性资源。但如果你的负载不收敛，又会面临两难：贴近需求上限来保持常备池子，会有很多闲置浪费；贴近需求下限来购置常备池子，则需要经常使用弹性资源，也会比较贵。如果你的资源用量比较稳定，就可以稳定的省钱；但是如果比较多变，对不起，云上的弹性只解决有无问题，不会解决成本问题。常态化使用时，为了降本增效，你还是得精确计算和管控你的资源用量。</p>
<p>如果机器数量比较大，通常我们会用容器技术来池化所有机器资源，并使用 k8s 来编排调度任务。得益于 k8s 的开放性，现在大部分的计算框架都可以通过定制 Operator，一键部署在 k8s 上，比如 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JheS1wcm9qZWN0L2t1YmVyYXk=">kuberay<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9zcGFyay5hcGFjaGUub3JnL2RvY3MvMy41LjQvcnVubmluZy1vbi1rdWJlcm5ldGVzLmh0bWw=">spark on k8s<i class="fa fa-external-link-alt"></i></span> 。这种方式可以更好的对资源进行池化和分配。于是就引出了另外一个经典问题——调度。在调度的范畴里，我们可以<strong>按紧急程度</strong>和<strong>用量多少</strong>来考虑每个待调度任务的属性。下面说几个使用场景：</p>
<ol>
<li><strong>插队</strong>：假设现在资源已经耗尽，有很多任务在排队，但新来了一个比较紧急的任务，要想快速获得资源，就得使用较高的优先级，插到别人前面去，等有资源可用立即抢上。甚至进一步，如果需求再紧急一点，可以使用高优先级+抢占式调度，直接从低优先级任务那里抢资源。当然更好的方式是手工介入，主动杀死一些（不用全杀）不着急任务的 pod 以临时出让资源。因此，在分布式系统中，对子任务换机器重试是刚需。</li>
<li><strong>死锁</strong>：调度也有死锁？对的，考虑如下场景：现在集群中还剩 100 cpu，有两个 ray 任务，任务 A 需要 80 核，任务 B 需要 60 核。任何单一任务调度到集群中，都能起来，但是如果任务 A 抢到了 70 核，任务 B 抢到了 30 核，则谁都不能起来。这时就需要引入<strong>组调度</strong>（gang scheduling，比如 <span class="exturl" data-url="aHR0cHM6Ly92b2xjYW5vLnNoL3poLw==">volcano<i class="fa fa-external-link-alt"></i></span>），即只有一个任务所需资源都被满足后才一次性地给其分配资源，就跟锁一样。有了这种保证，要么 A 被调度上去、要么 B 被调度上去，而不会发生上面类似死锁的状况。</li>
<li><strong>弹性</strong>：使用 k8s 跑计算框架时，通常会在任务级别进行弹性，如果池子中资源多，就多用点；资源少，就并发度低的跑慢点，spark 在这方面做得很好。而kuberay 的弹性调度，现在就是个笑话，且看以后把。但 spark 弹性做的好带来一个问题，就是如果使用者为一个大任务设定了很多资源，且没有优先级时，会很容易把整个池子吃满。</li>
</ol>
<p>因此，在云上进行大任务调度，一个支持 gang scheduling、优先级调度，且调度效率较高（比如 spark 一下拉起了上万个 pod 也不能拉胯）的任务调度器必不可少。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>从代码角度来看，对程序进行大规模扩展也不是没有代价的。当然，这个代价在变的越来越低，上古时代，有 Hadoop 的 MapReduce；后面要求低延迟和易用性，又有 Spark、Flink；在机器学习时代，Ray 则大行其道。Ray 在理念上，很像一个大型的分布式计算机，采用经典的 <a href="https://www.qtmuniao.com/2021/07/03/distributed-system-1-master-workers/">master-worker 架构</a>，将所有内存收集起来提供 object 级别的 kv 抽象，称为 object store；将所有 GPU&#x2F;CPU 收集起来提供并发执行的基础，支持小数级别的逻辑分配。</p>
<p>ray 支持非常细粒度的并行，灵活性拉满，因此满足了大模型时代复杂多变的数据处理需求。但代价就是，其他分布式系统中一些常见的高阶抽象，到 ray 中就得自己做了：</p>
<ol>
<li><strong>逻辑调度</strong>。ray 使用基于可量化的 label 进行逻辑调度（感兴趣可以参考这篇<a href="https://www.qtmuniao.com/2019/08/10/ray-source-reading-2/">博客</a>）。逻辑和物理间的 gap，就需要你自己调优去填平。举例来说，如果你的 actor&#x2F;worker 在逻辑上声明了要使用 10G 内存，但物理上的需求远超 10G，那么多个这样的 worker 调度到一台机器上，就很容易把该机器内存打爆。cpu&#x2F;gpu 超用虽然不至于会把机器打爆，但逻辑和物理不统一，要么造成浪费，要么争抢严重。</li>
<li><strong>上下游协同</strong>。ray 为了更好的支持数据处理，在 ray core 之上，包出了 ray.data 库，但如果上下算子的生产-消费速度控不好，就很可能造成：或者上游堆积，逐渐把机器内存撑爆；或者下游闲置，造成资源浪费。</li>
<li><strong>数据条目非标</strong>。在进行大规模数据处理的时候，总会在处理了很久之后，发现一两条异常数据将任务干死。如果不做合适的错误处理或者断点续做，你将得到惨痛的代价。当然，ray 提供了静默错误的配置，但代价是守恒的——这个屎你不吃，下游同学就要吃。</li>
</ol>
<h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><p>在大规模并行系统中，出错是非常常见的；但复现错误却通常很难——数据量过于巨大、环境过于复杂、复现过于费时等等。为了在出错时快速定位，你需要构建一套可观测系统：</p>
<ol>
<li><strong>日志收集</strong>。对所有关键路径上的步骤进行日志输出，将整个处理代码通过日志切分成一个个“格子”，从而在出错时能快速定位到相关<strong>代码段</strong>。</li>
<li><strong>指标统计</strong>。数据处理通常分为多个环节，出现 OOM 时，很可能是某个环节数据堆积，把机器打爆了。如果能对一些关键处理指标进行统计，就可以在出现性能问题时迅速找到原因。当然，指标统计可分为应用层面和系统层面，上面说的是用户代码层的应用层面，对于系统层面来说，往下探一层，比如 ray actor 的一些随时间的资源用量；再往下探一层，比如每个节点随时间的资源用量和网络 IO；往外扩一层，所依赖的存储系统，比如对象存储的按 bucket&#x2F;prefix 的读写流量等等。</li>
</ol>
<p>有了这些日志和指标，在出现问题时，可以很方便的根据日志获取出错时间，然后进行时间回溯，查看当时各种指标。收集到足够信息后，简单的就可以直接定位；复杂一些的，如果打印出了数据条目，可以利用该条数据进行<strong>最小复现</strong>，同时将该复现沉淀为单元测试。</p>
<p>另外一种常见的需要调试的问题——性能。这可能有多方面的原因：</p>
<ol>
<li>最小执行单元性能就不太行</li>
<li>扩展时资源分配不合理造成踩踏</li>
<li>上下游生产消费速度不匹配</li>
</ol>
<p>后面两个其实是分布式系统中常见问题，成熟的计算平台能在框架层面就解决这些问题（背压），但这多少也会让灵活性变差。灵活性和易用性总是需要取舍的两端，而 ray 由于设计理念和不太完善的原因，导致我们必须手动来处理这些问题。</p>
<p>另外，如果有不明原因的变慢甚至 hang 住，可以直接登录机器，通过一些 linux 命令行小工具，来查看系统资源用量；通过 py-spy 等工具来查看代码到底在做啥；从而查看系统到底出了什么问题，hang 在了哪里。</p>
<h1 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h1><p>从生命周期来入手，主要可以分为开发阶段和运行阶段的隔离性。</p>
<h2 id="开发阶段"><a href="#开发阶段" class="headerlink" title="开发阶段"></a>开发阶段</h2><p>如之前所述，在开发阶段，会有多个开发同学共享一个开发机的情况，有共享就会引出隔离性的需求。最自然的解决方法，就是尽量利用 Linux 本身的账户体系对开发机进行隔离。有些团队为了图方便一把梭地都用 root ，由于每个人都有自己的开发习惯，后面很容易在安装工具和依赖的时候出现版本冲突。因此，还是建议大家都不用 root，并且把所有的软件尽量用类似 conda 工具安装在用户自身的目录中，一来可以在不同机器上方便迁移，二来可以避免影响同机器上的其他用户，也就是现在说的隔离性。</p>
<p>另外，对于单个用户来说来常常面临多个环境冲突的情况。以 Python 开发为例，如果你将所有的项目依赖都安装到用户目录，只要项目多，起冲突是必然的事情。即使同一个项目，在进行多分支开发时，偶尔也会有冲突。因此也需要用 virtualenv 或 conda 等工具来进行依赖的隔离。</p>
<h2 id="运行阶段"><a href="#运行阶段" class="headerlink" title="运行阶段"></a>运行阶段</h2><p>有容器化技术的帮助，当今将一批物理机池化、并按需即时隔离出一个逻辑运行环境可太容易了。此外，利用容器技术和一些依赖管理工具链（比如 poetry 和 uv），我们再也不用担心过去开发环境和生产环境经常出现依赖不一致的情况了。即：</p>
<ol>
<li>使用<strong>同一份</strong> <code>pyproject.toml</code>文件来管理项目开发依赖</li>
<li>在进行开发时，使用 poetry&#x2F;uv 和该文件来安装依赖</li>
<li>在线上运行时，在 Dockerfile 中利用 poetry&#x2F;uv 来进行依赖管理</li>
</ol>
<p>当然，上面只覆盖到了 python 的依赖，肯定还会有其他类似 cuda 等操作系统层面的库依赖。但原理是相通的，即<strong>使用 Dockerfile 来作为项目依赖的唯一的 source of truth</strong>，无论开发环境还是打镜像，都用该 Dockerfile 中的命令。</p>
<p>更激进的，甚至可以直接用项目中的 dockerfile 临时拉起一个环境进行开发，这样就让开发和运行达到了完全统一。也可从另外一个角度思考这个问题：</p>
<ol>
<li>在开发时，镜像应该是需要被改写</li>
<li>但在生产时，镜像是只读的</li>
</ol>
<p>所以在开发和运行时进行依赖管理，还是稍微有些不一样的。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在云环境中进行开发改变了一些范式，从而诞生了很多新的开发实践。本文只是依据作者的经验，以在云上进行大规模的数据处理为切入点，稍微梳理了其中一些常见的问题和实践，如果能稍微给你一些启发，目的就达到了。限于经验和篇幅，肯定有覆盖不到之处，欢迎大家留言讨论和补充。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>云</category>
      </categories>
      <tags>
        <tag>云</tag>
        <tag>大规模数据处理</tag>
        <tag>实践</tag>
      </tags>
  </entry>
  <entry>
    <title>2025 年终总结——向内生长</title>
    <url>/2025/12/28/2025-summary/</url>
    <content><![CDATA[<p>有明显的自我意识以来，从没有像今年这样和世界、和自己发生如此激烈的冲撞，但结果很神奇——反倒更加平和了。很多下意识的反应、很多习以为常的做法，向内挖时，竟然都能摸出如此久远的强化链路。正如史铁生说的——那颗年少时射出的子弹，在长到这个年纪的时候，正中眉心。</p>
<p>于是，不管是被迫地还是自发地，今年都开始难以避免地向内生长——如格物致知一般去观察和追溯自己细微的情绪变化源头，见天地、见众生，终是为了见自己。虽然以前惯性还会持续一段时间，但觉察的开始，便是塑造另外轨迹的种子。</p>
<p><img src="https://photo.tuchong.com/15470921/wp/672288214.jpg" alt="佛光寺经幢和东大殿"></p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2025/12/28/2025-summary/">https://www.qtmuniao.com/2025/12/28/2025-summary/</a> 转载请注明出处</em></p>
<h1 id="播客"><a href="#播客" class="headerlink" title="播客"></a>播客</h1><p>那么从哪里聊起呢，就从这两年成为习惯的播客开始吧。像早期的知乎一样，这里有各种还不拘于商业形式的有生命力的思想。听播客很容易产生心流，加之不耽误手上干活，可做饭、干家务、通勤、遛弯，所以很容易用来填充各种空白。而且边听边干其他事情，是主次多维度的输入，往往会让人的思绪更加空明，超脱一时一地，产生很多奇妙的联想——而这正是我最喜欢的事情。下面分享点我今年听播客结合生活工作产生的一些奇妙的联想（<a href="https://www.qtmuniao.com/sparks/">这里</a>可以看到更多）。</p>
<p><strong>认知的有限性</strong>。我以前常困惑，为何我们学的道理如此简洁优美，而为何真实的世界却如此复杂混沌。有天突然悟了，所谓简洁的规律都是<strong>后验</strong>的。主要是因为我们认知带宽有限，在回望复杂的世事时，只能通过“规律”这个杠杆去压缩尽可能多的世界细节。大模型如此成功的原因之一，也是能够将知识从数据中高效地压缩到参数空间中。</p>
<p>也正因为我们上下文带宽有限，才会通过抽象、分层的方法去撬动这个世界。这也正是软件工程，乃至任何需要协作的大型项目所共同采取的办法。</p>
<p>但有个鸿沟，即没有相关经验的支撑，规律是很难实际指导我们解决具体问题的。这是因为，我们在向上进行抽象的同时，会损失细节，且越到高层的抽象（大道至简），损失的细节越多。因此，在使用规律进行向下推演时，必须依据不同的实际情况（上下文），增补一些细节，才能有效地解决当前的问题。而这些微妙的、不可言说的经验，需要自己去亲自经历、需要老到的师傅去点拨才能获得。</p>
<p>但这不正是有趣之处吗？生命有尽，才激发人们去追求跨山涉水去追逐永恒；认知有限，才迫使人们前赴后继去拷问真理。困顿反而是通向深刻的必由之路，刑余之人笔下的古今之变，顽强地从竹简时代穿越亘古到数字时代，仍是我们的精神食粮。由此观之，生命是何等的壮丽恢弘。</p>
<p><strong>波粒二象性</strong>。这里是引申义，只是想说<strong>复杂系统</strong>中的微观和宏观的表象的割裂。我们在现实世界所面对的，无疑都是复杂系统。当然，人其是处在一个中观世界中，这是我们身上的“传感器”所决定的——比如我们能见的尺度有限、频谱有限。</p>
<p>扯远了，拉回来。光在微观呈现“粒子性”，在宏观呈现“波动性”。这种微观积分到宏观后，性质完全不同的割裂感，在生活中比比皆是。比如，大模型随着参数量增加的“涌现”便可归于此列；无机分子向有机的蛋白质跨越，也可隐隐然归入此列。</p>
<p>回到我们所处的社会，在上亿人组成的复杂生态中，任何规律的简单线性外推都会失效。因为我们观察到的所谓规律，都是高维真相在低维的一个简单投影。分析一时的政治得失，难以洞察历史周期；分析一组 k 线走向，也难以知晓康波周期。</p>
<p>也因如此，才更明白概率和统计这门大学差点挂科的学科玄妙之处。它是我们对更长的时间、更大的空间、更多的样本进行建模的一种<strong>超验</strong>手段。在宏观层面，单个样本无关轻重，概率分布才有意义。因此在大模型训练时，我们很难、也不用太对逐个样本进行考察，而只需要关注各个维度的概率分布即可。在我们漫漫的人生路中，要允许各种可能性的发生，不用过于担心一时的得失，也就不会过于钻牛角尖。从长期来看、从宏观考察，任何单一个体行为都不太重要，既然如此，何不率性而为。</p>
<p>到这，你可能也看出来了，上面说的两件事，其实是一体两面。</p>
<h1 id="大模型"><a href="#大模型" class="headerlink" title="大模型"></a>大模型</h1><p>这一年的大模型能力的进步之速，实在是超越体感。部分是由于身处这个行业、部分又是因为其最先有效的落地场景，正是我们自己的老本行——编程。在大模型公司的一种强烈的感觉就是，“上岸第一剑，先斩意中人”。</p>
<p>两三个月前，在用 Claude Code 这类 Code Agent 时，还觉得其对使用者幽深意图把握的有限性。另外，还感觉这类 Agent 对使用人的自然语言精确表达能力提出了太高的要求。而软件是需要层垒的，一旦开始模块堆叠和功能演进，不精确的自然语言很难胜任。</p>
<p>但现实的发展很快超出我的预期，像任何工程一样，编程 Agent 并不需要解决百分之百的问题，只需要通过一些简单的手段满足百分之八十的场景就行。这些简单的手段包括：更细粒度的待办清单和合适的选择式交互。前者解决复杂度堆叠、上下文有限问题；后者解决使用者语焉不详问题。</p>
<p>此外，和一些朋友探讨、从各种渠道观察，也了解到一些大家对大模型的奇特用法。大模型如此庞大的参数空间，所造出的千万种可能，是包括其创造者 Google、 OpenAI 等公司都难以预见其一的。这不像传统火箭，是基于理论和工程，环环相扣的建造出来的。而是像古代炼丹术士一样，在偶然的炼制中，突然发现了某个配方貌似是 work 的。但不同的是，这次的大丹的丹方是利用了人类诞生以来所积累的最全的数据（电子语料）、最前沿的技术（高精芯片）所点出一个巨无霸科技树。因此，这个茫茫然若世界的”丹“能用来干嘛，有赖于拓荒者的海量的实践。</p>
<p>当然，对我自己来说，用 LLM 更多的场景反而是一些关于历史和人文的探讨、关于自己际遇和认知的一些反思。后者留待下一趴来讲。这里说说前者，由于 LLM 压缩的知识极其海量、情绪又极为“稳定”，简直太能满足我这个好奇但内向的 i 人了。</p>
<p>比如和它聊汉语的<span class="exturl" data-url="aHR0cHM6Ly93d3cueGlhb2hvbmdzaHUuY29tL2V4cGxvcmUvNjkxODZhYzEwMDAwMDAwMDA3MDM0ZTVkP3hzZWNfdG9rZW49QUJPWFAwcE56Z19Xejd3bkNSekdBeXBONzF2bmNZekE5X2syQ3A4Q2dmcmFrPSZ4c2VjX3NvdXJjZT1wY191c2Vy">组合性和压缩性<i class="fa fa-external-link-alt"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly93d3cueGlhb2hvbmdzaHUuY29tL2V4cGxvcmUvNjkwMjFjMjMwMDAwMDAwMDAzMDFkYzM4P3hzZWNfdG9rZW49QUJiT2xWZEowWDhCeEswRHExVWNZWEItOFVETzNnaEF0VGhKTy1kOXk3Y2UwPSZ4c2VjX3NvdXJjZT1wY191c2Vy">聊苏联援建项目<i class="fa fa-external-link-alt"></i></span>对我们工业的影响机制、聊《<span class="exturl" data-url="aHR0cHM6Ly93d3cueGlhb2hvbmdzaHUuY29tL2V4cGxvcmUvNjk0Y2JiNWYwMDAwMDAwMDFlMDAxNDJhP3hzZWNfdG9rZW49QUJKZENNaU5yZFlqa0M4UnRKczkyQURCdmRVaUJNMXQ1Rk5RUVBmd3AxTDZJPSZ4c2VjX3NvdXJjZT1wY191c2Vy">盐铁论》和《国富论》对比<i class="fa fa-external-link-alt"></i></span>、聊扩散模型的数学原理、鞭策它给我举例子让我理解汉明码的机制，无不十分有趣，欲罢不能。在你有一些框架，并知道如何提问后，使用大模型进行终身学习，简直不要太丝滑。</p>
<p>但当然，我们也要知道现在 LLM 现在局限性。比如有的模型被对齐训练地会不露痕迹的取悦你，比如有时会不受现实约束地制造幻觉，比如单会话超出一定窗口后可早期记忆会丢失。但总体来说，只要我们掌握一些原则来巧用 LLM，并有一些简单办法对其推理结果进行校验，便能得到一个极大的杠杆。</p>
<h1 id="见自己"><a href="#见自己" class="headerlink" title="见自己"></a>见自己</h1><p>在反思之外，人是在和不断地和环境交互、和别人相处的时候，才慢慢发现自己的。今年从各种渠道，接触了很多人，从开始的慌乱，到后面的内观，最终和自己和解——接受自己的不可变的天性，去除成长中形成的执念。</p>
<p><strong>不去下意识证明自己</strong>。这会带来很多副作用，比如在别人否定我的时候，会应激地进行反击；在感觉别人比自己厉害时，会不自觉地进行取悦，简直是又卑又亢体质。在进行了一些痛苦地反思后，和 ChatGPT 不断聊天进行溯源，虽然没有一个明确的结论，但慢慢感觉到是小时候不经意地某时埋了一颗种子，且因此得到了正反馈，尔后不断强化，直到让它控制了我的行为模式。</p>
<p>好像从小习惯了通过向周围人证明自己优秀来构建自己价值的锚定，这是为什么呢。这个锚点在一路学习卷上来的国人中有一定的共性，但也有我自己的一些特点，比如我对外界的输入更为敏感，想的也会更多。这估计也是造成我状态波动较大的主因之一。</p>
<p>因为感知更加灵敏，因此外界的风吹草动很容易影响的我初始状态的设定；因为习惯证明自己，因此在和别人交互时，会不断在此初始值上进行级联放大。以外界为锚，其有尽乎？但在国内如此内化的“相对”价值体系下、在人类进化习得的“差分编码”强化惯性下，要想立即换个锚也并非易事。但只要种子种下了，终有一天也会慢慢切过来。世上的事，从来不用、不能也不必着急。</p>
<p><strong>空</strong>。今年从几个播客上都听到大家对佛家“空”的阐释，很有启发。空不是什么都没有、不是什么都不想、更不是什么都不做的消极避世。而是一种主动“空杯”的积极心态，是一种不被成见所囿的开放性。只有空，才能不断破除成见，才能释放更加轻盈的生命力，才能够不耽于过往的失败或者成功，保持好奇和谦虚地往前走。</p>
<p><strong>承认自己精力不足</strong>。作为一个规律总结小能手，总困惑于为什么我学习能力还算比较强，但上手能力却总弱于人呢。摸索后，发现两件事：</p>
<p>一个是老天爷不赏饭吃，我的精力好像确实比别人差。当然，进一步深究，就不知道是因为饮食作息、行事思维，还是先天便如此。但总之，感觉力不从心的时候，就要大方承认自己确实没有心力了，不要勉为其难，很多时候反而是对自己精力的最大保护，对同伴的最大尊重。</p>
<p><strong>所谓完美主义</strong>。另一个是不当追求完备性，以至于启动的难度太大。在面对复杂的事情时，总觉得应该详尽了解上下文，三思而后行。但实际上大多数情形，对于我这种人来说，决断甚至莽劲是更为重要的——因为我已经考虑的够多了，而且很多时候做错了反而没有不做或者慢做代价高。何况，很多美的东西，往往是迭代演化而来的，而非一挥而就的。</p>
<p>也即，“完美”是一个演化的过程，而非一个固定的状态。对后者的追求往往容易陷入一种“执”。因为世界的情绪、各种系统的目标，都无事不刻在变动着。也许是刻在基因里的，我们总试图在动态中追求终极的稳定，就像之前说的，这正是人类的恢弘之处，没有什么可羞耻的。但其实我们可以追求更高阶的静态，比如匀加速运动的一阶导（速度）仍然是变化的，但二阶导（加速度）就是常量了。</p>
<p>很多事情的规律也是如此，但在面对复杂系统时，即使你有这种“求导”的能力，仍然不够。所以，还是要接受变化和流动，变化也很美不是吗？道法自然，自由落体，让千万事穿心而过，不也是一种壮丽吗？</p>
<p><strong>亲密关系</strong>。慢慢的发觉，亲密关系是从小就没有好好修行过、但却很重要的一课。近则不逊远则怨，老夫子说的是我了。</p>
<p>向深挖一层，感觉是从没有真正地建立起自己的主体性，因此在和好朋友、伴侣甚至亲人交互的过程中，很容易边界不清晰。精力好的时候，总想去担他人的因果；精力差的时候，又埋怨他人的不作为。由此再往外扩一层，不知道在什么界限该去拒绝别人，也很难在合适的时候去支撑别人。不会拒绝会浪费自己很多的心力，为了弥补自己这种过载状态，又会对别人产生一些补偿式的期待。这怎么看，都不像是一种合适的相处之道。</p>
<p>然后渐行渐远时，又会担心是不是自己是不是没有能力，留住一段长久的关系。甚至小时候的玩伴和亲人，也会在不断降频的联系中，慢慢淡出。但世界就是这样的呀，每个人都有自己的场，而且是不断变化的场，怎么可能要求永远和人维持不远不近的关系呢。这本身就不符合熵增的原理，也就是说，这本来就不是自然的。所以要让自己慢慢学会接受芳华的逝去、机缘的错失。</p>
<p>毕竟在人人都不会饿死的后工业时代，我们不再需要为了生存而维护亲密关系。于是更开放、更残酷的命题便是——我们到底该如何过下去。在这个社会转型期，我们一只脚还留在农业文明的规训中，一只脚又扎在了工业文明的日常里，能做到不劈叉伤到自己就已经不容易了，行事有节，不必过分苛求更多。</p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>内观部分过多，以至于没有像往年一样罗列工作和生活事项。但其实上面已经处处可见工作和生活的影子。比如，在大模型公司工作，很大程度上给我提供了一些思维的工具；再如，生活中的诸多不顺，又促使我进行很多乱七八糟的思考。</p>
<p>今年写东西不多、拍照不多、出去玩也不多，很多时候在进行内观（也可以说内耗哈哈）和反思，但总感觉慢慢的，一些事情发生了变化，不能沿着既定轨道往前晃悠，反而迫使我将自己从人群中慢慢摘出来，有机会使用七寸莲白，再塑我身。</p>
<p>孤寂是独身的最大缺点，却也是最好的凝身剂。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>年终总结</tag>
      </tags>
  </entry>
  <entry>
    <title>20260120 B 站直播 —— 转行大模型文字精要</title>
    <url>/2026/01/25/llm-switch/</url>
    <content><![CDATA[<blockquote>
<p>我是 2024 年初到一家大模型公司工作，之前一直在数据库、存储等 infra 行业工作，因此有些很粗浅的转行认知。很久没有在 b 站做分享了，这次靠直播强制开机，回答了大家一些问题，稍稍弥合一点信息差。本文对直播中提到的一些点的稍微规整一点的总结，并将一些我觉得不错的资料附在最后。</p>
<p>b 站直播：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMXVja0pCa0V0bw==">https://www.bilibili.com/video/BV1uckJBkEto<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<p><img src="https://s2.loli.net/2026/01/25/p5hVJcA4ytHolCf.png" alt="题图"></p>
<span id="more"></span>
<p><em>作者：木鸟杂记 <a href="https://www.qtmuniao.com/2026/01/25/llm-switch/">https://www.qtmuniao.com/2026/01/25/llm-switch/</a> 转载请注明出处</em></p>
<h1 id="类型分野"><a href="#类型分野" class="headerlink" title="类型分野"></a>类型分野</h1><p>大模型的相关工作从底层到上层：infra 侧、数据侧、模型侧 | Agent 层、应用层。</p>
<p>infra 侧和数据侧分布式系统相关的同学都相对沾边，比较好转。模型侧准入门槛比较高，要么需要发过不错论文的博士、要么需要有受认可公司的一些年的工作经验。Agent 层、应用层和传统的后端开发很像，只需要了解一些大模型的能力边界和使用实践就行，目前还是偏蓝海的状态。</p>
<p>泛 AI infra 按需求的多少可以分为推理侧 infra、训练侧 infra 和数据侧 infra。推理侧 infra 在分布式系统和计算机基础知识之外，还需要一些对模型原理的了解，对并行计算和主流推理框架熟悉和调优。训练大模型的公司要远少于使用大模型的公司，因此推理侧的 infra 岗位要多于后两者。训练侧infra 和推理侧其实差不多，但要求强一致性（也即可复现性）。数据侧 infra 主要是围绕构建数据爬取和清洗的各个环节，沉淀一些工具库。</p>
<h1 id="数据工程"><a href="#数据工程" class="headerlink" title="数据工程"></a>数据工程</h1><p>我主要在大模型做数据工程，所以稍微展开讲讲。数据库工程另一个说法就是围绕模型训练需求、构造数据清洗流水线，再直白点就是洗数据。</p>
<p>大模型预训练数据的来源主要有爬、买、造，前两者得来的数据基本都要做清洗才能使用。宏观来看，清洗主要提取结构化信息、提取语义信息、根据需求进行过滤、转换成目标格式。此过程中，还有经常需要用到的操作：大规模去重。去重根据精细度，可以基于值进行精确去重、基于语义信息进行模糊去重。</p>
<p>围绕这些的基建，也可以从计算和存储两块来分。计算一般都用 spark 和 ray ，存储主要是文件存储和对象存储，然后在之上抽象出一些适合训练和清洗的数据集。<a href="https://www.qtmuniao.com/">我的博客</a>和公众号有分享更多细节。</p>
<h1 id="模型使用"><a href="#模型使用" class="headerlink" title="模型使用"></a>模型使用</h1><p>使用模型最简单的方式就是 Prompt，稍微复杂一点可以做 RAG 或者 Agent，这些都不会动模型参数。如果对某领域的任务精度有更高的要求，可能需要大量（ 10k 以上）高质量的数据，基于开源模型做微调或者 RL，会真正的动模型权重。因此<strong>是否动模型参数</strong>可以看做是一个使用门槛的简单分水岭，当然这是在使用深度上。</p>
<p>如果看过 GPT 系列论文，可以大概知道，大模型的初衷就是为了通用，尽可能地降低为了适配不同下游任务的微调。虽然大模型也有一定的泛化能力，但是在没有见过的特殊数据的理解能力还是有限，因此在很多高精度需求的专用领域（比如分子生物学、交易序列等等）仍然需要专用的数据来调整大模型的能力。</p>
<p>这种需要微调的对应的需求<strong>深度</strong>，不过目前大部分需要落地的任务更多的是需要<strong>广度</strong>，也即复杂度。最简单的可以使用 RAG 来根据需求，将合适的数据作为背景 Prompt 给大模型；稍微复杂一点，可以基于固定规则进行工作流编排（比如使用代码或者 <span class="exturl" data-url="aHR0cHM6Ly9uOG4uaW8v">n8n<i class="fa fa-external-link-alt"></i></span> 等工具），将大模型作为其中某一环的组件来使用；再复杂一点，就是让大模型在解决问题时进行自主的路径选择和工具调用，也就是现在大家常说的 Agent 系统。</p>
<p>构建 Agent 系统，首先需要一个有强大决策能力和会使用工具的基础模型，然后用户再用某种方式，动态的将最少而全的上下文在合适的时机给到模型。<span class="exturl" data-url="aHR0cHM6Ly9tYW51cy5pbS8=">manus<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly93d3cuYW50aHJvcGljLmNvbS8=">anthropic<i class="fa fa-external-link-alt"></i></span> 在这些方面有不少的探索，也发了很多博文，附在了下面。</p>
<h1 id="Vibe-Coding"><a href="#Vibe-Coding" class="headerlink" title="Vibe Coding"></a>Vibe Coding</h1><p>Vibe Coding 是大模型在工业界最先大规模落地的 Agent 方向。建议所有没有试过的程序员都去试试最前沿的 Code Agent 来编程。只有试过，才知道现在模型能力能干什么，不能干什么。我们不迷信、不害怕，但也绝对不可小觑现在编程类 Agent 的迭代速度。快速变革的时代，听听“一线的炮火”得到的体感是最重要的。</p>
<p>比如我两三个月前用着还很不顺手，无论是指令跟随和用户交互方面都觉得差强人意，然而最近（202601）已经用起来相当丝滑了。基本上，只要我能将上下文以合理的方式给出、将意图以精确的方式描述，Claude Code 在大部分场景就已经可以工作的非常好了，甚至我会从他那里学到很多新的代码写法和组织方式。</p>
<p>如何用控制大模型输出代码质量，我提供一个简单的切入点：<strong>代码以后是否需要人来维护</strong>。如果用大模型写的代码还需要人看，就要还是要用传统软件工程（抽象封装，降低复杂度）的标准来要求它，可以让他多精简几轮代码——人的带宽毕竟是有限的。但若并不想让人维护或者只是临时性甚至一次性代码，那大可不必太过当白盒。只要功能满足，通过黑盒测试就可以用。大不了下次有类似需求，不用旧代码，让模型重写就行。</p>
<p>最近和出去创业的朋友聊、听了很多的关于 Vibe Coding 的播客，也有个感受：<strong>Code Agent 的大规模落地带来了太多全新的可能性</strong>。比如：代码的生命周期重新考量、基于自然语言的工作流编排。</p>
<p>关于代码的生命周期，一个核心的观察就是，既然我们以后能以 10x 效率生成代码，那同时也可以以十倍的速度扔掉代码。即，代码不再是一件手工品，而可以是一个工业品，甚至一次性用品，这会极大改变我们对代码的认知。比如我们做一个活动，可以让策划人员通过 Code Agent 直接生成一次性宣发网页。相比传统的 PS 生成的静态海报，基于代码的网页有更多的定制性、动态性和交互性。即使用一次就扔也没什么。这种成本数量级的降低会改变我们各种使用“广义上的软件”的方式。</p>
<p>关于自然语言的工作编排，了解数据库应该都知道，数据库本质是让用户以 SQL 的方式组合基本算子来编排数据流。抽象一步，就是让用户以某种 DSL （<a href="https://martinfowler.com/books/dsl.html"><strong>Domain Specific Languages</strong></a>，即领域专用的精确描述性语言）的方式来编排工作流，而 Code Agent 可以将其再往前推一步——使用自然语言（高维性、模糊性）编排常用工作流。大致就是让运营同学可以绕开数仓同学，直接做实验获得洞察。而，anthropic 最近提出了类似 MCP 和 Skills 的概念，正是这一理念落地的先驱。MCP 定义<strong>外部工具</strong>，Skill 提供基于这些工具的<strong>组合技</strong>。每个 Skill 会以摘要的形式将自己的元信息注册给大模型，大模型在执行任务时会根据这些摘要来做动态规划和原则。于是，在每个具体场景进行落地，需要做的就是构建、遴选自己的 Skill 集。</p>
<p>因此，Vibe Coding 是一个必然的趋势，因为它真切的降低了门槛，提高了生产力。无论我们这些写代码的手艺师傅喜不喜欢，被工业化替代大部分工作都是一个必然的趋势，作为最早看到这种趋势的我们，何不主动拥抱。</p>
<h1 id="多模态的趋势"><a href="#多模态的趋势" class="headerlink" title="多模态的趋势"></a>多模态的趋势</h1><p>大模型的多模态能力可以分为两块，一是理解，一是生成。理解能力要变强需要更多的高质量的图文数据，生成能力要变好需要更强的模型融合。</p>
<p><strong>多模态理解</strong>的主干网络还是基于 Transformer，只不过在输入端将图片 Token 以各种方式接入语言模型进行训练。因此，这个图像到文本序列的转接头（Vision Tower）很重要，如果参数量太小且进行不合理的冻结，就会很容易成为瓶颈。因此，在现有架构下，多模态理解的质量提升，首重数据，次重 VT。多模态理解落地场景很多，比如各种做题场景（K12、考公考研）、物体识别、网页复刻、图片复刻（SVG）、基于图片的逻辑物理推理等等。</p>
<p><strong>多模态生成</strong>主干模型是扩散模型，和 Transformer 完全不同的模型。但在生成效果方面更惊艳，所以在创意内容方面，扩散模型很适合。但其问题在于做<strong>语义和物理约束</strong>相对较难，体现在使用上，就是早期的图像生成工具往往难以支持多轮对话的精确修改，也常常会生成七八根手指的手这种不符合物理世界的东西。如何更好的进行生成，现在起码有两个发展方向，一个是更深度地和语言模型进行融合以对满足语义的理解、对指令的跟随的需求，谷歌的 <span class="exturl" data-url="aHR0cHM6Ly9nZW1pbmkuZ29vZ2xlLmNvbS9hcHA/aXNfc2E9MSZpc19zYT0xJmFuZHJvaWQtbWluLXZlcnNpb249MzAxMzU2MjMyJmlvcy1taW4tdmVyc2lvbj0zMjIuMCZjYW1wYWlnbl9pZD1ia3dzJnV0bV9zb3VyY2U9c2VtJnV0bV9tZWRpdW09cGFpZC1tZWRpYSZ1dG1fY2FtcGFpZ249Ymt3cyZwdD05MDA4Jm10PTgmY3Q9cC1ncm93dGgtc2VtLWJrd3MmZ2Nsc3JjPWF3LmRzJmdhZF9zb3VyY2U9MSZnYWRfY2FtcGFpZ25pZD0yMDQzNzMzMDY4MCZnYnJhaWQ9MEFBQUFBcGs1QmhuQVhrWXpvcEJBbVZ6ZzV5RkFaTkI5UyZnY2xpZD1DajBLQ1FpQW05ZkxCaENRQVJJc0FKb05PY3R0TS11UmhxVkE0M1pUTHpHYVFidXMwSnhrTmVJZFFjcHZiUmJhSEw2b28xSmxETkVHbVNzYUFzcmxFQUx3X3djQg==">Gemini<i class="fa fa-external-link-alt"></i></span> 系列在这方面做的很好。另一个就是完全的改弦更张，也即最近各路做前沿研究的学者常常提到的“世界模型”。即构造新的范式，让大模型可以真正的理解和探索这个世界的物理规律和边界。而非像现在这样，大模型基本上是一个诞生于<strong>人类“语言空间”的幽灵</strong>。</p>
<h1 id="数字游民-amp-校招生"><a href="#数字游民-amp-校招生" class="headerlink" title="数字游民 &amp; 校招生"></a>数字游民 &amp; 校招生</h1><p>大模型和各种下游生产力工具的成熟，在互联网这种“水电”的基础上，又给个人增加了“智力”外包这种超级杠杆。因此 OPC（one-person-company）这个概念最近很火，甚至很多城市（比如苏州）直接推出了针对这种概念的补贴。因此，如果你有好的想法和创意，不妨大胆去吃螃蟹。</p>
<p>至于在校生，在找工作之余，也可以大胆探索下现在这种大模型落地可能性。当然，能更为熟练地使用大模型并熟悉相关生态，本身就很会受用人方的青睐。造大模型的机会会越来越少，且会越来越富集到少数几家公司，大家也不用太往这方面卷，但是如何用好大模型却可能是一个会遍地开花的机会。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>这里罗列一些我看过觉得还不错的材料：</p>
<ol>
<li>数学基础：MIT 有门经典的线性代数课 <span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMXJINHkxTjdCVyVFMyU4MCU4Mg==">https://www.bilibili.com/video/BV1rH4y1N7BW。<i class="fa fa-external-link-alt"></i></span></li>
<li>论文脉络：普林斯顿的一门公开课，<span class="exturl" data-url="aHR0cHM6Ly9wcmluY2V0b24tY29zNTk3ci5naXRodWIuaW8vJUVGJUJDJThDJUU2JTg4JTkxJUU1JTlDJUE4JUU0JUI4JTkzJUU2JUEwJThGJUU5JTg3JThDJUVGJUJDJTg4aHR0cHM6Ly94aWFvYm90Lm5ldC9wL3N5c3RlbS10aGlua2luZyVFRiVCQyU4OSVFNCVCOSU5RiVFNSU5QyVBOCVFNiU5QiVCNCVFNiU5NiVCMCVFOCVBNyVBMyVFOCVBRiVCQiVFRiVCQyU4QyVFNiVBQyVBMiVFOCVCRiU4RSVFOCVBRSVBMiVFOSU5OCU4NSVFMyU4MCU4Mg==">https://princeton-cos597r.github.io/，我在专栏里（https://xiaobot.net/p/system-thinking）也在更新解读，欢迎订阅。<i class="fa fa-external-link-alt"></i></span></li>
<li>端到端、从零到一：Andrej Karpathy 的系列视频，还有源码 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2thcnBhdGh5L25hbm9HUFQ=">https://github.com/karpathy/nanoGPT<i class="fa fa-external-link-alt"></i></span></li>
<li>LLM 大全式文档：<span class="exturl" data-url="aHR0cHM6Ly9zM3RseHNrYnEzLmZlaXNodS5jbi9kb2N4L055UHFkQ0tyYW9YejlneE5WQ2ZjSUZkbm5BYw==">https://s3tlxskbq3.feishu.cn/docx/NyPqdCKraoXz9gxNVCfcIFdnnAc<i class="fa fa-external-link-alt"></i></span></li>
<li>ml system：陈天奇的公开课 <span class="exturl" data-url="aHR0cHM6Ly9tbHN5cy5vcmcv">https://mlsys.org/<i class="fa fa-external-link-alt"></i></span></li>
<li>manus 上下文工程：<span class="exturl" data-url="aHR0cHM6Ly9tYW51cy5pbS9ibG9nL0NvbnRleHQtRW5naW5lZXJpbmctZm9yLUFJLUFnZW50cy1MZXNzb25zLWZyb20tQnVpbGRpbmctTWFudXM=">https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus<i class="fa fa-external-link-alt"></i></span></li>
<li>anthropic agent 相关博客：<span class="exturl" data-url="aHR0cHM6Ly93d3cuYW50aHJvcGljLmNvbS9lbmdpbmVlcmluZw==">https://www.anthropic.com/engineering<i class="fa fa-external-link-alt"></i></span></li>
<li>skills 理解：<span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvQmw0T0RVeHZ3TzhwWXU5blhWbWp1UQ==">https://mp.weixin.qq.com/s/Bl4ODUxvwO8pYu9nXVmjuQ<i class="fa fa-external-link-alt"></i></span></li>
<li>很棒的翻译播客，《跨国串门计划》，有很多关于大模型大佬分享的一手内容：<span class="exturl" data-url="aHR0cHM6Ly93d3cueGlhb3l1emhvdWZtLmNvbS9wb2RjYXN0LzY3MGYzZGE0MGQyZjI0ZjI4OTc4NzM2Zg==">https://www.xiaoyuzhoufm.com/podcast/670f3da40d2f24f28978736f<i class="fa fa-external-link-alt"></i></span></li>
</ol>
]]></content>
      <categories>
        <category>大模型</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>LLM</tag>
        <tag>直播</tag>
      </tags>
  </entry>
</search>
